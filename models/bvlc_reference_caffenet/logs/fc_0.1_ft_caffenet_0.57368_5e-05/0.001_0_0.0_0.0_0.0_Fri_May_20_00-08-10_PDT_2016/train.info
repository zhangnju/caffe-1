I0520 00:08:10.634433 15139 caffe.cpp:186] Using GPUs 5
I0520 00:08:10.720423 15139 caffe.cpp:191] GPU 5: GeForce GTX TITAN X
I0520 00:08:12.464545 15139 solver.cpp:50] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.001
display: 200
max_iter: 160000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0
snapshot: 6000
snapshot_prefix: "models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train"
solver_mode: GPU
device_id: 5
net: "models/bvlc_reference_caffenet/train_val_ft.prototxt"
regularization_type: "L2"
stepvalue: 60000
stepvalue: 120000
stepvalue: 150000
breadth_decay: 0
kernel_shape_decay: 0
block_group_decay: 0
I0520 00:08:12.464896 15139 solver.cpp:94] Creating training net from net file: models/bvlc_reference_caffenet/train_val_ft.prototxt
I0520 00:08:12.465831 15139 net.cpp:315] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0520 00:08:12.465869 15139 net.cpp:315] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0520 00:08:12.465889 15139 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "examples/imagenet/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  connectivity_mode: DISCONNECTED_ELTWISE
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  connectivity_mode: DISCONNECTED_ELTWISE
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  connectivity_mode: DISCONNECTED_ELTWISE
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  connectivity_mode: DISCONNECTED_ELTWISE
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  connectivity_mode: DISCONNECTED_ELTWISE
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0520 00:08:12.466290 15139 layer_factory.hpp:77] Creating layer data
I0520 00:08:12.467170 15139 net.cpp:93] Creating Layer data
I0520 00:08:12.467232 15139 net.cpp:401] data -> data
I0520 00:08:12.467284 15139 net.cpp:401] data -> label
I0520 00:08:12.467303 15139 data_transformer.cpp:25] Loading mean file from: data/ilsvrc12/imagenet_mean.binaryproto
I0520 00:08:12.469370 15144 db_lmdb.cpp:38] Opened lmdb examples/imagenet/ilsvrc12_train_lmdb
I0520 00:08:13.144682 15139 data_layer.cpp:41] output data size: 256,3,227,227
I0520 00:08:13.704366 15139 net.cpp:143] Setting up data
I0520 00:08:13.704437 15139 net.cpp:150] Top shape: 256 3 227 227 (39574272)
I0520 00:08:13.704459 15139 net.cpp:150] Top shape: 256 (256)
I0520 00:08:13.704468 15139 net.cpp:158] Memory required for data: 158298112
I0520 00:08:13.704516 15139 layer_factory.hpp:77] Creating layer conv1
I0520 00:08:13.704586 15139 net.cpp:93] Creating Layer conv1
I0520 00:08:13.704596 15139 net.cpp:427] conv1 <- data
I0520 00:08:13.704630 15139 net.cpp:401] conv1 -> conv1
I0520 00:08:16.316476 15139 net.cpp:143] Setting up conv1
I0520 00:08:16.316535 15139 net.cpp:150] Top shape: 256 96 55 55 (74342400)
I0520 00:08:16.316552 15139 net.cpp:158] Memory required for data: 455667712
I0520 00:08:16.316607 15139 layer_factory.hpp:77] Creating layer relu1
I0520 00:08:16.316633 15139 net.cpp:93] Creating Layer relu1
I0520 00:08:16.316642 15139 net.cpp:427] relu1 <- conv1
I0520 00:08:16.316656 15139 net.cpp:388] relu1 -> conv1 (in-place)
I0520 00:08:16.317277 15139 net.cpp:143] Setting up relu1
I0520 00:08:16.317294 15139 net.cpp:150] Top shape: 256 96 55 55 (74342400)
I0520 00:08:16.317306 15139 net.cpp:158] Memory required for data: 753037312
I0520 00:08:16.317313 15139 layer_factory.hpp:77] Creating layer pool1
I0520 00:08:16.317327 15139 net.cpp:93] Creating Layer pool1
I0520 00:08:16.317332 15139 net.cpp:427] pool1 <- conv1
I0520 00:08:16.317358 15139 net.cpp:401] pool1 -> pool1
I0520 00:08:16.449506 15139 net.cpp:143] Setting up pool1
I0520 00:08:16.449569 15139 net.cpp:150] Top shape: 256 96 27 27 (17915904)
I0520 00:08:16.449587 15139 net.cpp:158] Memory required for data: 824700928
I0520 00:08:16.449599 15139 layer_factory.hpp:77] Creating layer norm1
I0520 00:08:16.449633 15139 net.cpp:93] Creating Layer norm1
I0520 00:08:16.449643 15139 net.cpp:427] norm1 <- pool1
I0520 00:08:16.449661 15139 net.cpp:401] norm1 -> norm1
I0520 00:08:16.579560 15139 net.cpp:143] Setting up norm1
I0520 00:08:16.579612 15139 net.cpp:150] Top shape: 256 96 27 27 (17915904)
I0520 00:08:16.579629 15139 net.cpp:158] Memory required for data: 896364544
I0520 00:08:16.579641 15139 layer_factory.hpp:77] Creating layer conv2
I0520 00:08:16.579681 15139 net.cpp:93] Creating Layer conv2
I0520 00:08:16.579690 15139 net.cpp:427] conv2 <- norm1
I0520 00:08:16.579707 15139 net.cpp:401] conv2 -> conv2
I0520 00:08:18.199852 15139 net.cpp:143] Setting up conv2
I0520 00:08:18.199892 15139 net.cpp:150] Top shape: 256 256 27 27 (47775744)
I0520 00:08:18.199903 15139 net.cpp:158] Memory required for data: 1087467520
I0520 00:08:18.199935 15139 layer_factory.hpp:77] Creating layer relu2
I0520 00:08:18.199952 15139 net.cpp:93] Creating Layer relu2
I0520 00:08:18.199959 15139 net.cpp:427] relu2 <- conv2
I0520 00:08:18.199970 15139 net.cpp:388] relu2 -> conv2 (in-place)
I0520 00:08:18.200273 15139 net.cpp:143] Setting up relu2
I0520 00:08:18.200284 15139 net.cpp:150] Top shape: 256 256 27 27 (47775744)
I0520 00:08:18.200291 15139 net.cpp:158] Memory required for data: 1278570496
I0520 00:08:18.200297 15139 layer_factory.hpp:77] Creating layer pool2
I0520 00:08:18.200307 15139 net.cpp:93] Creating Layer pool2
I0520 00:08:18.200311 15139 net.cpp:427] pool2 <- conv2
I0520 00:08:18.200317 15139 net.cpp:401] pool2 -> pool2
I0520 00:08:18.271373 15139 net.cpp:143] Setting up pool2
I0520 00:08:18.271414 15139 net.cpp:150] Top shape: 256 256 13 13 (11075584)
I0520 00:08:18.271425 15139 net.cpp:158] Memory required for data: 1322872832
I0520 00:08:18.271435 15139 layer_factory.hpp:77] Creating layer norm2
I0520 00:08:18.271457 15139 net.cpp:93] Creating Layer norm2
I0520 00:08:18.271464 15139 net.cpp:427] norm2 <- pool2
I0520 00:08:18.271474 15139 net.cpp:401] norm2 -> norm2
I0520 00:08:18.345700 15139 net.cpp:143] Setting up norm2
I0520 00:08:18.345758 15139 net.cpp:150] Top shape: 256 256 13 13 (11075584)
I0520 00:08:18.345777 15139 net.cpp:158] Memory required for data: 1367175168
I0520 00:08:18.345788 15139 layer_factory.hpp:77] Creating layer conv3
I0520 00:08:18.345826 15139 net.cpp:93] Creating Layer conv3
I0520 00:08:18.345836 15139 net.cpp:427] conv3 <- norm2
I0520 00:08:18.345855 15139 net.cpp:401] conv3 -> conv3
I0520 00:08:18.778595 15139 net.cpp:143] Setting up conv3
I0520 00:08:18.778650 15139 net.cpp:150] Top shape: 256 384 13 13 (16613376)
I0520 00:08:18.778667 15139 net.cpp:158] Memory required for data: 1433628672
I0520 00:08:18.778702 15139 layer_factory.hpp:77] Creating layer relu3
I0520 00:08:18.778720 15139 net.cpp:93] Creating Layer relu3
I0520 00:08:18.778729 15139 net.cpp:427] relu3 <- conv3
I0520 00:08:18.778743 15139 net.cpp:388] relu3 -> conv3 (in-place)
I0520 00:08:18.779093 15139 net.cpp:143] Setting up relu3
I0520 00:08:18.779106 15139 net.cpp:150] Top shape: 256 384 13 13 (16613376)
I0520 00:08:18.779117 15139 net.cpp:158] Memory required for data: 1500082176
I0520 00:08:18.779125 15139 layer_factory.hpp:77] Creating layer conv4
I0520 00:08:18.779153 15139 net.cpp:93] Creating Layer conv4
I0520 00:08:18.779161 15139 net.cpp:427] conv4 <- conv3
I0520 00:08:18.779172 15139 net.cpp:401] conv4 -> conv4
I0520 00:08:19.322629 15139 net.cpp:143] Setting up conv4
I0520 00:08:19.322675 15139 net.cpp:150] Top shape: 256 384 13 13 (16613376)
I0520 00:08:19.322690 15139 net.cpp:158] Memory required for data: 1566535680
I0520 00:08:19.322710 15139 layer_factory.hpp:77] Creating layer relu4
I0520 00:08:19.322732 15139 net.cpp:93] Creating Layer relu4
I0520 00:08:19.322738 15139 net.cpp:427] relu4 <- conv4
I0520 00:08:19.322757 15139 net.cpp:388] relu4 -> conv4 (in-place)
I0520 00:08:19.323038 15139 net.cpp:143] Setting up relu4
I0520 00:08:19.323048 15139 net.cpp:150] Top shape: 256 384 13 13 (16613376)
I0520 00:08:19.323055 15139 net.cpp:158] Memory required for data: 1632989184
I0520 00:08:19.323060 15139 layer_factory.hpp:77] Creating layer conv5
I0520 00:08:19.323079 15139 net.cpp:93] Creating Layer conv5
I0520 00:08:19.323084 15139 net.cpp:427] conv5 <- conv4
I0520 00:08:19.323092 15139 net.cpp:401] conv5 -> conv5
I0520 00:08:19.847676 15139 net.cpp:143] Setting up conv5
I0520 00:08:19.847715 15139 net.cpp:150] Top shape: 256 256 13 13 (11075584)
I0520 00:08:19.847730 15139 net.cpp:158] Memory required for data: 1677291520
I0520 00:08:19.847754 15139 layer_factory.hpp:77] Creating layer relu5
I0520 00:08:19.847771 15139 net.cpp:93] Creating Layer relu5
I0520 00:08:19.847777 15139 net.cpp:427] relu5 <- conv5
I0520 00:08:19.847787 15139 net.cpp:388] relu5 -> conv5 (in-place)
I0520 00:08:19.848062 15139 net.cpp:143] Setting up relu5
I0520 00:08:19.848072 15139 net.cpp:150] Top shape: 256 256 13 13 (11075584)
I0520 00:08:19.848080 15139 net.cpp:158] Memory required for data: 1721593856
I0520 00:08:19.848085 15139 layer_factory.hpp:77] Creating layer pool5
I0520 00:08:19.848095 15139 net.cpp:93] Creating Layer pool5
I0520 00:08:19.848100 15139 net.cpp:427] pool5 <- conv5
I0520 00:08:19.848109 15139 net.cpp:401] pool5 -> pool5
I0520 00:08:19.860148 15139 net.cpp:143] Setting up pool5
I0520 00:08:19.860183 15139 net.cpp:150] Top shape: 256 256 6 6 (2359296)
I0520 00:08:19.860194 15139 net.cpp:158] Memory required for data: 1731031040
I0520 00:08:19.860204 15139 layer_factory.hpp:77] Creating layer fc6
I0520 00:08:19.860229 15139 net.cpp:93] Creating Layer fc6
I0520 00:08:19.860235 15139 net.cpp:427] fc6 <- pool5
I0520 00:08:19.860245 15139 net.cpp:401] fc6 -> fc6
I0520 00:08:20.546895 15139 net.cpp:143] Setting up fc6
I0520 00:08:20.546936 15139 net.cpp:150] Top shape: 256 4096 (1048576)
I0520 00:08:20.546948 15139 net.cpp:158] Memory required for data: 1735225344
I0520 00:08:20.546967 15139 layer_factory.hpp:77] Creating layer relu6
I0520 00:08:20.546982 15139 net.cpp:93] Creating Layer relu6
I0520 00:08:20.546988 15139 net.cpp:427] relu6 <- fc6
I0520 00:08:20.546996 15139 net.cpp:388] relu6 -> fc6 (in-place)
I0520 00:08:20.547500 15139 net.cpp:143] Setting up relu6
I0520 00:08:20.547513 15139 net.cpp:150] Top shape: 256 4096 (1048576)
I0520 00:08:20.547523 15139 net.cpp:158] Memory required for data: 1739419648
I0520 00:08:20.547528 15139 layer_factory.hpp:77] Creating layer drop6
I0520 00:08:20.547540 15139 net.cpp:93] Creating Layer drop6
I0520 00:08:20.547544 15139 net.cpp:427] drop6 <- fc6
I0520 00:08:20.547550 15139 net.cpp:388] drop6 -> fc6 (in-place)
I0520 00:08:20.550324 15139 net.cpp:143] Setting up drop6
I0520 00:08:20.550339 15139 net.cpp:150] Top shape: 256 4096 (1048576)
I0520 00:08:20.550348 15139 net.cpp:158] Memory required for data: 1743613952
I0520 00:08:20.550354 15139 layer_factory.hpp:77] Creating layer fc7
I0520 00:08:20.550369 15139 net.cpp:93] Creating Layer fc7
I0520 00:08:20.550374 15139 net.cpp:427] fc7 <- fc6
I0520 00:08:20.550380 15139 net.cpp:401] fc7 -> fc7
I0520 00:08:20.958202 15139 net.cpp:143] Setting up fc7
I0520 00:08:20.958266 15139 net.cpp:150] Top shape: 256 4096 (1048576)
I0520 00:08:20.958281 15139 net.cpp:158] Memory required for data: 1747808256
I0520 00:08:20.958314 15139 layer_factory.hpp:77] Creating layer relu7
I0520 00:08:20.958338 15139 net.cpp:93] Creating Layer relu7
I0520 00:08:20.958349 15139 net.cpp:427] relu7 <- fc7
I0520 00:08:20.958362 15139 net.cpp:388] relu7 -> fc7 (in-place)
I0520 00:08:20.958854 15139 net.cpp:143] Setting up relu7
I0520 00:08:20.958868 15139 net.cpp:150] Top shape: 256 4096 (1048576)
I0520 00:08:20.958878 15139 net.cpp:158] Memory required for data: 1752002560
I0520 00:08:20.958886 15139 layer_factory.hpp:77] Creating layer drop7
I0520 00:08:20.958905 15139 net.cpp:93] Creating Layer drop7
I0520 00:08:20.958912 15139 net.cpp:427] drop7 <- fc7
I0520 00:08:20.958936 15139 net.cpp:388] drop7 -> fc7 (in-place)
I0520 00:08:20.962664 15139 net.cpp:143] Setting up drop7
I0520 00:08:20.962720 15139 net.cpp:150] Top shape: 256 4096 (1048576)
I0520 00:08:20.962735 15139 net.cpp:158] Memory required for data: 1756196864
I0520 00:08:20.962748 15139 layer_factory.hpp:77] Creating layer fc8
I0520 00:08:20.962776 15139 net.cpp:93] Creating Layer fc8
I0520 00:08:20.962785 15139 net.cpp:427] fc8 <- fc7
I0520 00:08:20.962802 15139 net.cpp:401] fc8 -> fc8
I0520 00:08:21.073776 15139 net.cpp:143] Setting up fc8
I0520 00:08:21.073844 15139 net.cpp:150] Top shape: 256 1000 (256000)
I0520 00:08:21.073861 15139 net.cpp:158] Memory required for data: 1757220864
I0520 00:08:21.073886 15139 layer_factory.hpp:77] Creating layer loss
I0520 00:08:21.073905 15139 net.cpp:93] Creating Layer loss
I0520 00:08:21.073915 15139 net.cpp:427] loss <- fc8
I0520 00:08:21.073927 15139 net.cpp:427] loss <- label
I0520 00:08:21.073942 15139 net.cpp:401] loss -> loss
I0520 00:08:21.074009 15139 layer_factory.hpp:77] Creating layer loss
I0520 00:08:21.076993 15139 net.cpp:143] Setting up loss
I0520 00:08:21.077033 15139 net.cpp:150] Top shape: (1)
I0520 00:08:21.077045 15139 net.cpp:153]     with loss weight 1
I0520 00:08:21.077111 15139 net.cpp:158] Memory required for data: 1757220868
I0520 00:08:21.077122 15139 net.cpp:219] loss needs backward computation.
I0520 00:08:21.077132 15139 net.cpp:219] fc8 needs backward computation.
I0520 00:08:21.077141 15139 net.cpp:219] drop7 needs backward computation.
I0520 00:08:21.077147 15139 net.cpp:219] relu7 needs backward computation.
I0520 00:08:21.077153 15139 net.cpp:219] fc7 needs backward computation.
I0520 00:08:21.077160 15139 net.cpp:219] drop6 needs backward computation.
I0520 00:08:21.077167 15139 net.cpp:219] relu6 needs backward computation.
I0520 00:08:21.077174 15139 net.cpp:219] fc6 needs backward computation.
I0520 00:08:21.077183 15139 net.cpp:219] pool5 needs backward computation.
I0520 00:08:21.077190 15139 net.cpp:219] relu5 needs backward computation.
I0520 00:08:21.077198 15139 net.cpp:219] conv5 needs backward computation.
I0520 00:08:21.077204 15139 net.cpp:219] relu4 needs backward computation.
I0520 00:08:21.077211 15139 net.cpp:219] conv4 needs backward computation.
I0520 00:08:21.077217 15139 net.cpp:219] relu3 needs backward computation.
I0520 00:08:21.077226 15139 net.cpp:219] conv3 needs backward computation.
I0520 00:08:21.077234 15139 net.cpp:219] norm2 needs backward computation.
I0520 00:08:21.077240 15139 net.cpp:219] pool2 needs backward computation.
I0520 00:08:21.077247 15139 net.cpp:219] relu2 needs backward computation.
I0520 00:08:21.077255 15139 net.cpp:219] conv2 needs backward computation.
I0520 00:08:21.077261 15139 net.cpp:219] norm1 needs backward computation.
I0520 00:08:21.077268 15139 net.cpp:219] pool1 needs backward computation.
I0520 00:08:21.077275 15139 net.cpp:219] relu1 needs backward computation.
I0520 00:08:21.077283 15139 net.cpp:219] conv1 needs backward computation.
I0520 00:08:21.077291 15139 net.cpp:221] data does not need backward computation.
I0520 00:08:21.077297 15139 net.cpp:263] This network produces output loss
I0520 00:08:21.077322 15139 net.cpp:276] Network initialization done.
I0520 00:08:21.078408 15139 solver.cpp:184] Creating test net (#0) specified by net file: models/bvlc_reference_caffenet/train_val_ft.prototxt
I0520 00:08:21.078491 15139 net.cpp:315] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0520 00:08:21.078531 15139 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "examples/imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  connectivity_mode: DISCONNECTED_ELTWISE
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  connectivity_mode: DISCONNECTED_ELTWISE
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  connectivity_mode: DISCONNECTED_ELTWISE
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  connectivity_mode: DISCONNECTED_ELTWISE
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  connectivity_mode: DISCONNECTED_ELTWISE
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0520 00:08:21.079026 15139 layer_factory.hpp:77] Creating layer data
I0520 00:08:21.079190 15139 net.cpp:93] Creating Layer data
I0520 00:08:21.079207 15139 net.cpp:401] data -> data
I0520 00:08:21.079224 15139 net.cpp:401] data -> label
I0520 00:08:21.079241 15139 data_transformer.cpp:25] Loading mean file from: data/ilsvrc12/imagenet_mean.binaryproto
I0520 00:08:21.081508 15146 db_lmdb.cpp:38] Opened lmdb examples/imagenet/ilsvrc12_val_lmdb
I0520 00:08:21.206688 15139 data_layer.cpp:41] output data size: 50,3,227,227
I0520 00:08:21.314823 15139 net.cpp:143] Setting up data
I0520 00:08:21.314891 15139 net.cpp:150] Top shape: 50 3 227 227 (7729350)
I0520 00:08:21.315027 15139 net.cpp:150] Top shape: 50 (50)
I0520 00:08:21.315052 15139 net.cpp:158] Memory required for data: 30917600
I0520 00:08:21.315068 15139 layer_factory.hpp:77] Creating layer label_data_1_split
I0520 00:08:21.315091 15139 net.cpp:93] Creating Layer label_data_1_split
I0520 00:08:21.315101 15139 net.cpp:427] label_data_1_split <- label
I0520 00:08:21.315119 15139 net.cpp:401] label_data_1_split -> label_data_1_split_0
I0520 00:08:21.315140 15139 net.cpp:401] label_data_1_split -> label_data_1_split_1
I0520 00:08:21.315331 15139 net.cpp:143] Setting up label_data_1_split
I0520 00:08:21.315342 15139 net.cpp:150] Top shape: 50 (50)
I0520 00:08:21.315351 15139 net.cpp:150] Top shape: 50 (50)
I0520 00:08:21.315359 15139 net.cpp:158] Memory required for data: 30918000
I0520 00:08:21.315366 15139 layer_factory.hpp:77] Creating layer conv1
I0520 00:08:21.315392 15139 net.cpp:93] Creating Layer conv1
I0520 00:08:21.315398 15139 net.cpp:427] conv1 <- data
I0520 00:08:21.315409 15139 net.cpp:401] conv1 -> conv1
I0520 00:08:21.604104 15139 net.cpp:143] Setting up conv1
I0520 00:08:21.604174 15139 net.cpp:150] Top shape: 50 96 55 55 (14520000)
I0520 00:08:21.604192 15139 net.cpp:158] Memory required for data: 88998000
I0520 00:08:21.604226 15139 layer_factory.hpp:77] Creating layer relu1
I0520 00:08:21.604249 15139 net.cpp:93] Creating Layer relu1
I0520 00:08:21.604259 15139 net.cpp:427] relu1 <- conv1
I0520 00:08:21.604272 15139 net.cpp:388] relu1 -> conv1 (in-place)
I0520 00:08:21.604674 15139 net.cpp:143] Setting up relu1
I0520 00:08:21.604691 15139 net.cpp:150] Top shape: 50 96 55 55 (14520000)
I0520 00:08:21.604702 15139 net.cpp:158] Memory required for data: 147078000
I0520 00:08:21.604710 15139 layer_factory.hpp:77] Creating layer pool1
I0520 00:08:21.604727 15139 net.cpp:93] Creating Layer pool1
I0520 00:08:21.604735 15139 net.cpp:427] pool1 <- conv1
I0520 00:08:21.604748 15139 net.cpp:401] pool1 -> pool1
I0520 00:08:21.632920 15139 net.cpp:143] Setting up pool1
I0520 00:08:21.632980 15139 net.cpp:150] Top shape: 50 96 27 27 (3499200)
I0520 00:08:21.632997 15139 net.cpp:158] Memory required for data: 161074800
I0520 00:08:21.633009 15139 layer_factory.hpp:77] Creating layer norm1
I0520 00:08:21.633036 15139 net.cpp:93] Creating Layer norm1
I0520 00:08:21.633047 15139 net.cpp:427] norm1 <- pool1
I0520 00:08:21.633064 15139 net.cpp:401] norm1 -> norm1
I0520 00:08:21.662091 15139 net.cpp:143] Setting up norm1
I0520 00:08:21.662153 15139 net.cpp:150] Top shape: 50 96 27 27 (3499200)
I0520 00:08:21.662170 15139 net.cpp:158] Memory required for data: 175071600
I0520 00:08:21.662184 15139 layer_factory.hpp:77] Creating layer conv2
I0520 00:08:21.662217 15139 net.cpp:93] Creating Layer conv2
I0520 00:08:21.662257 15139 net.cpp:427] conv2 <- norm1
I0520 00:08:21.662307 15139 net.cpp:401] conv2 -> conv2
I0520 00:08:22.061264 15139 net.cpp:143] Setting up conv2
I0520 00:08:22.061327 15139 net.cpp:150] Top shape: 50 256 27 27 (9331200)
I0520 00:08:22.061344 15139 net.cpp:158] Memory required for data: 212396400
I0520 00:08:22.061378 15139 layer_factory.hpp:77] Creating layer relu2
I0520 00:08:22.061398 15139 net.cpp:93] Creating Layer relu2
I0520 00:08:22.061406 15139 net.cpp:427] relu2 <- conv2
I0520 00:08:22.061419 15139 net.cpp:388] relu2 -> conv2 (in-place)
I0520 00:08:22.061801 15139 net.cpp:143] Setting up relu2
I0520 00:08:22.061817 15139 net.cpp:150] Top shape: 50 256 27 27 (9331200)
I0520 00:08:22.061827 15139 net.cpp:158] Memory required for data: 249721200
I0520 00:08:22.061836 15139 layer_factory.hpp:77] Creating layer pool2
I0520 00:08:22.061851 15139 net.cpp:93] Creating Layer pool2
I0520 00:08:22.061857 15139 net.cpp:427] pool2 <- conv2
I0520 00:08:22.061868 15139 net.cpp:401] pool2 -> pool2
I0520 00:08:22.077700 15139 net.cpp:143] Setting up pool2
I0520 00:08:22.077769 15139 net.cpp:150] Top shape: 50 256 13 13 (2163200)
I0520 00:08:22.077785 15139 net.cpp:158] Memory required for data: 258374000
I0520 00:08:22.077797 15139 layer_factory.hpp:77] Creating layer norm2
I0520 00:08:22.077822 15139 net.cpp:93] Creating Layer norm2
I0520 00:08:22.077831 15139 net.cpp:427] norm2 <- pool2
I0520 00:08:22.077847 15139 net.cpp:401] norm2 -> norm2
I0520 00:08:22.094183 15139 net.cpp:143] Setting up norm2
I0520 00:08:22.094249 15139 net.cpp:150] Top shape: 50 256 13 13 (2163200)
I0520 00:08:22.094269 15139 net.cpp:158] Memory required for data: 267026800
I0520 00:08:22.094281 15139 layer_factory.hpp:77] Creating layer conv3
I0520 00:08:22.094316 15139 net.cpp:93] Creating Layer conv3
I0520 00:08:22.094326 15139 net.cpp:427] conv3 <- norm2
I0520 00:08:22.094344 15139 net.cpp:401] conv3 -> conv3
I0520 00:08:22.221629 15139 net.cpp:143] Setting up conv3
I0520 00:08:22.221685 15139 net.cpp:150] Top shape: 50 384 13 13 (3244800)
I0520 00:08:22.221703 15139 net.cpp:158] Memory required for data: 280006000
I0520 00:08:22.221735 15139 layer_factory.hpp:77] Creating layer relu3
I0520 00:08:22.221755 15139 net.cpp:93] Creating Layer relu3
I0520 00:08:22.221763 15139 net.cpp:427] relu3 <- conv3
I0520 00:08:22.221776 15139 net.cpp:388] relu3 -> conv3 (in-place)
I0520 00:08:22.222498 15139 net.cpp:143] Setting up relu3
I0520 00:08:22.222519 15139 net.cpp:150] Top shape: 50 384 13 13 (3244800)
I0520 00:08:22.222530 15139 net.cpp:158] Memory required for data: 292985200
I0520 00:08:22.222539 15139 layer_factory.hpp:77] Creating layer conv4
I0520 00:08:22.222563 15139 net.cpp:93] Creating Layer conv4
I0520 00:08:22.222571 15139 net.cpp:427] conv4 <- conv3
I0520 00:08:22.222584 15139 net.cpp:401] conv4 -> conv4
I0520 00:08:22.368185 15139 net.cpp:143] Setting up conv4
I0520 00:08:22.368242 15139 net.cpp:150] Top shape: 50 384 13 13 (3244800)
I0520 00:08:22.368259 15139 net.cpp:158] Memory required for data: 305964400
I0520 00:08:22.368284 15139 layer_factory.hpp:77] Creating layer relu4
I0520 00:08:22.368304 15139 net.cpp:93] Creating Layer relu4
I0520 00:08:22.368314 15139 net.cpp:427] relu4 <- conv4
I0520 00:08:22.368327 15139 net.cpp:388] relu4 -> conv4 (in-place)
I0520 00:08:22.368706 15139 net.cpp:143] Setting up relu4
I0520 00:08:22.368719 15139 net.cpp:150] Top shape: 50 384 13 13 (3244800)
I0520 00:08:22.368729 15139 net.cpp:158] Memory required for data: 318943600
I0520 00:08:22.368736 15139 layer_factory.hpp:77] Creating layer conv5
I0520 00:08:22.368759 15139 net.cpp:93] Creating Layer conv5
I0520 00:08:22.368767 15139 net.cpp:427] conv5 <- conv4
I0520 00:08:22.368777 15139 net.cpp:401] conv5 -> conv5
I0520 00:08:22.511989 15139 net.cpp:143] Setting up conv5
I0520 00:08:22.512049 15139 net.cpp:150] Top shape: 50 256 13 13 (2163200)
I0520 00:08:22.512068 15139 net.cpp:158] Memory required for data: 327596400
I0520 00:08:22.512100 15139 layer_factory.hpp:77] Creating layer relu5
I0520 00:08:22.512121 15139 net.cpp:93] Creating Layer relu5
I0520 00:08:22.512146 15139 net.cpp:427] relu5 <- conv5
I0520 00:08:22.512179 15139 net.cpp:388] relu5 -> conv5 (in-place)
I0520 00:08:22.512548 15139 net.cpp:143] Setting up relu5
I0520 00:08:22.512560 15139 net.cpp:150] Top shape: 50 256 13 13 (2163200)
I0520 00:08:22.512570 15139 net.cpp:158] Memory required for data: 336249200
I0520 00:08:22.512578 15139 layer_factory.hpp:77] Creating layer pool5
I0520 00:08:22.512593 15139 net.cpp:93] Creating Layer pool5
I0520 00:08:22.512599 15139 net.cpp:427] pool5 <- conv5
I0520 00:08:22.512609 15139 net.cpp:401] pool5 -> pool5
I0520 00:08:22.516013 15139 net.cpp:143] Setting up pool5
I0520 00:08:22.516052 15139 net.cpp:150] Top shape: 50 256 6 6 (460800)
I0520 00:08:22.516064 15139 net.cpp:158] Memory required for data: 338092400
I0520 00:08:22.516073 15139 layer_factory.hpp:77] Creating layer fc6
I0520 00:08:22.516096 15139 net.cpp:93] Creating Layer fc6
I0520 00:08:22.516104 15139 net.cpp:427] fc6 <- pool5
I0520 00:08:22.516119 15139 net.cpp:401] fc6 -> fc6
I0520 00:08:23.502233 15139 net.cpp:143] Setting up fc6
I0520 00:08:23.502291 15139 net.cpp:150] Top shape: 50 4096 (204800)
I0520 00:08:23.502307 15139 net.cpp:158] Memory required for data: 338911600
I0520 00:08:23.502336 15139 layer_factory.hpp:77] Creating layer relu6
I0520 00:08:23.502358 15139 net.cpp:93] Creating Layer relu6
I0520 00:08:23.502368 15139 net.cpp:427] relu6 <- fc6
I0520 00:08:23.502382 15139 net.cpp:388] relu6 -> fc6 (in-place)
I0520 00:08:23.503176 15139 net.cpp:143] Setting up relu6
I0520 00:08:23.503195 15139 net.cpp:150] Top shape: 50 4096 (204800)
I0520 00:08:23.503206 15139 net.cpp:158] Memory required for data: 339730800
I0520 00:08:23.503213 15139 layer_factory.hpp:77] Creating layer drop6
I0520 00:08:23.503228 15139 net.cpp:93] Creating Layer drop6
I0520 00:08:23.503235 15139 net.cpp:427] drop6 <- fc6
I0520 00:08:23.503247 15139 net.cpp:388] drop6 -> fc6 (in-place)
I0520 00:08:23.504439 15139 net.cpp:143] Setting up drop6
I0520 00:08:23.504457 15139 net.cpp:150] Top shape: 50 4096 (204800)
I0520 00:08:23.504468 15139 net.cpp:158] Memory required for data: 340550000
I0520 00:08:23.504477 15139 layer_factory.hpp:77] Creating layer fc7
I0520 00:08:23.504498 15139 net.cpp:93] Creating Layer fc7
I0520 00:08:23.504505 15139 net.cpp:427] fc7 <- fc6
I0520 00:08:23.504518 15139 net.cpp:401] fc7 -> fc7
I0520 00:08:23.942383 15139 net.cpp:143] Setting up fc7
I0520 00:08:23.942435 15139 net.cpp:150] Top shape: 50 4096 (204800)
I0520 00:08:23.942451 15139 net.cpp:158] Memory required for data: 341369200
I0520 00:08:23.942474 15139 layer_factory.hpp:77] Creating layer relu7
I0520 00:08:23.942493 15139 net.cpp:93] Creating Layer relu7
I0520 00:08:23.942502 15139 net.cpp:427] relu7 <- fc7
I0520 00:08:23.942518 15139 net.cpp:388] relu7 -> fc7 (in-place)
I0520 00:08:23.942891 15139 net.cpp:143] Setting up relu7
I0520 00:08:23.942906 15139 net.cpp:150] Top shape: 50 4096 (204800)
I0520 00:08:23.942916 15139 net.cpp:158] Memory required for data: 342188400
I0520 00:08:23.942924 15139 layer_factory.hpp:77] Creating layer drop7
I0520 00:08:23.942936 15139 net.cpp:93] Creating Layer drop7
I0520 00:08:23.942944 15139 net.cpp:427] drop7 <- fc7
I0520 00:08:23.942952 15139 net.cpp:388] drop7 -> fc7 (in-place)
I0520 00:08:23.944144 15139 net.cpp:143] Setting up drop7
I0520 00:08:23.944162 15139 net.cpp:150] Top shape: 50 4096 (204800)
I0520 00:08:23.944175 15139 net.cpp:158] Memory required for data: 343007600
I0520 00:08:23.944185 15139 layer_factory.hpp:77] Creating layer fc8
I0520 00:08:23.944202 15139 net.cpp:93] Creating Layer fc8
I0520 00:08:23.944210 15139 net.cpp:427] fc8 <- fc7
I0520 00:08:23.944222 15139 net.cpp:401] fc8 -> fc8
I0520 00:08:24.050623 15139 net.cpp:143] Setting up fc8
I0520 00:08:24.050683 15139 net.cpp:150] Top shape: 50 1000 (50000)
I0520 00:08:24.050698 15139 net.cpp:158] Memory required for data: 343207600
I0520 00:08:24.050721 15139 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0520 00:08:24.050740 15139 net.cpp:93] Creating Layer fc8_fc8_0_split
I0520 00:08:24.050773 15139 net.cpp:427] fc8_fc8_0_split <- fc8
I0520 00:08:24.050807 15139 net.cpp:401] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0520 00:08:24.050822 15139 net.cpp:401] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0520 00:08:24.051080 15139 net.cpp:143] Setting up fc8_fc8_0_split
I0520 00:08:24.051091 15139 net.cpp:150] Top shape: 50 1000 (50000)
I0520 00:08:24.051103 15139 net.cpp:150] Top shape: 50 1000 (50000)
I0520 00:08:24.051111 15139 net.cpp:158] Memory required for data: 343607600
I0520 00:08:24.051118 15139 layer_factory.hpp:77] Creating layer accuracy
I0520 00:08:24.051133 15139 net.cpp:93] Creating Layer accuracy
I0520 00:08:24.051141 15139 net.cpp:427] accuracy <- fc8_fc8_0_split_0
I0520 00:08:24.051148 15139 net.cpp:427] accuracy <- label_data_1_split_0
I0520 00:08:24.051162 15139 net.cpp:401] accuracy -> accuracy
I0520 00:08:24.051219 15139 net.cpp:143] Setting up accuracy
I0520 00:08:24.051229 15139 net.cpp:150] Top shape: (1)
I0520 00:08:24.051236 15139 net.cpp:158] Memory required for data: 343607604
I0520 00:08:24.051244 15139 layer_factory.hpp:77] Creating layer loss
I0520 00:08:24.051257 15139 net.cpp:93] Creating Layer loss
I0520 00:08:24.051265 15139 net.cpp:427] loss <- fc8_fc8_0_split_1
I0520 00:08:24.051272 15139 net.cpp:427] loss <- label_data_1_split_1
I0520 00:08:24.051280 15139 net.cpp:401] loss -> loss
I0520 00:08:24.051295 15139 layer_factory.hpp:77] Creating layer loss
I0520 00:08:24.053655 15139 net.cpp:143] Setting up loss
I0520 00:08:24.053690 15139 net.cpp:150] Top shape: (1)
I0520 00:08:24.053704 15139 net.cpp:153]     with loss weight 1
I0520 00:08:24.053727 15139 net.cpp:158] Memory required for data: 343607608
I0520 00:08:24.053736 15139 net.cpp:219] loss needs backward computation.
I0520 00:08:24.053745 15139 net.cpp:221] accuracy does not need backward computation.
I0520 00:08:24.053752 15139 net.cpp:219] fc8_fc8_0_split needs backward computation.
I0520 00:08:24.053761 15139 net.cpp:219] fc8 needs backward computation.
I0520 00:08:24.053768 15139 net.cpp:219] drop7 needs backward computation.
I0520 00:08:24.053776 15139 net.cpp:219] relu7 needs backward computation.
I0520 00:08:24.053792 15139 net.cpp:219] fc7 needs backward computation.
I0520 00:08:24.053799 15139 net.cpp:219] drop6 needs backward computation.
I0520 00:08:24.053807 15139 net.cpp:219] relu6 needs backward computation.
I0520 00:08:24.053812 15139 net.cpp:219] fc6 needs backward computation.
I0520 00:08:24.053820 15139 net.cpp:219] pool5 needs backward computation.
I0520 00:08:24.053843 15139 net.cpp:219] relu5 needs backward computation.
I0520 00:08:24.053851 15139 net.cpp:219] conv5 needs backward computation.
I0520 00:08:24.053860 15139 net.cpp:219] relu4 needs backward computation.
I0520 00:08:24.053869 15139 net.cpp:219] conv4 needs backward computation.
I0520 00:08:24.053876 15139 net.cpp:219] relu3 needs backward computation.
I0520 00:08:24.053884 15139 net.cpp:219] conv3 needs backward computation.
I0520 00:08:24.053891 15139 net.cpp:219] norm2 needs backward computation.
I0520 00:08:24.053900 15139 net.cpp:219] pool2 needs backward computation.
I0520 00:08:24.053908 15139 net.cpp:219] relu2 needs backward computation.
I0520 00:08:24.053915 15139 net.cpp:219] conv2 needs backward computation.
I0520 00:08:24.053922 15139 net.cpp:219] norm1 needs backward computation.
I0520 00:08:24.053931 15139 net.cpp:219] pool1 needs backward computation.
I0520 00:08:24.053939 15139 net.cpp:219] relu1 needs backward computation.
I0520 00:08:24.053946 15139 net.cpp:219] conv1 needs backward computation.
I0520 00:08:24.053954 15139 net.cpp:221] label_data_1_split does not need backward computation.
I0520 00:08:24.053962 15139 net.cpp:221] data does not need backward computation.
I0520 00:08:24.053969 15139 net.cpp:263] This network produces output accuracy
I0520 00:08:24.053977 15139 net.cpp:263] This network produces output loss
I0520 00:08:24.054006 15139 net.cpp:276] Network initialization done.
I0520 00:08:24.054185 15139 solver.cpp:62] Solver scaffolding done.
I0520 00:08:24.727787 15139 caffe.cpp:130] Finetuning from models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_414000.caffemodel
I0520 00:08:41.492207 15139 base_conv_layer.cpp:16] layer	conv1	has sparsity of 0.144944
I0520 00:08:41.492925 15139 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0520 00:08:41.492936 15139 base_conv_layer.cpp:128] all zero weights of conv1 are frozen
I0520 00:08:41.495381 15139 base_conv_layer.cpp:16] layer	conv2	has sparsity of 0.824473
I0520 00:08:41.497767 15139 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0520 00:08:41.497779 15139 base_conv_layer.cpp:128] all zero weights of conv2 are frozen
I0520 00:08:41.503824 15139 base_conv_layer.cpp:16] layer	conv3	has sparsity of 0.911358
I0520 00:08:41.510609 15139 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0520 00:08:41.510625 15139 base_conv_layer.cpp:128] all zero weights of conv3 are frozen
I0520 00:08:41.515382 15139 base_conv_layer.cpp:16] layer	conv4	has sparsity of 0.891767
I0520 00:08:41.520506 15139 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0520 00:08:41.520520 15139 base_conv_layer.cpp:128] all zero weights of conv4 are frozen
I0520 00:08:41.524217 15139 base_conv_layer.cpp:16] layer	conv5	has sparsity of 0.852797
I0520 00:08:41.527721 15139 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0520 00:08:41.527734 15139 base_conv_layer.cpp:128] all zero weights of conv5 are frozen
I0520 00:08:41.599242 15139 inner_product_layer.cpp:11] layer	fc6	has sparsity of 0.856069
I0520 00:08:41.913689 15139 inner_product_layer.cpp:11] layer	fc7	has sparsity of 0.783495
I0520 00:08:42.047111 15139 inner_product_layer.cpp:11] layer	fc8	has sparsity of 0.303915
I0520 00:09:39.379331 15139 base_conv_layer.cpp:16] layer	conv1	has sparsity of 0.144944
I0520 00:09:39.381625 15139 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0520 00:09:39.381647 15139 base_conv_layer.cpp:128] all zero weights of conv1 are frozen
I0520 00:09:39.385326 15139 base_conv_layer.cpp:16] layer	conv2	has sparsity of 0.824473
I0520 00:09:39.388523 15139 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0520 00:09:39.388540 15139 base_conv_layer.cpp:128] all zero weights of conv2 are frozen
I0520 00:09:39.396420 15139 base_conv_layer.cpp:16] layer	conv3	has sparsity of 0.911358
I0520 00:09:39.405447 15139 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0520 00:09:39.405467 15139 base_conv_layer.cpp:128] all zero weights of conv3 are frozen
I0520 00:09:39.413383 15139 base_conv_layer.cpp:16] layer	conv4	has sparsity of 0.891767
I0520 00:09:39.420354 15139 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0520 00:09:39.420374 15139 base_conv_layer.cpp:128] all zero weights of conv4 are frozen
I0520 00:09:39.426522 15139 base_conv_layer.cpp:16] layer	conv5	has sparsity of 0.852797
I0520 00:09:39.431089 15139 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0520 00:09:39.431109 15139 base_conv_layer.cpp:128] all zero weights of conv5 are frozen
I0520 00:09:39.507227 15139 inner_product_layer.cpp:11] layer	fc6	has sparsity of 0.856069
I0520 00:09:39.924355 15139 inner_product_layer.cpp:11] layer	fc7	has sparsity of 0.783495
I0520 00:09:40.101873 15139 inner_product_layer.cpp:11] layer	fc8	has sparsity of 0.303915
I0520 00:09:40.205924 15139 caffe.cpp:220] Starting Optimization
I0520 00:09:40.205986 15139 solver.cpp:290] Solving CaffeNet
I0520 00:09:40.205999 15139 solver.cpp:291] Learning Rate Policy: multistep
I0520 00:09:40.208884 15139 solver.cpp:348] Iteration 0, Testing net (#0)
I0520 00:09:40.593039 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:11:01.802764 15139 solver.cpp:415]     Test net output #0: accuracy = 0.568019
I0520 00:11:01.803069 15139 solver.cpp:415]     Test net output #1: loss = 1.85349 (* 1 = 1.85349 loss)
I0520 00:11:01.935271 15139 solver.cpp:231] Iteration 0, loss = 1.09817
I0520 00:11:01.935353 15139 solver.cpp:247]     Train net output #0: loss = 1.09817 (* 1 = 1.09817 loss)
I0520 00:11:01.935396 15139 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0520 00:11:02.100667 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4473	0	91.1358	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0520 00:11:02.102449 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:11:02.104382 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:11:02.104408 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:11:02.191489 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09817
I0520 00:11:04.554918 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:12:27.185180 15139 solver.cpp:231] Iteration 200, loss = 1.49983
I0520 00:12:27.185567 15139 solver.cpp:247]     Train net output #0: loss = 1.49983 (* 1 = 1.49983 loss)
I0520 00:12:27.185595 15139 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0520 00:12:27.343420 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.6465	3.125	82.5231	0	91.1559	5.98958	89.2008	0	85.3052	0	85.6134	0	78.3563	0	30.397	2.7	
I0520 00:12:27.418479 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:12:27.421350 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:12:27.421391 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:12:27.421859 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.49983
I0520 00:13:50.324554 15139 solver.cpp:231] Iteration 400, loss = 1.32368
I0520 00:13:50.324812 15139 solver.cpp:247]     Train net output #0: loss = 1.32368 (* 1 = 1.32368 loss)
I0520 00:13:50.324837 15139 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0520 00:13:50.485570 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.7153	3.125	82.5524	0	91.1647	5.98958	89.2152	0	85.322	0	85.6205	0	78.3638	0	30.4022	2.7	
I0520 00:13:50.561867 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:13:50.564395 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:13:50.564460 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:13:50.565131 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32368
I0520 00:15:04.630645 15139 solver.cpp:231] Iteration 600, loss = 1.21339
I0520 00:15:04.633644 15139 solver.cpp:247]     Train net output #0: loss = 1.21339 (* 1 = 1.21339 loss)
I0520 00:15:04.633679 15139 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0520 00:15:04.792914 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.7785	3.125	82.5645	0	91.1735	5.98958	89.2254	0	85.3312	0	85.6277	0	78.3717	0	30.4082	2.7	
I0520 00:15:04.868582 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:15:04.870681 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:15:04.870712 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:15:04.871228 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21339
I0520 00:16:25.142288 15139 solver.cpp:231] Iteration 800, loss = 1.23612
I0520 00:16:25.142590 15139 solver.cpp:247]     Train net output #0: loss = 1.23612 (* 1 = 1.23612 loss)
I0520 00:16:25.142613 15139 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0520 00:16:25.302670 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.8215	3.125	82.5811	0	91.1777	5.98958	89.2337	0	85.338	0	85.6348	0	78.3795	0	30.414	2.7	
I0520 00:16:25.377893 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:16:25.380002 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:16:25.380033 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:16:25.380533 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23612
I0520 00:17:41.717872 15139 solver.cpp:348] Iteration 1000, Testing net (#0)
I0520 00:17:42.739377 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:18:52.702873 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56014
I0520 00:18:52.703203 15139 solver.cpp:415]     Test net output #1: loss = 1.89843 (* 1 = 1.89843 loss)
I0520 00:18:52.790771 15139 solver.cpp:231] Iteration 1000, loss = 1.33181
I0520 00:18:52.790858 15139 solver.cpp:247]     Train net output #0: loss = 1.33181 (* 1 = 1.33181 loss)
I0520 00:18:52.790879 15139 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0520 00:18:52.956006 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.8215	3.125	82.5915	0	91.1823	5.98958	89.2397	0	85.3448	0	85.6418	0	78.3878	0	30.4188	2.7	
I0520 00:18:53.032333 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:18:53.035174 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:18:53.035223 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:18:53.035977 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33181
I0520 00:18:57.778786 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:20:06.143302 15139 solver.cpp:231] Iteration 1200, loss = 1.30628
I0520 00:20:06.143569 15139 solver.cpp:247]     Train net output #0: loss = 1.30628 (* 1 = 1.30628 loss)
I0520 00:20:06.143589 15139 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0520 00:20:06.304337 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.8732	3.125	82.6012	0	91.1858	5.98958	89.2441	0	85.3493	0	85.6489	0	78.3957	0	30.4245	2.7	
I0520 00:20:06.379238 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:20:06.381283 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:20:06.381316 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:20:06.382005 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30628
I0520 00:21:22.483149 15139 solver.cpp:231] Iteration 1400, loss = 1.47901
I0520 00:21:22.483428 15139 solver.cpp:247]     Train net output #0: loss = 1.47901 (* 1 = 1.47901 loss)
I0520 00:21:22.483532 15139 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0520 00:21:22.642222 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.8559	3.125	82.6143	0	91.1881	5.98958	89.2476	0	85.3538	0	85.6559	0	78.4039	0	30.4288	2.7	
I0520 00:21:22.720646 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:21:22.722266 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:21:22.722304 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:21:22.722849 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.47901
I0520 00:22:37.099673 15139 solver.cpp:231] Iteration 1600, loss = 1.19732
I0520 00:22:37.099937 15139 solver.cpp:247]     Train net output #0: loss = 1.19732 (* 1 = 1.19732 loss)
I0520 00:22:37.099958 15139 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0520 00:22:37.262805 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.8904	3.125	82.6104	0	91.1887	5.98958	89.2491	0	85.3599	0	85.6629	0	78.412	0	30.4349	2.7	
I0520 00:22:37.338621 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:22:37.340862 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:22:37.340896 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:22:37.341593 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19732
I0520 00:23:53.488037 15139 solver.cpp:231] Iteration 1800, loss = 1.37336
I0520 00:23:53.488364 15139 solver.cpp:247]     Train net output #0: loss = 1.37336 (* 1 = 1.37336 loss)
I0520 00:23:53.488390 15139 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0520 00:23:53.646278 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.9392	3.125	82.6256	0	91.1896	5.98958	89.2543	0	85.3611	0	85.6697	0	78.4201	0	30.4398	2.7	
I0520 00:23:53.720940 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:23:53.722585 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:23:53.722618 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:23:53.723119 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.37336
I0520 00:25:09.708477 15139 solver.cpp:348] Iteration 2000, Testing net (#0)
I0520 00:25:11.383363 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:26:27.776119 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55758
I0520 00:26:27.776442 15139 solver.cpp:415]     Test net output #1: loss = 1.90864 (* 1 = 1.90864 loss)
I0520 00:26:27.866441 15139 solver.cpp:231] Iteration 2000, loss = 1.44167
I0520 00:26:27.866533 15139 solver.cpp:247]     Train net output #0: loss = 1.44167 (* 1 = 1.44167 loss)
I0520 00:26:27.866554 15139 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0520 00:26:28.033033 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.9478	3.125	82.6061	0	91.1924	5.98958	89.2551	0	85.3638	0	85.6764	0	78.428	0	30.4449	2.7	
I0520 00:26:28.109073 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:26:28.111544 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:26:28.111603 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:26:28.112457 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.44167
I0520 00:26:35.875427 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:27:43.926790 15139 solver.cpp:231] Iteration 2200, loss = 1.46606
I0520 00:27:43.929646 15139 solver.cpp:247]     Train net output #0: loss = 1.46606 (* 1 = 1.46606 loss)
I0520 00:27:43.929677 15139 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0520 00:27:44.087101 15139 sgd_solver.cpp:120]     Element Sparsity %: 
14.9822	3.125	82.6273	0	91.1947	5.98958	89.2596	0	85.3669	0	85.683	0	78.4358	0	30.4498	2.7	
I0520 00:27:44.163843 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:27:44.166898 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:27:44.166949 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:27:44.167536 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.46606
I0520 00:29:03.957834 15139 solver.cpp:231] Iteration 2400, loss = 1.31381
I0520 00:29:03.958148 15139 solver.cpp:247]     Train net output #0: loss = 1.31381 (* 1 = 1.31381 loss)
I0520 00:29:03.958170 15139 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0520 00:29:04.118113 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.0253	3.125	82.6364	0	91.1974	5.98958	89.2604	0	85.369	0	85.6897	0	78.4439	0	30.4555	2.7	
I0520 00:29:04.192910 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:29:04.195013 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:29:04.195052 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:29:04.195541 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31381
I0520 00:30:40.223503 15139 solver.cpp:231] Iteration 2600, loss = 1.55951
I0520 00:30:40.223829 15139 solver.cpp:247]     Train net output #0: loss = 1.55951 (* 1 = 1.55951 loss)
I0520 00:30:40.223857 15139 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0520 00:30:40.382506 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.031	3.125	82.6348	0	91.1991	5.98958	89.2637	0	85.3721	0	85.6964	0	78.452	0	30.4601	2.7	
I0520 00:30:40.457510 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:30:40.460350 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:30:40.460391 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:30:40.460871 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.55951
I0520 00:32:27.671479 15139 solver.cpp:231] Iteration 2800, loss = 1.2303
I0520 00:32:27.673667 15139 solver.cpp:247]     Train net output #0: loss = 1.2303 (* 1 = 1.2303 loss)
I0520 00:32:27.673701 15139 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0520 00:32:27.832226 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.008	3.125	82.639	0	91.1993	5.98958	89.266	0	85.3748	0	85.7033	0	78.4598	0	30.4659	2.7	
I0520 00:32:27.907402 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:32:27.909464 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:32:27.909584 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:32:27.910089 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2303
I0520 00:33:41.833468 15139 solver.cpp:348] Iteration 3000, Testing net (#0)
I0520 00:33:44.131389 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:34:59.586833 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5575
I0520 00:34:59.587138 15139 solver.cpp:415]     Test net output #1: loss = 1.90901 (* 1 = 1.90901 loss)
I0520 00:34:59.676223 15139 solver.cpp:231] Iteration 3000, loss = 1.30303
I0520 00:34:59.676304 15139 solver.cpp:247]     Train net output #0: loss = 1.30303 (* 1 = 1.30303 loss)
I0520 00:34:59.676322 15139 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0520 00:34:59.836175 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.097	3.125	82.6393	0	91.2003	5.98958	89.2679	0	85.3776	0	85.71	0	78.4678	0	30.4709	2.7	
I0520 00:34:59.910639 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:34:59.913455 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:34:59.917250 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:34:59.917945 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30303
I0520 00:35:10.453196 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:36:20.799579 15139 solver.cpp:231] Iteration 3200, loss = 1.34939
I0520 00:36:20.801630 15139 solver.cpp:247]     Train net output #0: loss = 1.34939 (* 1 = 1.34939 loss)
I0520 00:36:20.801681 15139 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0520 00:36:20.959512 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.0568	3.125	82.6377	0	91.2029	5.98958	89.2697	0	85.3782	0	85.7169	0	78.4755	0	30.476	2.7	
I0520 00:36:21.034324 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:36:21.036387 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:36:21.036422 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:36:21.036921 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34939
I0520 00:37:45.961199 15139 solver.cpp:231] Iteration 3400, loss = 1.31351
I0520 00:37:45.961486 15139 solver.cpp:247]     Train net output #0: loss = 1.31351 (* 1 = 1.31351 loss)
I0520 00:37:45.961508 15139 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0520 00:37:46.121459 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.074	3.125	82.6423	0	91.2029	5.98958	89.2703	0	85.38	0	85.7233	0	78.4837	0	30.4812	2.7	
I0520 00:37:46.196158 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:37:46.198115 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:37:46.198138 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:37:46.198665 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31351
I0520 00:39:03.870914 15139 solver.cpp:231] Iteration 3600, loss = 1.34015
I0520 00:39:03.871351 15139 solver.cpp:247]     Train net output #0: loss = 1.34015 (* 1 = 1.34015 loss)
I0520 00:39:03.871374 15139 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0520 00:39:04.031352 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.1429	3.125	82.6491	0	91.2022	5.98958	89.2714	0	85.3832	0	85.7296	0	78.4914	0	30.4866	2.7	
I0520 00:39:04.106412 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:39:04.109570 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:39:04.109643 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:39:04.110188 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34015
I0520 00:40:19.218804 15139 solver.cpp:231] Iteration 3800, loss = 1.21279
I0520 00:40:19.219223 15139 solver.cpp:247]     Train net output #0: loss = 1.21279 (* 1 = 1.21279 loss)
I0520 00:40:19.219261 15139 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0520 00:40:19.381657 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.0884	3.125	82.6396	0	91.2043	5.98958	89.2742	0	85.3843	0	85.7363	0	78.4994	0	30.491	2.7	
I0520 00:40:19.457093 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:40:19.460933 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:40:19.460994 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:40:19.461630 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21279
I0520 00:41:42.521095 15139 solver.cpp:348] Iteration 4000, Testing net (#0)
I0520 00:41:45.129046 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:42:55.176648 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55648
I0520 00:42:55.176888 15139 solver.cpp:415]     Test net output #1: loss = 1.90415 (* 1 = 1.90415 loss)
I0520 00:42:55.264772 15139 solver.cpp:231] Iteration 4000, loss = 1.14925
I0520 00:42:55.264946 15139 solver.cpp:247]     Train net output #0: loss = 1.14925 (* 1 = 1.14925 loss)
I0520 00:42:55.264986 15139 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0520 00:42:55.432387 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.1659	3.125	82.6559	0	91.2066	5.98958	89.2732	0	85.3848	0	85.7426	0	78.5073	0	30.4956	2.7	
I0520 00:42:55.507869 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:42:55.510510 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:42:55.510550 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:42:55.511337 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14925
I0520 00:43:08.447366 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:44:12.473978 15139 solver.cpp:231] Iteration 4200, loss = 1.23191
I0520 00:44:12.477682 15139 solver.cpp:247]     Train net output #0: loss = 1.23191 (* 1 = 1.23191 loss)
I0520 00:44:12.477720 15139 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0520 00:44:12.633632 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.2462	3.125	82.6527	0	91.2056	5.98958	89.2753	0	85.3861	0	85.7489	0	78.5151	0	30.5014	2.7	
I0520 00:44:12.708801 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:44:12.711807 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:44:12.711856 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:44:12.712404 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23191
I0520 00:45:34.521217 15139 solver.cpp:231] Iteration 4400, loss = 1.09038
I0520 00:45:34.521643 15139 solver.cpp:247]     Train net output #0: loss = 1.09038 (* 1 = 1.09038 loss)
I0520 00:45:34.521666 15139 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0520 00:45:34.682756 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.206	3.125	82.6416	0	91.2056	5.98958	89.2751	0	85.3882	0	85.7554	0	78.5226	0	30.5069	2.7	
I0520 00:45:34.757756 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:45:34.760548 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:45:34.760591 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:45:34.761195 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09038
I0520 00:46:56.864910 15139 solver.cpp:231] Iteration 4600, loss = 1.41628
I0520 00:46:56.865252 15139 solver.cpp:247]     Train net output #0: loss = 1.41628 (* 1 = 1.41628 loss)
I0520 00:46:56.865272 15139 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0520 00:46:57.025641 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.206	3.125	82.6484	0	91.2046	5.98958	89.2762	0	85.3884	0	85.7617	0	78.5303	0	30.5112	2.7	
I0520 00:46:57.112464 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:46:57.115089 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:46:57.115123 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:46:57.115571 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.41628
I0520 00:48:16.600219 15139 solver.cpp:231] Iteration 4800, loss = 1.51205
I0520 00:48:16.600564 15139 solver.cpp:247]     Train net output #0: loss = 1.51205 (* 1 = 1.51205 loss)
I0520 00:48:16.600594 15139 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0520 00:48:16.762461 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.1515	3.125	82.6449	0	91.2054	5.98958	89.278	0	85.39	0	85.7678	0	78.5381	0	30.5164	2.7	
I0520 00:48:16.837263 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:48:16.838892 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:48:16.838922 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:48:16.839507 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.51205
I0520 00:49:43.661115 15139 solver.cpp:348] Iteration 5000, Testing net (#0)
I0520 00:49:46.887434 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:51:05.054921 15139 solver.cpp:415]     Test net output #0: accuracy = 0.555379
I0520 00:51:05.055234 15139 solver.cpp:415]     Test net output #1: loss = 1.90942 (* 1 = 1.90942 loss)
I0520 00:51:05.144752 15139 solver.cpp:231] Iteration 5000, loss = 1.34368
I0520 00:51:05.144853 15139 solver.cpp:247]     Train net output #0: loss = 1.34368 (* 1 = 1.34368 loss)
I0520 00:51:05.144871 15139 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0520 00:51:05.308454 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.1888	3.125	82.6543	0	91.2066	5.98958	89.2788	0	85.3916	0	85.774	0	78.5456	0	30.5221	2.7	
I0520 00:51:05.383765 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:51:05.386360 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:51:05.386401 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:51:05.386946 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34368
I0520 00:51:22.619879 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 00:52:28.061601 15139 solver.cpp:231] Iteration 5200, loss = 1.23283
I0520 00:52:28.061830 15139 solver.cpp:247]     Train net output #0: loss = 1.23283 (* 1 = 1.23283 loss)
I0520 00:52:28.061851 15139 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0520 00:52:28.223706 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.2405	3.125	82.6579	0	91.2068	5.98958	89.2797	0	85.3898	0	85.7801	0	78.5532	0	30.528	2.7	
I0520 00:52:28.299379 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:52:28.301451 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:52:28.301473 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:52:28.301928 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23283
I0520 00:53:51.105815 15139 solver.cpp:231] Iteration 5400, loss = 1.55366
I0520 00:53:51.107431 15139 solver.cpp:247]     Train net output #0: loss = 1.55366 (* 1 = 1.55366 loss)
I0520 00:53:51.107461 15139 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0520 00:53:51.266033 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.252	3.125	82.6683	0	91.2081	5.98958	89.28	0	85.3932	0	85.7864	0	78.5608	0	30.534	2.7	
I0520 00:53:51.342244 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:53:51.345309 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:53:51.345350 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:53:51.346101 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.55366
I0520 00:55:12.660691 15139 solver.cpp:231] Iteration 5600, loss = 1.42431
I0520 00:55:12.660995 15139 solver.cpp:247]     Train net output #0: loss = 1.42431 (* 1 = 1.42431 loss)
I0520 00:55:12.661015 15139 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0520 00:55:12.820312 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.2749	3.125	82.6628	0	91.2073	5.98958	89.2813	0	85.3932	0	85.7923	0	78.5684	0	30.5394	2.7	
I0520 00:55:12.895474 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:55:12.898248 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:55:12.898291 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:55:12.898797 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.42431
I0520 00:56:41.160151 15139 solver.cpp:231] Iteration 5800, loss = 1.34941
I0520 00:56:41.160439 15139 solver.cpp:247]     Train net output #0: loss = 1.34941 (* 1 = 1.34941 loss)
I0520 00:56:41.160459 15139 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I0520 00:56:41.320359 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.186	3.125	82.6631	0	91.2078	5.98958	89.2812	0	85.3963	0	85.7985	0	78.5759	0	30.5448	2.7	
I0520 00:56:41.395261 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 00:56:41.397894 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 00:56:41.397933 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 00:56:41.398417 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34941
I0520 00:58:12.700759 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_6000.caffemodel
I0520 00:59:02.763623 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_6000.solverstate
I0520 00:59:03.255101 15139 solver.cpp:348] Iteration 6000, Testing net (#0)
I0520 00:59:06.670966 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:00:18.360355 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55468
I0520 01:00:18.360652 15139 solver.cpp:415]     Test net output #1: loss = 1.91383 (* 1 = 1.91383 loss)
I0520 01:00:18.448222 15139 solver.cpp:231] Iteration 6000, loss = 1.24455
I0520 01:00:18.448300 15139 solver.cpp:247]     Train net output #0: loss = 1.24455 (* 1 = 1.24455 loss)
I0520 01:00:18.448318 15139 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0520 01:00:18.614590 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.3007	3.125	82.668	0	91.2095	5.98958	89.2819	0	85.3934	0	85.8045	0	78.5835	0	30.5497	2.7	
I0520 01:00:18.616593 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:00:18.619107 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:00:18.619132 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:00:18.619722 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24455
I0520 01:00:36.717212 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:01:33.286566 15139 solver.cpp:231] Iteration 6200, loss = 1.30125
I0520 01:01:33.286921 15139 solver.cpp:247]     Train net output #0: loss = 1.30125 (* 1 = 1.30125 loss)
I0520 01:01:33.286944 15139 sgd_solver.cpp:106] Iteration 6200, lr = 0.001
I0520 01:01:33.447264 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.3122	3.125	82.6644	0	91.2108	5.98958	89.2822	0	85.3968	0	85.8105	0	78.5907	0	30.5547	2.7	
I0520 01:01:33.521728 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:01:33.523998 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:01:33.524024 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:01:33.524392 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30125
I0520 01:02:48.115855 15139 solver.cpp:231] Iteration 6400, loss = 1.18156
I0520 01:02:48.116188 15139 solver.cpp:247]     Train net output #0: loss = 1.18156 (* 1 = 1.18156 loss)
I0520 01:02:48.116210 15139 sgd_solver.cpp:106] Iteration 6400, lr = 0.001
I0520 01:02:48.277083 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.2634	3.125	82.6598	0	91.2107	5.98958	89.2836	0	85.3961	0	85.8166	0	78.5983	0	30.5602	2.7	
I0520 01:02:48.356894 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:02:48.359724 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:02:48.359767 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:02:48.360466 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18156
I0520 01:04:01.260931 15139 solver.cpp:231] Iteration 6600, loss = 1.34429
I0520 01:04:01.261337 15139 solver.cpp:247]     Train net output #0: loss = 1.34429 (* 1 = 1.34429 loss)
I0520 01:04:01.261370 15139 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I0520 01:04:01.423517 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.2921	3.125	82.6439	0	91.211	5.98958	89.2851	0	85.3975	0	85.8225	0	78.6059	0	30.5649	2.7	
I0520 01:04:01.499086 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:04:01.500532 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:04:01.500550 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:04:01.501004 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34429
I0520 01:05:16.034672 15139 solver.cpp:231] Iteration 6800, loss = 1.49484
I0520 01:05:16.034899 15139 solver.cpp:247]     Train net output #0: loss = 1.49484 (* 1 = 1.49484 loss)
I0520 01:05:16.034924 15139 sgd_solver.cpp:106] Iteration 6800, lr = 0.001
I0520 01:05:16.196977 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.3639	3.125	82.6657	0	91.2123	5.98958	89.2866	0	85.3975	0	85.8287	0	78.6137	0	30.5708	2.7	
I0520 01:05:16.272402 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:05:16.274394 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:05:16.274427 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:05:16.275070 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.49484
I0520 01:06:31.589910 15139 solver.cpp:348] Iteration 7000, Testing net (#0)
I0520 01:06:36.655441 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:07:47.521096 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55234
I0520 01:07:47.521703 15139 solver.cpp:415]     Test net output #1: loss = 1.93167 (* 1 = 1.93167 loss)
I0520 01:07:47.610956 15139 solver.cpp:231] Iteration 7000, loss = 1.27906
I0520 01:07:47.611026 15139 solver.cpp:247]     Train net output #0: loss = 1.27906 (* 1 = 1.27906 loss)
I0520 01:07:47.611043 15139 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0520 01:07:47.770540 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.3983	3.125	82.6396	0	91.2126	5.98958	89.2866	0	85.4006	0	85.8344	0	78.621	0	30.5758	2.7	
I0520 01:07:47.847072 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:07:47.848919 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:07:47.848950 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:07:47.849467 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27906
I0520 01:08:08.442108 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:09:02.433989 15139 solver.cpp:231] Iteration 7200, loss = 1.26222
I0520 01:09:02.435598 15139 solver.cpp:247]     Train net output #0: loss = 1.26222 (* 1 = 1.26222 loss)
I0520 01:09:02.435624 15139 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I0520 01:09:02.595952 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.4098	3.125	82.6585	0	91.2138	5.98958	89.2896	0	85.4004	0	85.8402	0	78.6283	0	30.5803	2.7	
I0520 01:09:02.671075 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:09:02.672796 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:09:02.672821 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:09:02.673317 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26222
I0520 01:10:14.598896 15139 solver.cpp:231] Iteration 7400, loss = 1.417
I0520 01:10:14.599130 15139 solver.cpp:247]     Train net output #0: loss = 1.417 (* 1 = 1.417 loss)
I0520 01:10:14.599148 15139 sgd_solver.cpp:106] Iteration 7400, lr = 0.001
I0520 01:10:14.761428 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.404	3.125	82.6576	0	91.212	5.98958	89.2899	0	85.4006	0	85.846	0	78.6357	0	30.5853	2.7	
I0520 01:10:14.838687 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:10:14.840128 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:10:14.840143 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:10:14.840556 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.417
I0520 01:11:30.631618 15139 solver.cpp:231] Iteration 7600, loss = 1.42026
I0520 01:11:30.631898 15139 solver.cpp:247]     Train net output #0: loss = 1.42026 (* 1 = 1.42026 loss)
I0520 01:11:30.631922 15139 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I0520 01:11:30.792840 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.3495	3.125	82.6621	0	91.2123	5.98958	89.2899	0	85.4006	0	85.8517	0	78.643	0	30.5903	2.7	
I0520 01:11:30.867658 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:11:30.869750 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:11:30.869788 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:11:30.870313 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.42026
I0520 01:12:50.530515 15139 solver.cpp:231] Iteration 7800, loss = 1.30769
I0520 01:12:50.530735 15139 solver.cpp:247]     Train net output #0: loss = 1.30769 (* 1 = 1.30769 loss)
I0520 01:12:50.530915 15139 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0520 01:12:50.692925 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.4069	3.125	82.6572	0	91.2137	5.98958	89.2896	0	85.4022	0	85.8576	0	78.6505	0	30.5958	2.7	
I0520 01:12:50.768679 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:12:50.770964 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:12:50.770998 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:12:50.771559 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30769
I0520 01:14:04.739270 15139 solver.cpp:348] Iteration 8000, Testing net (#0)
I0520 01:14:09.554401 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:15:26.636018 15139 solver.cpp:415]     Test net output #0: accuracy = 0.557439
I0520 01:15:26.636274 15139 solver.cpp:415]     Test net output #1: loss = 1.90309 (* 1 = 1.90309 loss)
I0520 01:15:26.777978 15139 solver.cpp:231] Iteration 8000, loss = 1.46538
I0520 01:15:26.778050 15139 solver.cpp:247]     Train net output #0: loss = 1.46538 (* 1 = 1.46538 loss)
I0520 01:15:26.778069 15139 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0520 01:15:26.945439 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.4241	3.125	82.6598	0	91.2143	5.98958	89.2883	0	85.4024	0	85.8634	0	78.658	0	30.6012	2.7	
I0520 01:15:27.020156 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:15:27.021788 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:15:27.021821 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:15:27.022373 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.46538
I0520 01:15:49.606540 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:16:42.739835 15139 solver.cpp:231] Iteration 8200, loss = 1.28019
I0520 01:16:42.740038 15139 solver.cpp:247]     Train net output #0: loss = 1.28019 (* 1 = 1.28019 loss)
I0520 01:16:42.740058 15139 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I0520 01:16:42.898648 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5131	3.125	82.6673	0	91.2146	5.98958	89.2895	0	85.4017	0	85.8691	0	78.6652	0	30.6059	2.7	
I0520 01:16:42.977639 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:16:42.979732 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:16:42.979756 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:16:42.980315 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28019
I0520 01:17:56.643759 15139 solver.cpp:231] Iteration 8400, loss = 1.44115
I0520 01:17:56.644194 15139 solver.cpp:247]     Train net output #0: loss = 1.44115 (* 1 = 1.44115 loss)
I0520 01:17:56.644224 15139 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0520 01:17:56.805835 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.4012	3.125	82.667	0	91.2149	5.98958	89.2914	0	85.4004	0	85.8748	0	78.6727	0	30.6113	2.7	
I0520 01:17:56.880748 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:17:56.883210 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:17:56.883261 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:17:56.883947 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.44115
I0520 01:19:20.986855 15139 solver.cpp:231] Iteration 8600, loss = 1.28648
I0520 01:19:20.989833 15139 solver.cpp:247]     Train net output #0: loss = 1.28648 (* 1 = 1.28648 loss)
I0520 01:19:20.989871 15139 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I0520 01:19:21.149457 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.47	3.125	82.6751	0	91.2143	5.98958	89.2913	0	85.404	0	85.8804	0	78.6801	0	30.6165	2.7	
I0520 01:19:21.225028 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:19:21.227841 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:19:21.227880 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:19:21.228390 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28648
I0520 01:20:34.348983 15139 solver.cpp:231] Iteration 8800, loss = 1.33438
I0520 01:20:34.349373 15139 solver.cpp:247]     Train net output #0: loss = 1.33438 (* 1 = 1.33438 loss)
I0520 01:20:34.349409 15139 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I0520 01:20:34.510959 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.404	3.125	82.6618	0	91.2146	5.98958	89.2901	0	85.4033	0	85.8862	0	78.6872	0	30.6222	2.7	
I0520 01:20:34.586530 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:20:34.588768 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:20:34.588795 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:20:34.589471 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33438
I0520 01:22:02.188321 15139 solver.cpp:348] Iteration 9000, Testing net (#0)
I0520 01:22:07.403764 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:23:20.706837 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55756
I0520 01:23:20.707185 15139 solver.cpp:415]     Test net output #1: loss = 1.90068 (* 1 = 1.90068 loss)
I0520 01:23:20.794567 15139 solver.cpp:231] Iteration 9000, loss = 1.26874
I0520 01:23:20.794658 15139 solver.cpp:247]     Train net output #0: loss = 1.26874 (* 1 = 1.26874 loss)
I0520 01:23:20.794682 15139 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0520 01:23:20.960460 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.4758	3.125	82.6618	0	91.2141	5.98958	89.2896	0	85.4036	0	85.8917	0	78.6948	0	30.6274	2.7	
I0520 01:23:21.035610 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:23:21.037282 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:23:21.037312 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:23:21.037958 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26874
I0520 01:23:49.843598 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:24:40.211920 15139 solver.cpp:231] Iteration 9200, loss = 1.32108
I0520 01:24:40.212271 15139 solver.cpp:247]     Train net output #0: loss = 1.32108 (* 1 = 1.32108 loss)
I0520 01:24:40.212294 15139 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I0520 01:24:40.372362 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.4873	3.125	82.6566	0	91.2146	5.98958	89.2913	0	85.4036	0	85.8972	0	78.702	0	30.6329	2.7	
I0520 01:24:40.447515 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:24:40.450454 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:24:40.450500 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:24:40.451030 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32108
I0520 01:26:03.997602 15139 solver.cpp:231] Iteration 9400, loss = 1.3601
I0520 01:26:04.002713 15139 solver.cpp:247]     Train net output #0: loss = 1.3601 (* 1 = 1.3601 loss)
I0520 01:26:04.002743 15139 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I0520 01:26:04.158601 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.4873	3.125	82.6621	0	91.2143	5.98958	89.2911	0	85.4031	0	85.9029	0	78.7092	0	30.6384	2.7	
I0520 01:26:04.234069 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:26:04.236693 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:26:04.236732 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:26:04.237293 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.3601
I0520 01:27:23.559836 15139 solver.cpp:231] Iteration 9600, loss = 1.45829
I0520 01:27:23.560381 15139 solver.cpp:247]     Train net output #0: loss = 1.45829 (* 1 = 1.45829 loss)
I0520 01:27:23.560425 15139 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0520 01:27:23.721707 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5274	3.125	82.6647	0	91.2155	5.98958	89.292	0	85.4058	0	85.9084	0	78.7168	0	30.6435	2.7	
I0520 01:27:23.797109 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:27:23.799779 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:27:23.799823 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:27:23.800442 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.45829
I0520 01:28:37.987634 15139 solver.cpp:231] Iteration 9800, loss = 1.46101
I0520 01:28:37.987933 15139 solver.cpp:247]     Train net output #0: loss = 1.46101 (* 1 = 1.46101 loss)
I0520 01:28:37.987967 15139 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I0520 01:28:38.149164 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.3868	3.125	82.6556	0	91.2146	5.98958	89.2923	0	85.4074	0	85.914	0	78.7241	0	30.649	2.7	
I0520 01:28:38.225308 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:28:38.227756 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:28:38.227802 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:28:38.228667 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.46101
I0520 01:30:07.033717 15139 solver.cpp:348] Iteration 10000, Testing net (#0)
I0520 01:30:14.240774 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:31:22.539739 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55716
I0520 01:31:22.540319 15139 solver.cpp:415]     Test net output #1: loss = 1.90612 (* 1 = 1.90612 loss)
I0520 01:31:22.631486 15139 solver.cpp:231] Iteration 10000, loss = 1.52502
I0520 01:31:22.631574 15139 solver.cpp:247]     Train net output #0: loss = 1.52502 (* 1 = 1.52502 loss)
I0520 01:31:22.631603 15139 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0520 01:31:22.797298 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.4356	3.125	82.6572	0	91.2151	5.98958	89.2926	0	85.4069	0	85.9195	0	78.7314	0	30.654	2.7	
I0520 01:31:22.872649 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:31:22.875013 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:31:22.875059 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:31:22.875659 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.52502
I0520 01:31:54.776779 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:32:48.513713 15139 solver.cpp:231] Iteration 10200, loss = 1.27608
I0520 01:32:48.513996 15139 solver.cpp:247]     Train net output #0: loss = 1.27608 (* 1 = 1.27608 loss)
I0520 01:32:48.514020 15139 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I0520 01:32:48.674563 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.4901	3.125	82.6566	0	91.2164	5.98958	89.2931	0	85.4085	0	85.925	0	78.7383	0	30.6587	2.7	
I0520 01:32:48.748764 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:32:48.750989 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:32:48.751015 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:32:48.751430 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27608
I0520 01:34:08.027773 15139 solver.cpp:231] Iteration 10400, loss = 1.19461
I0520 01:34:08.028028 15139 solver.cpp:247]     Train net output #0: loss = 1.19461 (* 1 = 1.19461 loss)
I0520 01:34:08.028056 15139 sgd_solver.cpp:106] Iteration 10400, lr = 0.001
I0520 01:34:08.189172 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5332	3.125	82.668	0	91.2175	5.98958	89.2931	0	85.4092	0	85.9305	0	78.7457	0	30.6638	2.7	
I0520 01:34:08.264367 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:34:08.266361 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:34:08.266404 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:34:08.267040 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19461
I0520 01:35:27.731657 15139 solver.cpp:231] Iteration 10600, loss = 1.4146
I0520 01:35:27.732103 15139 solver.cpp:247]     Train net output #0: loss = 1.4146 (* 1 = 1.4146 loss)
I0520 01:35:27.732130 15139 sgd_solver.cpp:106] Iteration 10600, lr = 0.001
I0520 01:35:27.894289 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.45	3.125	82.6781	0	91.2182	5.98958	89.2929	0	85.4085	0	85.9362	0	78.753	0	30.6686	2.7	
I0520 01:35:27.969487 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:35:27.972146 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:35:27.972198 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:35:27.972796 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.4146
I0520 01:37:03.284164 15139 solver.cpp:231] Iteration 10800, loss = 1.47879
I0520 01:37:03.284389 15139 solver.cpp:247]     Train net output #0: loss = 1.47879 (* 1 = 1.47879 loss)
I0520 01:37:03.284411 15139 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I0520 01:37:03.445219 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5246	3.125	82.6738	0	91.2178	5.98958	89.2944	0	85.4076	0	85.9418	0	78.7602	0	30.6739	2.7	
I0520 01:37:03.519951 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:37:03.521688 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:37:03.521718 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:37:03.522243 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.47879
I0520 01:38:22.548221 15139 solver.cpp:348] Iteration 11000, Testing net (#0)
I0520 01:38:28.707021 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:39:46.760205 15139 solver.cpp:415]     Test net output #0: accuracy = 0.558999
I0520 01:39:46.760481 15139 solver.cpp:415]     Test net output #1: loss = 1.90204 (* 1 = 1.90204 loss)
I0520 01:39:46.848409 15139 solver.cpp:231] Iteration 11000, loss = 1.18653
I0520 01:39:46.848489 15139 solver.cpp:247]     Train net output #0: loss = 1.18653 (* 1 = 1.18653 loss)
I0520 01:39:46.848510 15139 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0520 01:39:47.016291 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.6336	3.125	82.6689	0	91.2184	5.98958	89.2952	0	85.4099	0	85.9473	0	78.7671	0	30.6787	2.7	
I0520 01:39:47.091843 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:39:47.094368 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:39:47.094413 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:39:47.094934 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18653
I0520 01:40:20.650629 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:41:10.107695 15139 solver.cpp:231] Iteration 11200, loss = 1.33461
I0520 01:41:10.107998 15139 solver.cpp:247]     Train net output #0: loss = 1.33461 (* 1 = 1.33461 loss)
I0520 01:41:10.108018 15139 sgd_solver.cpp:106] Iteration 11200, lr = 0.001
I0520 01:41:10.270654 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5705	3.125	82.6764	0	91.2175	5.98958	89.2959	0	85.4099	0	85.9527	0	78.7744	0	30.6846	2.7	
I0520 01:41:10.346117 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:41:10.347968 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:41:10.348001 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:41:10.348582 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33461
I0520 01:42:34.644222 15139 solver.cpp:231] Iteration 11400, loss = 1.18874
I0520 01:42:34.644608 15139 solver.cpp:247]     Train net output #0: loss = 1.18874 (* 1 = 1.18874 loss)
I0520 01:42:34.644640 15139 sgd_solver.cpp:106] Iteration 11400, lr = 0.001
I0520 01:42:34.805564 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.6107	3.125	82.6693	0	91.2177	5.98958	89.2943	0	85.4092	0	85.958	0	78.7815	0	30.6896	2.7	
I0520 01:42:34.896942 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:42:34.898725 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:42:34.898766 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:42:34.899296 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18874
I0520 01:44:05.564093 15139 solver.cpp:231] Iteration 11600, loss = 1.38595
I0520 01:44:05.564453 15139 solver.cpp:247]     Train net output #0: loss = 1.38595 (* 1 = 1.38595 loss)
I0520 01:44:05.564481 15139 sgd_solver.cpp:106] Iteration 11600, lr = 0.001
I0520 01:44:05.724350 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.582	3.125	82.6631	0	91.2155	5.98958	89.2938	0	85.4106	0	85.9632	0	78.7884	0	30.6949	2.7	
I0520 01:44:05.800029 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:44:05.801872 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:44:05.801903 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:44:05.802456 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.38595
I0520 01:45:26.933847 15139 solver.cpp:231] Iteration 11800, loss = 1.27481
I0520 01:45:26.934202 15139 solver.cpp:247]     Train net output #0: loss = 1.27481 (* 1 = 1.27481 loss)
I0520 01:45:26.934236 15139 sgd_solver.cpp:106] Iteration 11800, lr = 0.001
I0520 01:45:27.095728 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5934	3.125	82.6673	0	91.2159	5.98958	89.2946	0	85.4101	0	85.9687	0	78.7956	0	30.6993	2.7	
I0520 01:45:27.170969 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:45:27.173250 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:45:27.173290 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:45:27.173869 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27481
I0520 01:46:59.342453 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_12000.caffemodel
I0520 01:48:00.494485 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_12000.solverstate
I0520 01:48:00.982097 15139 solver.cpp:348] Iteration 12000, Testing net (#0)
I0520 01:48:06.896528 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:49:15.008050 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55612
I0520 01:49:15.008424 15139 solver.cpp:415]     Test net output #1: loss = 1.90442 (* 1 = 1.90442 loss)
I0520 01:49:15.096917 15139 solver.cpp:231] Iteration 12000, loss = 1.219
I0520 01:49:15.097010 15139 solver.cpp:247]     Train net output #0: loss = 1.219 (* 1 = 1.219 loss)
I0520 01:49:15.097031 15139 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0520 01:49:15.260803 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5131	3.125	82.6579	0	91.2158	5.98958	89.2946	0	85.4099	0	85.9739	0	78.8025	0	30.7049	2.7	
I0520 01:49:15.263274 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:49:15.265628 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0520 01:49:15.265700 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:49:15.266381 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.219
I0520 01:49:51.213151 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:50:32.972484 15139 solver.cpp:231] Iteration 12200, loss = 1.39073
I0520 01:50:32.972699 15139 solver.cpp:247]     Train net output #0: loss = 1.39073 (* 1 = 1.39073 loss)
I0520 01:50:32.972720 15139 sgd_solver.cpp:106] Iteration 12200, lr = 0.001
I0520 01:50:33.133114 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5246	3.125	82.6742	0	91.2168	5.98958	89.2962	0	85.4103	0	85.9791	0	78.8094	0	30.7093	2.8	
I0520 01:50:33.208212 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:50:33.210377 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.8	
I0520 01:50:33.210413 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:50:33.210887 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.39073
I0520 01:51:51.096063 15139 solver.cpp:231] Iteration 12400, loss = 1.45376
I0520 01:51:51.096230 15139 solver.cpp:247]     Train net output #0: loss = 1.45376 (* 1 = 1.45376 loss)
I0520 01:51:51.096251 15139 sgd_solver.cpp:106] Iteration 12400, lr = 0.001
I0520 01:51:51.258332 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5475	3.125	82.6654	0	91.2173	5.98958	89.297	0	85.4079	0	85.9843	0	78.8163	0	30.7145	2.8	
I0520 01:51:51.332972 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:51:51.334499 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.8	
I0520 01:51:51.334520 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:51:51.334877 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.45376
I0520 01:53:22.757660 15139 solver.cpp:231] Iteration 12600, loss = 1.13818
I0520 01:53:22.757998 15139 solver.cpp:247]     Train net output #0: loss = 1.13818 (* 1 = 1.13818 loss)
I0520 01:53:22.758020 15139 sgd_solver.cpp:106] Iteration 12600, lr = 0.001
I0520 01:53:22.918404 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5906	3.125	82.6634	0	91.2182	5.98958	89.2973	0	85.4101	0	85.9897	0	78.823	0	30.7197	2.8	
I0520 01:53:22.994104 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:53:22.996166 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.8	
I0520 01:53:22.996199 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:53:22.996925 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13818
I0520 01:54:36.813876 15139 solver.cpp:231] Iteration 12800, loss = 1.20289
I0520 01:54:36.815011 15139 solver.cpp:247]     Train net output #0: loss = 1.20289 (* 1 = 1.20289 loss)
I0520 01:54:36.815035 15139 sgd_solver.cpp:106] Iteration 12800, lr = 0.001
I0520 01:54:36.976804 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5418	3.125	82.6745	0	91.2203	5.98958	89.2968	0	85.4097	0	85.9949	0	78.83	0	30.7252	2.8	
I0520 01:54:37.052538 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:54:37.054757 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.8	
I0520 01:54:37.054795 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:54:37.055538 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20289
I0520 01:55:57.983875 15139 solver.cpp:348] Iteration 13000, Testing net (#0)
I0520 01:56:06.464689 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:57:22.734791 15139 solver.cpp:415]     Test net output #0: accuracy = 0.556679
I0520 01:57:22.735069 15139 solver.cpp:415]     Test net output #1: loss = 1.90224 (* 1 = 1.90224 loss)
I0520 01:57:22.822432 15139 solver.cpp:231] Iteration 13000, loss = 1.05549
I0520 01:57:22.822564 15139 solver.cpp:247]     Train net output #0: loss = 1.05549 (* 1 = 1.05549 loss)
I0520 01:57:22.822584 15139 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0520 01:57:22.993942 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5647	3.125	82.6787	0	91.2191	6.25	89.2985	0	85.4117	0	86.0002	0	78.837	0	30.7297	2.8	
I0520 01:57:23.068850 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:57:23.071766 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 01:57:23.071815 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:57:23.072330 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.05549
I0520 01:58:05.368609 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 01:58:46.587234 15139 solver.cpp:231] Iteration 13200, loss = 1.47281
I0520 01:58:46.587469 15139 solver.cpp:247]     Train net output #0: loss = 1.47281 (* 1 = 1.47281 loss)
I0520 01:58:46.587494 15139 sgd_solver.cpp:106] Iteration 13200, lr = 0.001
I0520 01:58:46.747279 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.516	3.125	82.6751	0	91.2191	6.25	89.299	0	85.4115	0	86.0056	0	78.8436	0	30.7351	2.8	
I0520 01:58:46.822312 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 01:58:46.824626 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 01:58:46.824666 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 01:58:46.825196 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.47281
I0520 02:00:11.859150 15139 solver.cpp:231] Iteration 13400, loss = 1.21811
I0520 02:00:11.859457 15139 solver.cpp:247]     Train net output #0: loss = 1.21811 (* 1 = 1.21811 loss)
I0520 02:00:11.859483 15139 sgd_solver.cpp:106] Iteration 13400, lr = 0.001
I0520 02:00:12.020256 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.493	3.125	82.6761	0	91.2204	6.25	89.2985	0	85.4117	0	86.0105	0	78.8507	0	30.7407	2.8	
I0520 02:00:12.095244 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:00:12.096860 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:00:12.096884 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:00:12.097430 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21811
I0520 02:01:32.120301 15139 solver.cpp:231] Iteration 13600, loss = 1.37991
I0520 02:01:32.120582 15139 solver.cpp:247]     Train net output #0: loss = 1.37991 (* 1 = 1.37991 loss)
I0520 02:01:32.120604 15139 sgd_solver.cpp:106] Iteration 13600, lr = 0.001
I0520 02:01:32.280625 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.6107	3.125	82.6699	0	91.2207	6.25	89.3002	0	85.4103	0	86.0158	0	78.8574	0	30.7458	2.8	
I0520 02:01:32.355653 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:01:32.358538 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:01:32.358577 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:01:32.359127 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.37991
I0520 02:03:01.618489 15139 solver.cpp:231] Iteration 13800, loss = 1.18884
I0520 02:03:01.618751 15139 solver.cpp:247]     Train net output #0: loss = 1.18884 (* 1 = 1.18884 loss)
I0520 02:03:01.618772 15139 sgd_solver.cpp:106] Iteration 13800, lr = 0.001
I0520 02:03:01.778585 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.4844	3.125	82.6647	0	91.2192	6.25	89.3006	0	85.4117	0	86.0211	0	78.8643	0	30.7508	2.8	
I0520 02:03:01.854218 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:03:01.858073 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:03:01.858139 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:03:01.858690 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18884
I0520 02:04:24.234196 15139 solver.cpp:348] Iteration 14000, Testing net (#0)
I0520 02:04:32.692117 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:05:43.262846 15139 solver.cpp:415]     Test net output #0: accuracy = 0.558679
I0520 02:05:43.263139 15139 solver.cpp:415]     Test net output #1: loss = 1.89857 (* 1 = 1.89857 loss)
I0520 02:05:43.368402 15139 solver.cpp:231] Iteration 14000, loss = 1.17409
I0520 02:05:43.368485 15139 solver.cpp:247]     Train net output #0: loss = 1.17409 (* 1 = 1.17409 loss)
I0520 02:05:43.368504 15139 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0520 02:05:43.529047 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.6279	3.125	82.6702	0	91.2204	6.25	89.3008	0	85.4119	0	86.0261	0	78.8711	0	30.7563	2.8	
I0520 02:05:43.605087 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:05:43.607488 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:05:43.607527 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:05:43.608181 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17409
I0520 02:06:25.607260 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:07:03.914468 15139 solver.cpp:231] Iteration 14200, loss = 1.44182
I0520 02:07:03.916956 15139 solver.cpp:247]     Train net output #0: loss = 1.44182 (* 1 = 1.44182 loss)
I0520 02:07:03.916982 15139 sgd_solver.cpp:106] Iteration 14200, lr = 0.001
I0520 02:07:04.075163 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.5533	3.125	82.6657	0	91.22	6.25	89.3009	0	85.4112	0	86.0312	0	78.878	0	30.7621	2.8	
I0520 02:07:04.150173 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:07:04.153071 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:07:04.153121 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:07:04.153638 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.44182
I0520 02:08:25.218420 15139 solver.cpp:231] Iteration 14400, loss = 1.46185
I0520 02:08:25.218665 15139 solver.cpp:247]     Train net output #0: loss = 1.46185 (* 1 = 1.46185 loss)
I0520 02:08:25.218685 15139 sgd_solver.cpp:106] Iteration 14400, lr = 0.001
I0520 02:08:25.378686 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.6307	3.125	82.6585	0	91.2228	6.25	89.3005	0	85.4121	0	86.0363	0	78.8847	0	30.7681	2.8	
I0520 02:08:25.454499 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:08:25.457171 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:08:25.457207 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:08:25.457803 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.46185
I0520 02:09:46.659606 15139 solver.cpp:231] Iteration 14600, loss = 1.06653
I0520 02:09:46.659957 15139 solver.cpp:247]     Train net output #0: loss = 1.06653 (* 1 = 1.06653 loss)
I0520 02:09:46.659982 15139 sgd_solver.cpp:106] Iteration 14600, lr = 0.001
I0520 02:09:46.821286 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.648	3.125	82.6562	0	91.223	6.25	89.2985	0	85.4112	0	86.0416	0	78.8916	0	30.7731	2.8	
I0520 02:09:46.897632 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:09:46.900969 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:09:46.901017 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:09:46.901540 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.06653
I0520 02:11:06.716714 15139 solver.cpp:231] Iteration 14800, loss = 1.47747
I0520 02:11:06.717144 15139 solver.cpp:247]     Train net output #0: loss = 1.47747 (* 1 = 1.47747 loss)
I0520 02:11:06.717272 15139 sgd_solver.cpp:106] Iteration 14800, lr = 0.001
I0520 02:11:06.876559 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.6336	3.125	82.6536	0	91.222	6.25	89.3009	0	85.4119	0	86.0468	0	78.8986	0	30.7789	2.8	
I0520 02:11:06.952682 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:11:06.954923 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:11:06.954954 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:11:06.955576 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.47747
I0520 02:12:38.234055 15139 solver.cpp:348] Iteration 15000, Testing net (#0)
I0520 02:12:47.544806 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:13:49.741149 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55572
I0520 02:13:49.741477 15139 solver.cpp:415]     Test net output #1: loss = 1.91467 (* 1 = 1.91467 loss)
I0520 02:13:49.829205 15139 solver.cpp:231] Iteration 15000, loss = 1.5102
I0520 02:13:49.829468 15139 solver.cpp:247]     Train net output #0: loss = 1.5102 (* 1 = 1.5102 loss)
I0520 02:13:49.829491 15139 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I0520 02:13:49.994681 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.6767	3.125	82.6611	0	91.2222	6.25	89.3011	0	85.4115	0	86.0519	0	78.9053	0	30.7839	2.8	
I0520 02:13:50.069888 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:13:50.072693 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:13:50.072731 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:13:50.073246 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.5102
I0520 02:14:33.279211 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:15:05.993508 15139 solver.cpp:231] Iteration 15200, loss = 1.35476
I0520 02:15:05.993808 15139 solver.cpp:247]     Train net output #0: loss = 1.35476 (* 1 = 1.35476 loss)
I0520 02:15:05.993830 15139 sgd_solver.cpp:106] Iteration 15200, lr = 0.001
I0520 02:15:06.154618 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.714	3.125	82.6631	0	91.2226	6.25	89.3011	0	85.4119	0	86.0568	0	78.9121	0	30.7896	2.8	
I0520 02:15:06.228989 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:15:06.231073 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:15:06.231109 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:15:06.231801 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35476
I0520 02:16:39.448583 15139 solver.cpp:231] Iteration 15400, loss = 1.31877
I0520 02:16:39.448850 15139 solver.cpp:247]     Train net output #0: loss = 1.31877 (* 1 = 1.31877 loss)
I0520 02:16:39.448870 15139 sgd_solver.cpp:106] Iteration 15400, lr = 0.001
I0520 02:16:39.608808 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7025	3.125	82.6631	0	91.2231	6.25	89.3008	0	85.4137	0	86.062	0	78.9192	0	30.7952	2.8	
I0520 02:16:39.683656 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:16:39.686115 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:16:39.686151 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:16:39.686736 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31877
I0520 02:17:57.238106 15139 solver.cpp:231] Iteration 15600, loss = 1.13733
I0520 02:17:57.238387 15139 solver.cpp:247]     Train net output #0: loss = 1.13733 (* 1 = 1.13733 loss)
I0520 02:17:57.238411 15139 sgd_solver.cpp:106] Iteration 15600, lr = 0.001
I0520 02:17:57.398403 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.714	3.125	82.6686	0	91.2242	6.25	89.3014	0	85.4149	0	86.0671	0	78.9261	0	30.8005	2.8	
I0520 02:17:57.473973 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:17:57.477109 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:17:57.477139 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:17:57.477672 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13733
I0520 02:19:20.231242 15139 solver.cpp:231] Iteration 15800, loss = 1.2723
I0520 02:19:20.231721 15139 solver.cpp:247]     Train net output #0: loss = 1.2723 (* 1 = 1.2723 loss)
I0520 02:19:20.231746 15139 sgd_solver.cpp:106] Iteration 15800, lr = 0.001
I0520 02:19:20.391962 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7226	3.125	82.6683	0	91.2235	6.25	89.3005	0	85.414	0	86.0722	0	78.9332	0	30.8057	2.8	
I0520 02:19:20.466840 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:19:20.469699 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:19:20.469738 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:19:20.470132 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2723
I0520 02:20:37.363803 15139 solver.cpp:348] Iteration 16000, Testing net (#0)
I0520 02:20:47.120277 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:21:59.843060 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55708
I0520 02:21:59.843294 15139 solver.cpp:415]     Test net output #1: loss = 1.91182 (* 1 = 1.91182 loss)
I0520 02:21:59.930945 15139 solver.cpp:231] Iteration 16000, loss = 1.38148
I0520 02:21:59.931020 15139 solver.cpp:247]     Train net output #0: loss = 1.38148 (* 1 = 1.38148 loss)
I0520 02:21:59.931038 15139 sgd_solver.cpp:106] Iteration 16000, lr = 0.001
I0520 02:22:00.095639 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7685	3.125	82.6748	0	91.2237	6.25	89.3015	0	85.4158	0	86.0772	0	78.9398	0	30.8109	2.8	
I0520 02:22:00.170164 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:22:00.172142 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:22:00.172163 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:22:00.172567 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.38148
I0520 02:22:44.732478 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:23:19.436868 15139 solver.cpp:231] Iteration 16200, loss = 1.253
I0520 02:23:19.437242 15139 solver.cpp:247]     Train net output #0: loss = 1.253 (* 1 = 1.253 loss)
I0520 02:23:19.437265 15139 sgd_solver.cpp:106] Iteration 16200, lr = 0.001
I0520 02:23:19.599102 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7685	3.125	82.6683	0	91.2237	6.25	89.3006	0	85.4155	0	86.0821	0	78.9466	0	30.8158	2.8	
I0520 02:23:19.674108 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:23:19.676378 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:23:19.676424 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:23:19.676966 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.253
I0520 02:24:40.728345 15139 solver.cpp:231] Iteration 16400, loss = 1.20418
I0520 02:24:40.729640 15139 solver.cpp:247]     Train net output #0: loss = 1.20418 (* 1 = 1.20418 loss)
I0520 02:24:40.729666 15139 sgd_solver.cpp:106] Iteration 16400, lr = 0.001
I0520 02:24:40.889488 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7742	3.125	82.6696	0	91.2233	6.25	89.3024	0	85.4171	0	86.0869	0	78.953	0	30.8209	2.8	
I0520 02:24:40.964598 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:24:40.967449 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:24:40.967497 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:24:40.968240 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20418
I0520 02:25:54.477772 15139 solver.cpp:231] Iteration 16600, loss = 1.5628
I0520 02:25:54.478130 15139 solver.cpp:247]     Train net output #0: loss = 1.5628 (* 1 = 1.5628 loss)
I0520 02:25:54.478157 15139 sgd_solver.cpp:106] Iteration 16600, lr = 0.001
I0520 02:25:54.639888 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7943	3.125	82.667	0	91.2238	6.25	89.3033	0	85.4171	0	86.0917	0	78.9596	0	30.8264	2.8	
I0520 02:25:54.715701 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:25:54.717418 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:25:54.717453 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:25:54.718215 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.5628
I0520 02:27:18.613831 15139 solver.cpp:231] Iteration 16800, loss = 1.34557
I0520 02:27:18.614918 15139 solver.cpp:247]     Train net output #0: loss = 1.34557 (* 1 = 1.34557 loss)
I0520 02:27:18.614940 15139 sgd_solver.cpp:106] Iteration 16800, lr = 0.001
I0520 02:27:18.772999 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7283	3.125	82.6683	0	91.2233	6.25	89.3018	0	85.4167	0	86.0968	0	78.9665	0	30.8313	2.8	
I0520 02:27:18.848155 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:27:18.851209 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:27:18.851271 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:27:18.851896 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34557
I0520 02:28:53.544736 15139 solver.cpp:348] Iteration 17000, Testing net (#0)
I0520 02:29:03.487233 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:30:09.390422 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55938
I0520 02:30:09.390704 15139 solver.cpp:415]     Test net output #1: loss = 1.89906 (* 1 = 1.89906 loss)
I0520 02:30:09.480412 15139 solver.cpp:231] Iteration 17000, loss = 1.43349
I0520 02:30:09.480505 15139 solver.cpp:247]     Train net output #0: loss = 1.43349 (* 1 = 1.43349 loss)
I0520 02:30:09.480526 15139 sgd_solver.cpp:106] Iteration 17000, lr = 0.001
I0520 02:30:09.646718 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.757	3.125	82.6657	0	91.2245	6.25	89.3021	0	85.4151	0	86.1014	0	78.973	0	30.8364	2.8	
I0520 02:30:09.721925 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:30:09.724220 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:30:09.724263 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:30:09.724838 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.43349
I0520 02:30:59.410215 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:31:28.558553 15139 solver.cpp:231] Iteration 17200, loss = 1.17318
I0520 02:31:28.558656 15139 solver.cpp:247]     Train net output #0: loss = 1.17318 (* 1 = 1.17318 loss)
I0520 02:31:28.558763 15139 sgd_solver.cpp:106] Iteration 17200, lr = 0.001
I0520 02:31:28.718559 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7886	3.125	82.6774	0	91.2247	6.25	89.3038	0	85.4178	0	86.1061	0	78.9796	0	30.8413	2.8	
I0520 02:31:28.794816 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:31:28.797384 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:31:28.797418 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:31:28.797977 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17318
I0520 02:32:47.122519 15139 solver.cpp:231] Iteration 17400, loss = 1.35063
I0520 02:32:47.122836 15139 solver.cpp:247]     Train net output #0: loss = 1.35063 (* 1 = 1.35063 loss)
I0520 02:32:47.122859 15139 sgd_solver.cpp:106] Iteration 17400, lr = 0.001
I0520 02:32:47.282768 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7197	3.125	82.668	0	91.2242	6.25	89.303	0	85.4162	0	86.1111	0	78.986	0	30.846	2.8	
I0520 02:32:47.357883 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:32:47.360818 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:32:47.360859 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:32:47.361389 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35063
I0520 02:34:17.866080 15139 solver.cpp:231] Iteration 17600, loss = 1.34591
I0520 02:34:17.866400 15139 solver.cpp:247]     Train net output #0: loss = 1.34591 (* 1 = 1.34591 loss)
I0520 02:34:17.866422 15139 sgd_solver.cpp:106] Iteration 17600, lr = 0.001
I0520 02:34:18.027042 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.691	3.125	82.666	0	91.2251	6.25	89.3024	0	85.4178	0	86.1159	0	78.9926	0	30.8514	2.8	
I0520 02:34:18.102478 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:34:18.105741 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:34:18.105787 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:34:18.106353 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34591
I0520 02:35:44.025243 15139 solver.cpp:231] Iteration 17800, loss = 1.41018
I0520 02:35:44.025534 15139 solver.cpp:247]     Train net output #0: loss = 1.41018 (* 1 = 1.41018 loss)
I0520 02:35:44.025591 15139 sgd_solver.cpp:106] Iteration 17800, lr = 0.001
I0520 02:35:44.186823 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8058	3.125	82.6755	0	91.2264	6.25	89.303	0	85.4169	0	86.1206	0	78.9993	0	30.8561	2.8	
I0520 02:35:44.261534 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:35:44.263043 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:35:44.263068 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:35:44.263604 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.41018
I0520 02:37:05.105324 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_18000.caffemodel
I0520 02:37:53.934675 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_18000.solverstate
I0520 02:37:54.620779 15139 solver.cpp:348] Iteration 18000, Testing net (#0)
I0520 02:38:05.794488 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:39:15.858921 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56036
I0520 02:39:15.859194 15139 solver.cpp:415]     Test net output #1: loss = 1.89413 (* 1 = 1.89413 loss)
I0520 02:39:15.951627 15139 solver.cpp:231] Iteration 18000, loss = 1.33378
I0520 02:39:15.951721 15139 solver.cpp:247]     Train net output #0: loss = 1.33378 (* 1 = 1.33378 loss)
I0520 02:39:15.951741 15139 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0520 02:39:16.122848 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8259	3.125	82.6771	0	91.2265	6.25	89.3047	0	85.4169	0	86.1253	0	79.0058	0	30.8611	2.8	
I0520 02:39:16.124996 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:39:16.127915 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:39:16.127964 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:39:16.128480 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33378
I0520 02:40:11.923467 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:40:39.354625 15139 solver.cpp:231] Iteration 18200, loss = 1.24864
I0520 02:40:39.354728 15139 solver.cpp:247]     Train net output #0: loss = 1.24864 (* 1 = 1.24864 loss)
I0520 02:40:39.354794 15139 sgd_solver.cpp:106] Iteration 18200, lr = 0.001
I0520 02:40:39.515504 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7713	3.125	82.6693	0	91.2263	6.25	89.3053	0	85.418	0	86.1301	0	79.0123	0	30.8667	2.8	
I0520 02:40:39.591995 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:40:39.594949 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:40:39.595001 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:40:39.595657 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24864
I0520 02:42:09.464206 15139 solver.cpp:231] Iteration 18400, loss = 1.17828
I0520 02:42:09.464460 15139 solver.cpp:247]     Train net output #0: loss = 1.17828 (* 1 = 1.17828 loss)
I0520 02:42:09.464483 15139 sgd_solver.cpp:106] Iteration 18400, lr = 0.001
I0520 02:42:09.624089 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7398	3.125	82.6702	0	91.2253	6.25	89.3053	0	85.4185	0	86.135	0	79.019	0	30.8718	2.8	
I0520 02:42:09.698909 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:42:09.701004 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:42:09.701038 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:42:09.701576 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17828
I0520 02:43:29.334069 15139 solver.cpp:231] Iteration 18600, loss = 1.40931
I0520 02:43:29.334302 15139 solver.cpp:247]     Train net output #0: loss = 1.40931 (* 1 = 1.40931 loss)
I0520 02:43:29.334326 15139 sgd_solver.cpp:106] Iteration 18600, lr = 0.001
I0520 02:43:29.495237 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8316	3.125	82.6751	0	91.2255	6.25	89.3041	0	85.4194	0	86.1399	0	79.0258	0	30.8775	2.8	
I0520 02:43:29.570412 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:43:29.572296 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:43:29.572340 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:43:29.572873 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.40931
I0520 02:44:44.303498 15139 solver.cpp:231] Iteration 18800, loss = 1.44492
I0520 02:44:44.307456 15139 solver.cpp:247]     Train net output #0: loss = 1.44492 (* 1 = 1.44492 loss)
I0520 02:44:44.307490 15139 sgd_solver.cpp:106] Iteration 18800, lr = 0.001
I0520 02:44:44.465749 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8058	3.125	82.6729	0	91.2269	6.25	89.3041	0	85.4212	0	86.1445	0	79.0322	0	30.8824	2.8	
I0520 02:44:44.540493 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:44:44.542403 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:44:44.542440 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:44:44.543016 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.44492
I0520 02:45:58.004896 15139 solver.cpp:348] Iteration 19000, Testing net (#0)
I0520 02:46:10.935142 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:47:18.028086 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55868
I0520 02:47:18.028457 15139 solver.cpp:415]     Test net output #1: loss = 1.9013 (* 1 = 1.9013 loss)
I0520 02:47:18.116199 15139 solver.cpp:231] Iteration 19000, loss = 1.35213
I0520 02:47:18.116279 15139 solver.cpp:247]     Train net output #0: loss = 1.35213 (* 1 = 1.35213 loss)
I0520 02:47:18.116297 15139 sgd_solver.cpp:106] Iteration 19000, lr = 0.001
I0520 02:47:18.284970 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8775	3.125	82.6712	0	91.2283	6.25	89.3062	0	85.421	0	86.149	0	79.039	0	30.8874	2.8	
I0520 02:47:18.360357 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:47:18.363447 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:47:18.363489 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:47:18.364059 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35213
I0520 02:48:11.197840 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:48:43.184799 15139 solver.cpp:231] Iteration 19200, loss = 1.49215
I0520 02:48:43.185151 15139 solver.cpp:247]     Train net output #0: loss = 1.49215 (* 1 = 1.49215 loss)
I0520 02:48:43.185173 15139 sgd_solver.cpp:106] Iteration 19200, lr = 0.001
I0520 02:48:43.343307 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7312	3.125	82.6699	0	91.2305	6.25	89.3071	0	85.4223	0	86.1537	0	79.0454	0	30.8928	2.8	
I0520 02:48:43.418890 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:48:43.422256 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:48:43.422308 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:48:43.422902 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.49215
I0520 02:50:00.319347 15139 solver.cpp:231] Iteration 19400, loss = 1.34185
I0520 02:50:00.319656 15139 solver.cpp:247]     Train net output #0: loss = 1.34185 (* 1 = 1.34185 loss)
I0520 02:50:00.319677 15139 sgd_solver.cpp:106] Iteration 19400, lr = 0.001
I0520 02:50:00.481868 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7398	3.125	82.6615	0	91.2285	6.25	89.3068	0	85.4223	0	86.1584	0	79.0516	0	30.8987	2.8	
I0520 02:50:00.562582 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:50:00.565587 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:50:00.565636 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:50:00.566417 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34185
I0520 02:51:14.782250 15139 solver.cpp:231] Iteration 19600, loss = 1.28034
I0520 02:51:14.784104 15139 solver.cpp:247]     Train net output #0: loss = 1.28034 (* 1 = 1.28034 loss)
I0520 02:51:14.784129 15139 sgd_solver.cpp:106] Iteration 19600, lr = 0.001
I0520 02:51:14.944571 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.734	3.125	82.6715	0	91.2302	6.25	89.3063	0	85.4223	0	86.1633	0	79.0583	0	30.9038	2.8	
I0520 02:51:15.019438 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:51:15.021168 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:51:15.021196 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:51:15.021776 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28034
I0520 02:52:31.292099 15139 solver.cpp:231] Iteration 19800, loss = 1.31489
I0520 02:52:31.292387 15139 solver.cpp:247]     Train net output #0: loss = 1.31489 (* 1 = 1.31489 loss)
I0520 02:52:31.292408 15139 sgd_solver.cpp:106] Iteration 19800, lr = 0.001
I0520 02:52:31.452994 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.757	3.125	82.6689	0	91.2282	6.25	89.3074	0	85.4214	0	86.168	0	79.0646	0	30.9091	2.8	
I0520 02:52:31.528905 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:52:31.530578 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:52:31.530614 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:52:31.531178 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31489
I0520 02:53:48.040848 15139 solver.cpp:348] Iteration 20000, Testing net (#0)
I0520 02:53:59.430434 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:54:59.876176 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55992
I0520 02:54:59.876575 15139 solver.cpp:415]     Test net output #1: loss = 1.90485 (* 1 = 1.90485 loss)
I0520 02:54:59.967739 15139 solver.cpp:231] Iteration 20000, loss = 1.15492
I0520 02:54:59.967818 15139 solver.cpp:247]     Train net output #0: loss = 1.15492 (* 1 = 1.15492 loss)
I0520 02:54:59.967839 15139 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0520 02:55:00.135843 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7283	3.125	82.6553	0	91.2297	6.25	89.3078	0	85.4205	0	86.1727	0	79.0711	0	30.914	2.8	
I0520 02:55:00.210731 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:55:00.212729 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:55:00.212766 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:55:00.213367 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15492
I0520 02:55:52.953197 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 02:56:12.686831 15139 solver.cpp:231] Iteration 20200, loss = 1.35742
I0520 02:56:12.686913 15139 solver.cpp:247]     Train net output #0: loss = 1.35742 (* 1 = 1.35742 loss)
I0520 02:56:12.686935 15139 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0520 02:56:12.847899 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8058	3.125	82.6735	0	91.2291	6.25	89.3077	0	85.4207	0	86.1772	0	79.0776	0	30.9195	2.8	
I0520 02:56:12.926826 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:56:12.928395 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:56:12.928422 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:56:12.928869 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35742
I0520 02:57:28.608386 15139 solver.cpp:231] Iteration 20400, loss = 1.29476
I0520 02:57:28.609618 15139 solver.cpp:247]     Train net output #0: loss = 1.29476 (* 1 = 1.29476 loss)
I0520 02:57:28.609654 15139 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0520 02:57:28.770833 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8201	3.125	82.6585	0	91.2282	6.25	89.308	0	85.4216	0	86.1817	0	79.0842	0	30.9249	2.8	
I0520 02:57:28.847470 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:57:28.850451 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:57:28.850514 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:57:28.851380 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.29476
I0520 02:58:59.172466 15139 solver.cpp:231] Iteration 20600, loss = 1.34981
I0520 02:58:59.172916 15139 solver.cpp:247]     Train net output #0: loss = 1.34981 (* 1 = 1.34981 loss)
I0520 02:58:59.172950 15139 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0520 02:58:59.332188 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.823	3.125	82.6589	0	91.229	6.25	89.3075	0	85.4205	0	86.1863	0	79.0907	0	30.9304	2.8	
I0520 02:58:59.407594 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 02:58:59.409909 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 02:58:59.409955 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 02:58:59.410507 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34981
I0520 03:00:21.340293 15139 solver.cpp:231] Iteration 20800, loss = 1.26182
I0520 03:00:21.340574 15139 solver.cpp:247]     Train net output #0: loss = 1.26182 (* 1 = 1.26182 loss)
I0520 03:00:21.340596 15139 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0520 03:00:21.500344 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7283	3.125	82.665	0	91.2288	6.25	89.3066	0	85.4207	0	86.1908	0	79.0973	0	30.9355	2.8	
I0520 03:00:21.575377 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:00:21.578099 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:00:21.578174 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:00:21.578685 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26182
I0520 03:01:59.064512 15139 solver.cpp:348] Iteration 21000, Testing net (#0)
I0520 03:02:11.670332 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:03:17.050556 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55956
I0520 03:03:17.053654 15139 solver.cpp:415]     Test net output #1: loss = 1.89657 (* 1 = 1.89657 loss)
I0520 03:03:17.144860 15139 solver.cpp:231] Iteration 21000, loss = 1.21621
I0520 03:03:17.144944 15139 solver.cpp:247]     Train net output #0: loss = 1.21621 (* 1 = 1.21621 loss)
I0520 03:03:17.144965 15139 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0520 03:03:17.309901 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8775	3.125	82.6729	0	91.2294	6.25	89.3078	0	85.4212	0	86.1955	0	79.1038	0	30.941	2.8	
I0520 03:03:17.385293 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:03:17.388332 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:03:17.388377 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:03:17.389001 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21621
I0520 03:04:21.665207 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:04:40.416859 15139 solver.cpp:231] Iteration 21200, loss = 1.33126
I0520 03:04:40.416965 15139 solver.cpp:247]     Train net output #0: loss = 1.33126 (* 1 = 1.33126 loss)
I0520 03:04:40.416988 15139 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0520 03:04:40.575919 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8919	3.125	82.6712	0	91.2298	6.25	89.3074	0	85.4219	0	86.2	0	79.11	0	30.9472	2.8	
I0520 03:04:40.651212 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:04:40.653393 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:04:40.653419 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:04:40.653923 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33126
I0520 03:06:01.042469 15139 solver.cpp:231] Iteration 21400, loss = 1.03525
I0520 03:06:01.045641 15139 solver.cpp:247]     Train net output #0: loss = 1.03525 (* 1 = 1.03525 loss)
I0520 03:06:01.045675 15139 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0520 03:06:01.205135 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7599	3.125	82.6689	0	91.2285	6.25	89.308	0	85.421	0	86.2046	0	79.1162	0	30.9519	2.8	
I0520 03:06:01.283124 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:06:01.285877 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:06:01.285913 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:06:01.286578 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.03525
I0520 03:07:26.089059 15139 solver.cpp:231] Iteration 21600, loss = 1.06786
I0520 03:07:26.090553 15139 solver.cpp:247]     Train net output #0: loss = 1.06786 (* 1 = 1.06786 loss)
I0520 03:07:26.090580 15139 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0520 03:07:26.251081 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7599	3.125	82.6706	0	91.23	6.25	89.3095	0	85.4219	0	86.209	0	79.1226	0	30.9566	2.8	
I0520 03:07:26.326319 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:07:26.328192 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:07:26.328227 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:07:26.328996 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.06786
I0520 03:08:43.887887 15139 solver.cpp:231] Iteration 21800, loss = 1.11883
I0520 03:08:43.888308 15139 solver.cpp:247]     Train net output #0: loss = 1.11883 (* 1 = 1.11883 loss)
I0520 03:08:43.888329 15139 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0520 03:08:44.050067 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.866	3.125	82.6715	0	91.2294	6.25	89.3098	0	85.4205	0	86.2136	0	79.1289	0	30.9623	2.8	
I0520 03:08:44.126224 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:08:44.129391 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:08:44.129427 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:08:44.130147 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11883
I0520 03:10:03.657798 15139 solver.cpp:348] Iteration 22000, Testing net (#0)
I0520 03:10:16.642287 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:11:26.944555 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55488
I0520 03:11:26.945605 15139 solver.cpp:415]     Test net output #1: loss = 1.92233 (* 1 = 1.92233 loss)
I0520 03:11:27.035714 15139 solver.cpp:231] Iteration 22000, loss = 1.2761
I0520 03:11:27.035784 15139 solver.cpp:247]     Train net output #0: loss = 1.2761 (* 1 = 1.2761 loss)
I0520 03:11:27.035805 15139 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0520 03:11:27.203814 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7427	3.125	82.6702	0	91.2306	6.25	89.3106	0	85.4228	0	86.2183	0	79.1353	0	30.9678	2.8	
I0520 03:11:27.278724 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:11:27.280338 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:11:27.280362 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:11:27.280899 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2761
I0520 03:12:35.194236 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:12:49.260172 15139 solver.cpp:231] Iteration 22200, loss = 1.23631
I0520 03:12:49.260304 15139 solver.cpp:247]     Train net output #0: loss = 1.23631 (* 1 = 1.23631 loss)
I0520 03:12:49.260330 15139 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0520 03:12:49.421906 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.6881	3.125	82.6667	0	91.2313	6.25	89.3107	0	85.4225	0	86.2226	0	79.1416	0	30.9729	2.8	
I0520 03:12:49.497944 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:12:49.500107 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:12:49.500128 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:12:49.500598 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23631
I0520 03:14:10.674747 15139 solver.cpp:231] Iteration 22400, loss = 1.2861
I0520 03:14:10.677741 15139 solver.cpp:247]     Train net output #0: loss = 1.2861 (* 1 = 1.2861 loss)
I0520 03:14:10.677770 15139 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0520 03:14:10.835646 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.757	3.125	82.6689	0	91.2298	6.25	89.3094	0	85.4214	0	86.2272	0	79.1479	0	30.9781	2.8	
I0520 03:14:10.912077 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:14:10.914536 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:14:10.914578 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:14:10.915352 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2861
I0520 03:15:39.212759 15139 solver.cpp:231] Iteration 22600, loss = 1.57885
I0520 03:15:39.217639 15139 solver.cpp:247]     Train net output #0: loss = 1.57885 (* 1 = 1.57885 loss)
I0520 03:15:39.217671 15139 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0520 03:15:39.372411 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7513	3.125	82.6742	0	91.2303	6.25	89.3109	0	85.4225	0	86.2317	0	79.1541	0	30.9835	2.8	
I0520 03:15:39.447509 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:15:39.449194 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:15:39.449224 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:15:39.449751 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.57885
I0520 03:17:04.400930 15139 solver.cpp:231] Iteration 22800, loss = 1.33874
I0520 03:17:04.401209 15139 solver.cpp:247]     Train net output #0: loss = 1.33874 (* 1 = 1.33874 loss)
I0520 03:17:04.401232 15139 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0520 03:17:04.561362 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8058	3.125	82.6745	0	91.2312	6.25	89.311	0	85.423	0	86.2364	0	79.1608	0	30.9883	2.8	
I0520 03:17:04.636175 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:17:04.638159 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:17:04.638196 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:17:04.638689 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33874
I0520 03:18:21.766225 15139 solver.cpp:348] Iteration 23000, Testing net (#0)
I0520 03:18:39.736184 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:19:49.712412 15139 solver.cpp:415]     Test net output #0: accuracy = 0.559539
I0520 03:19:49.713609 15139 solver.cpp:415]     Test net output #1: loss = 1.89685 (* 1 = 1.89685 loss)
I0520 03:19:49.801208 15139 solver.cpp:231] Iteration 23000, loss = 1.17105
I0520 03:19:49.801290 15139 solver.cpp:247]     Train net output #0: loss = 1.17105 (* 1 = 1.17105 loss)
I0520 03:19:49.801311 15139 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0520 03:19:49.970950 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.846	3.125	82.6768	0	91.2321	6.25	89.3116	0	85.4234	0	86.2407	0	79.1671	0	30.9927	2.8	
I0520 03:19:50.045853 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:19:50.048192 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:19:50.048233 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:19:50.048759 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17105
I0520 03:20:53.929960 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:21:05.394811 15139 solver.cpp:231] Iteration 23200, loss = 1.32856
I0520 03:21:05.394901 15139 solver.cpp:247]     Train net output #0: loss = 1.32856 (* 1 = 1.32856 loss)
I0520 03:21:05.394923 15139 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0520 03:21:05.558403 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8718	3.125	82.6732	0	91.2323	6.25	89.3107	0	85.4228	0	86.2452	0	79.1732	0	30.9973	2.8	
I0520 03:21:05.633268 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:21:05.635128 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:21:05.635157 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:21:05.635651 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32856
I0520 03:22:38.405192 15139 solver.cpp:231] Iteration 23400, loss = 1.36827
I0520 03:22:38.405426 15139 solver.cpp:247]     Train net output #0: loss = 1.36827 (* 1 = 1.36827 loss)
I0520 03:22:38.405462 15139 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0520 03:22:38.566699 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7599	3.125	82.6719	0	91.2322	6.25	89.311	0	85.4219	0	86.2497	0	79.1797	0	31.0025	2.8	
I0520 03:22:38.641795 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:22:38.644033 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:22:38.644104 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:22:38.644697 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.36827
I0520 03:24:05.135483 15139 solver.cpp:231] Iteration 23600, loss = 1.31952
I0520 03:24:05.135920 15139 solver.cpp:247]     Train net output #0: loss = 1.31952 (* 1 = 1.31952 loss)
I0520 03:24:05.135951 15139 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0520 03:24:05.298079 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9005	3.125	82.6709	0	91.2312	6.25	89.3118	0	85.4221	0	86.2541	0	79.1858	0	31.0071	2.8	
I0520 03:24:05.374536 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:24:05.376952 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:24:05.376991 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:24:05.377774 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31952
I0520 03:25:26.905701 15139 solver.cpp:231] Iteration 23800, loss = 1.51931
I0520 03:25:26.913676 15139 solver.cpp:247]     Train net output #0: loss = 1.51931 (* 1 = 1.51931 loss)
I0520 03:25:26.913712 15139 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0520 03:25:27.066216 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8287	3.125	82.6755	0	91.2312	6.25	89.3104	0	85.4203	0	86.2583	0	79.1918	0	31.0123	2.8	
I0520 03:25:27.141396 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:25:27.144040 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:25:27.144083 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:25:27.144575 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.51931
I0520 03:26:44.992813 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_24000.caffemodel
I0520 03:27:02.619350 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_24000.solverstate
I0520 03:27:03.099599 15139 solver.cpp:348] Iteration 24000, Testing net (#0)
I0520 03:27:16.332015 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:28:17.524092 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5579
I0520 03:28:17.524348 15139 solver.cpp:415]     Test net output #1: loss = 1.89929 (* 1 = 1.89929 loss)
I0520 03:28:17.615555 15139 solver.cpp:231] Iteration 24000, loss = 1.32779
I0520 03:28:17.615623 15139 solver.cpp:247]     Train net output #0: loss = 1.32779 (* 1 = 1.32779 loss)
I0520 03:28:17.615641 15139 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0520 03:28:17.776357 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7828	3.125	82.6742	0	91.2323	6.25	89.3109	0	85.4203	0	86.2627	0	79.1976	0	31.0176	2.8	
I0520 03:28:17.777976 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:28:17.779813 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:28:17.779842 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:28:17.780624 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32779
I0520 03:29:24.183979 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:29:34.216940 15139 solver.cpp:231] Iteration 24200, loss = 1.13833
I0520 03:29:34.217042 15139 solver.cpp:247]     Train net output #0: loss = 1.13833 (* 1 = 1.13833 loss)
I0520 03:29:34.217062 15139 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0520 03:29:34.375252 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9751	3.125	82.6706	0	91.2322	6.25	89.3115	0	85.4216	0	86.267	0	79.2036	0	31.0232	2.8	
I0520 03:29:34.450590 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:29:34.453708 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:29:34.453752 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:29:34.454277 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13833
I0520 03:30:55.158848 15139 solver.cpp:231] Iteration 24400, loss = 1.45159
I0520 03:30:55.159286 15139 solver.cpp:247]     Train net output #0: loss = 1.45159 (* 1 = 1.45159 loss)
I0520 03:30:55.159307 15139 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0520 03:30:55.321477 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9607	3.125	82.6709	0	91.2325	6.25	89.3113	0	85.4219	0	86.2713	0	79.2099	0	31.0282	2.8	
I0520 03:30:55.397409 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:30:55.399684 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:30:55.399732 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:30:55.400498 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.45159
I0520 03:32:11.274112 15139 solver.cpp:231] Iteration 24600, loss = 1.20001
I0520 03:32:11.274426 15139 solver.cpp:247]     Train net output #0: loss = 1.20001 (* 1 = 1.20001 loss)
I0520 03:32:11.274449 15139 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0520 03:32:11.436748 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9837	3.125	82.6644	0	91.2311	6.25	89.31	0	85.4228	0	86.2756	0	79.2162	0	31.0325	2.8	
I0520 03:32:11.517694 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:32:11.520781 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:32:11.520822 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:32:11.521520 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20001
I0520 03:33:28.564435 15139 solver.cpp:231] Iteration 24800, loss = 1.39785
I0520 03:33:28.564633 15139 solver.cpp:247]     Train net output #0: loss = 1.39785 (* 1 = 1.39785 loss)
I0520 03:33:28.564654 15139 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0520 03:33:28.726832 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8402	3.125	82.667	0	91.2308	6.25	89.3092	0	85.4207	0	86.2799	0	79.2221	0	31.0388	2.8	
I0520 03:33:28.805042 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:33:28.808655 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:33:28.808704 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:33:28.809373 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.39785
I0520 03:34:48.567711 15139 solver.cpp:348] Iteration 25000, Testing net (#0)
I0520 03:35:01.671090 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:36:05.546172 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5587
I0520 03:36:05.550775 15139 solver.cpp:415]     Test net output #1: loss = 1.88987 (* 1 = 1.88987 loss)
I0520 03:36:05.643496 15139 solver.cpp:231] Iteration 25000, loss = 1.44821
I0520 03:36:05.643578 15139 solver.cpp:247]     Train net output #0: loss = 1.44821 (* 1 = 1.44821 loss)
I0520 03:36:05.643600 15139 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0520 03:36:05.808099 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9923	3.125	82.6706	0	91.2321	6.25	89.3092	0	85.4219	0	86.2843	0	79.2282	0	31.0429	2.8	
I0520 03:36:05.883056 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:36:05.885215 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:36:05.885259 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:36:05.885881 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.44821
I0520 03:37:20.748819 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:37:27.738685 15139 solver.cpp:231] Iteration 25200, loss = 1.1616
I0520 03:37:27.738806 15139 solver.cpp:247]     Train net output #0: loss = 1.1616 (* 1 = 1.1616 loss)
I0520 03:37:27.738826 15139 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0520 03:37:27.898699 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9464	3.125	82.6803	0	91.2334	6.25	89.3092	0	85.4225	0	86.2882	0	79.2341	0	31.0485	2.8	
I0520 03:37:27.973961 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:37:27.976312 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:37:27.976346 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:37:27.976845 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1616
I0520 03:38:47.733644 15139 solver.cpp:231] Iteration 25400, loss = 1.3042
I0520 03:38:47.733876 15139 solver.cpp:247]     Train net output #0: loss = 1.3042 (* 1 = 1.3042 loss)
I0520 03:38:47.733898 15139 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0520 03:38:47.895579 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9177	3.125	82.668	0	91.2329	6.25	89.3098	0	85.4232	0	86.2925	0	79.2405	0	31.053	2.8	
I0520 03:38:47.970744 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:38:47.972650 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:38:47.972683 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:38:47.973217 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.3042
I0520 03:40:06.823521 15139 solver.cpp:231] Iteration 25600, loss = 1.34076
I0520 03:40:06.828080 15139 solver.cpp:247]     Train net output #0: loss = 1.34076 (* 1 = 1.34076 loss)
I0520 03:40:06.828114 15139 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0520 03:40:06.985306 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8689	3.125	82.6683	0	91.2349	6.25	89.3112	0	85.4219	0	86.2967	0	79.2467	0	31.0586	2.8	
I0520 03:40:07.060312 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:40:07.061995 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:40:07.062028 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:40:07.062559 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34076
I0520 03:41:29.656796 15139 solver.cpp:231] Iteration 25800, loss = 1.15614
I0520 03:41:29.661639 15139 solver.cpp:247]     Train net output #0: loss = 1.15614 (* 1 = 1.15614 loss)
I0520 03:41:29.661669 15139 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0520 03:41:29.816797 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9034	3.125	82.6758	0	91.2339	6.25	89.3113	0	85.4221	0	86.3011	0	79.2527	0	31.0632	2.8	
I0520 03:41:29.891630 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:41:29.893704 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:41:29.893734 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:41:29.894237 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15614
I0520 03:42:49.586145 15139 solver.cpp:348] Iteration 26000, Testing net (#0)
I0520 03:43:04.056099 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:44:14.452947 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56
I0520 03:44:14.453287 15139 solver.cpp:415]     Test net output #1: loss = 1.8928 (* 1 = 1.8928 loss)
I0520 03:44:14.544548 15139 solver.cpp:231] Iteration 26000, loss = 1.41439
I0520 03:44:14.544618 15139 solver.cpp:247]     Train net output #0: loss = 1.41439 (* 1 = 1.41439 loss)
I0520 03:44:14.544637 15139 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0520 03:44:14.711864 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9234	3.125	82.679	0	91.2341	6.25	89.3124	0	85.4237	0	86.3054	0	79.2588	0	31.0686	2.8	
I0520 03:44:14.786604 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:44:14.788285 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:44:14.788318 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:44:14.788875 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.41439
I0520 03:45:36.350976 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:45:41.681015 15139 solver.cpp:231] Iteration 26200, loss = 1.2344
I0520 03:45:41.681143 15139 solver.cpp:247]     Train net output #0: loss = 1.2344 (* 1 = 1.2344 loss)
I0520 03:45:41.681324 15139 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0520 03:45:41.841051 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9034	3.125	82.6732	0	91.2349	6.25	89.3112	0	85.4259	0	86.3099	0	79.265	0	31.0745	2.8	
I0520 03:45:41.916702 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:45:41.920068 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:45:41.920115 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:45:41.920609 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2344
I0520 03:47:03.908102 15139 solver.cpp:231] Iteration 26400, loss = 1.26648
I0520 03:47:03.908454 15139 solver.cpp:247]     Train net output #0: loss = 1.26648 (* 1 = 1.26648 loss)
I0520 03:47:03.908475 15139 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0520 03:47:04.068388 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7541	3.125	82.6869	0	91.2361	6.25	89.3131	0	85.4271	0	86.3139	0	79.2711	0	31.079	2.8	
I0520 03:47:04.143606 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:47:04.146713 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:47:04.146770 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:47:04.147296 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26648
I0520 03:48:20.395779 15139 solver.cpp:231] Iteration 26600, loss = 1.41693
I0520 03:48:20.396071 15139 solver.cpp:247]     Train net output #0: loss = 1.41693 (* 1 = 1.41693 loss)
I0520 03:48:20.396092 15139 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0520 03:48:20.557662 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.823	3.125	82.6852	0	91.2346	6.25	89.313	0	85.425	0	86.3182	0	79.2773	0	31.0838	2.8	
I0520 03:48:20.633498 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:48:20.635164 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:48:20.635195 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:48:20.635807 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.41693
I0520 03:49:37.417619 15139 solver.cpp:231] Iteration 26800, loss = 1.13975
I0520 03:49:37.417879 15139 solver.cpp:247]     Train net output #0: loss = 1.13975 (* 1 = 1.13975 loss)
I0520 03:49:37.418040 15139 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0520 03:49:37.580482 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8058	3.125	82.6895	0	91.2341	6.25	89.3131	0	85.4257	0	86.3225	0	79.2832	0	31.0885	2.8	
I0520 03:49:37.656383 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:49:37.658520 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:49:37.658555 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:49:37.659092 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13975
I0520 03:50:57.346200 15139 solver.cpp:348] Iteration 27000, Testing net (#0)
I0520 03:51:15.855670 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:52:17.178900 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5568
I0520 03:52:17.179152 15139 solver.cpp:415]     Test net output #1: loss = 1.91206 (* 1 = 1.91206 loss)
I0520 03:52:17.266338 15139 solver.cpp:231] Iteration 27000, loss = 1.31696
I0520 03:52:17.266417 15139 solver.cpp:247]     Train net output #0: loss = 1.31696 (* 1 = 1.31696 loss)
I0520 03:52:17.266435 15139 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0520 03:52:17.426457 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8115	3.125	82.6748	0	91.2334	6.25	89.3125	0	85.4259	0	86.3268	0	79.2894	0	31.0934	2.8	
I0520 03:52:17.502885 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:52:17.504706 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:52:17.504742 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:52:17.505254 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31696
I0520 03:53:34.939687 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 03:53:36.024279 15139 solver.cpp:231] Iteration 27200, loss = 1.17464
I0520 03:53:36.024390 15139 solver.cpp:247]     Train net output #0: loss = 1.17464 (* 1 = 1.17464 loss)
I0520 03:53:36.024408 15139 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0520 03:53:36.184303 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8747	3.125	82.6875	0	91.2359	6.25	89.3142	0	85.4264	0	86.3309	0	79.2957	0	31.0978	2.8	
I0520 03:53:36.260598 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:53:36.264017 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:53:36.264068 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:53:36.264853 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17464
I0520 03:54:59.976795 15139 solver.cpp:231] Iteration 27400, loss = 1.20891
I0520 03:54:59.976989 15139 solver.cpp:247]     Train net output #0: loss = 1.20891 (* 1 = 1.20891 loss)
I0520 03:54:59.977010 15139 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0520 03:55:00.138195 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8603	3.125	82.6761	0	91.2356	6.25	89.3148	0	85.4268	0	86.3352	0	79.3014	0	31.1024	2.8	
I0520 03:55:00.217306 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:55:00.219228 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:55:00.219262 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:55:00.219887 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20891
I0520 03:56:24.721734 15139 solver.cpp:231] Iteration 27600, loss = 1.18188
I0520 03:56:24.722298 15139 solver.cpp:247]     Train net output #0: loss = 1.18188 (* 1 = 1.18188 loss)
I0520 03:56:24.722319 15139 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0520 03:56:24.881716 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8976	3.125	82.6768	0	91.2369	6.25	89.3136	0	85.4282	0	86.3393	0	79.3072	0	31.1072	2.8	
I0520 03:56:24.956635 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:56:24.958813 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:56:24.958850 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:56:24.959369 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18188
I0520 03:57:48.816741 15139 solver.cpp:231] Iteration 27800, loss = 1.26041
I0520 03:57:48.817054 15139 solver.cpp:247]     Train net output #0: loss = 1.26041 (* 1 = 1.26041 loss)
I0520 03:57:48.817075 15139 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0520 03:57:48.977691 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7226	3.125	82.6751	0	91.2377	6.25	89.3154	0	85.4286	0	86.3434	0	79.3133	0	31.1116	2.8	
I0520 03:57:49.053864 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 03:57:49.056262 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 03:57:49.056308 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 03:57:49.056958 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26041
I0520 03:59:15.669435 15139 solver.cpp:348] Iteration 28000, Testing net (#0)
I0520 03:59:33.790925 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:00:39.658967 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55854
I0520 04:00:39.665441 15139 solver.cpp:415]     Test net output #1: loss = 1.89836 (* 1 = 1.89836 loss)
I0520 04:00:39.778025 15139 solver.cpp:231] Iteration 28000, loss = 1.35696
I0520 04:00:39.778226 15139 solver.cpp:247]     Train net output #0: loss = 1.35696 (* 1 = 1.35696 loss)
I0520 04:00:39.778250 15139 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0520 04:00:39.942519 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8115	3.125	82.6781	0	91.2359	6.25	89.3157	0	85.4286	0	86.3477	0	79.3193	0	31.1174	2.8	
I0520 04:00:40.016952 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:00:40.024732 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:00:40.024791 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:00:40.025509 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35696
I0520 04:02:03.314741 15139 solver.cpp:231] Iteration 28200, loss = 1.42564
I0520 04:02:03.315032 15139 solver.cpp:247]     Train net output #0: loss = 1.42564 (* 1 = 1.42564 loss)
I0520 04:02:03.315059 15139 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0520 04:02:03.473989 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8976	3.125	82.6706	0	91.2343	6.25	89.3161	0	85.4314	0	86.352	0	79.3254	0	31.122	2.8	
I0520 04:02:03.550596 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:02:03.553527 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:02:03.553583 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:02:03.554244 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.42564
I0520 04:02:04.809998 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:03:19.837218 15139 solver.cpp:231] Iteration 28400, loss = 1.36907
I0520 04:03:19.837476 15139 solver.cpp:247]     Train net output #0: loss = 1.36907 (* 1 = 1.36907 loss)
I0520 04:03:19.837509 15139 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0520 04:03:20.010918 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9435	3.125	82.6758	0	91.2358	6.25	89.3166	0	85.4291	0	86.3559	0	79.3311	0	31.1271	2.8	
I0520 04:03:20.089000 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:03:20.090701 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:03:20.090734 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:03:20.091331 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.36907
I0520 04:04:42.401741 15139 solver.cpp:231] Iteration 28600, loss = 1.21287
I0520 04:04:42.402148 15139 solver.cpp:247]     Train net output #0: loss = 1.21287 (* 1 = 1.21287 loss)
I0520 04:04:42.402169 15139 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0520 04:04:42.561949 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9177	3.125	82.6803	0	91.2373	6.25	89.3166	0	85.4289	0	86.36	0	79.3373	0	31.1319	2.8	
I0520 04:04:42.636970 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:04:42.638839 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:04:42.638871 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:04:42.639377 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21287
I0520 04:06:02.029312 15139 solver.cpp:231] Iteration 28800, loss = 1.41271
I0520 04:06:02.029769 15139 solver.cpp:247]     Train net output #0: loss = 1.41271 (* 1 = 1.41271 loss)
I0520 04:06:02.029793 15139 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0520 04:06:02.189719 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9005	3.125	82.6833	0	91.238	6.25	89.3175	0	85.4291	0	86.364	0	79.3429	0	31.1371	2.8	
I0520 04:06:02.269389 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:06:02.272330 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:06:02.272379 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:06:02.273200 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.41271
I0520 04:07:29.689384 15139 solver.cpp:348] Iteration 29000, Testing net (#0)
I0520 04:07:48.144753 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:08:44.697783 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55924
I0520 04:08:44.698079 15139 solver.cpp:415]     Test net output #1: loss = 1.89897 (* 1 = 1.89897 loss)
I0520 04:08:44.785966 15139 solver.cpp:231] Iteration 29000, loss = 1.29888
I0520 04:08:44.786051 15139 solver.cpp:247]     Train net output #0: loss = 1.29888 (* 1 = 1.29888 loss)
I0520 04:08:44.786072 15139 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0520 04:08:44.952765 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9751	3.125	82.6865	0	91.2366	6.25	89.3173	0	85.4289	0	86.3679	0	79.349	0	31.1413	2.8	
I0520 04:08:45.028071 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:08:45.030215 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:08:45.030249 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:08:45.030906 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.29888
I0520 04:09:57.923368 15139 solver.cpp:231] Iteration 29200, loss = 1.23822
I0520 04:09:57.923668 15139 solver.cpp:247]     Train net output #0: loss = 1.23822 (* 1 = 1.23822 loss)
I0520 04:09:57.923830 15139 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0520 04:09:58.085317 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0009	3.125	82.6784	0	91.2373	6.25	89.3178	0	85.4291	0	86.3719	0	79.355	0	31.1458	2.8	
I0520 04:09:58.160949 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:09:58.163506 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:09:58.163535 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:09:58.164118 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23822
I0520 04:10:01.954113 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:11:12.732246 15139 solver.cpp:231] Iteration 29400, loss = 1.34549
I0520 04:11:12.732504 15139 solver.cpp:247]     Train net output #0: loss = 1.34549 (* 1 = 1.34549 loss)
I0520 04:11:12.732525 15139 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0520 04:11:12.893964 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9722	3.125	82.6807	0	91.2361	6.25	89.3172	0	85.4296	0	86.376	0	79.361	0	31.151	2.8	
I0520 04:11:12.969799 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:11:12.972532 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:11:12.972561 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:11:12.973160 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34549
I0520 04:12:28.498770 15139 solver.cpp:231] Iteration 29600, loss = 1.11663
I0520 04:12:28.499140 15139 solver.cpp:247]     Train net output #0: loss = 1.11663 (* 1 = 1.11663 loss)
I0520 04:12:28.499174 15139 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0520 04:12:28.660176 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0009	3.125	82.6696	0	91.2365	6.25	89.3175	0	85.43	0	86.3802	0	79.3668	0	31.1558	2.8	
I0520 04:12:28.735049 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:12:28.737175 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:12:28.737205 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:12:28.737723 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11663
I0520 04:13:50.546119 15139 solver.cpp:231] Iteration 29800, loss = 1.39423
I0520 04:13:50.546425 15139 solver.cpp:247]     Train net output #0: loss = 1.39423 (* 1 = 1.39423 loss)
I0520 04:13:50.546448 15139 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0520 04:13:50.707895 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9464	3.125	82.6745	0	91.2376	6.25	89.3181	0	85.43	0	86.3844	0	79.3729	0	31.1605	2.8	
I0520 04:13:50.783659 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:13:50.786304 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:13:50.786345 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:13:50.786918 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.39423
I0520 04:15:07.299120 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_30000.caffemodel
I0520 04:15:41.922663 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_30000.solverstate
I0520 04:15:42.479215 15139 solver.cpp:348] Iteration 30000, Testing net (#0)
I0520 04:15:58.404675 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:16:57.004824 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55718
I0520 04:16:57.005115 15139 solver.cpp:415]     Test net output #1: loss = 1.90062 (* 1 = 1.90062 loss)
I0520 04:16:57.092968 15139 solver.cpp:231] Iteration 30000, loss = 1.36243
I0520 04:16:57.093057 15139 solver.cpp:247]     Train net output #0: loss = 1.36243 (* 1 = 1.36243 loss)
I0520 04:16:57.093076 15139 sgd_solver.cpp:106] Iteration 30000, lr = 0.001
I0520 04:16:57.258584 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0124	3.125	82.681	0	91.2384	6.25	89.3185	0	85.4318	0	86.3886	0	79.3788	0	31.1657	2.8	
I0520 04:16:57.261099 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:16:57.263394 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:16:57.263430 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:16:57.263941 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.36243
I0520 04:18:13.587035 15139 solver.cpp:231] Iteration 30200, loss = 1.20602
I0520 04:18:13.587273 15139 solver.cpp:247]     Train net output #0: loss = 1.20602 (* 1 = 1.20602 loss)
I0520 04:18:13.587294 15139 sgd_solver.cpp:106] Iteration 30200, lr = 0.001
I0520 04:18:13.749162 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9378	3.125	82.6771	0	91.2376	6.25	89.317	0	85.4311	0	86.3925	0	79.3846	0	31.1705	2.8	
I0520 04:18:13.824105 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:18:13.826285 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:18:13.826316 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:18:13.826858 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20602
I0520 04:18:21.825984 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:19:49.003973 15139 solver.cpp:231] Iteration 30400, loss = 1.36259
I0520 04:19:49.004214 15139 solver.cpp:247]     Train net output #0: loss = 1.36259 (* 1 = 1.36259 loss)
I0520 04:19:49.004235 15139 sgd_solver.cpp:106] Iteration 30400, lr = 0.001
I0520 04:19:49.165843 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9866	3.125	82.6699	0	91.2372	6.25	89.3176	0	85.4316	0	86.3965	0	79.3904	0	31.1758	2.8	
I0520 04:19:49.240864 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:19:49.242452 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:19:49.242489 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:19:49.243008 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.36259
I0520 04:21:12.809180 15139 solver.cpp:231] Iteration 30600, loss = 1.31664
I0520 04:21:12.809434 15139 solver.cpp:247]     Train net output #0: loss = 1.31664 (* 1 = 1.31664 loss)
I0520 04:21:12.809456 15139 sgd_solver.cpp:106] Iteration 30600, lr = 0.001
I0520 04:21:12.968866 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0985	3.125	82.6836	0	91.2369	6.25	89.3185	0	85.4311	0	86.4005	0	79.396	0	31.1805	2.8	
I0520 04:21:13.048691 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:21:13.050916 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:21:13.050964 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:21:13.051628 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31664
I0520 04:22:30.401635 15139 solver.cpp:231] Iteration 30800, loss = 1.42172
I0520 04:22:30.401907 15139 solver.cpp:247]     Train net output #0: loss = 1.42172 (* 1 = 1.42172 loss)
I0520 04:22:30.401932 15139 sgd_solver.cpp:106] Iteration 30800, lr = 0.001
I0520 04:22:30.560550 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0669	3.125	82.6885	0	91.2372	6.25	89.319	0	85.4318	0	86.4045	0	79.4019	0	31.1849	2.8	
I0520 04:22:30.635502 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:22:30.637603 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:22:30.637637 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:22:30.638133 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.42172
I0520 04:23:46.364068 15139 solver.cpp:348] Iteration 31000, Testing net (#0)
I0520 04:24:06.386860 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:25:08.679316 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5582
I0520 04:25:08.679610 15139 solver.cpp:415]     Test net output #1: loss = 1.90441 (* 1 = 1.90441 loss)
I0520 04:25:08.767169 15139 solver.cpp:231] Iteration 31000, loss = 1.19326
I0520 04:25:08.767284 15139 solver.cpp:247]     Train net output #0: loss = 1.19326 (* 1 = 1.19326 loss)
I0520 04:25:08.767305 15139 sgd_solver.cpp:106] Iteration 31000, lr = 0.001
I0520 04:25:08.935415 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9952	3.125	82.6859	0	91.2382	6.25	89.3199	0	85.4334	0	86.4084	0	79.4075	0	31.1904	2.8	
I0520 04:25:09.010849 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:25:09.013546 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:25:09.013602 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:25:09.014181 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19326
I0520 04:26:35.626734 15139 solver.cpp:231] Iteration 31200, loss = 1.4324
I0520 04:26:35.628389 15139 solver.cpp:247]     Train net output #0: loss = 1.4324 (* 1 = 1.4324 loss)
I0520 04:26:35.628417 15139 sgd_solver.cpp:106] Iteration 31200, lr = 0.001
I0520 04:26:35.787051 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0296	3.125	82.6774	0	91.2384	6.25	89.3193	0	85.4341	0	86.4125	0	79.4132	0	31.1946	2.8	
I0520 04:26:35.862212 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:26:35.864881 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:26:35.864917 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:26:35.865538 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.4324
I0520 04:26:49.181740 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:28:08.917536 15139 solver.cpp:231] Iteration 31400, loss = 1.26234
I0520 04:28:08.917975 15139 solver.cpp:247]     Train net output #0: loss = 1.26234 (* 1 = 1.26234 loss)
I0520 04:28:08.917996 15139 sgd_solver.cpp:106] Iteration 31400, lr = 0.001
I0520 04:28:09.077252 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8747	3.125	82.6839	0	91.2384	6.25	89.3208	0	85.4329	0	86.4163	0	79.4191	0	31.1989	2.8	
I0520 04:28:09.152317 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:28:09.155238 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:28:09.155287 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:28:09.155866 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26234
I0520 04:29:30.309757 15139 solver.cpp:231] Iteration 31600, loss = 1.11312
I0520 04:29:30.313697 15139 solver.cpp:247]     Train net output #0: loss = 1.11312 (* 1 = 1.11312 loss)
I0520 04:29:30.313733 15139 sgd_solver.cpp:106] Iteration 31600, lr = 0.001
I0520 04:29:30.471858 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.955	3.125	82.679	0	91.2368	6.25	89.3202	0	85.4334	0	86.4202	0	79.4247	0	31.2036	2.8	
I0520 04:29:30.547034 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:29:30.549940 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:29:30.549988 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:29:30.550537 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11312
I0520 04:30:53.602427 15139 solver.cpp:231] Iteration 31800, loss = 1.3523
I0520 04:30:53.602754 15139 solver.cpp:247]     Train net output #0: loss = 1.3523 (* 1 = 1.3523 loss)
I0520 04:30:53.602776 15139 sgd_solver.cpp:106] Iteration 31800, lr = 0.001
I0520 04:30:53.764587 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0009	3.125	82.68	0	91.2369	6.25	89.3185	0	85.4332	0	86.4241	0	79.4303	0	31.2078	2.8	
I0520 04:30:53.839704 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:30:53.841532 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:30:53.841572 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:30:53.842349 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.3523
I0520 04:32:11.533670 15139 solver.cpp:348] Iteration 32000, Testing net (#0)
I0520 04:32:30.745378 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:33:28.840684 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5579
I0520 04:33:28.840863 15139 solver.cpp:415]     Test net output #1: loss = 1.91068 (* 1 = 1.91068 loss)
I0520 04:33:28.928277 15139 solver.cpp:231] Iteration 32000, loss = 1.32447
I0520 04:33:28.928346 15139 solver.cpp:247]     Train net output #0: loss = 1.32447 (* 1 = 1.32447 loss)
I0520 04:33:28.928365 15139 sgd_solver.cpp:106] Iteration 32000, lr = 0.001
I0520 04:33:29.091634 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9493	3.125	82.6777	0	91.2364	6.25	89.3169	0	85.4327	0	86.4279	0	79.4358	0	31.2127	2.8	
I0520 04:33:29.167664 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:33:29.169721 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:33:29.169780 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:33:29.170440 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32447
I0520 04:34:46.849468 15139 solver.cpp:231] Iteration 32200, loss = 1.49716
I0520 04:34:46.849851 15139 solver.cpp:247]     Train net output #0: loss = 1.49716 (* 1 = 1.49716 loss)
I0520 04:34:46.849874 15139 sgd_solver.cpp:106] Iteration 32200, lr = 0.001
I0520 04:34:47.008442 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0296	3.125	82.6891	0	91.2392	6.25	89.319	0	85.4325	0	86.4319	0	79.4415	0	31.2177	2.8	
I0520 04:34:47.083748 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:34:47.086439 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:34:47.086462 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:34:47.086993 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.49716
I0520 04:35:00.220003 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:36:13.549942 15139 solver.cpp:231] Iteration 32400, loss = 1.23445
I0520 04:36:13.550271 15139 solver.cpp:247]     Train net output #0: loss = 1.23445 (* 1 = 1.23445 loss)
I0520 04:36:13.550293 15139 sgd_solver.cpp:106] Iteration 32400, lr = 0.001
I0520 04:36:13.712045 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8919	3.125	82.6816	0	91.2368	6.25	89.3179	0	85.4327	0	86.4359	0	79.4477	0	31.2226	2.8	
I0520 04:36:13.788466 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:36:13.790630 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:36:13.790674 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:36:13.791147 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23445
I0520 04:37:41.359949 15139 solver.cpp:231] Iteration 32600, loss = 1.4016
I0520 04:37:41.360224 15139 solver.cpp:247]     Train net output #0: loss = 1.4016 (* 1 = 1.4016 loss)
I0520 04:37:41.360244 15139 sgd_solver.cpp:106] Iteration 32600, lr = 0.001
I0520 04:37:41.520342 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9837	3.125	82.6823	0	91.2373	6.25	89.3187	0	85.4327	0	86.4397	0	79.4533	0	31.228	2.8	
I0520 04:37:41.596189 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:37:41.599150 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:37:41.599201 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:37:41.599728 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.4016
I0520 04:39:03.577114 15139 solver.cpp:231] Iteration 32800, loss = 1.41315
I0520 04:39:03.577411 15139 solver.cpp:247]     Train net output #0: loss = 1.41315 (* 1 = 1.41315 loss)
I0520 04:39:03.577437 15139 sgd_solver.cpp:106] Iteration 32800, lr = 0.001
I0520 04:39:03.737644 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8919	3.125	82.6839	0	91.2384	6.25	89.3202	0	85.4336	0	86.4435	0	79.459	0	31.2327	2.8	
I0520 04:39:03.813345 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:39:03.816241 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:39:03.816283 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:39:03.816943 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.41315
I0520 04:40:25.539907 15139 solver.cpp:348] Iteration 33000, Testing net (#0)
I0520 04:40:44.382846 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:41:42.312091 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55876
I0520 04:41:42.312377 15139 solver.cpp:415]     Test net output #1: loss = 1.89627 (* 1 = 1.89627 loss)
I0520 04:41:42.400008 15139 solver.cpp:231] Iteration 33000, loss = 1.41321
I0520 04:41:42.400082 15139 solver.cpp:247]     Train net output #0: loss = 1.41321 (* 1 = 1.41321 loss)
I0520 04:41:42.400123 15139 sgd_solver.cpp:106] Iteration 33000, lr = 0.001
I0520 04:41:42.570878 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8574	3.125	82.6878	0	91.2383	6.25	89.3199	0	85.4334	0	86.4474	0	79.4647	0	31.2368	2.8	
I0520 04:41:42.645705 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:41:42.647315 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:41:42.647349 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:41:42.647969 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.41321
I0520 04:43:02.915128 15139 solver.cpp:231] Iteration 33200, loss = 1.32019
I0520 04:43:02.915434 15139 solver.cpp:247]     Train net output #0: loss = 1.32019 (* 1 = 1.32019 loss)
I0520 04:43:02.915465 15139 sgd_solver.cpp:106] Iteration 33200, lr = 0.001
I0520 04:43:03.074175 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8833	3.125	82.6784	0	91.2384	6.25	89.3199	0	85.4338	0	86.4513	0	79.4703	0	31.2424	2.8	
I0520 04:43:03.149502 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:43:03.151051 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:43:03.151075 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:43:03.151499 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32019
I0520 04:43:17.156977 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:44:15.969748 15139 solver.cpp:231] Iteration 33400, loss = 1.27145
I0520 04:44:15.969904 15139 solver.cpp:247]     Train net output #0: loss = 1.27145 (* 1 = 1.27145 loss)
I0520 04:44:15.969924 15139 sgd_solver.cpp:106] Iteration 33400, lr = 0.001
I0520 04:44:16.132900 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9263	3.125	82.6846	0	91.2386	6.25	89.3196	0	85.4341	0	86.4552	0	79.4755	0	31.2472	2.8	
I0520 04:44:16.208354 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:44:16.210142 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:44:16.210171 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:44:16.210707 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27145
I0520 04:45:27.805421 15139 solver.cpp:231] Iteration 33600, loss = 1.22349
I0520 04:45:27.805666 15139 solver.cpp:247]     Train net output #0: loss = 1.22349 (* 1 = 1.22349 loss)
I0520 04:45:27.805687 15139 sgd_solver.cpp:106] Iteration 33600, lr = 0.001
I0520 04:45:27.967393 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9837	3.125	82.6855	0	91.2392	6.25	89.3199	0	85.4345	0	86.4588	0	79.4811	0	31.2521	2.8	
I0520 04:45:28.042940 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:45:28.044502 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:45:28.044520 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:45:28.045058 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22349
I0520 04:46:39.681047 15139 solver.cpp:231] Iteration 33800, loss = 1.40467
I0520 04:46:39.681308 15139 solver.cpp:247]     Train net output #0: loss = 1.40467 (* 1 = 1.40467 loss)
I0520 04:46:39.681332 15139 sgd_solver.cpp:106] Iteration 33800, lr = 0.001
I0520 04:46:39.843467 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9234	3.125	82.6872	0	91.2407	6.25	89.3192	0	85.4345	0	86.4627	0	79.4868	0	31.2576	2.8	
I0520 04:46:39.919579 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:46:39.922000 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:46:39.922075 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:46:39.922951 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.40467
I0520 04:48:00.088346 15139 solver.cpp:348] Iteration 34000, Testing net (#0)
I0520 04:48:20.070899 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:49:17.979954 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55718
I0520 04:49:17.980224 15139 solver.cpp:415]     Test net output #1: loss = 1.90121 (* 1 = 1.90121 loss)
I0520 04:49:18.071146 15139 solver.cpp:231] Iteration 34000, loss = 1.24815
I0520 04:49:18.071213 15139 solver.cpp:247]     Train net output #0: loss = 1.24815 (* 1 = 1.24815 loss)
I0520 04:49:18.071229 15139 sgd_solver.cpp:106] Iteration 34000, lr = 0.001
I0520 04:49:18.236613 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0239	3.125	82.6888	0	91.2405	6.25	89.3193	0	85.4332	0	86.4666	0	79.4921	0	31.2616	2.8	
I0520 04:49:18.311866 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:49:18.313658 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:49:18.313688 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:49:18.314335 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24815
I0520 04:50:38.477157 15139 solver.cpp:231] Iteration 34200, loss = 1.42057
I0520 04:50:38.477428 15139 solver.cpp:247]     Train net output #0: loss = 1.42057 (* 1 = 1.42057 loss)
I0520 04:50:38.477449 15139 sgd_solver.cpp:106] Iteration 34200, lr = 0.001
I0520 04:50:38.635596 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9263	3.125	82.6732	0	91.2395	6.25	89.3188	0	85.4334	0	86.4703	0	79.4977	0	31.2659	2.8	
I0520 04:50:38.710286 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:50:38.711891 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:50:38.711917 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:50:38.712404 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.42057
I0520 04:50:58.660341 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:52:03.175377 15139 solver.cpp:231] Iteration 34400, loss = 1.46512
I0520 04:52:03.175701 15139 solver.cpp:247]     Train net output #0: loss = 1.46512 (* 1 = 1.46512 loss)
I0520 04:52:03.175743 15139 sgd_solver.cpp:106] Iteration 34400, lr = 0.001
I0520 04:52:03.336652 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9292	3.125	82.6846	0	91.241	6.25	89.3201	0	85.4338	0	86.4741	0	79.5029	0	31.2721	2.8	
I0520 04:52:03.411782 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:52:03.414273 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:52:03.414320 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:52:03.414963 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.46512
I0520 04:53:26.036345 15139 solver.cpp:231] Iteration 34600, loss = 1.46945
I0520 04:53:26.036619 15139 solver.cpp:247]     Train net output #0: loss = 1.46945 (* 1 = 1.46945 loss)
I0520 04:53:26.036641 15139 sgd_solver.cpp:106] Iteration 34600, lr = 0.001
I0520 04:53:26.197099 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9234	3.125	82.6842	0	91.2412	6.25	89.3182	0	85.4352	0	86.4778	0	79.5084	0	31.2763	2.8	
I0520 04:53:26.275756 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:53:26.277448 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:53:26.277469 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:53:26.278022 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.46945
I0520 04:54:46.491849 15139 solver.cpp:231] Iteration 34800, loss = 1.40696
I0520 04:54:46.492200 15139 solver.cpp:247]     Train net output #0: loss = 1.40696 (* 1 = 1.40696 loss)
I0520 04:54:46.492231 15139 sgd_solver.cpp:106] Iteration 34800, lr = 0.001
I0520 04:54:46.651347 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.955	3.125	82.6869	0	91.2396	6.25	89.3192	0	85.4336	0	86.4816	0	79.5141	0	31.2808	2.8	
I0520 04:54:46.726346 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:54:46.728886 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:54:46.728922 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:54:46.729490 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.40696
I0520 04:56:05.131557 15139 solver.cpp:348] Iteration 35000, Testing net (#0)
I0520 04:56:23.510318 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 04:57:24.152179 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5587
I0520 04:57:24.152514 15139 solver.cpp:415]     Test net output #1: loss = 1.89703 (* 1 = 1.89703 loss)
I0520 04:57:24.241744 15139 solver.cpp:231] Iteration 35000, loss = 1.27294
I0520 04:57:24.241837 15139 solver.cpp:247]     Train net output #0: loss = 1.27294 (* 1 = 1.27294 loss)
I0520 04:57:24.241858 15139 sgd_solver.cpp:106] Iteration 35000, lr = 0.001
I0520 04:57:24.407940 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.846	3.125	82.6966	0	91.2411	6.25	89.3201	0	85.4363	0	86.4854	0	79.5197	0	31.2864	2.8	
I0520 04:57:24.483196 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:57:24.484918 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:57:24.484940 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:57:24.485560 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27294
I0520 04:58:46.270328 15139 solver.cpp:231] Iteration 35200, loss = 1.21768
I0520 04:58:46.273629 15139 solver.cpp:247]     Train net output #0: loss = 1.21768 (* 1 = 1.21768 loss)
I0520 04:58:46.273656 15139 sgd_solver.cpp:106] Iteration 35200, lr = 0.001
I0520 04:58:46.430451 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.064	3.125	82.6963	0	91.2416	6.25	89.321	0	85.4363	0	86.4893	0	79.5254	0	31.2917	2.8	
I0520 04:58:46.505496 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 04:58:46.507019 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 04:58:46.507043 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 04:58:46.507472 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21768
I0520 04:59:07.710422 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:00:15.885999 15139 solver.cpp:231] Iteration 35400, loss = 0.963845
I0520 05:00:15.891371 15139 solver.cpp:247]     Train net output #0: loss = 0.963845 (* 1 = 0.963845 loss)
I0520 05:00:15.891405 15139 sgd_solver.cpp:106] Iteration 35400, lr = 0.001
I0520 05:00:16.046304 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0927	3.125	82.6914	0	91.2408	6.25	89.3214	0	85.4368	0	86.4931	0	79.5307	0	31.2958	2.8	
I0520 05:00:16.121722 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:00:16.124721 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:00:16.124768 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:00:16.125264 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.963845
I0520 05:01:36.934137 15139 solver.cpp:231] Iteration 35600, loss = 1.34191
I0520 05:01:36.934365 15139 solver.cpp:247]     Train net output #0: loss = 1.34191 (* 1 = 1.34191 loss)
I0520 05:01:36.934386 15139 sgd_solver.cpp:106] Iteration 35600, lr = 0.001
I0520 05:01:37.097079 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9292	3.125	82.694	0	91.2418	6.25	89.3217	0	85.4366	0	86.4969	0	79.5362	0	31.3005	2.8	
I0520 05:01:37.173349 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:01:37.176153 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:01:37.176192 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:01:37.176851 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34191
I0520 05:03:07.772598 15139 solver.cpp:231] Iteration 35800, loss = 1.40279
I0520 05:03:07.772850 15139 solver.cpp:247]     Train net output #0: loss = 1.40279 (* 1 = 1.40279 loss)
I0520 05:03:07.772871 15139 sgd_solver.cpp:106] Iteration 35800, lr = 0.001
I0520 05:03:07.932787 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.932	3.125	82.6901	0	91.2415	6.25	89.3223	0	85.4372	0	86.5007	0	79.5418	0	31.3046	2.8	
I0520 05:03:08.008363 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:03:08.010470 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:03:08.010510 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:03:08.011075 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.40279
I0520 05:04:24.680539 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_36000.caffemodel
I0520 05:04:50.365502 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_36000.solverstate
I0520 05:04:51.096060 15139 solver.cpp:348] Iteration 36000, Testing net (#0)
I0520 05:05:12.195618 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:06:12.453920 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55938
I0520 05:06:12.457629 15139 solver.cpp:415]     Test net output #1: loss = 1.89385 (* 1 = 1.89385 loss)
I0520 05:06:12.544929 15139 solver.cpp:231] Iteration 36000, loss = 1.23814
I0520 05:06:12.544997 15139 solver.cpp:247]     Train net output #0: loss = 1.23814 (* 1 = 1.23814 loss)
I0520 05:06:12.545016 15139 sgd_solver.cpp:106] Iteration 36000, lr = 0.001
I0520 05:06:12.705266 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9292	3.125	82.6881	0	91.2408	6.25	89.3231	0	85.4363	0	86.5044	0	79.5474	0	31.3096	2.8	
I0520 05:06:12.707208 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:06:12.709101 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:06:12.709133 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:06:12.709882 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23814
I0520 05:07:25.080549 15139 solver.cpp:231] Iteration 36200, loss = 1.31804
I0520 05:07:25.080885 15139 solver.cpp:247]     Train net output #0: loss = 1.31804 (* 1 = 1.31804 loss)
I0520 05:07:25.080910 15139 sgd_solver.cpp:106] Iteration 36200, lr = 0.001
I0520 05:07:25.243369 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.955	3.125	82.6881	0	91.242	6.25	89.3223	0	85.4375	0	86.508	0	79.5527	0	31.3143	2.8	
I0520 05:07:25.320065 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:07:25.328013 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:07:25.328094 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:07:25.328959 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31804
I0520 05:07:48.704036 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:08:46.101133 15139 solver.cpp:231] Iteration 36400, loss = 1.38139
I0520 05:08:46.101375 15139 solver.cpp:247]     Train net output #0: loss = 1.38139 (* 1 = 1.38139 loss)
I0520 05:08:46.101397 15139 sgd_solver.cpp:106] Iteration 36400, lr = 0.001
I0520 05:08:46.262945 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9665	3.125	82.6911	0	91.2404	6.25	89.3214	0	85.4354	0	86.5117	0	79.5583	0	31.3195	2.8	
I0520 05:08:46.338804 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:08:46.341799 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:08:46.341842 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:08:46.342358 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.38139
I0520 05:10:11.273820 15139 solver.cpp:231] Iteration 36600, loss = 1.35419
I0520 05:10:11.274157 15139 solver.cpp:247]     Train net output #0: loss = 1.35419 (* 1 = 1.35419 loss)
I0520 05:10:11.274178 15139 sgd_solver.cpp:106] Iteration 36600, lr = 0.001
I0520 05:10:11.434191 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0554	3.125	82.6917	0	91.2434	6.25	89.3226	0	85.4372	0	86.5151	0	79.5638	0	31.324	2.8	
I0520 05:10:11.508956 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:10:11.510810 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:10:11.510854 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:10:11.511415 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35419
I0520 05:11:32.385159 15139 solver.cpp:231] Iteration 36800, loss = 1.17354
I0520 05:11:32.385915 15139 solver.cpp:247]     Train net output #0: loss = 1.17354 (* 1 = 1.17354 loss)
I0520 05:11:32.385941 15139 sgd_solver.cpp:106] Iteration 36800, lr = 0.001
I0520 05:11:32.544862 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9665	3.125	82.6934	0	91.2425	6.25	89.3237	0	85.4366	0	86.519	0	79.5694	0	31.3283	2.8	
I0520 05:11:32.619761 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:11:32.622249 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:11:32.622294 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:11:32.622861 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17354
I0520 05:12:50.318369 15139 solver.cpp:348] Iteration 37000, Testing net (#0)
I0520 05:13:09.117089 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:14:01.206439 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55982
I0520 05:14:01.206822 15139 solver.cpp:415]     Test net output #1: loss = 1.89125 (* 1 = 1.89125 loss)
I0520 05:14:01.294365 15139 solver.cpp:231] Iteration 37000, loss = 1.38719
I0520 05:14:01.294450 15139 solver.cpp:247]     Train net output #0: loss = 1.38719 (* 1 = 1.38719 loss)
I0520 05:14:01.294469 15139 sgd_solver.cpp:106] Iteration 37000, lr = 0.001
I0520 05:14:01.458552 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.823	3.125	82.6908	0	91.242	6.25	89.3249	0	85.4377	0	86.5227	0	79.5746	0	31.3326	2.8	
I0520 05:14:01.534301 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:14:01.538036 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:14:01.538077 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:14:01.538754 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.38719
I0520 05:15:22.454967 15139 solver.cpp:231] Iteration 37200, loss = 1.32615
I0520 05:15:22.455268 15139 solver.cpp:247]     Train net output #0: loss = 1.32615 (* 1 = 1.32615 loss)
I0520 05:15:22.455294 15139 sgd_solver.cpp:106] Iteration 37200, lr = 0.001
I0520 05:15:22.616575 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.7914	3.125	82.6995	0	91.241	6.25	89.3252	0	85.4388	0	86.5263	0	79.58	0	31.3375	2.8	
I0520 05:15:22.696611 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:15:22.698742 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:15:22.698772 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:15:22.699380 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32615
I0520 05:15:48.786442 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:16:41.542321 15139 solver.cpp:231] Iteration 37400, loss = 1.3125
I0520 05:16:41.542615 15139 solver.cpp:247]     Train net output #0: loss = 1.3125 (* 1 = 1.3125 loss)
I0520 05:16:41.542639 15139 sgd_solver.cpp:106] Iteration 37400, lr = 0.001
I0520 05:16:41.704349 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9263	3.125	82.6992	0	91.2417	6.25	89.3228	0	85.439	0	86.53	0	79.5853	0	31.3424	2.8	
I0520 05:16:41.780652 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:16:41.782850 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:16:41.782887 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:16:41.783649 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.3125
I0520 05:17:57.761466 15139 solver.cpp:231] Iteration 37600, loss = 1.37674
I0520 05:17:57.761777 15139 solver.cpp:247]     Train net output #0: loss = 1.37674 (* 1 = 1.37674 loss)
I0520 05:17:57.761797 15139 sgd_solver.cpp:106] Iteration 37600, lr = 0.001
I0520 05:17:57.923852 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1186	3.125	82.6976	0	91.2433	6.25	89.3232	0	85.4388	0	86.5334	0	79.5906	0	31.3464	2.8	
I0520 05:17:57.999431 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:17:58.001847 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:17:58.001880 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:17:58.002362 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.37674
I0520 05:19:13.635618 15139 solver.cpp:231] Iteration 37800, loss = 1.17238
I0520 05:19:13.637609 15139 solver.cpp:247]     Train net output #0: loss = 1.17238 (* 1 = 1.17238 loss)
I0520 05:19:13.637631 15139 sgd_solver.cpp:106] Iteration 37800, lr = 0.001
I0520 05:19:13.796947 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9665	3.125	82.6927	0	91.2426	6.25	89.3229	0	85.4386	0	86.537	0	79.596	0	31.3517	2.8	
I0520 05:19:13.872697 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:19:13.875605 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:19:13.875643 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:19:13.876133 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17238
I0520 05:20:32.791582 15139 solver.cpp:348] Iteration 38000, Testing net (#0)
I0520 05:20:52.945439 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:21:44.917407 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55888
I0520 05:21:44.917605 15139 solver.cpp:415]     Test net output #1: loss = 1.89795 (* 1 = 1.89795 loss)
I0520 05:21:45.004822 15139 solver.cpp:231] Iteration 38000, loss = 1.35592
I0520 05:21:45.004901 15139 solver.cpp:247]     Train net output #0: loss = 1.35592 (* 1 = 1.35592 loss)
I0520 05:21:45.004920 15139 sgd_solver.cpp:106] Iteration 38000, lr = 0.001
I0520 05:21:45.167450 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.998	3.125	82.6973	0	91.2434	6.25	89.3244	0	85.4404	0	86.5408	0	79.6012	0	31.3567	2.8	
I0520 05:21:45.243016 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:21:45.245920 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:21:45.245957 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:21:45.246515 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35592
I0520 05:23:05.665391 15139 solver.cpp:231] Iteration 38200, loss = 1.41898
I0520 05:23:05.665750 15139 solver.cpp:247]     Train net output #0: loss = 1.41898 (* 1 = 1.41898 loss)
I0520 05:23:05.665782 15139 sgd_solver.cpp:106] Iteration 38200, lr = 0.001
I0520 05:23:05.824283 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9894	3.125	82.6973	0	91.243	6.25	89.3243	0	85.4381	0	86.5443	0	79.6066	0	31.3612	2.8	
I0520 05:23:05.899268 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:23:05.901762 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:23:05.901808 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:23:05.902490 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.41898
I0520 05:23:40.425007 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:24:27.139014 15139 solver.cpp:231] Iteration 38400, loss = 1.34903
I0520 05:24:27.139277 15139 solver.cpp:247]     Train net output #0: loss = 1.34903 (* 1 = 1.34903 loss)
I0520 05:24:27.139297 15139 sgd_solver.cpp:106] Iteration 38400, lr = 0.001
I0520 05:24:27.301648 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0526	3.125	82.6924	0	91.2437	6.25	89.3238	0	85.4379	0	86.548	0	79.6121	0	31.3666	2.8	
I0520 05:24:27.376696 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:24:27.379654 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:24:27.379698 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:24:27.380234 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34903
I0520 05:25:46.498400 15139 solver.cpp:231] Iteration 38600, loss = 1.21431
I0520 05:25:46.498741 15139 solver.cpp:247]     Train net output #0: loss = 1.21431 (* 1 = 1.21431 loss)
I0520 05:25:46.498762 15139 sgd_solver.cpp:106] Iteration 38600, lr = 0.001
I0520 05:25:46.658643 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0698	3.125	82.694	0	91.2437	6.25	89.3253	0	85.4375	0	86.5516	0	79.6173	0	31.3712	2.8	
I0520 05:25:46.733657 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:25:46.736482 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:25:46.736523 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:25:46.736997 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21431
I0520 05:27:14.223891 15139 solver.cpp:231] Iteration 38800, loss = 1.32102
I0520 05:27:14.224191 15139 solver.cpp:247]     Train net output #0: loss = 1.32102 (* 1 = 1.32102 loss)
I0520 05:27:14.224213 15139 sgd_solver.cpp:106] Iteration 38800, lr = 0.001
I0520 05:27:14.384984 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0755	3.125	82.7035	0	91.2437	6.25	89.3235	0	85.4381	0	86.5553	0	79.6222	0	31.3759	2.8	
I0520 05:27:14.460932 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:27:14.464043 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:27:14.464092 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:27:14.464725 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32102
I0520 05:28:38.884778 15139 solver.cpp:348] Iteration 39000, Testing net (#0)
I0520 05:29:00.632035 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:29:53.522930 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5602
I0520 05:29:53.523202 15139 solver.cpp:415]     Test net output #1: loss = 1.88514 (* 1 = 1.88514 loss)
I0520 05:29:53.613100 15139 solver.cpp:231] Iteration 39000, loss = 1.10217
I0520 05:29:53.613178 15139 solver.cpp:247]     Train net output #0: loss = 1.10217 (* 1 = 1.10217 loss)
I0520 05:29:53.613198 15139 sgd_solver.cpp:106] Iteration 39000, lr = 0.001
I0520 05:29:53.772580 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9923	3.125	82.7048	0	91.246	6.25	89.3228	0	85.4372	0	86.5587	0	79.6272	0	31.3806	2.8	
I0520 05:29:53.848052 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:29:53.850100 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:29:53.850134 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:29:53.850981 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10217
I0520 05:31:13.054447 15139 solver.cpp:231] Iteration 39200, loss = 1.2368
I0520 05:31:13.055049 15139 solver.cpp:247]     Train net output #0: loss = 1.2368 (* 1 = 1.2368 loss)
I0520 05:31:13.055071 15139 sgd_solver.cpp:106] Iteration 39200, lr = 0.001
I0520 05:31:13.215117 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9808	3.125	82.7031	0	91.2464	6.25	89.324	0	85.4381	0	86.5622	0	79.6326	0	31.3851	2.8	
I0520 05:31:13.290175 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:31:13.292780 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:31:13.292814 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:31:13.293355 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2368
I0520 05:31:46.820000 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:32:37.628635 15139 solver.cpp:231] Iteration 39400, loss = 1.07159
I0520 05:32:37.630957 15139 solver.cpp:247]     Train net output #0: loss = 1.07159 (* 1 = 1.07159 loss)
I0520 05:32:37.630982 15139 sgd_solver.cpp:106] Iteration 39400, lr = 0.001
I0520 05:32:37.788720 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9894	3.125	82.7139	0	91.2458	6.25	89.3235	0	85.439	0	86.5658	0	79.6379	0	31.39	2.8	
I0520 05:32:37.863872 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:32:37.866879 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:32:37.866920 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:32:37.867460 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.07159
I0520 05:34:03.654045 15139 solver.cpp:231] Iteration 39600, loss = 1.38342
I0520 05:34:03.656807 15139 solver.cpp:247]     Train net output #0: loss = 1.38342 (* 1 = 1.38342 loss)
I0520 05:34:03.656832 15139 sgd_solver.cpp:106] Iteration 39600, lr = 0.001
I0520 05:34:03.814157 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.8689	3.125	82.7064	0	91.2464	6.25	89.3247	0	85.4388	0	86.5695	0	79.6433	0	31.3947	2.8	
I0520 05:34:03.889892 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:34:03.892913 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:34:03.892957 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:34:03.893673 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.38342
I0520 05:35:25.865267 15139 solver.cpp:231] Iteration 39800, loss = 1.33608
I0520 05:35:25.865476 15139 solver.cpp:247]     Train net output #0: loss = 1.33608 (* 1 = 1.33608 loss)
I0520 05:35:25.865495 15139 sgd_solver.cpp:106] Iteration 39800, lr = 0.001
I0520 05:35:26.025905 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0382	3.125	82.6979	0	91.2453	6.25	89.3232	0	85.4402	0	86.5729	0	79.6487	0	31.4001	2.8	
I0520 05:35:26.105653 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:35:26.108703 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:35:26.108754 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:35:26.109333 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33608
I0520 05:36:52.575749 15139 solver.cpp:348] Iteration 40000, Testing net (#0)
I0520 05:37:13.299800 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:38:03.402473 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56162
I0520 05:38:03.402868 15139 solver.cpp:415]     Test net output #1: loss = 1.88745 (* 1 = 1.88745 loss)
I0520 05:38:03.493546 15139 solver.cpp:231] Iteration 40000, loss = 1.3773
I0520 05:38:03.493629 15139 solver.cpp:247]     Train net output #0: loss = 1.3773 (* 1 = 1.3773 loss)
I0520 05:38:03.493649 15139 sgd_solver.cpp:106] Iteration 40000, lr = 0.001
I0520 05:38:03.653367 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0267	3.125	82.695	0	91.2463	6.25	89.3235	0	85.4399	0	86.5766	0	79.6537	0	31.4047	2.8	
I0520 05:38:03.730080 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:38:03.731993 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:38:03.732028 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:38:03.732643 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.3773
I0520 05:39:32.769315 15139 solver.cpp:231] Iteration 40200, loss = 1.11512
I0520 05:39:32.769632 15139 solver.cpp:247]     Train net output #0: loss = 1.11512 (* 1 = 1.11512 loss)
I0520 05:39:32.769654 15139 sgd_solver.cpp:106] Iteration 40200, lr = 0.001
I0520 05:39:32.930821 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9234	3.125	82.6979	0	91.2459	6.25	89.3237	0	85.4397	0	86.58	0	79.6589	0	31.4094	2.8	
I0520 05:39:33.006502 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:39:33.009659 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:39:33.009704 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:39:33.010272 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11512
I0520 05:40:13.709828 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:41:02.828012 15139 solver.cpp:231] Iteration 40400, loss = 1.28312
I0520 05:41:02.828250 15139 solver.cpp:247]     Train net output #0: loss = 1.28312 (* 1 = 1.28312 loss)
I0520 05:41:02.828271 15139 sgd_solver.cpp:106] Iteration 40400, lr = 0.001
I0520 05:41:02.987779 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0899	3.125	82.6943	0	91.247	6.25	89.3247	0	85.4411	0	86.5835	0	79.6642	0	31.4145	2.8	
I0520 05:41:03.063330 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:41:03.066609 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:41:03.066655 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:41:03.067121 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28312
I0520 05:42:33.686959 15139 solver.cpp:231] Iteration 40600, loss = 1.15831
I0520 05:42:33.687243 15139 solver.cpp:247]     Train net output #0: loss = 1.15831 (* 1 = 1.15831 loss)
I0520 05:42:33.687265 15139 sgd_solver.cpp:106] Iteration 40600, lr = 0.001
I0520 05:42:33.846762 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1559	3.125	82.7074	0	91.248	6.25	89.3241	0	85.4415	0	86.5871	0	79.6696	0	31.4194	2.8	
I0520 05:42:33.922307 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:42:33.925909 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:42:33.925967 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:42:33.926542 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15831
I0520 05:44:04.241760 15139 solver.cpp:231] Iteration 40800, loss = 1.15233
I0520 05:44:04.245668 15139 solver.cpp:247]     Train net output #0: loss = 1.15233 (* 1 = 1.15233 loss)
I0520 05:44:04.245702 15139 sgd_solver.cpp:106] Iteration 40800, lr = 0.001
I0520 05:44:04.400672 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0526	3.125	82.7051	0	91.2482	6.25	89.3246	0	85.442	0	86.5907	0	79.6747	0	31.4246	2.8	
I0520 05:44:04.476240 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:44:04.479743 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:44:04.479815 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:44:04.480356 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15233
I0520 05:45:24.134069 15139 solver.cpp:348] Iteration 41000, Testing net (#0)
I0520 05:45:45.352046 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:46:47.270715 15139 solver.cpp:415]     Test net output #0: accuracy = 0.559
I0520 05:46:47.271050 15139 solver.cpp:415]     Test net output #1: loss = 1.89841 (* 1 = 1.89841 loss)
I0520 05:46:47.360579 15139 solver.cpp:231] Iteration 41000, loss = 1.42448
I0520 05:46:47.360685 15139 solver.cpp:247]     Train net output #0: loss = 1.42448 (* 1 = 1.42448 loss)
I0520 05:46:47.360705 15139 sgd_solver.cpp:106] Iteration 41000, lr = 0.001
I0520 05:46:47.521059 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1501	3.125	82.7018	0	91.2476	6.25	89.3249	0	85.4436	0	86.5943	0	79.68	0	31.4292	2.8	
I0520 05:46:47.597966 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:46:47.601258 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:46:47.601292 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:46:47.601750 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.42448
I0520 05:48:14.170732 15139 solver.cpp:231] Iteration 41200, loss = 1.28732
I0520 05:48:14.171017 15139 solver.cpp:247]     Train net output #0: loss = 1.28732 (* 1 = 1.28732 loss)
I0520 05:48:14.171037 15139 sgd_solver.cpp:106] Iteration 41200, lr = 0.001
I0520 05:48:14.330555 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1329	3.125	82.7106	0	91.2475	6.25	89.3261	0	85.4438	0	86.5977	0	79.6852	0	31.4346	2.8	
I0520 05:48:14.406504 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:48:14.410038 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:48:14.410094 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:48:14.410639 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28732
I0520 05:48:55.805671 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:49:42.489279 15139 solver.cpp:231] Iteration 41400, loss = 1.54135
I0520 05:49:42.489471 15139 solver.cpp:247]     Train net output #0: loss = 1.54135 (* 1 = 1.54135 loss)
I0520 05:49:42.489493 15139 sgd_solver.cpp:106] Iteration 41400, lr = 0.001
I0520 05:49:42.648917 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1817	3.125	82.7067	0	91.2476	6.25	89.3271	0	85.4452	0	86.6013	0	79.6903	0	31.4393	2.8	
I0520 05:49:42.724800 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:49:42.728425 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:49:42.728482 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:49:42.729115 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.54135
I0520 05:51:10.318025 15139 solver.cpp:231] Iteration 41600, loss = 1.37811
I0520 05:51:10.318318 15139 solver.cpp:247]     Train net output #0: loss = 1.37811 (* 1 = 1.37811 loss)
I0520 05:51:10.318341 15139 sgd_solver.cpp:106] Iteration 41600, lr = 0.001
I0520 05:51:10.480821 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1301	3.125	82.7021	0	91.2487	6.25	89.3264	0	85.4449	0	86.6049	0	79.6956	0	31.4436	2.8	
I0520 05:51:10.555331 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:51:10.557878 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:51:10.557904 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:51:10.558315 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.37811
I0520 05:52:34.268105 15139 solver.cpp:231] Iteration 41800, loss = 1.38979
I0520 05:52:34.268558 15139 solver.cpp:247]     Train net output #0: loss = 1.38979 (* 1 = 1.38979 loss)
I0520 05:52:34.268580 15139 sgd_solver.cpp:106] Iteration 41800, lr = 0.001
I0520 05:52:34.429287 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0841	3.125	82.7197	0	91.247	6.25	89.3276	0	85.4449	0	86.6083	0	79.7006	0	31.4481	2.8	
I0520 05:52:34.505576 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:52:34.509038 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:52:34.509083 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:52:34.509678 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.38979
I0520 05:53:51.896819 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_42000.caffemodel
I0520 05:55:27.649029 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_42000.solverstate
I0520 05:55:28.396718 15139 solver.cpp:348] Iteration 42000, Testing net (#0)
I0520 05:55:50.953943 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:56:43.792771 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56024
I0520 05:56:43.793048 15139 solver.cpp:415]     Test net output #1: loss = 1.89149 (* 1 = 1.89149 loss)
I0520 05:56:43.879775 15139 solver.cpp:231] Iteration 42000, loss = 1.2236
I0520 05:56:43.879855 15139 solver.cpp:247]     Train net output #0: loss = 1.2236 (* 1 = 1.2236 loss)
I0520 05:56:43.879874 15139 sgd_solver.cpp:106] Iteration 42000, lr = 0.001
I0520 05:56:44.046921 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2534	3.125	82.7061	0	91.2465	6.25	89.3264	0	85.444	0	86.6116	0	79.7054	0	31.4526	2.8	
I0520 05:56:44.049031 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:56:44.051597 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:56:44.051621 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:56:44.052122 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2236
I0520 05:58:00.961702 15139 solver.cpp:231] Iteration 42200, loss = 1.28808
I0520 05:58:00.962501 15139 solver.cpp:247]     Train net output #0: loss = 1.28808 (* 1 = 1.28808 loss)
I0520 05:58:00.962529 15139 sgd_solver.cpp:106] Iteration 42200, lr = 0.001
I0520 05:58:01.122616 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1444	3.125	82.7171	0	91.2496	6.25	89.3268	0	85.4452	0	86.615	0	79.7105	0	31.4573	2.8	
I0520 05:58:01.198119 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:58:01.201196 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:58:01.201236 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:58:01.201783 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28808
I0520 05:58:39.049391 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 05:59:15.351604 15139 solver.cpp:231] Iteration 42400, loss = 1.28791
I0520 05:59:15.351943 15139 solver.cpp:247]     Train net output #0: loss = 1.28791 (* 1 = 1.28791 loss)
I0520 05:59:15.351966 15139 sgd_solver.cpp:106] Iteration 42400, lr = 0.001
I0520 05:59:15.513653 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3108	3.125	82.7135	0	91.2488	6.25	89.3277	0	85.4456	0	86.6184	0	79.7155	0	31.4626	2.8	
I0520 05:59:15.588989 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 05:59:15.592445 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.8	
I0520 05:59:15.592489 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 05:59:15.593056 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28791
I0520 06:00:29.824030 15139 solver.cpp:231] Iteration 42600, loss = 1.27222
I0520 06:00:29.824503 15139 solver.cpp:247]     Train net output #0: loss = 1.27222 (* 1 = 1.27222 loss)
I0520 06:00:29.824525 15139 sgd_solver.cpp:106] Iteration 42600, lr = 0.001
I0520 06:00:29.986615 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1702	3.125	82.71	0	91.2487	6.25	89.3267	0	85.4445	0	86.622	0	79.7208	0	31.4671	2.9	
I0520 06:00:30.061862 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:00:30.064867 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:00:30.064908 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:00:30.065487 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27222
I0520 06:02:06.035462 15139 solver.cpp:231] Iteration 42800, loss = 1.26455
I0520 06:02:06.035801 15139 solver.cpp:247]     Train net output #0: loss = 1.26455 (* 1 = 1.26455 loss)
I0520 06:02:06.035825 15139 sgd_solver.cpp:106] Iteration 42800, lr = 0.001
I0520 06:02:06.195255 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1961	3.125	82.7135	0	91.249	6.25	89.3271	0	85.4429	0	86.6255	0	79.7261	0	31.4723	2.9	
I0520 06:02:06.269848 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:02:06.271651 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:02:06.271669 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:02:06.272192 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26455
I0520 06:03:51.082742 15139 solver.cpp:348] Iteration 43000, Testing net (#0)
I0520 06:04:12.924046 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:05:06.174865 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5572
I0520 06:05:06.175202 15139 solver.cpp:415]     Test net output #1: loss = 1.90504 (* 1 = 1.90504 loss)
I0520 06:05:06.262364 15139 solver.cpp:231] Iteration 43000, loss = 1.42604
I0520 06:05:06.262444 15139 solver.cpp:247]     Train net output #0: loss = 1.42604 (* 1 = 1.42604 loss)
I0520 06:05:06.262467 15139 sgd_solver.cpp:106] Iteration 43000, lr = 0.001
I0520 06:05:06.436486 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1731	3.125	82.7051	0	91.2494	6.25	89.3268	0	85.4442	0	86.6289	0	79.7313	0	31.4769	2.9	
I0520 06:05:06.520755 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:05:06.525430 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:05:06.525480 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:05:06.527310 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.42604
I0520 06:06:25.968804 15139 solver.cpp:231] Iteration 43200, loss = 1.21159
I0520 06:06:25.969162 15139 solver.cpp:247]     Train net output #0: loss = 1.21159 (* 1 = 1.21159 loss)
I0520 06:06:25.969183 15139 sgd_solver.cpp:106] Iteration 43200, lr = 0.001
I0520 06:06:26.129341 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1817	3.125	82.7148	0	91.2487	6.25	89.3264	0	85.4449	0	86.6323	0	79.7362	0	31.4819	2.9	
I0520 06:06:26.204869 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:06:26.208014 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:06:26.208055 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:06:26.208555 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21159
I0520 06:07:10.385187 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:07:45.754369 15139 solver.cpp:231] Iteration 43400, loss = 1.45327
I0520 06:07:45.754773 15139 solver.cpp:247]     Train net output #0: loss = 1.45327 (* 1 = 1.45327 loss)
I0520 06:07:45.754794 15139 sgd_solver.cpp:106] Iteration 43400, lr = 0.001
I0520 06:07:45.914786 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.064	3.125	82.7139	0	91.2495	6.25	89.3264	0	85.4433	0	86.6357	0	79.7413	0	31.4861	2.9	
I0520 06:07:45.989547 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:07:45.991381 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:07:45.991412 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:07:45.991989 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.45327
I0520 06:09:04.746453 15139 solver.cpp:231] Iteration 43600, loss = 1.3763
I0520 06:09:04.749634 15139 solver.cpp:247]     Train net output #0: loss = 1.3763 (* 1 = 1.3763 loss)
I0520 06:09:04.749665 15139 sgd_solver.cpp:106] Iteration 43600, lr = 0.001
I0520 06:09:04.909510 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1989	3.125	82.708	0	91.2504	6.25	89.327	0	85.4436	0	86.6392	0	79.7463	0	31.4913	2.9	
I0520 06:09:04.985308 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:09:04.988143 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:09:04.988194 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:09:04.988761 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.3763
I0520 06:10:22.260247 15139 solver.cpp:231] Iteration 43800, loss = 1.13661
I0520 06:10:22.260530 15139 solver.cpp:247]     Train net output #0: loss = 1.13661 (* 1 = 1.13661 loss)
I0520 06:10:22.260560 15139 sgd_solver.cpp:106] Iteration 43800, lr = 0.001
I0520 06:10:22.420279 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2362	3.125	82.709	0	91.2504	6.25	89.3277	0	85.4452	0	86.6426	0	79.7513	0	31.4956	2.9	
I0520 06:10:22.498337 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:10:22.500141 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:10:22.500170 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:10:22.500759 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13661
I0520 06:11:58.562017 15139 solver.cpp:348] Iteration 44000, Testing net (#0)
I0520 06:12:22.304036 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:13:16.416102 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56254
I0520 06:13:16.416405 15139 solver.cpp:415]     Test net output #1: loss = 1.88649 (* 1 = 1.88649 loss)
I0520 06:13:16.507019 15139 solver.cpp:231] Iteration 44000, loss = 1.20548
I0520 06:13:16.507105 15139 solver.cpp:247]     Train net output #0: loss = 1.20548 (* 1 = 1.20548 loss)
I0520 06:13:16.507124 15139 sgd_solver.cpp:106] Iteration 44000, lr = 0.001
I0520 06:13:16.673801 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2534	3.125	82.7142	0	91.25	6.25	89.3291	0	85.4452	0	86.6457	0	79.7562	0	31.4999	2.9	
I0520 06:13:16.749215 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:13:16.752094 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:13:16.752138 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:13:16.752723 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20548
I0520 06:14:38.492739 15139 solver.cpp:231] Iteration 44200, loss = 1.38582
I0520 06:14:38.493100 15139 solver.cpp:247]     Train net output #0: loss = 1.38582 (* 1 = 1.38582 loss)
I0520 06:14:38.493120 15139 sgd_solver.cpp:106] Iteration 44200, lr = 0.001
I0520 06:14:38.651348 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1358	3.125	82.7067	0	91.2493	6.25	89.3282	0	85.4447	0	86.649	0	79.7614	0	31.5051	2.9	
I0520 06:14:38.727075 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:14:38.729872 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:14:38.729928 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:14:38.730563 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.38582
I0520 06:15:40.434592 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:16:15.298341 15139 solver.cpp:231] Iteration 44400, loss = 1.5487
I0520 06:16:15.303187 15139 solver.cpp:247]     Train net output #0: loss = 1.5487 (* 1 = 1.5487 loss)
I0520 06:16:15.303218 15139 sgd_solver.cpp:106] Iteration 44400, lr = 0.001
I0520 06:16:15.459436 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1731	3.125	82.7087	0	91.2506	6.25	89.3291	0	85.4476	0	86.6523	0	79.7665	0	31.5104	2.9	
I0520 06:16:15.535466 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:16:15.537616 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:16:15.537645 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:16:15.538192 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.5487
I0520 06:17:31.026918 15139 solver.cpp:231] Iteration 44600, loss = 1.33879
I0520 06:17:31.028203 15139 solver.cpp:247]     Train net output #0: loss = 1.33879 (* 1 = 1.33879 loss)
I0520 06:17:31.028228 15139 sgd_solver.cpp:106] Iteration 44600, lr = 0.001
I0520 06:17:31.191015 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1989	3.125	82.7103	0	91.2505	6.25	89.3276	0	85.4449	0	86.6556	0	79.7712	0	31.515	2.9	
I0520 06:17:31.267088 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:17:31.270081 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:17:31.270124 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:17:31.270934 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33879
I0520 06:18:53.649330 15139 solver.cpp:231] Iteration 44800, loss = 1.28215
I0520 06:18:53.649611 15139 solver.cpp:247]     Train net output #0: loss = 1.28215 (* 1 = 1.28215 loss)
I0520 06:18:53.649633 15139 sgd_solver.cpp:106] Iteration 44800, lr = 0.001
I0520 06:18:53.810916 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.176	3.125	82.7025	0	91.25	6.25	89.3277	0	85.4454	0	86.6589	0	79.7764	0	31.5207	2.9	
I0520 06:18:53.886412 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:18:53.889396 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:18:53.889436 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:18:53.889945 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28215
I0520 06:20:12.717793 15139 solver.cpp:348] Iteration 45000, Testing net (#0)
I0520 06:20:41.780088 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:21:32.916260 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56346
I0520 06:21:32.916599 15139 solver.cpp:415]     Test net output #1: loss = 1.87884 (* 1 = 1.87884 loss)
I0520 06:21:33.003937 15139 solver.cpp:231] Iteration 45000, loss = 1.50428
I0520 06:21:33.004025 15139 solver.cpp:247]     Train net output #0: loss = 1.50428 (* 1 = 1.50428 loss)
I0520 06:21:33.004045 15139 sgd_solver.cpp:106] Iteration 45000, lr = 0.001
I0520 06:21:33.168741 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2305	3.125	82.7096	0	91.2511	6.25	89.3282	0	85.4456	0	86.6623	0	79.7816	0	31.5253	2.9	
I0520 06:21:33.243988 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:21:33.246511 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:21:33.246538 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:21:33.247084 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.50428
I0520 06:22:52.982664 15139 solver.cpp:231] Iteration 45200, loss = 1.23293
I0520 06:22:52.983367 15139 solver.cpp:247]     Train net output #0: loss = 1.23293 (* 1 = 1.23293 loss)
I0520 06:22:52.983389 15139 sgd_solver.cpp:106] Iteration 45200, lr = 0.001
I0520 06:22:53.142894 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1501	3.125	82.7122	0	91.2512	6.25	89.3282	0	85.4442	0	86.6657	0	79.7868	0	31.5293	2.9	
I0520 06:22:53.218089 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:22:53.220011 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:22:53.220046 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:22:53.220593 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23293
I0520 06:23:41.731158 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:24:10.115830 15139 solver.cpp:231] Iteration 45400, loss = 1.13803
I0520 06:24:10.115947 15139 solver.cpp:247]     Train net output #0: loss = 1.13803 (* 1 = 1.13803 loss)
I0520 06:24:10.115969 15139 sgd_solver.cpp:106] Iteration 45400, lr = 0.001
I0520 06:24:10.276334 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.153	3.125	82.7217	0	91.2529	6.25	89.3291	0	85.4452	0	86.669	0	79.7918	0	31.534	2.9	
I0520 06:24:10.351542 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:24:10.354768 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:24:10.354814 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:24:10.355324 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13803
I0520 06:25:48.666021 15139 solver.cpp:231] Iteration 45600, loss = 1.40957
I0520 06:25:48.666765 15139 solver.cpp:247]     Train net output #0: loss = 1.40957 (* 1 = 1.40957 loss)
I0520 06:25:48.666790 15139 sgd_solver.cpp:106] Iteration 45600, lr = 0.001
I0520 06:25:48.825409 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1616	3.125	82.7168	0	91.2531	6.25	89.3298	0	85.4458	0	86.6723	0	79.7969	0	31.5395	2.9	
I0520 06:25:48.901227 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:25:48.904199 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:25:48.904242 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:25:48.904754 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.40957
I0520 06:27:07.957346 15139 solver.cpp:231] Iteration 45800, loss = 1.12727
I0520 06:27:07.957676 15139 solver.cpp:247]     Train net output #0: loss = 1.12727 (* 1 = 1.12727 loss)
I0520 06:27:07.957706 15139 sgd_solver.cpp:106] Iteration 45800, lr = 0.001
I0520 06:27:08.119863 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2448	3.125	82.7168	0	91.2508	6.25	89.3286	0	85.4458	0	86.6756	0	79.802	0	31.5438	2.9	
I0520 06:27:08.194782 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:27:08.196624 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:27:08.196666 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:27:08.197312 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12727
I0520 06:28:21.126286 15139 solver.cpp:348] Iteration 46000, Testing net (#0)
I0520 06:28:46.358402 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:29:35.029906 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56106
I0520 06:29:35.033645 15139 solver.cpp:415]     Test net output #1: loss = 1.88956 (* 1 = 1.88956 loss)
I0520 06:29:35.121470 15139 solver.cpp:231] Iteration 46000, loss = 1.29999
I0520 06:29:35.121574 15139 solver.cpp:247]     Train net output #0: loss = 1.29999 (* 1 = 1.29999 loss)
I0520 06:29:35.121598 15139 sgd_solver.cpp:106] Iteration 46000, lr = 0.001
I0520 06:29:35.287434 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.242	3.125	82.7139	0	91.2514	6.25	89.3294	0	85.4454	0	86.6789	0	79.8069	0	31.5486	2.9	
I0520 06:29:35.363759 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:29:35.366729 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:29:35.366770 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:29:35.367305 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.29999
I0520 06:30:51.726270 15139 solver.cpp:231] Iteration 46200, loss = 1.34628
I0520 06:30:51.726634 15139 solver.cpp:247]     Train net output #0: loss = 1.34628 (* 1 = 1.34628 loss)
I0520 06:30:51.726665 15139 sgd_solver.cpp:106] Iteration 46200, lr = 0.001
I0520 06:30:51.885309 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0583	3.125	82.7214	0	91.2526	6.25	89.3307	0	85.4452	0	86.6822	0	79.8117	0	31.5533	2.9	
I0520 06:30:51.959964 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:30:51.961859 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:30:51.961891 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:30:51.962559 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34628
I0520 06:31:44.263065 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:32:10.792033 15139 solver.cpp:231] Iteration 46400, loss = 1.36347
I0520 06:32:10.792126 15139 solver.cpp:247]     Train net output #0: loss = 1.36347 (* 1 = 1.36347 loss)
I0520 06:32:10.792147 15139 sgd_solver.cpp:106] Iteration 46400, lr = 0.001
I0520 06:32:10.953260 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.308	3.125	82.7197	0	91.2534	6.25	89.3317	0	85.4452	0	86.6854	0	79.8165	0	31.5584	2.9	
I0520 06:32:11.028264 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:32:11.030407 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:32:11.030439 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:32:11.030853 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.36347
I0520 06:33:28.354308 15139 solver.cpp:231] Iteration 46600, loss = 1.18673
I0520 06:33:28.355078 15139 solver.cpp:247]     Train net output #0: loss = 1.18673 (* 1 = 1.18673 loss)
I0520 06:33:28.355098 15139 sgd_solver.cpp:106] Iteration 46600, lr = 0.001
I0520 06:33:28.516196 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2477	3.125	82.7204	0	91.2538	6.25	89.3315	0	85.4452	0	86.6887	0	79.8218	0	31.5642	2.9	
I0520 06:33:28.591537 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:33:28.594918 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:33:28.594969 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:33:28.595696 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18673
I0520 06:34:53.213207 15139 solver.cpp:231] Iteration 46800, loss = 1.24394
I0520 06:34:53.213520 15139 solver.cpp:247]     Train net output #0: loss = 1.24394 (* 1 = 1.24394 loss)
I0520 06:34:53.213541 15139 sgd_solver.cpp:106] Iteration 46800, lr = 0.001
I0520 06:34:53.371721 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2104	3.125	82.7178	0	91.2533	6.25	89.3323	0	85.4445	0	86.6918	0	79.8268	0	31.5691	2.9	
I0520 06:34:53.446537 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:34:53.448529 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:34:53.448550 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:34:53.449012 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24394
I0520 06:36:17.168581 15139 solver.cpp:348] Iteration 47000, Testing net (#0)
I0520 06:36:46.005276 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:37:39.594846 15139 solver.cpp:415]     Test net output #0: accuracy = 0.560759
I0520 06:37:39.595140 15139 solver.cpp:415]     Test net output #1: loss = 1.89874 (* 1 = 1.89874 loss)
I0520 06:37:39.689725 15139 solver.cpp:231] Iteration 47000, loss = 1.22004
I0520 06:37:39.689910 15139 solver.cpp:247]     Train net output #0: loss = 1.22004 (* 1 = 1.22004 loss)
I0520 06:37:39.689930 15139 sgd_solver.cpp:106] Iteration 47000, lr = 0.001
I0520 06:37:39.849304 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2994	3.125	82.7113	0	91.2533	6.25	89.3317	0	85.4461	0	86.695	0	79.8319	0	31.5736	2.9	
I0520 06:37:39.923792 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:37:39.925356 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:37:39.925370 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:37:39.925772 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22004
I0520 06:38:57.213718 15139 solver.cpp:231] Iteration 47200, loss = 1.18239
I0520 06:38:57.213995 15139 solver.cpp:247]     Train net output #0: loss = 1.18239 (* 1 = 1.18239 loss)
I0520 06:38:57.214016 15139 sgd_solver.cpp:106] Iteration 47200, lr = 0.001
I0520 06:38:57.375658 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2707	3.125	82.7207	0	91.2543	6.25	89.3321	0	85.4467	0	86.6983	0	79.8367	0	31.5788	2.9	
I0520 06:38:57.451720 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:38:57.454042 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:38:57.454080 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:38:57.454833 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18239
I0520 06:39:54.484421 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:40:20.774363 15139 solver.cpp:231] Iteration 47400, loss = 1.26562
I0520 06:40:20.774447 15139 solver.cpp:247]     Train net output #0: loss = 1.26562 (* 1 = 1.26562 loss)
I0520 06:40:20.774467 15139 sgd_solver.cpp:106] Iteration 47400, lr = 0.001
I0520 06:40:20.936326 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2879	3.125	82.7194	0	91.2533	6.25	89.3315	0	85.4476	0	86.7015	0	79.8416	0	31.5829	2.9	
I0520 06:40:21.011350 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:40:21.013473 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:40:21.013507 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:40:21.014034 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26562
I0520 06:41:43.236904 15139 solver.cpp:231] Iteration 47600, loss = 1.34642
I0520 06:41:43.237196 15139 solver.cpp:247]     Train net output #0: loss = 1.34642 (* 1 = 1.34642 loss)
I0520 06:41:43.237218 15139 sgd_solver.cpp:106] Iteration 47600, lr = 0.001
I0520 06:41:43.397807 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2534	3.125	82.7116	0	91.2526	6.25	89.3312	0	85.4463	0	86.7049	0	79.8465	0	31.5878	2.9	
I0520 06:41:43.472995 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:41:43.476114 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:41:43.476156 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:41:43.476696 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34642
I0520 06:43:03.964970 15139 solver.cpp:231] Iteration 47800, loss = 1.1278
I0520 06:43:03.965924 15139 solver.cpp:247]     Train net output #0: loss = 1.1278 (* 1 = 1.1278 loss)
I0520 06:43:03.965945 15139 sgd_solver.cpp:106] Iteration 47800, lr = 0.001
I0520 06:43:04.126155 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1874	3.125	82.7188	0	91.2534	6.25	89.3318	0	85.4488	0	86.7079	0	79.8515	0	31.5925	2.9	
I0520 06:43:04.203054 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:43:04.206501 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:43:04.206552 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:43:04.207279 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1278
I0520 06:44:20.174291 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_48000.caffemodel
I0520 06:45:13.657198 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_48000.solverstate
I0520 06:45:14.142443 15139 solver.cpp:348] Iteration 48000, Testing net (#0)
I0520 06:45:38.936794 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:46:28.847007 15139 solver.cpp:415]     Test net output #0: accuracy = 0.560639
I0520 06:46:28.847338 15139 solver.cpp:415]     Test net output #1: loss = 1.89655 (* 1 = 1.89655 loss)
I0520 06:46:28.936626 15139 solver.cpp:231] Iteration 48000, loss = 1.14447
I0520 06:46:28.936727 15139 solver.cpp:247]     Train net output #0: loss = 1.14447 (* 1 = 1.14447 loss)
I0520 06:46:28.936745 15139 sgd_solver.cpp:106] Iteration 48000, lr = 0.001
I0520 06:46:29.106895 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1645	3.125	82.7155	0	91.2521	6.25	89.3326	0	85.4501	0	86.7111	0	79.8565	0	31.5963	2.9	
I0520 06:46:29.108959 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:46:29.111526 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:46:29.111555 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:46:29.112012 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14447
I0520 06:47:50.608990 15139 solver.cpp:231] Iteration 48200, loss = 1.17478
I0520 06:47:50.609217 15139 solver.cpp:247]     Train net output #0: loss = 1.17478 (* 1 = 1.17478 loss)
I0520 06:47:50.609239 15139 sgd_solver.cpp:106] Iteration 48200, lr = 0.001
I0520 06:47:50.770648 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1961	3.125	82.7135	0	91.2531	6.25	89.3332	0	85.4488	0	86.7142	0	79.8614	0	31.6014	2.9	
I0520 06:47:50.845571 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:47:50.847581 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:47:50.847625 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:47:50.848165 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17478
I0520 06:48:51.057498 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:49:14.777665 15139 solver.cpp:231] Iteration 48400, loss = 1.32118
I0520 06:49:14.777756 15139 solver.cpp:247]     Train net output #0: loss = 1.32118 (* 1 = 1.32118 loss)
I0520 06:49:14.777777 15139 sgd_solver.cpp:106] Iteration 48400, lr = 0.001
I0520 06:49:14.938940 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1272	3.125	82.7152	0	91.2539	6.25	89.3342	0	85.4483	0	86.7175	0	79.8661	0	31.6065	2.9	
I0520 06:49:15.014158 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:49:15.016237 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:49:15.016266 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:49:15.016856 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32118
I0520 06:50:48.934945 15139 solver.cpp:231] Iteration 48600, loss = 1.32248
I0520 06:50:48.935240 15139 solver.cpp:247]     Train net output #0: loss = 1.32248 (* 1 = 1.32248 loss)
I0520 06:50:48.935261 15139 sgd_solver.cpp:106] Iteration 48600, lr = 0.001
I0520 06:50:49.096521 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1645	3.125	82.7181	0	91.2534	6.25	89.3345	0	85.4488	0	86.7206	0	79.8709	0	31.6112	2.9	
I0520 06:50:49.171654 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:50:49.174257 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:50:49.174296 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:50:49.174801 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32248
I0520 06:52:22.180732 15139 solver.cpp:231] Iteration 48800, loss = 1.23944
I0520 06:52:22.181125 15139 solver.cpp:247]     Train net output #0: loss = 1.23944 (* 1 = 1.23944 loss)
I0520 06:52:22.181160 15139 sgd_solver.cpp:106] Iteration 48800, lr = 0.001
I0520 06:52:22.341187 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0554	3.125	82.7074	0	91.2542	6.25	89.3336	0	85.4506	0	86.7237	0	79.8757	0	31.6155	2.9	
I0520 06:52:22.416992 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:52:22.420128 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:52:22.420171 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:52:22.420686 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23944
I0520 06:53:47.204802 15139 solver.cpp:348] Iteration 49000, Testing net (#0)
I0520 06:54:15.781707 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:55:14.038496 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56292
I0520 06:55:14.038825 15139 solver.cpp:415]     Test net output #1: loss = 1.88304 (* 1 = 1.88304 loss)
I0520 06:55:14.128487 15139 solver.cpp:231] Iteration 49000, loss = 1.40169
I0520 06:55:14.128582 15139 solver.cpp:247]     Train net output #0: loss = 1.40169 (* 1 = 1.40169 loss)
I0520 06:55:14.128605 15139 sgd_solver.cpp:106] Iteration 49000, lr = 0.001
I0520 06:55:14.295328 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1961	3.125	82.7113	0	91.2547	6.25	89.3359	0	85.4503	0	86.7269	0	79.8803	0	31.6208	2.9	
I0520 06:55:14.370767 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:55:14.373999 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:55:14.374050 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:55:14.374758 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.40169
I0520 06:56:40.015674 15139 solver.cpp:231] Iteration 49200, loss = 1.24605
I0520 06:56:40.015964 15139 solver.cpp:247]     Train net output #0: loss = 1.24605 (* 1 = 1.24605 loss)
I0520 06:56:40.015982 15139 sgd_solver.cpp:106] Iteration 49200, lr = 0.001
I0520 06:56:40.175071 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1444	3.125	82.7083	0	91.2549	6.25	89.3359	0	85.4497	0	86.7299	0	79.8851	0	31.6264	2.9	
I0520 06:56:40.250727 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:56:40.254062 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:56:40.254106 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:56:40.254761 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24605
I0520 06:57:40.448730 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 06:57:58.287973 15139 solver.cpp:231] Iteration 49400, loss = 1.31374
I0520 06:57:58.288070 15139 solver.cpp:247]     Train net output #0: loss = 1.31374 (* 1 = 1.31374 loss)
I0520 06:57:58.288089 15139 sgd_solver.cpp:106] Iteration 49400, lr = 0.001
I0520 06:57:58.450080 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1932	3.125	82.7243	0	91.2546	6.25	89.3357	0	85.4506	0	86.7331	0	79.8901	0	31.632	2.9	
I0520 06:57:58.525925 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:57:58.528139 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:57:58.528193 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:57:58.528761 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31374
I0520 06:59:15.285362 15139 solver.cpp:231] Iteration 49600, loss = 1.19569
I0520 06:59:15.285794 15139 solver.cpp:247]     Train net output #0: loss = 1.19569 (* 1 = 1.19569 loss)
I0520 06:59:15.285820 15139 sgd_solver.cpp:106] Iteration 49600, lr = 0.001
I0520 06:59:15.446051 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1329	3.125	82.7171	0	91.2559	6.25	89.336	0	85.4503	0	86.7363	0	79.895	0	31.6364	2.9	
I0520 06:59:15.526315 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 06:59:15.528733 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 06:59:15.528772 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 06:59:15.529534 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19569
I0520 07:00:35.622320 15139 solver.cpp:231] Iteration 49800, loss = 1.26416
I0520 07:00:35.622479 15139 solver.cpp:247]     Train net output #0: loss = 1.26416 (* 1 = 1.26416 loss)
I0520 07:00:35.622499 15139 sgd_solver.cpp:106] Iteration 49800, lr = 0.001
I0520 07:00:35.782222 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1301	3.125	82.7106	0	91.2554	6.25	89.3362	0	85.4501	0	86.7395	0	79.8998	0	31.6412	2.9	
I0520 07:00:35.856868 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:00:35.862742 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:00:35.862785 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:00:35.863275 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26416
I0520 07:01:57.342173 15139 solver.cpp:348] Iteration 50000, Testing net (#0)
I0520 07:02:22.477404 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:03:09.604295 15139 solver.cpp:415]     Test net output #0: accuracy = 0.562899
I0520 07:03:09.604599 15139 solver.cpp:415]     Test net output #1: loss = 1.88414 (* 1 = 1.88414 loss)
I0520 07:03:09.692859 15139 solver.cpp:231] Iteration 50000, loss = 1.39012
I0520 07:03:09.692935 15139 solver.cpp:247]     Train net output #0: loss = 1.39012 (* 1 = 1.39012 loss)
I0520 07:03:09.692956 15139 sgd_solver.cpp:106] Iteration 50000, lr = 0.001
I0520 07:03:09.856361 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.11	3.125	82.7188	0	91.2564	6.25	89.3372	0	85.4533	0	86.7428	0	79.9045	0	31.6452	2.9	
I0520 07:03:09.931134 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:03:09.932703 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:03:09.932728 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:03:09.933136 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.39012
I0520 07:04:22.975924 15139 solver.cpp:231] Iteration 50200, loss = 1.32462
I0520 07:04:22.976186 15139 solver.cpp:247]     Train net output #0: loss = 1.32462 (* 1 = 1.32462 loss)
I0520 07:04:22.976204 15139 sgd_solver.cpp:106] Iteration 50200, lr = 0.001
I0520 07:04:23.137187 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.087	3.125	82.7197	0	91.2572	6.25	89.3369	0	85.4535	0	86.7459	0	79.9093	0	31.6493	2.9	
I0520 07:04:23.212646 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:04:23.214406 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:04:23.214432 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:04:23.214929 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32462
I0520 07:05:26.078716 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:05:42.830201 15139 solver.cpp:231] Iteration 50400, loss = 1.20655
I0520 07:05:42.830327 15139 solver.cpp:247]     Train net output #0: loss = 1.20655 (* 1 = 1.20655 loss)
I0520 07:05:42.830346 15139 sgd_solver.cpp:106] Iteration 50400, lr = 0.001
I0520 07:05:42.990572 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2793	3.125	82.7142	0	91.2554	6.25	89.3369	0	85.4542	0	86.7491	0	79.9137	0	31.6539	2.9	
I0520 07:05:43.065520 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:05:43.067963 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:05:43.068012 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:05:43.068629 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20655
I0520 07:07:01.300999 15139 solver.cpp:231] Iteration 50600, loss = 1.39037
I0520 07:07:01.301282 15139 solver.cpp:247]     Train net output #0: loss = 1.39037 (* 1 = 1.39037 loss)
I0520 07:07:01.301302 15139 sgd_solver.cpp:106] Iteration 50600, lr = 0.001
I0520 07:07:01.460547 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2764	3.125	82.7259	0	91.257	6.25	89.3371	0	85.4553	0	86.7523	0	79.9184	0	31.6587	2.9	
I0520 07:07:01.535933 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:07:01.539083 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:07:01.539126 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:07:01.539649 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.39037
I0520 07:08:21.269074 15139 solver.cpp:231] Iteration 50800, loss = 1.18604
I0520 07:08:21.270205 15139 solver.cpp:247]     Train net output #0: loss = 1.18604 (* 1 = 1.18604 loss)
I0520 07:08:21.270236 15139 sgd_solver.cpp:106] Iteration 50800, lr = 0.001
I0520 07:08:21.427620 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2592	3.125	82.7275	0	91.2574	6.25	89.3377	0	85.4567	0	86.7553	0	79.9234	0	31.6642	2.9	
I0520 07:08:21.503339 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:08:21.505123 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:08:21.505159 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:08:21.505911 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18604
I0520 07:09:47.398949 15139 solver.cpp:348] Iteration 51000, Testing net (#0)
I0520 07:10:13.535559 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:11:02.916555 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5612
I0520 07:11:02.916793 15139 solver.cpp:415]     Test net output #1: loss = 1.88984 (* 1 = 1.88984 loss)
I0520 07:11:03.004544 15139 solver.cpp:231] Iteration 51000, loss = 1.44081
I0520 07:11:03.004622 15139 solver.cpp:247]     Train net output #0: loss = 1.44081 (* 1 = 1.44081 loss)
I0520 07:11:03.004642 15139 sgd_solver.cpp:106] Iteration 51000, lr = 0.001
I0520 07:11:03.164014 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1961	3.125	82.724	0	91.2566	6.25	89.3366	0	85.4553	0	86.7585	0	79.9282	0	31.6688	2.9	
I0520 07:11:03.241067 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:11:03.244468 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:11:03.244516 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:11:03.245151 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.44081
I0520 07:12:23.657749 15139 solver.cpp:231] Iteration 51200, loss = 1.45314
I0520 07:12:23.658002 15139 solver.cpp:247]     Train net output #0: loss = 1.45314 (* 1 = 1.45314 loss)
I0520 07:12:23.658022 15139 sgd_solver.cpp:106] Iteration 51200, lr = 0.001
I0520 07:12:23.817380 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1961	3.125	82.7275	0	91.2588	6.25	89.3371	0	85.4558	0	86.7615	0	79.933	0	31.6734	2.9	
I0520 07:12:23.892102 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:12:23.893985 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:12:23.894016 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:12:23.894464 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.45314
I0520 07:13:34.002244 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:13:48.736399 15139 solver.cpp:231] Iteration 51400, loss = 1.1605
I0520 07:13:48.736505 15139 solver.cpp:247]     Train net output #0: loss = 1.1605 (* 1 = 1.1605 loss)
I0520 07:13:48.736524 15139 sgd_solver.cpp:106] Iteration 51400, lr = 0.001
I0520 07:13:48.896561 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3194	3.125	82.7327	0	91.2601	6.25	89.3375	0	85.4556	0	86.7644	0	79.9377	0	31.6776	2.9	
I0520 07:13:48.971902 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:13:48.975466 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:13:48.975503 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:13:48.976111 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1605
I0520 07:15:09.912284 15139 solver.cpp:231] Iteration 51600, loss = 1.25954
I0520 07:15:09.912588 15139 solver.cpp:247]     Train net output #0: loss = 1.25954 (* 1 = 1.25954 loss)
I0520 07:15:09.912623 15139 sgd_solver.cpp:106] Iteration 51600, lr = 0.001
I0520 07:15:10.074354 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.351	3.125	82.7292	0	91.2598	6.25	89.3375	0	85.4558	0	86.7676	0	79.9425	0	31.6813	2.9	
I0520 07:15:10.149488 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:15:10.151830 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:15:10.151861 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:15:10.152482 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25954
I0520 07:16:34.606083 15139 solver.cpp:231] Iteration 51800, loss = 1.33871
I0520 07:16:34.606408 15139 solver.cpp:247]     Train net output #0: loss = 1.33871 (* 1 = 1.33871 loss)
I0520 07:16:34.606448 15139 sgd_solver.cpp:106] Iteration 51800, lr = 0.001
I0520 07:16:34.767640 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.285	3.125	82.7236	0	91.2597	6.25	89.3375	0	85.4551	0	86.7706	0	79.9474	0	31.6867	2.9	
I0520 07:16:34.842512 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:16:34.844163 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:16:34.844190 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:16:34.844723 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33871
I0520 07:18:01.438127 15139 solver.cpp:348] Iteration 52000, Testing net (#0)
I0520 07:18:31.284317 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:19:15.211686 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5588
I0520 07:19:15.211915 15139 solver.cpp:415]     Test net output #1: loss = 1.90171 (* 1 = 1.90171 loss)
I0520 07:19:15.300169 15139 solver.cpp:231] Iteration 52000, loss = 1.22603
I0520 07:19:15.300380 15139 solver.cpp:247]     Train net output #0: loss = 1.22603 (* 1 = 1.22603 loss)
I0520 07:19:15.300406 15139 sgd_solver.cpp:106] Iteration 52000, lr = 0.001
I0520 07:19:15.465358 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1358	3.125	82.7197	0	91.2594	6.25	89.338	0	85.4562	0	86.7737	0	79.9522	0	31.6917	2.9	
I0520 07:19:15.545722 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:19:15.547782 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:19:15.547819 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:19:15.548462 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22603
I0520 07:20:46.221669 15139 solver.cpp:231] Iteration 52200, loss = 1.39405
I0520 07:20:46.222043 15139 solver.cpp:247]     Train net output #0: loss = 1.39405 (* 1 = 1.39405 loss)
I0520 07:20:46.222065 15139 sgd_solver.cpp:106] Iteration 52200, lr = 0.001
I0520 07:20:46.381969 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2793	3.125	82.7292	0	91.2595	6.25	89.3392	0	85.4551	0	86.7769	0	79.9571	0	31.6959	2.9	
I0520 07:20:46.456665 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:20:46.458783 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:20:46.458816 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:20:46.459338 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.39405
I0520 07:21:57.638389 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:22:08.304466 15139 solver.cpp:231] Iteration 52400, loss = 1.24122
I0520 07:22:08.304575 15139 solver.cpp:247]     Train net output #0: loss = 1.24122 (* 1 = 1.24122 loss)
I0520 07:22:08.304594 15139 sgd_solver.cpp:106] Iteration 52400, lr = 0.001
I0520 07:22:08.464787 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2621	3.125	82.7266	0	91.258	6.25	89.3387	0	85.456	0	86.78	0	79.962	0	31.7002	2.9	
I0520 07:22:08.540976 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:22:08.544147 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:22:08.544188 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:22:08.544736 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24122
I0520 07:23:25.516757 15139 solver.cpp:231] Iteration 52600, loss = 1.32296
I0520 07:23:25.517063 15139 solver.cpp:247]     Train net output #0: loss = 1.32296 (* 1 = 1.32296 loss)
I0520 07:23:25.517083 15139 sgd_solver.cpp:106] Iteration 52600, lr = 0.001
I0520 07:23:25.679359 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3194	3.125	82.7295	0	91.2593	6.25	89.3395	0	85.4574	0	86.783	0	79.9671	0	31.7051	2.9	
I0520 07:23:25.754744 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:23:25.757781 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:23:25.757830 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:23:25.758390 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32296
I0520 07:24:42.364588 15139 solver.cpp:231] Iteration 52800, loss = 1.20726
I0520 07:24:42.364871 15139 solver.cpp:247]     Train net output #0: loss = 1.20726 (* 1 = 1.20726 loss)
I0520 07:24:42.364893 15139 sgd_solver.cpp:106] Iteration 52800, lr = 0.001
I0520 07:24:42.524615 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3166	3.125	82.7311	0	91.2598	6.25	89.3395	0	85.4583	0	86.786	0	79.9715	0	31.7107	2.9	
I0520 07:24:42.599701 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:24:42.602511 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:24:42.602550 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:24:42.603112 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20726
I0520 07:25:57.685781 15139 solver.cpp:348] Iteration 53000, Testing net (#0)
I0520 07:26:29.381660 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:27:15.470599 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55968
I0520 07:27:15.470851 15139 solver.cpp:415]     Test net output #1: loss = 1.89652 (* 1 = 1.89652 loss)
I0520 07:27:15.558115 15139 solver.cpp:231] Iteration 53000, loss = 1.38574
I0520 07:27:15.558183 15139 solver.cpp:247]     Train net output #0: loss = 1.38574 (* 1 = 1.38574 loss)
I0520 07:27:15.558221 15139 sgd_solver.cpp:106] Iteration 53000, lr = 0.001
I0520 07:27:15.723055 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2965	3.125	82.7275	0	91.2589	6.25	89.3387	0	85.4565	0	86.7891	0	79.9762	0	31.7157	2.9	
I0520 07:27:15.797910 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:27:15.799630 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:27:15.799657 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:27:15.800235 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.38574
I0520 07:28:29.467983 15139 solver.cpp:231] Iteration 53200, loss = 1.50906
I0520 07:28:29.468219 15139 solver.cpp:247]     Train net output #0: loss = 1.50906 (* 1 = 1.50906 loss)
I0520 07:28:29.468240 15139 sgd_solver.cpp:106] Iteration 53200, lr = 0.001
I0520 07:28:29.626915 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3022	3.125	82.7298	0	91.2603	6.25	89.3395	0	85.4585	0	86.7923	0	79.981	0	31.7201	2.9	
I0520 07:28:29.702566 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:28:29.704510 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:28:29.704535 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:28:29.705093 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.50906
I0520 07:29:34.734659 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:29:42.476995 15139 solver.cpp:231] Iteration 53400, loss = 1.31233
I0520 07:29:42.477073 15139 solver.cpp:247]     Train net output #0: loss = 1.31233 (* 1 = 1.31233 loss)
I0520 07:29:42.477092 15139 sgd_solver.cpp:106] Iteration 53400, lr = 0.001
I0520 07:29:42.639255 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3567	3.125	82.7324	0	91.2594	6.25	89.3401	0	85.4598	0	86.7952	0	79.9858	0	31.7247	2.9	
I0520 07:29:42.713990 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:29:42.715931 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:29:42.715958 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:29:42.716413 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31233
I0520 07:30:55.502583 15139 solver.cpp:231] Iteration 53600, loss = 1.17778
I0520 07:30:55.502888 15139 solver.cpp:247]     Train net output #0: loss = 1.17778 (* 1 = 1.17778 loss)
I0520 07:30:55.502907 15139 sgd_solver.cpp:106] Iteration 53600, lr = 0.001
I0520 07:30:55.664232 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2821	3.125	82.7292	0	91.2604	6.25	89.3396	0	85.458	0	86.7982	0	79.9905	0	31.7291	2.9	
I0520 07:30:55.739454 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:30:55.741580 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:30:55.741611 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:30:55.742195 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17778
I0520 07:32:15.676033 15139 solver.cpp:231] Iteration 53800, loss = 1.35791
I0520 07:32:15.676265 15139 solver.cpp:247]     Train net output #0: loss = 1.35791 (* 1 = 1.35791 loss)
I0520 07:32:15.676286 15139 sgd_solver.cpp:106] Iteration 53800, lr = 0.001
I0520 07:32:15.837185 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2678	3.125	82.7347	0	91.2612	6.25	89.3392	0	85.4607	0	86.8015	0	79.9953	0	31.7336	2.9	
I0520 07:32:15.912892 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:32:15.914997 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:32:15.915041 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:32:15.915545 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35791
I0520 07:33:40.953544 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_54000.caffemodel
I0520 07:35:00.503677 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_54000.solverstate
I0520 07:35:01.188484 15139 solver.cpp:348] Iteration 54000, Testing net (#0)
I0520 07:35:34.245327 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:36:28.696836 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56064
I0520 07:36:28.701652 15139 solver.cpp:415]     Test net output #1: loss = 1.88978 (* 1 = 1.88978 loss)
I0520 07:36:28.792191 15139 solver.cpp:231] Iteration 54000, loss = 1.52146
I0520 07:36:28.792264 15139 solver.cpp:247]     Train net output #0: loss = 1.52146 (* 1 = 1.52146 loss)
I0520 07:36:28.792284 15139 sgd_solver.cpp:106] Iteration 54000, lr = 0.001
I0520 07:36:28.958276 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3367	3.125	82.7318	0	91.2619	6.25	89.3396	0	85.4596	0	86.8046	0	79.9999	0	31.7382	2.9	
I0520 07:36:28.960352 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:36:28.962595 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:36:28.962621 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:36:28.963268 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.52146
I0520 07:37:44.537866 15139 solver.cpp:231] Iteration 54200, loss = 1.17317
I0520 07:37:44.538223 15139 solver.cpp:247]     Train net output #0: loss = 1.17317 (* 1 = 1.17317 loss)
I0520 07:37:44.538244 15139 sgd_solver.cpp:106] Iteration 54200, lr = 0.001
I0520 07:37:44.696470 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3281	3.125	82.7314	0	91.2616	6.25	89.3389	0	85.4589	0	86.8076	0	80.0044	0	31.7425	2.9	
I0520 07:37:44.771430 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:37:44.773562 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:37:44.773605 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:37:44.774169 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17317
I0520 07:38:58.113976 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:39:04.114850 15139 solver.cpp:231] Iteration 54400, loss = 1.31676
I0520 07:39:04.114943 15139 solver.cpp:247]     Train net output #0: loss = 1.31676 (* 1 = 1.31676 loss)
I0520 07:39:04.114965 15139 sgd_solver.cpp:106] Iteration 54400, lr = 0.001
I0520 07:39:04.275274 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3338	3.125	82.7279	0	91.2624	6.25	89.3398	0	85.4598	0	86.8106	0	80.009	0	31.7467	2.9	
I0520 07:39:04.350903 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:39:04.352668 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:39:04.352694 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:39:04.353281 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31676
I0520 07:40:22.367045 15139 solver.cpp:231] Iteration 54600, loss = 1.09574
I0520 07:40:22.367346 15139 solver.cpp:247]     Train net output #0: loss = 1.09574 (* 1 = 1.09574 loss)
I0520 07:40:22.367367 15139 sgd_solver.cpp:106] Iteration 54600, lr = 0.001
I0520 07:40:22.526723 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3108	3.125	82.723	0	91.2627	6.25	89.3395	0	85.4601	0	86.8136	0	80.0136	0	31.7511	2.9	
I0520 07:40:22.601467 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:40:22.603590 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:40:22.603657 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:40:22.604260 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09574
I0520 07:41:39.566342 15139 solver.cpp:231] Iteration 54800, loss = 1.49511
I0520 07:41:39.566701 15139 solver.cpp:247]     Train net output #0: loss = 1.49511 (* 1 = 1.49511 loss)
I0520 07:41:39.566725 15139 sgd_solver.cpp:106] Iteration 54800, lr = 0.001
I0520 07:41:39.728739 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2047	3.125	82.7314	0	91.2629	6.25	89.3402	0	85.4592	0	86.8165	0	80.018	0	31.7565	2.9	
I0520 07:41:39.804594 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:41:39.806896 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:41:39.806926 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:41:39.807502 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.49511
I0520 07:42:53.496924 15139 solver.cpp:348] Iteration 55000, Testing net (#0)
I0520 07:43:24.964977 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:44:15.818956 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55944
I0520 07:44:15.819133 15139 solver.cpp:415]     Test net output #1: loss = 1.89244 (* 1 = 1.89244 loss)
I0520 07:44:15.913215 15139 solver.cpp:231] Iteration 55000, loss = 1.17454
I0520 07:44:15.913338 15139 solver.cpp:247]     Train net output #0: loss = 1.17454 (* 1 = 1.17454 loss)
I0520 07:44:15.913362 15139 sgd_solver.cpp:106] Iteration 55000, lr = 0.001
I0520 07:44:16.071251 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0985	3.125	82.7253	0	91.2634	6.25	89.3407	0	85.4603	0	86.8194	0	80.0226	0	31.7612	2.9	
I0520 07:44:16.148666 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:44:16.151214 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:44:16.151252 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:44:16.151968 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17454
I0520 07:45:42.819679 15139 solver.cpp:231] Iteration 55200, loss = 1.19807
I0520 07:45:42.820008 15139 solver.cpp:247]     Train net output #0: loss = 1.19807 (* 1 = 1.19807 loss)
I0520 07:45:42.820049 15139 sgd_solver.cpp:106] Iteration 55200, lr = 0.001
I0520 07:45:42.982573 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0727	3.125	82.7386	0	91.2623	6.25	89.3405	0	85.4596	0	86.8223	0	80.0269	0	31.7657	2.9	
I0520 07:45:43.058214 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:45:43.060642 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:45:43.060690 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:45:43.061332 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19807
I0520 07:47:06.853266 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:47:09.504140 15139 solver.cpp:231] Iteration 55400, loss = 1.1745
I0520 07:47:09.504235 15139 solver.cpp:247]     Train net output #0: loss = 1.1745 (* 1 = 1.1745 loss)
I0520 07:47:09.504253 15139 sgd_solver.cpp:106] Iteration 55400, lr = 0.001
I0520 07:47:09.663959 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2391	3.125	82.7275	0	91.2617	6.25	89.3405	0	85.4612	0	86.8254	0	80.0313	0	31.7709	2.9	
I0520 07:47:09.738905 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:47:09.740962 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:47:09.740990 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:47:09.741526 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1745
I0520 07:48:33.088047 15139 solver.cpp:231] Iteration 55600, loss = 1.12838
I0520 07:48:33.089637 15139 solver.cpp:247]     Train net output #0: loss = 1.12838 (* 1 = 1.12838 loss)
I0520 07:48:33.089660 15139 sgd_solver.cpp:106] Iteration 55600, lr = 0.001
I0520 07:48:33.246973 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2477	3.125	82.7337	0	91.2629	6.25	89.3413	0	85.4617	0	86.8283	0	80.036	0	31.7757	2.9	
I0520 07:48:33.321935 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:48:33.323956 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:48:33.323990 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:48:33.324475 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12838
I0520 07:49:52.020866 15139 solver.cpp:231] Iteration 55800, loss = 1.18333
I0520 07:49:52.021214 15139 solver.cpp:247]     Train net output #0: loss = 1.18333 (* 1 = 1.18333 loss)
I0520 07:49:52.021239 15139 sgd_solver.cpp:106] Iteration 55800, lr = 0.001
I0520 07:49:52.181100 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3022	3.125	82.7425	0	91.2637	6.25	89.3411	0	85.4603	0	86.8312	0	80.0405	0	31.78	2.9	
I0520 07:49:52.255735 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:49:52.257967 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:49:52.257997 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:49:52.258683 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18333
I0520 07:51:18.212730 15139 solver.cpp:348] Iteration 56000, Testing net (#0)
I0520 07:51:47.710531 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:52:37.320071 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56054
I0520 07:52:37.320468 15139 solver.cpp:415]     Test net output #1: loss = 1.89189 (* 1 = 1.89189 loss)
I0520 07:52:37.411228 15139 solver.cpp:231] Iteration 56000, loss = 1.15755
I0520 07:52:37.411329 15139 solver.cpp:247]     Train net output #0: loss = 1.15755 (* 1 = 1.15755 loss)
I0520 07:52:37.411348 15139 sgd_solver.cpp:106] Iteration 56000, lr = 0.001
I0520 07:52:37.570993 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2534	3.125	82.7373	0	91.2642	6.25	89.3411	0	85.4607	0	86.8342	0	80.045	0	31.7847	2.9	
I0520 07:52:37.646404 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:52:37.649740 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:52:37.649796 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:52:37.650427 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15755
I0520 07:53:56.528270 15139 solver.cpp:231] Iteration 56200, loss = 1.29924
I0520 07:53:56.528578 15139 solver.cpp:247]     Train net output #0: loss = 1.29924 (* 1 = 1.29924 loss)
I0520 07:53:56.528733 15139 sgd_solver.cpp:106] Iteration 56200, lr = 0.001
I0520 07:53:56.688138 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3797	3.125	82.7334	0	91.2641	6.25	89.3422	0	85.4605	0	86.837	0	80.0493	0	31.79	2.9	
I0520 07:53:56.763380 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:53:56.766791 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:53:56.766840 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:53:56.767442 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.29924
I0520 07:55:17.437363 15139 solver.cpp:231] Iteration 56400, loss = 1.33717
I0520 07:55:17.441668 15139 solver.cpp:247]     Train net output #0: loss = 1.33717 (* 1 = 1.33717 loss)
I0520 07:55:17.441701 15139 sgd_solver.cpp:106] Iteration 56400, lr = 0.001
I0520 07:55:17.597965 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2707	3.125	82.7373	0	91.2635	6.25	89.3422	0	85.4596	0	86.84	0	80.0539	0	31.7948	2.9	
I0520 07:55:17.673032 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:55:17.675500 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:55:17.675545 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:55:17.676111 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33717
I0520 07:55:17.676307 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 07:56:37.517607 15139 solver.cpp:231] Iteration 56600, loss = 1.3579
I0520 07:56:37.517989 15139 solver.cpp:247]     Train net output #0: loss = 1.3579 (* 1 = 1.3579 loss)
I0520 07:56:37.518012 15139 sgd_solver.cpp:106] Iteration 56600, lr = 0.001
I0520 07:56:37.677781 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2276	3.125	82.7376	0	91.2642	6.25	89.3428	0	85.461	0	86.843	0	80.0584	0	31.7997	2.9	
I0520 07:56:37.753285 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:56:37.755681 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:56:37.755728 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:56:37.756258 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.3579
I0520 07:57:56.282342 15139 solver.cpp:231] Iteration 56800, loss = 1.24789
I0520 07:57:56.282551 15139 solver.cpp:247]     Train net output #0: loss = 1.24789 (* 1 = 1.24789 loss)
I0520 07:57:56.282577 15139 sgd_solver.cpp:106] Iteration 56800, lr = 0.001
I0520 07:57:56.442122 15139 sgd_solver.cpp:120]     Element Sparsity %: 
15.9407	3.125	82.7357	0	91.2635	6.25	89.343	0	85.4617	0	86.846	0	80.0629	0	31.8041	2.9	
I0520 07:57:56.517102 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 07:57:56.519639 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 07:57:56.519685 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 07:57:56.520308 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24789
I0520 07:59:26.608366 15139 solver.cpp:348] Iteration 57000, Testing net (#0)
I0520 08:00:00.112110 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:00:53.093657 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56222
I0520 08:00:53.097653 15139 solver.cpp:415]     Test net output #1: loss = 1.88517 (* 1 = 1.88517 loss)
I0520 08:00:53.185627 15139 solver.cpp:231] Iteration 57000, loss = 1.22743
I0520 08:00:53.185716 15139 solver.cpp:247]     Train net output #0: loss = 1.22743 (* 1 = 1.22743 loss)
I0520 08:00:53.185734 15139 sgd_solver.cpp:106] Iteration 57000, lr = 0.001
I0520 08:00:53.354166 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.1358	3.125	82.7383	0	91.2627	6.25	89.3431	0	85.4617	0	86.8489	0	80.0676	0	31.8079	2.9	
I0520 08:00:53.430203 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:00:53.434017 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:00:53.434069 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:00:53.434620 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22743
I0520 08:02:09.714678 15139 solver.cpp:231] Iteration 57200, loss = 1.076
I0520 08:02:09.714923 15139 solver.cpp:247]     Train net output #0: loss = 1.076 (* 1 = 1.076 loss)
I0520 08:02:09.714944 15139 sgd_solver.cpp:106] Iteration 57200, lr = 0.001
I0520 08:02:09.875586 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3539	3.125	82.7432	0	91.2636	6.25	89.3437	0	85.4619	0	86.8519	0	80.0726	0	31.8125	2.9	
I0520 08:02:09.950772 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:02:09.953254 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:02:09.953299 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:02:09.953817 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.076
I0520 08:03:35.412336 15139 solver.cpp:231] Iteration 57400, loss = 1.31803
I0520 08:03:35.412715 15139 solver.cpp:247]     Train net output #0: loss = 1.31803 (* 1 = 1.31803 loss)
I0520 08:03:35.412747 15139 sgd_solver.cpp:106] Iteration 57400, lr = 0.001
I0520 08:03:35.572438 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2018	3.125	82.7402	0	91.263	6.25	89.3433	0	85.4607	0	86.8547	0	80.0772	0	31.8172	2.9	
I0520 08:03:35.657873 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:03:35.660581 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:03:35.660622 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:03:35.661275 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31803
I0520 08:03:38.278955 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:05:01.072818 15139 solver.cpp:231] Iteration 57600, loss = 1.47847
I0520 08:05:01.073101 15139 solver.cpp:247]     Train net output #0: loss = 1.47847 (* 1 = 1.47847 loss)
I0520 08:05:01.073122 15139 sgd_solver.cpp:106] Iteration 57600, lr = 0.001
I0520 08:05:01.232508 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3367	3.125	82.7412	0	91.2632	6.25	89.3442	0	85.4601	0	86.8576	0	80.082	0	31.8214	2.9	
I0520 08:05:01.307662 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:05:01.309731 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:05:01.309773 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:05:01.310262 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.47847
I0520 08:06:40.195905 15139 solver.cpp:231] Iteration 57800, loss = 1.40606
I0520 08:06:40.196247 15139 solver.cpp:247]     Train net output #0: loss = 1.40606 (* 1 = 1.40606 loss)
I0520 08:06:40.196270 15139 sgd_solver.cpp:106] Iteration 57800, lr = 0.001
I0520 08:06:40.356974 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3051	3.125	82.7425	0	91.2653	6.25	89.3437	0	85.4617	0	86.8605	0	80.0865	0	31.8259	2.9	
I0520 08:06:40.433910 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:06:40.437602 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:06:40.437661 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:06:40.438215 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.40606
I0520 08:08:02.082388 15139 solver.cpp:348] Iteration 58000, Testing net (#0)
I0520 08:08:35.235996 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:09:26.208125 15139 solver.cpp:415]     Test net output #0: accuracy = 0.55856
I0520 08:09:26.208448 15139 solver.cpp:415]     Test net output #1: loss = 1.89944 (* 1 = 1.89944 loss)
I0520 08:09:26.296258 15139 solver.cpp:231] Iteration 58000, loss = 1.45563
I0520 08:09:26.296371 15139 solver.cpp:247]     Train net output #0: loss = 1.45563 (* 1 = 1.45563 loss)
I0520 08:09:26.296397 15139 sgd_solver.cpp:106] Iteration 58000, lr = 0.001
I0520 08:09:26.457221 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2563	3.125	82.7428	0	91.2644	6.25	89.3436	0	85.4628	0	86.8632	0	80.0907	0	31.831	2.9	
I0520 08:09:26.534461 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:09:26.537508 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:09:26.537539 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:09:26.542071 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.45563
I0520 08:10:53.487124 15139 solver.cpp:231] Iteration 58200, loss = 1.35511
I0520 08:10:53.487525 15139 solver.cpp:247]     Train net output #0: loss = 1.35511 (* 1 = 1.35511 loss)
I0520 08:10:53.487551 15139 sgd_solver.cpp:106] Iteration 58200, lr = 0.001
I0520 08:10:53.645503 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.4228	3.125	82.7412	0	91.2658	6.25	89.3451	0	85.4617	0	86.866	0	80.0951	0	31.836	2.9	
I0520 08:10:53.720803 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:10:53.724167 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:10:53.724215 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:10:53.724766 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35511
I0520 08:12:22.989776 15139 solver.cpp:231] Iteration 58400, loss = 1.1817
I0520 08:12:22.990142 15139 solver.cpp:247]     Train net output #0: loss = 1.1817 (* 1 = 1.1817 loss)
I0520 08:12:22.990161 15139 sgd_solver.cpp:106] Iteration 58400, lr = 0.001
I0520 08:12:23.148355 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2592	3.125	82.7412	0	91.2655	6.25	89.3445	0	85.4637	0	86.8689	0	80.0995	0	31.8401	2.9	
I0520 08:12:23.223270 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:12:23.226378 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:12:23.226429 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:12:23.227061 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1817
I0520 08:12:29.174896 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:13:42.740159 15139 solver.cpp:231] Iteration 58600, loss = 1.13158
I0520 08:13:42.740423 15139 solver.cpp:247]     Train net output #0: loss = 1.13158 (* 1 = 1.13158 loss)
I0520 08:13:42.740447 15139 sgd_solver.cpp:106] Iteration 58600, lr = 0.001
I0520 08:13:42.901402 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2362	3.125	82.722	0	91.266	6.25	89.3455	0	85.4635	0	86.8719	0	80.1038	0	31.8451	2.9	
I0520 08:13:42.977172 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:13:42.979101 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:13:42.979140 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:13:42.979956 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13158
I0520 08:15:03.782987 15139 solver.cpp:231] Iteration 58800, loss = 1.51526
I0520 08:15:03.783248 15139 solver.cpp:247]     Train net output #0: loss = 1.51526 (* 1 = 1.51526 loss)
I0520 08:15:03.783270 15139 sgd_solver.cpp:106] Iteration 58800, lr = 0.001
I0520 08:15:03.943115 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2965	3.125	82.7425	0	91.2669	6.25	89.3458	0	85.4644	0	86.8748	0	80.108	0	31.8505	2.9	
I0520 08:15:04.022828 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:15:04.025146 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:15:04.025194 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:15:04.025872 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.51526
I0520 08:16:34.308148 15139 solver.cpp:348] Iteration 59000, Testing net (#0)
I0520 08:17:10.794869 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:17:58.052093 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56156
I0520 08:17:58.052383 15139 solver.cpp:415]     Test net output #1: loss = 1.88703 (* 1 = 1.88703 loss)
I0520 08:17:58.143162 15139 solver.cpp:231] Iteration 59000, loss = 1.29904
I0520 08:17:58.143285 15139 solver.cpp:247]     Train net output #0: loss = 1.29904 (* 1 = 1.29904 loss)
I0520 08:17:58.143306 15139 sgd_solver.cpp:106] Iteration 59000, lr = 0.001
I0520 08:17:58.311970 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3854	3.125	82.7467	0	91.2656	6.25	89.3461	0	85.4639	0	86.8777	0	80.1125	0	31.8544	2.9	
I0520 08:17:58.388290 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:17:58.392446 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:17:58.392500 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:17:58.393198 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.29904
I0520 08:19:24.526213 15139 solver.cpp:231] Iteration 59200, loss = 1.21907
I0520 08:19:24.526612 15139 solver.cpp:247]     Train net output #0: loss = 1.21907 (* 1 = 1.21907 loss)
I0520 08:19:24.526634 15139 sgd_solver.cpp:106] Iteration 59200, lr = 0.001
I0520 08:19:24.684898 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3424	3.125	82.7334	0	91.2671	6.25	89.3457	0	85.4637	0	86.8806	0	80.1169	0	31.8592	2.9	
I0520 08:19:24.760226 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:19:24.763628 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:19:24.763675 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:19:24.764262 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21907
I0520 08:20:50.343878 15139 solver.cpp:231] Iteration 59400, loss = 1.39092
I0520 08:20:50.345638 15139 solver.cpp:247]     Train net output #0: loss = 1.39092 (* 1 = 1.39092 loss)
I0520 08:20:50.345665 15139 sgd_solver.cpp:106] Iteration 59400, lr = 0.001
I0520 08:20:50.504113 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.0956	3.125	82.7386	0	91.2659	6.25	89.3464	0	85.465	0	86.8835	0	80.1213	0	31.8636	2.9	
I0520 08:20:50.579607 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:20:50.582463 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:20:50.582520 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:20:50.583052 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.39092
I0520 08:20:59.917176 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:22:16.771872 15139 solver.cpp:231] Iteration 59600, loss = 1.32871
I0520 08:22:16.772140 15139 solver.cpp:247]     Train net output #0: loss = 1.32871 (* 1 = 1.32871 loss)
I0520 08:22:16.772159 15139 sgd_solver.cpp:106] Iteration 59600, lr = 0.001
I0520 08:22:16.932319 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.2592	3.125	82.7435	0	91.2662	6.25	89.3449	0	85.4641	0	86.8862	0	80.1258	0	31.8674	2.9	
I0520 08:22:17.008527 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:22:17.011916 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:22:17.011976 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:22:17.012730 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32871
I0520 08:23:42.410341 15139 solver.cpp:231] Iteration 59800, loss = 1.25651
I0520 08:23:42.413641 15139 solver.cpp:247]     Train net output #0: loss = 1.25651 (* 1 = 1.25651 loss)
I0520 08:23:42.413668 15139 sgd_solver.cpp:106] Iteration 59800, lr = 0.001
I0520 08:23:42.570797 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.4113	3.125	82.7389	0	91.2677	6.25	89.346	0	85.4632	0	86.8889	0	80.1299	0	31.8726	2.9	
I0520 08:23:42.646232 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:23:42.650198 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:23:42.650241 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:23:42.650761 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25651
I0520 08:25:10.056885 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_60000.caffemodel
I0520 08:27:06.130600 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_60000.solverstate
I0520 08:27:06.944557 15139 solver.cpp:348] Iteration 60000, Testing net (#0)
I0520 08:27:41.426398 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:28:36.184082 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56228
I0520 08:28:36.184332 15139 solver.cpp:415]     Test net output #1: loss = 1.88753 (* 1 = 1.88753 loss)
I0520 08:28:36.275030 15139 solver.cpp:231] Iteration 60000, loss = 1.27612
I0520 08:28:36.275116 15139 solver.cpp:247]     Train net output #0: loss = 1.27612 (* 1 = 1.27612 loss)
I0520 08:28:36.275133 15139 sgd_solver.cpp:46] MultiStep Status: Iteration 60000, step = 1
I0520 08:28:36.275141 15139 sgd_solver.cpp:106] Iteration 60000, lr = 0.0001
I0520 08:28:36.434521 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.3481	3.125	82.7415	0	91.2676	6.25	89.3457	0	85.4646	0	86.8918	0	80.1344	0	31.8784	2.9	
I0520 08:28:36.436676 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:28:36.439401 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:28:36.439431 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:28:36.439978 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27612
I0520 08:30:03.949359 15139 solver.cpp:231] Iteration 60200, loss = 1.21086
I0520 08:30:03.949643 15139 solver.cpp:247]     Train net output #0: loss = 1.21086 (* 1 = 1.21086 loss)
I0520 08:30:03.949664 15139 sgd_solver.cpp:106] Iteration 60200, lr = 0.0001
I0520 08:30:04.110384 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.483	3.125	82.7467	0	91.2684	6.25	89.346	0	85.4646	0	86.8921	0	80.1347	0	31.8789	2.9	
I0520 08:30:04.185595 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:30:04.188716 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:30:04.188765 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:30:04.189366 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21086
I0520 08:31:29.810837 15139 solver.cpp:231] Iteration 60400, loss = 1.11783
I0520 08:31:29.811131 15139 solver.cpp:247]     Train net output #0: loss = 1.11783 (* 1 = 1.11783 loss)
I0520 08:31:29.811151 15139 sgd_solver.cpp:106] Iteration 60400, lr = 0.0001
I0520 08:31:29.969828 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.5203	3.125	82.7471	0	91.2686	6.25	89.3461	0	85.4648	0	86.8922	0	80.1348	0	31.8791	2.9	
I0520 08:31:30.045428 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:31:30.048954 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:31:30.049006 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:31:30.049621 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11783
I0520 08:31:40.633188 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:32:54.834657 15139 solver.cpp:231] Iteration 60600, loss = 1.26367
I0520 08:32:54.834982 15139 solver.cpp:247]     Train net output #0: loss = 1.26367 (* 1 = 1.26367 loss)
I0520 08:32:54.835005 15139 sgd_solver.cpp:106] Iteration 60600, lr = 0.0001
I0520 08:32:54.994313 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.5576	3.125	82.7477	0	91.2687	6.25	89.3461	0	85.4648	0	86.8922	0	80.1349	0	31.8793	2.9	
I0520 08:32:55.069715 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:32:55.073050 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:32:55.073091 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:32:55.073648 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26367
I0520 08:34:20.610365 15139 solver.cpp:231] Iteration 60800, loss = 1.27156
I0520 08:34:20.610792 15139 solver.cpp:247]     Train net output #0: loss = 1.27156 (* 1 = 1.27156 loss)
I0520 08:34:20.610812 15139 sgd_solver.cpp:106] Iteration 60800, lr = 0.0001
I0520 08:34:20.770664 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.5806	3.125	82.7487	0	91.2688	6.25	89.3463	0	85.465	0	86.8922	0	80.135	0	31.8794	2.9	
I0520 08:34:20.845408 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:34:20.848546 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:34:20.848589 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:34:20.849081 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27156
I0520 08:35:49.332934 15139 solver.cpp:348] Iteration 61000, Testing net (#0)
I0520 08:36:23.012176 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:37:12.372201 15139 solver.cpp:415]     Test net output #0: accuracy = 0.569
I0520 08:37:12.372480 15139 solver.cpp:415]     Test net output #1: loss = 1.85298 (* 1 = 1.85298 loss)
I0520 08:37:12.470504 15139 solver.cpp:231] Iteration 61000, loss = 1.12976
I0520 08:37:12.470615 15139 solver.cpp:247]     Train net output #0: loss = 1.12976 (* 1 = 1.12976 loss)
I0520 08:37:12.470639 15139 sgd_solver.cpp:106] Iteration 61000, lr = 0.0001
I0520 08:37:12.637688 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.5978	3.125	82.749	0	91.2689	6.25	89.3463	0	85.465	0	86.8923	0	80.1351	0	31.8795	2.9	
I0520 08:37:12.713165 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:37:12.716106 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:37:12.716150 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:37:12.716759 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12976
I0520 08:38:40.287886 15139 solver.cpp:231] Iteration 61200, loss = 1.27536
I0520 08:38:40.288378 15139 solver.cpp:247]     Train net output #0: loss = 1.27536 (* 1 = 1.27536 loss)
I0520 08:38:40.288401 15139 sgd_solver.cpp:106] Iteration 61200, lr = 0.0001
I0520 08:38:40.449172 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6035	3.125	82.7494	0	91.2691	6.25	89.3463	0	85.465	0	86.8923	0	80.1351	0	31.8797	2.9	
I0520 08:38:40.524531 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:38:40.528017 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:38:40.528059 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:38:40.528738 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27536
I0520 08:40:09.502004 15139 solver.cpp:231] Iteration 61400, loss = 1.27138
I0520 08:40:09.505689 15139 solver.cpp:247]     Train net output #0: loss = 1.27138 (* 1 = 1.27138 loss)
I0520 08:40:09.505759 15139 sgd_solver.cpp:106] Iteration 61400, lr = 0.0001
I0520 08:40:09.660675 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6236	3.125	82.7494	0	91.2691	6.25	89.3463	0	85.465	0	86.8923	0	80.1351	0	31.8798	2.9	
I0520 08:40:09.736317 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:40:09.739862 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:40:09.739918 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:40:09.740478 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27138
I0520 08:40:24.976289 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:41:52.571063 15139 solver.cpp:231] Iteration 61600, loss = 1.25206
I0520 08:41:52.573647 15139 solver.cpp:247]     Train net output #0: loss = 1.25206 (* 1 = 1.25206 loss)
I0520 08:41:52.573673 15139 sgd_solver.cpp:106] Iteration 61600, lr = 0.0001
I0520 08:41:52.731102 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.638	3.125	82.7497	0	91.2693	6.25	89.3464	0	85.4653	0	86.8924	0	80.1352	0	31.8799	2.9	
I0520 08:41:52.806380 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:41:52.809408 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:41:52.809439 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:41:52.809976 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25206
I0520 08:43:42.041966 15139 solver.cpp:231] Iteration 61800, loss = 1.09329
I0520 08:43:42.042310 15139 solver.cpp:247]     Train net output #0: loss = 1.09329 (* 1 = 1.09329 loss)
I0520 08:43:42.042331 15139 sgd_solver.cpp:106] Iteration 61800, lr = 0.0001
I0520 08:43:42.201093 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.638	3.125	82.7497	0	91.2694	6.25	89.3464	0	85.4653	0	86.8924	0	80.1352	0	31.8799	2.9	
I0520 08:43:42.276746 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:43:42.279873 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:43:42.279908 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:43:42.280447 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09329
I0520 08:45:12.058939 15139 solver.cpp:348] Iteration 62000, Testing net (#0)
I0520 08:45:48.311295 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:46:37.561307 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56882
I0520 08:46:37.565650 15139 solver.cpp:415]     Test net output #1: loss = 1.85062 (* 1 = 1.85062 loss)
I0520 08:46:37.652966 15139 solver.cpp:231] Iteration 62000, loss = 1.34419
I0520 08:46:37.653069 15139 solver.cpp:247]     Train net output #0: loss = 1.34419 (* 1 = 1.34419 loss)
I0520 08:46:37.653090 15139 sgd_solver.cpp:106] Iteration 62000, lr = 0.0001
I0520 08:46:37.818522 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6437	3.125	82.7503	0	91.2694	6.25	89.3464	0	85.4653	0	86.8924	0	80.1352	0	31.88	2.9	
I0520 08:46:37.899704 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:46:37.903619 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:46:37.903678 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:46:37.904320 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34419
I0520 08:47:57.299401 15139 solver.cpp:231] Iteration 62200, loss = 1.112
I0520 08:47:57.301647 15139 solver.cpp:247]     Train net output #0: loss = 1.112 (* 1 = 1.112 loss)
I0520 08:47:57.301683 15139 sgd_solver.cpp:106] Iteration 62200, lr = 0.0001
I0520 08:47:57.459308 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6466	3.125	82.7503	0	91.2694	6.25	89.3466	0	85.4653	0	86.8925	0	80.1353	0	31.88	2.9	
I0520 08:47:57.535259 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:47:57.538751 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:47:57.538796 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:47:57.539366 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.112
I0520 08:49:26.141633 15139 solver.cpp:231] Iteration 62400, loss = 1.32285
I0520 08:49:26.145712 15139 solver.cpp:247]     Train net output #0: loss = 1.32285 (* 1 = 1.32285 loss)
I0520 08:49:26.145755 15139 sgd_solver.cpp:106] Iteration 62400, lr = 0.0001
I0520 08:49:26.302487 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6523	3.125	82.751	0	91.2696	6.25	89.3467	0	85.4653	0	86.8925	0	80.1354	0	31.8801	2.9	
I0520 08:49:26.378289 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:49:26.382164 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:49:26.382230 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:49:26.382860 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32285
I0520 08:49:44.635783 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:50:53.808490 15139 solver.cpp:231] Iteration 62600, loss = 1.24237
I0520 08:50:53.809927 15139 solver.cpp:247]     Train net output #0: loss = 1.24237 (* 1 = 1.24237 loss)
I0520 08:50:53.809947 15139 sgd_solver.cpp:106] Iteration 62600, lr = 0.0001
I0520 08:50:53.969734 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6552	3.125	82.751	0	91.2696	6.25	89.3467	0	85.4655	0	86.8925	0	80.1354	0	31.8801	2.9	
I0520 08:50:54.045634 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:50:54.048732 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:50:54.048763 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:50:54.049283 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24237
I0520 08:52:21.799612 15139 solver.cpp:231] Iteration 62800, loss = 1.37662
I0520 08:52:21.799904 15139 solver.cpp:247]     Train net output #0: loss = 1.37662 (* 1 = 1.37662 loss)
I0520 08:52:21.799926 15139 sgd_solver.cpp:106] Iteration 62800, lr = 0.0001
I0520 08:52:21.959702 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6609	3.125	82.7513	0	91.2696	6.25	89.3469	0	85.4655	0	86.8926	0	80.1355	0	31.8802	2.9	
I0520 08:52:22.034960 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:52:22.037920 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:52:22.037962 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:52:22.038506 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.37662
I0520 08:53:46.937363 15139 solver.cpp:348] Iteration 63000, Testing net (#0)
I0520 08:54:22.692101 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:55:06.262414 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57018
I0520 08:55:06.262759 15139 solver.cpp:415]     Test net output #1: loss = 1.84615 (* 1 = 1.84615 loss)
I0520 08:55:06.350213 15139 solver.cpp:231] Iteration 63000, loss = 1.0528
I0520 08:55:06.350291 15139 solver.cpp:247]     Train net output #0: loss = 1.0528 (* 1 = 1.0528 loss)
I0520 08:55:06.350308 15139 sgd_solver.cpp:106] Iteration 63000, lr = 0.0001
I0520 08:55:06.516353 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6667	3.125	82.752	0	91.2696	6.25	89.347	0	85.4655	0	86.8926	0	80.1355	0	31.8803	2.9	
I0520 08:55:06.591716 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:55:06.594780 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:55:06.594830 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:55:06.595382 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.0528
I0520 08:56:35.347821 15139 solver.cpp:231] Iteration 63200, loss = 1.19316
I0520 08:56:35.348125 15139 solver.cpp:247]     Train net output #0: loss = 1.19316 (* 1 = 1.19316 loss)
I0520 08:56:35.348151 15139 sgd_solver.cpp:106] Iteration 63200, lr = 0.0001
I0520 08:56:35.507956 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6753	3.125	82.752	0	91.2698	6.25	89.347	0	85.4655	0	86.8926	0	80.1356	0	31.8803	2.9	
I0520 08:56:35.583264 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:56:35.584978 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:56:35.585000 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:56:35.585603 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19316
I0520 08:57:49.567212 15139 solver.cpp:231] Iteration 63400, loss = 1.32923
I0520 08:57:49.567549 15139 solver.cpp:247]     Train net output #0: loss = 1.32923 (* 1 = 1.32923 loss)
I0520 08:57:49.567571 15139 sgd_solver.cpp:106] Iteration 63400, lr = 0.0001
I0520 08:57:49.729351 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.681	3.125	82.7533	0	91.2698	6.25	89.3472	0	85.4655	0	86.8926	0	80.1356	0	31.8803	2.9	
I0520 08:57:49.805579 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:57:49.807122 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:57:49.807144 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:57:49.807585 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32923
I0520 08:58:07.792512 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 08:59:05.935941 15139 solver.cpp:231] Iteration 63600, loss = 1.16463
I0520 08:59:05.936182 15139 solver.cpp:247]     Train net output #0: loss = 1.16463 (* 1 = 1.16463 loss)
I0520 08:59:05.936204 15139 sgd_solver.cpp:106] Iteration 63600, lr = 0.0001
I0520 08:59:06.101150 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6896	3.125	82.7536	0	91.2698	6.25	89.3472	0	85.4655	0	86.8927	0	80.1356	0	31.8804	2.9	
I0520 08:59:06.175922 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 08:59:06.177649 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 08:59:06.177690 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 08:59:06.178228 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16463
I0520 09:00:26.296877 15139 solver.cpp:231] Iteration 63800, loss = 1.10348
I0520 09:00:26.297160 15139 solver.cpp:247]     Train net output #0: loss = 1.10348 (* 1 = 1.10348 loss)
I0520 09:00:26.297181 15139 sgd_solver.cpp:106] Iteration 63800, lr = 0.0001
I0520 09:00:26.456872 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6925	3.125	82.7546	0	91.2698	6.25	89.3473	0	85.4655	0	86.8927	0	80.1356	0	31.8804	2.9	
I0520 09:00:26.531632 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:00:26.533330 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:00:26.533363 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:00:26.533905 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10348
I0520 09:01:43.985579 15139 solver.cpp:348] Iteration 64000, Testing net (#0)
I0520 09:02:21.217268 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:03:07.988365 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57014
I0520 09:03:07.988667 15139 solver.cpp:415]     Test net output #1: loss = 1.8468 (* 1 = 1.8468 loss)
I0520 09:03:08.076057 15139 solver.cpp:231] Iteration 64000, loss = 1.29964
I0520 09:03:08.076117 15139 solver.cpp:247]     Train net output #0: loss = 1.29964 (* 1 = 1.29964 loss)
I0520 09:03:08.076135 15139 sgd_solver.cpp:106] Iteration 64000, lr = 0.0001
I0520 09:03:08.235301 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.6954	3.125	82.7552	0	91.2698	6.25	89.3473	0	85.4655	0	86.8927	0	80.1356	0	31.8806	2.9	
I0520 09:03:08.309680 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:03:08.311287 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:03:08.311313 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:03:08.312034 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.29964
I0520 09:04:33.089640 15139 solver.cpp:231] Iteration 64200, loss = 1.20148
I0520 09:04:33.089893 15139 solver.cpp:247]     Train net output #0: loss = 1.20148 (* 1 = 1.20148 loss)
I0520 09:04:33.089926 15139 sgd_solver.cpp:106] Iteration 64200, lr = 0.0001
I0520 09:04:33.249152 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.704	3.125	82.7552	0	91.2698	6.25	89.3473	0	85.4657	0	86.8927	0	80.1357	0	31.8807	2.9	
I0520 09:04:33.324180 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:04:33.338129 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:04:33.338187 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:04:33.338768 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20148
I0520 09:05:52.457499 15139 solver.cpp:231] Iteration 64400, loss = 1.08052
I0520 09:05:52.461678 15139 solver.cpp:247]     Train net output #0: loss = 1.08052 (* 1 = 1.08052 loss)
I0520 09:05:52.461714 15139 sgd_solver.cpp:106] Iteration 64400, lr = 0.0001
I0520 09:05:52.616488 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7068	3.125	82.7552	0	91.2698	6.25	89.3473	0	85.466	0	86.8927	0	80.1357	0	31.8808	2.9	
I0520 09:05:52.691388 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:05:52.693473 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:05:52.693508 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:05:52.694010 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08052
I0520 09:06:14.832211 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:07:10.604780 15139 solver.cpp:231] Iteration 64600, loss = 1.13236
I0520 09:07:10.609673 15139 solver.cpp:247]     Train net output #0: loss = 1.13236 (* 1 = 1.13236 loss)
I0520 09:07:10.609706 15139 sgd_solver.cpp:106] Iteration 64600, lr = 0.0001
I0520 09:07:10.766652 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7068	3.125	82.7559	0	91.2699	6.25	89.3473	0	85.466	0	86.8928	0	80.1358	0	31.8808	2.9	
I0520 09:07:10.842528 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:07:10.844602 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:07:10.844631 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:07:10.845343 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13236
I0520 09:08:31.443948 15139 solver.cpp:231] Iteration 64800, loss = 1.23514
I0520 09:08:31.444100 15139 solver.cpp:247]     Train net output #0: loss = 1.23514 (* 1 = 1.23514 loss)
I0520 09:08:31.444121 15139 sgd_solver.cpp:106] Iteration 64800, lr = 0.0001
I0520 09:08:31.602581 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7126	3.125	82.7565	0	91.2699	6.25	89.3473	0	85.466	0	86.8928	0	80.1358	0	31.8808	2.9	
I0520 09:08:31.677454 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:08:31.679850 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:08:31.679883 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:08:31.680366 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23514
I0520 09:09:55.663909 15139 solver.cpp:348] Iteration 65000, Testing net (#0)
I0520 09:10:34.900851 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:11:18.644158 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57016
I0520 09:11:18.644433 15139 solver.cpp:415]     Test net output #1: loss = 1.84698 (* 1 = 1.84698 loss)
I0520 09:11:18.770831 15139 solver.cpp:231] Iteration 65000, loss = 1.05553
I0520 09:11:18.770913 15139 solver.cpp:247]     Train net output #0: loss = 1.05553 (* 1 = 1.05553 loss)
I0520 09:11:18.770932 15139 sgd_solver.cpp:106] Iteration 65000, lr = 0.0001
I0520 09:11:18.935561 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7126	3.125	82.7565	0	91.2699	6.25	89.3473	0	85.466	0	86.8928	0	80.1359	0	31.8809	2.9	
I0520 09:11:19.010913 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:11:19.013253 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:11:19.013288 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:11:19.013882 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.05553
I0520 09:12:40.627310 15139 solver.cpp:231] Iteration 65200, loss = 1.36425
I0520 09:12:40.627691 15139 solver.cpp:247]     Train net output #0: loss = 1.36425 (* 1 = 1.36425 loss)
I0520 09:12:40.627708 15139 sgd_solver.cpp:106] Iteration 65200, lr = 0.0001
I0520 09:12:40.789496 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7126	3.125	82.7568	0	91.2699	6.25	89.3475	0	85.466	0	86.8929	0	80.1359	0	31.8811	2.9	
I0520 09:12:40.864743 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:12:40.867327 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:12:40.867368 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:12:40.867771 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.36425
I0520 09:14:14.033140 15139 solver.cpp:231] Iteration 65400, loss = 1.20755
I0520 09:14:14.033742 15139 solver.cpp:247]     Train net output #0: loss = 1.20755 (* 1 = 1.20755 loss)
I0520 09:14:14.033767 15139 sgd_solver.cpp:106] Iteration 65400, lr = 0.0001
I0520 09:14:14.193439 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7126	3.125	82.7572	0	91.2699	6.25	89.3475	0	85.466	0	86.8929	0	80.136	0	31.8813	2.9	
I0520 09:14:14.269048 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:14:14.272034 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:14:14.272074 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:14:14.272723 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20755
I0520 09:14:41.363112 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:15:43.891583 15139 solver.cpp:231] Iteration 65600, loss = 1.09251
I0520 09:15:43.891885 15139 solver.cpp:247]     Train net output #0: loss = 1.09251 (* 1 = 1.09251 loss)
I0520 09:15:43.891906 15139 sgd_solver.cpp:106] Iteration 65600, lr = 0.0001
I0520 09:15:44.051898 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7183	3.125	82.7572	0	91.2699	6.25	89.3475	0	85.466	0	86.8929	0	80.136	0	31.8814	2.9	
I0520 09:15:44.127287 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:15:44.130297 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:15:44.130338 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:15:44.130879 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09251
I0520 09:17:06.173421 15139 solver.cpp:231] Iteration 65800, loss = 1.20577
I0520 09:17:06.173669 15139 solver.cpp:247]     Train net output #0: loss = 1.20577 (* 1 = 1.20577 loss)
I0520 09:17:06.173691 15139 sgd_solver.cpp:106] Iteration 65800, lr = 0.0001
I0520 09:17:06.333117 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7241	3.125	82.7572	0	91.2704	6.25	89.3475	0	85.466	0	86.8929	0	80.136	0	31.8815	2.9	
I0520 09:17:06.408143 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:17:06.411396 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:17:06.411442 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:17:06.412003 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20577
I0520 09:18:33.628499 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_66000.caffemodel
I0520 09:19:50.692822 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_66000.solverstate
I0520 09:19:51.288002 15139 solver.cpp:348] Iteration 66000, Testing net (#0)
I0520 09:20:26.633913 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:21:07.561731 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57
I0520 09:21:07.562082 15139 solver.cpp:415]     Test net output #1: loss = 1.84708 (* 1 = 1.84708 loss)
I0520 09:21:07.650404 15139 solver.cpp:231] Iteration 66000, loss = 1.3594
I0520 09:21:07.650485 15139 solver.cpp:247]     Train net output #0: loss = 1.3594 (* 1 = 1.3594 loss)
I0520 09:21:07.650506 15139 sgd_solver.cpp:106] Iteration 66000, lr = 0.0001
I0520 09:21:07.810199 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7269	3.125	82.7575	0	91.2704	6.25	89.3476	0	85.466	0	86.8929	0	80.1361	0	31.8815	2.9	
I0520 09:21:07.811954 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:21:07.813837 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:21:07.813856 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:21:07.814543 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.3594
I0520 09:22:47.790812 15139 solver.cpp:231] Iteration 66200, loss = 1.22775
I0520 09:22:47.791183 15139 solver.cpp:247]     Train net output #0: loss = 1.22775 (* 1 = 1.22775 loss)
I0520 09:22:47.791205 15139 sgd_solver.cpp:106] Iteration 66200, lr = 0.0001
I0520 09:22:47.951354 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7327	3.125	82.7581	0	91.2704	6.25	89.3476	0	85.466	0	86.8929	0	80.1361	0	31.8815	2.9	
I0520 09:22:48.027675 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:22:48.029273 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:22:48.029296 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:22:48.029955 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22775
I0520 09:24:07.084712 15139 solver.cpp:231] Iteration 66400, loss = 1.22095
I0520 09:24:07.085005 15139 solver.cpp:247]     Train net output #0: loss = 1.22095 (* 1 = 1.22095 loss)
I0520 09:24:07.085026 15139 sgd_solver.cpp:106] Iteration 66400, lr = 0.0001
I0520 09:24:07.246042 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7327	3.125	82.7581	0	91.2704	6.25	89.3476	0	85.466	0	86.893	0	80.1362	0	31.8816	2.9	
I0520 09:24:07.321256 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:24:07.323292 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:24:07.323315 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:24:07.323706 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22095
I0520 09:24:43.293257 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:25:38.213569 15139 solver.cpp:231] Iteration 66600, loss = 1.06679
I0520 09:25:38.213878 15139 solver.cpp:247]     Train net output #0: loss = 1.06679 (* 1 = 1.06679 loss)
I0520 09:25:38.213902 15139 sgd_solver.cpp:106] Iteration 66600, lr = 0.0001
I0520 09:25:38.373874 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7413	3.125	82.7581	0	91.2704	6.25	89.3476	0	85.466	0	86.893	0	80.1362	0	31.8818	2.9	
I0520 09:25:38.448727 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:25:38.454571 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:25:38.454620 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:25:38.455132 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.06679
I0520 09:26:59.536504 15139 solver.cpp:231] Iteration 66800, loss = 1.12542
I0520 09:26:59.536782 15139 solver.cpp:247]     Train net output #0: loss = 1.12542 (* 1 = 1.12542 loss)
I0520 09:26:59.536803 15139 sgd_solver.cpp:106] Iteration 66800, lr = 0.0001
I0520 09:26:59.697227 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7499	3.125	82.7581	0	91.2704	6.25	89.3476	0	85.466	0	86.893	0	80.1362	0	31.8819	2.9	
I0520 09:26:59.772256 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:26:59.774219 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:26:59.774248 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:26:59.774755 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12542
I0520 09:28:32.649696 15139 solver.cpp:348] Iteration 67000, Testing net (#0)
I0520 09:29:09.538283 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:29:51.508771 15139 solver.cpp:415]     Test net output #0: accuracy = 0.56948
I0520 09:29:51.513645 15139 solver.cpp:415]     Test net output #1: loss = 1.84676 (* 1 = 1.84676 loss)
I0520 09:29:51.634335 15139 solver.cpp:231] Iteration 67000, loss = 1.1276
I0520 09:29:51.634408 15139 solver.cpp:247]     Train net output #0: loss = 1.1276 (* 1 = 1.1276 loss)
I0520 09:29:51.634430 15139 sgd_solver.cpp:106] Iteration 67000, lr = 0.0001
I0520 09:29:51.801833 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7528	3.125	82.7581	0	91.2704	6.25	89.3476	0	85.466	0	86.893	0	80.1362	0	31.882	2.9	
I0520 09:29:51.876763 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:29:51.882488 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:29:51.882531 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:29:51.883105 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1276
I0520 09:31:12.220779 15139 solver.cpp:231] Iteration 67200, loss = 1.18327
I0520 09:31:12.221072 15139 solver.cpp:247]     Train net output #0: loss = 1.18327 (* 1 = 1.18327 loss)
I0520 09:31:12.221098 15139 sgd_solver.cpp:106] Iteration 67200, lr = 0.0001
I0520 09:31:12.380858 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7528	3.125	82.7585	0	91.2704	6.25	89.3476	0	85.466	0	86.893	0	80.1363	0	31.8821	2.9	
I0520 09:31:12.457222 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:31:12.460060 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:31:12.460099 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:31:12.460858 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18327
I0520 09:32:42.793450 15139 solver.cpp:231] Iteration 67400, loss = 1.24377
I0520 09:32:42.793684 15139 solver.cpp:247]     Train net output #0: loss = 1.24377 (* 1 = 1.24377 loss)
I0520 09:32:42.793705 15139 sgd_solver.cpp:106] Iteration 67400, lr = 0.0001
I0520 09:32:42.954176 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7556	3.125	82.7585	0	91.2705	6.25	89.3478	0	85.4662	0	86.893	0	80.1363	0	31.8822	2.9	
I0520 09:32:43.029489 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:32:43.032130 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:32:43.032163 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:32:43.032662 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24377
I0520 09:33:13.127903 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:34:02.646571 15139 solver.cpp:231] Iteration 67600, loss = 1.36974
I0520 09:34:02.647847 15139 solver.cpp:247]     Train net output #0: loss = 1.36974 (* 1 = 1.36974 loss)
I0520 09:34:02.647871 15139 sgd_solver.cpp:106] Iteration 67600, lr = 0.0001
I0520 09:34:02.805583 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7585	3.125	82.7588	0	91.2706	6.25	89.3478	0	85.4662	0	86.8931	0	80.1363	0	31.8823	2.9	
I0520 09:34:02.881788 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:34:02.885002 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:34:02.885032 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:34:02.885792 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.36974
I0520 09:35:22.490278 15139 solver.cpp:231] Iteration 67800, loss = 1.37373
I0520 09:35:22.493728 15139 solver.cpp:247]     Train net output #0: loss = 1.37373 (* 1 = 1.37373 loss)
I0520 09:35:22.493762 15139 sgd_solver.cpp:106] Iteration 67800, lr = 0.0001
I0520 09:35:22.649973 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7585	3.125	82.7588	0	91.2707	6.25	89.3478	0	85.4662	0	86.8931	0	80.1364	0	31.8825	2.9	
I0520 09:35:22.725288 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:35:22.729135 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:35:22.729178 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:35:22.729758 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.37373
I0520 09:36:43.800547 15139 solver.cpp:348] Iteration 68000, Testing net (#0)
I0520 09:37:20.248044 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:37:59.790935 15139 solver.cpp:415]     Test net output #0: accuracy = 0.571259
I0520 09:37:59.791262 15139 solver.cpp:415]     Test net output #1: loss = 1.84466 (* 1 = 1.84466 loss)
I0520 09:37:59.879351 15139 solver.cpp:231] Iteration 68000, loss = 1.34875
I0520 09:37:59.879425 15139 solver.cpp:247]     Train net output #0: loss = 1.34875 (* 1 = 1.34875 loss)
I0520 09:37:59.879444 15139 sgd_solver.cpp:106] Iteration 68000, lr = 0.0001
I0520 09:38:00.039052 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7614	3.125	82.7594	0	91.2707	6.25	89.3479	0	85.4662	0	86.8931	0	80.1364	0	31.8826	2.9	
I0520 09:38:00.114022 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:38:00.116354 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:38:00.116386 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:38:00.116928 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34875
I0520 09:39:20.295595 15139 solver.cpp:231] Iteration 68200, loss = 1.13271
I0520 09:39:20.295864 15139 solver.cpp:247]     Train net output #0: loss = 1.13271 (* 1 = 1.13271 loss)
I0520 09:39:20.295884 15139 sgd_solver.cpp:106] Iteration 68200, lr = 0.0001
I0520 09:39:20.458699 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7614	3.125	82.7594	0	91.2707	6.25	89.3479	0	85.4662	0	86.8931	0	80.1365	0	31.8827	2.9	
I0520 09:39:20.533462 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:39:20.535348 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:39:20.535377 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:39:20.535897 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13271
I0520 09:40:38.094172 15139 solver.cpp:231] Iteration 68400, loss = 1.0816
I0520 09:40:38.094521 15139 solver.cpp:247]     Train net output #0: loss = 1.0816 (* 1 = 1.0816 loss)
I0520 09:40:38.094555 15139 sgd_solver.cpp:106] Iteration 68400, lr = 0.0001
I0520 09:40:38.254878 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7614	3.125	82.7594	0	91.2708	6.25	89.3481	0	85.4662	0	86.8931	0	80.1365	0	31.8828	2.9	
I0520 09:40:38.330195 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:40:38.333770 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:40:38.333817 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:40:38.334439 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.0816
I0520 09:41:10.640584 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:41:55.169275 15139 solver.cpp:231] Iteration 68600, loss = 1.35163
I0520 09:41:55.169610 15139 solver.cpp:247]     Train net output #0: loss = 1.35163 (* 1 = 1.35163 loss)
I0520 09:41:55.169641 15139 sgd_solver.cpp:106] Iteration 68600, lr = 0.0001
I0520 09:41:55.330729 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7642	3.125	82.7598	0	91.2708	6.25	89.3481	0	85.4662	0	86.8932	0	80.1365	0	31.8829	2.9	
I0520 09:41:55.406205 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:41:55.409235 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:41:55.409265 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:41:55.409785 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35163
I0520 09:43:12.685025 15139 solver.cpp:231] Iteration 68800, loss = 1.16653
I0520 09:43:12.685334 15139 solver.cpp:247]     Train net output #0: loss = 1.16653 (* 1 = 1.16653 loss)
I0520 09:43:12.685355 15139 sgd_solver.cpp:106] Iteration 68800, lr = 0.0001
I0520 09:43:12.846115 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.77	3.125	82.7598	0	91.271	6.25	89.3481	0	85.4662	0	86.8932	0	80.1366	0	31.883	2.9	
I0520 09:43:12.921017 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:43:12.923094 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:43:12.923125 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:43:12.923609 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16653
I0520 09:44:46.673185 15139 solver.cpp:348] Iteration 69000, Testing net (#0)
I0520 09:45:23.309077 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:46:01.715879 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57134
I0520 09:46:01.717617 15139 solver.cpp:415]     Test net output #1: loss = 1.84575 (* 1 = 1.84575 loss)
I0520 09:46:01.806818 15139 solver.cpp:231] Iteration 69000, loss = 1.24421
I0520 09:46:01.806890 15139 solver.cpp:247]     Train net output #0: loss = 1.24421 (* 1 = 1.24421 loss)
I0520 09:46:01.806913 15139 sgd_solver.cpp:106] Iteration 69000, lr = 0.0001
I0520 09:46:01.966414 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7728	3.125	82.7598	0	91.271	6.25	89.3481	0	85.4662	0	86.8932	0	80.1366	0	31.8831	2.9	
I0520 09:46:02.041790 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:46:02.044299 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:46:02.044334 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:46:02.044896 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24421
I0520 09:47:25.601022 15139 solver.cpp:231] Iteration 69200, loss = 1.17217
I0520 09:47:25.603648 15139 solver.cpp:247]     Train net output #0: loss = 1.17217 (* 1 = 1.17217 loss)
I0520 09:47:25.603674 15139 sgd_solver.cpp:106] Iteration 69200, lr = 0.0001
I0520 09:47:25.762233 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7728	3.125	82.7598	0	91.271	6.25	89.3481	0	85.4662	0	86.8932	0	80.1366	0	31.8831	2.9	
I0520 09:47:25.837043 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:47:25.839303 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:47:25.839329 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:47:25.839844 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17217
I0520 09:48:53.227672 15139 solver.cpp:231] Iteration 69400, loss = 0.928616
I0520 09:48:53.228003 15139 solver.cpp:247]     Train net output #0: loss = 0.928616 (* 1 = 0.928616 loss)
I0520 09:48:53.228025 15139 sgd_solver.cpp:106] Iteration 69400, lr = 0.0001
I0520 09:48:53.387668 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7728	3.125	82.7598	0	91.2711	6.25	89.3481	0	85.4662	0	86.8932	0	80.1366	0	31.8832	2.9	
I0520 09:48:53.463436 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:48:53.465011 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:48:53.465065 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:48:53.465709 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.928616
I0520 09:49:29.279300 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:50:14.172771 15139 solver.cpp:231] Iteration 69600, loss = 1.26066
I0520 09:50:14.173956 15139 solver.cpp:247]     Train net output #0: loss = 1.26066 (* 1 = 1.26066 loss)
I0520 09:50:14.173981 15139 sgd_solver.cpp:106] Iteration 69600, lr = 0.0001
I0520 09:50:14.332120 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7728	3.125	82.7601	0	91.2711	6.25	89.3481	0	85.4662	0	86.8932	0	80.1367	0	31.8833	2.9	
I0520 09:50:14.407979 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:50:14.410384 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:50:14.410426 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:50:14.411031 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26066
I0520 09:51:39.611732 15139 solver.cpp:231] Iteration 69800, loss = 1.44731
I0520 09:51:39.614269 15139 solver.cpp:247]     Train net output #0: loss = 1.44731 (* 1 = 1.44731 loss)
I0520 09:51:39.614297 15139 sgd_solver.cpp:106] Iteration 69800, lr = 0.0001
I0520 09:51:39.772151 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7872	3.125	82.7604	0	91.2711	6.25	89.3481	0	85.4662	0	86.8933	0	80.1367	0	31.8834	2.9	
I0520 09:51:39.847306 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:51:39.849792 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:51:39.849828 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:51:39.850355 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.44731
I0520 09:52:58.835161 15139 solver.cpp:348] Iteration 70000, Testing net (#0)
I0520 09:53:44.778980 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:54:29.943084 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57134
I0520 09:54:29.943356 15139 solver.cpp:415]     Test net output #1: loss = 1.84607 (* 1 = 1.84607 loss)
I0520 09:54:30.032388 15139 solver.cpp:231] Iteration 70000, loss = 1.21902
I0520 09:54:30.032470 15139 solver.cpp:247]     Train net output #0: loss = 1.21902 (* 1 = 1.21902 loss)
I0520 09:54:30.032491 15139 sgd_solver.cpp:106] Iteration 70000, lr = 0.0001
I0520 09:54:30.201995 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7929	3.125	82.7604	0	91.2711	6.25	89.3481	0	85.4662	0	86.8933	0	80.1368	0	31.8834	2.9	
I0520 09:54:30.277145 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:54:30.283627 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:54:30.283669 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:54:30.284199 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21902
I0520 09:55:52.683962 15139 solver.cpp:231] Iteration 70200, loss = 1.16262
I0520 09:55:52.684298 15139 solver.cpp:247]     Train net output #0: loss = 1.16262 (* 1 = 1.16262 loss)
I0520 09:55:52.684440 15139 sgd_solver.cpp:106] Iteration 70200, lr = 0.0001
I0520 09:55:52.843710 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7929	3.125	82.7611	0	91.2711	6.25	89.3481	0	85.4662	0	86.8933	0	80.1368	0	31.8835	2.9	
I0520 09:55:52.918943 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:55:52.921736 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:55:52.921777 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:55:52.922288 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16262
I0520 09:57:12.580945 15139 solver.cpp:231] Iteration 70400, loss = 1.30387
I0520 09:57:12.581310 15139 solver.cpp:247]     Train net output #0: loss = 1.30387 (* 1 = 1.30387 loss)
I0520 09:57:12.581331 15139 sgd_solver.cpp:106] Iteration 70400, lr = 0.0001
I0520 09:57:12.746462 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7929	3.125	82.7614	0	91.2711	6.25	89.3481	0	85.4662	0	86.8933	0	80.1368	0	31.8836	2.9	
I0520 09:57:12.839789 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:57:12.842759 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:57:12.842809 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:57:12.843495 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30387
I0520 09:57:50.805246 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 09:58:30.084863 15139 solver.cpp:231] Iteration 70600, loss = 1.28647
I0520 09:58:30.085180 15139 solver.cpp:247]     Train net output #0: loss = 1.28647 (* 1 = 1.28647 loss)
I0520 09:58:30.085366 15139 sgd_solver.cpp:106] Iteration 70600, lr = 0.0001
I0520 09:58:30.243893 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7958	3.125	82.7614	0	91.2711	6.25	89.3481	0	85.4662	0	86.8933	0	80.1368	0	31.8837	2.9	
I0520 09:58:30.318557 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 09:58:30.320442 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 09:58:30.320463 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 09:58:30.321038 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28647
I0520 10:00:10.047508 15139 solver.cpp:231] Iteration 70800, loss = 1.4025
I0520 10:00:10.047818 15139 solver.cpp:247]     Train net output #0: loss = 1.4025 (* 1 = 1.4025 loss)
I0520 10:00:10.047839 15139 sgd_solver.cpp:106] Iteration 70800, lr = 0.0001
I0520 10:00:10.208469 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7958	3.125	82.7614	0	91.2711	6.25	89.3482	0	85.4662	0	86.8934	0	80.1369	0	31.8838	2.9	
I0520 10:00:10.284159 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:00:10.287953 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:00:10.288005 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:00:10.288496 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.4025
I0520 10:01:40.687772 15139 solver.cpp:348] Iteration 71000, Testing net (#0)
I0520 10:02:18.836139 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:03:00.142421 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57082
I0520 10:03:00.145628 15139 solver.cpp:415]     Test net output #1: loss = 1.84603 (* 1 = 1.84603 loss)
I0520 10:03:00.233746 15139 solver.cpp:231] Iteration 71000, loss = 1.15067
I0520 10:03:00.233829 15139 solver.cpp:247]     Train net output #0: loss = 1.15067 (* 1 = 1.15067 loss)
I0520 10:03:00.233855 15139 sgd_solver.cpp:106] Iteration 71000, lr = 0.0001
I0520 10:03:00.401140 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7958	3.125	82.7614	0	91.2711	6.25	89.3482	0	85.4662	0	86.8934	0	80.1369	0	31.8838	2.9	
I0520 10:03:00.476390 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:03:00.478857 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:03:00.478904 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:03:00.479614 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15067
I0520 10:04:23.410218 15139 solver.cpp:231] Iteration 71200, loss = 1.16536
I0520 10:04:23.410562 15139 solver.cpp:247]     Train net output #0: loss = 1.16536 (* 1 = 1.16536 loss)
I0520 10:04:23.410593 15139 sgd_solver.cpp:106] Iteration 71200, lr = 0.0001
I0520 10:04:23.571210 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7958	3.125	82.7614	0	91.2711	6.25	89.3482	0	85.4664	0	86.8934	0	80.1369	0	31.8839	2.9	
I0520 10:04:23.646661 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:04:23.648780 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:04:23.648813 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:04:23.649282 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16536
I0520 10:05:46.628496 15139 solver.cpp:231] Iteration 71400, loss = 1.32295
I0520 10:05:46.628847 15139 solver.cpp:247]     Train net output #0: loss = 1.32295 (* 1 = 1.32295 loss)
I0520 10:05:46.628870 15139 sgd_solver.cpp:106] Iteration 71400, lr = 0.0001
I0520 10:05:46.787807 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.7958	3.125	82.7614	0	91.2711	6.25	89.3482	0	85.4666	0	86.8934	0	80.1369	0	31.884	2.9	
I0520 10:05:46.862596 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:05:46.864666 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:05:46.864697 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:05:46.865226 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32295
I0520 10:06:30.169419 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:07:07.430565 15139 solver.cpp:231] Iteration 71600, loss = 1.38959
I0520 10:07:07.430866 15139 solver.cpp:247]     Train net output #0: loss = 1.38959 (* 1 = 1.38959 loss)
I0520 10:07:07.430896 15139 sgd_solver.cpp:106] Iteration 71600, lr = 0.0001
I0520 10:07:07.591145 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8015	3.125	82.7617	0	91.2711	6.25	89.3484	0	85.4669	0	86.8934	0	80.1369	0	31.8841	2.9	
I0520 10:07:07.667029 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:07:07.669297 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:07:07.669343 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:07:07.670001 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.38959
I0520 10:08:23.428238 15139 solver.cpp:231] Iteration 71800, loss = 1.35265
I0520 10:08:23.428663 15139 solver.cpp:247]     Train net output #0: loss = 1.35265 (* 1 = 1.35265 loss)
I0520 10:08:23.428689 15139 sgd_solver.cpp:106] Iteration 71800, lr = 0.0001
I0520 10:08:23.589242 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8015	3.125	82.7617	0	91.2711	6.25	89.3485	0	85.4669	0	86.8934	0	80.137	0	31.8842	2.9	
I0520 10:08:23.665171 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:08:23.667567 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:08:23.667609 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:08:23.668185 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35265
I0520 10:09:43.559968 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_72000.caffemodel
I0520 10:11:15.888109 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_72000.solverstate
I0520 10:11:16.379475 15139 solver.cpp:348] Iteration 72000, Testing net (#0)
I0520 10:12:00.519873 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:12:40.839927 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57096
I0520 10:12:40.840214 15139 solver.cpp:415]     Test net output #1: loss = 1.84578 (* 1 = 1.84578 loss)
I0520 10:12:40.930933 15139 solver.cpp:231] Iteration 72000, loss = 1.22906
I0520 10:12:40.931010 15139 solver.cpp:247]     Train net output #0: loss = 1.22906 (* 1 = 1.22906 loss)
I0520 10:12:40.931049 15139 sgd_solver.cpp:106] Iteration 72000, lr = 0.0001
I0520 10:12:41.095690 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8015	3.125	82.7624	0	91.2712	6.25	89.3485	0	85.4669	0	86.8935	0	80.137	0	31.8842	2.9	
I0520 10:12:41.098302 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:12:41.101711 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:12:41.101752 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:12:41.102322 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22906
I0520 10:14:05.064637 15139 solver.cpp:231] Iteration 72200, loss = 1.02633
I0520 10:14:05.064992 15139 solver.cpp:247]     Train net output #0: loss = 1.02633 (* 1 = 1.02633 loss)
I0520 10:14:05.065057 15139 sgd_solver.cpp:106] Iteration 72200, lr = 0.0001
I0520 10:14:05.223433 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8015	3.125	82.7627	0	91.2712	6.25	89.3485	0	85.4669	0	86.8935	0	80.137	0	31.8843	2.9	
I0520 10:14:05.298921 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:14:05.302182 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:14:05.302235 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:14:05.302780 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.02633
I0520 10:15:27.305707 15139 solver.cpp:231] Iteration 72400, loss = 1.26579
I0520 10:15:27.309648 15139 solver.cpp:247]     Train net output #0: loss = 1.26579 (* 1 = 1.26579 loss)
I0520 10:15:27.309679 15139 sgd_solver.cpp:106] Iteration 72400, lr = 0.0001
I0520 10:15:27.466578 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8015	3.125	82.763	0	91.2712	6.25	89.3485	0	85.4669	0	86.8935	0	80.1371	0	31.8843	2.9	
I0520 10:15:27.541396 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:15:27.543582 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:15:27.543618 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:15:27.544088 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26579
I0520 10:16:12.952389 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:16:52.693192 15139 solver.cpp:231] Iteration 72600, loss = 1.08908
I0520 10:16:52.693459 15139 solver.cpp:247]     Train net output #0: loss = 1.08908 (* 1 = 1.08908 loss)
I0520 10:16:52.693480 15139 sgd_solver.cpp:106] Iteration 72600, lr = 0.0001
I0520 10:16:52.853986 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8101	3.125	82.763	0	91.2712	6.25	89.3485	0	85.4669	0	86.8935	0	80.1371	0	31.8844	2.9	
I0520 10:16:52.928975 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:16:52.931128 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:16:52.931171 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:16:52.931671 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08908
I0520 10:18:26.064730 15139 solver.cpp:231] Iteration 72800, loss = 1.17348
I0520 10:18:26.065068 15139 solver.cpp:247]     Train net output #0: loss = 1.17348 (* 1 = 1.17348 loss)
I0520 10:18:26.065129 15139 sgd_solver.cpp:106] Iteration 72800, lr = 0.0001
I0520 10:18:26.223222 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8101	3.125	82.7633	0	91.2712	6.25	89.3485	0	85.4669	0	86.8935	0	80.1371	0	31.8845	2.9	
I0520 10:18:26.299834 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:18:26.303652 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:18:26.303719 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:18:26.305325 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17348
I0520 10:19:59.664796 15139 solver.cpp:348] Iteration 73000, Testing net (#0)
I0520 10:20:41.967039 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:21:21.512127 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57116
I0520 10:21:21.512466 15139 solver.cpp:415]     Test net output #1: loss = 1.84346 (* 1 = 1.84346 loss)
I0520 10:21:21.604428 15139 solver.cpp:231] Iteration 73000, loss = 1.23636
I0520 10:21:21.604527 15139 solver.cpp:247]     Train net output #0: loss = 1.23636 (* 1 = 1.23636 loss)
I0520 10:21:21.604547 15139 sgd_solver.cpp:106] Iteration 73000, lr = 0.0001
I0520 10:21:21.766870 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8101	3.125	82.7633	0	91.2712	6.25	89.3485	0	85.4669	0	86.8936	0	80.1371	0	31.8845	2.9	
I0520 10:21:21.844998 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:21:21.847745 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:21:21.847795 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:21:21.848439 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23636
I0520 10:22:46.309679 15139 solver.cpp:231] Iteration 73200, loss = 1.21389
I0520 10:22:46.310003 15139 solver.cpp:247]     Train net output #0: loss = 1.21389 (* 1 = 1.21389 loss)
I0520 10:22:46.310027 15139 sgd_solver.cpp:106] Iteration 73200, lr = 0.0001
I0520 10:22:46.470333 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8101	3.125	82.7633	0	91.2712	6.25	89.3485	0	85.4669	0	86.8936	0	80.1371	0	31.8846	2.9	
I0520 10:22:46.546438 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:22:46.551396 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:22:46.551472 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:22:46.552443 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21389
I0520 10:24:15.908179 15139 solver.cpp:231] Iteration 73400, loss = 1.14028
I0520 10:24:15.908499 15139 solver.cpp:247]     Train net output #0: loss = 1.14028 (* 1 = 1.14028 loss)
I0520 10:24:15.908522 15139 sgd_solver.cpp:106] Iteration 73400, lr = 0.0001
I0520 10:24:16.066786 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8101	3.125	82.764	0	91.2712	6.25	89.3485	0	85.4669	0	86.8936	0	80.1372	0	31.8846	2.9	
I0520 10:24:16.142444 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:24:16.145519 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:24:16.145589 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:24:16.146183 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14028
I0520 10:25:23.108817 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:25:58.828757 15139 solver.cpp:231] Iteration 73600, loss = 1.22761
I0520 10:25:58.829150 15139 solver.cpp:247]     Train net output #0: loss = 1.22761 (* 1 = 1.22761 loss)
I0520 10:25:58.829177 15139 sgd_solver.cpp:106] Iteration 73600, lr = 0.0001
I0520 10:25:58.989454 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.813	3.125	82.764	0	91.2712	6.25	89.3485	0	85.4669	0	86.8936	0	80.1372	0	31.8847	2.9	
I0520 10:25:59.064947 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:25:59.068255 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:25:59.068310 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:25:59.068869 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22761
I0520 10:27:20.311131 15139 solver.cpp:231] Iteration 73800, loss = 1.11315
I0520 10:27:20.311542 15139 solver.cpp:247]     Train net output #0: loss = 1.11315 (* 1 = 1.11315 loss)
I0520 10:27:20.311578 15139 sgd_solver.cpp:106] Iteration 73800, lr = 0.0001
I0520 10:27:20.469161 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.813	3.125	82.7646	0	91.2712	6.25	89.3485	0	85.4669	0	86.8937	0	80.1372	0	31.8848	2.9	
I0520 10:27:20.544658 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:27:20.548231 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:27:20.548305 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:27:20.548944 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11315
I0520 10:29:08.141729 15139 solver.cpp:348] Iteration 74000, Testing net (#0)
I0520 10:29:53.341892 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:30:35.085475 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5711
I0520 10:30:35.087369 15139 solver.cpp:415]     Test net output #1: loss = 1.84401 (* 1 = 1.84401 loss)
I0520 10:30:35.174758 15139 solver.cpp:231] Iteration 74000, loss = 1.28489
I0520 10:30:35.174841 15139 solver.cpp:247]     Train net output #0: loss = 1.28489 (* 1 = 1.28489 loss)
I0520 10:30:35.174860 15139 sgd_solver.cpp:106] Iteration 74000, lr = 0.0001
I0520 10:30:35.342658 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.813	3.125	82.765	0	91.2712	6.25	89.3485	0	85.4669	0	86.8937	0	80.1372	0	31.8849	2.9	
I0520 10:30:35.422976 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:30:35.425590 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:30:35.425627 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:30:35.426232 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28489
I0520 10:31:55.554946 15139 solver.cpp:231] Iteration 74200, loss = 1.15668
I0520 10:31:55.555398 15139 solver.cpp:247]     Train net output #0: loss = 1.15668 (* 1 = 1.15668 loss)
I0520 10:31:55.555421 15139 sgd_solver.cpp:106] Iteration 74200, lr = 0.0001
I0520 10:31:55.715692 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8216	3.125	82.7653	0	91.2712	6.25	89.3485	0	85.4669	0	86.8937	0	80.1373	0	31.885	2.9	
I0520 10:31:55.791868 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:31:55.795167 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:31:55.795191 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:31:55.795742 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15668
I0520 10:33:11.841334 15139 solver.cpp:231] Iteration 74400, loss = 1.05309
I0520 10:33:11.841624 15139 solver.cpp:247]     Train net output #0: loss = 1.05309 (* 1 = 1.05309 loss)
I0520 10:33:11.841645 15139 sgd_solver.cpp:106] Iteration 74400, lr = 0.0001
I0520 10:33:12.002564 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8245	3.125	82.7656	0	91.2712	6.25	89.3485	0	85.4669	0	86.8937	0	80.1373	0	31.885	2.9	
I0520 10:33:12.078382 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:33:12.080992 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:33:12.081024 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:33:12.081609 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.05309
I0520 10:34:00.184590 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:34:29.132642 15139 solver.cpp:231] Iteration 74600, loss = 1.41256
I0520 10:34:29.132745 15139 solver.cpp:247]     Train net output #0: loss = 1.41256 (* 1 = 1.41256 loss)
I0520 10:34:29.132766 15139 sgd_solver.cpp:106] Iteration 74600, lr = 0.0001
I0520 10:34:29.301316 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8245	3.125	82.7663	0	91.2712	6.25	89.3485	0	85.4669	0	86.8938	0	80.1373	0	31.8851	2.9	
I0520 10:34:29.377699 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:34:29.379916 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:34:29.379954 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:34:29.380655 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.41256
I0520 10:35:48.097018 15139 solver.cpp:231] Iteration 74800, loss = 1.01306
I0520 10:35:48.097411 15139 solver.cpp:247]     Train net output #0: loss = 1.01306 (* 1 = 1.01306 loss)
I0520 10:35:48.097432 15139 sgd_solver.cpp:106] Iteration 74800, lr = 0.0001
I0520 10:35:48.256778 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8274	3.125	82.7663	0	91.2712	6.25	89.3485	0	85.4669	0	86.8938	0	80.1374	0	31.8851	2.9	
I0520 10:35:48.337101 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:35:48.339988 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:35:48.340029 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:35:48.340615 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.01306
I0520 10:37:14.235554 15139 solver.cpp:348] Iteration 75000, Testing net (#0)
I0520 10:38:01.871351 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:38:35.459763 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57118
I0520 10:38:35.459974 15139 solver.cpp:415]     Test net output #1: loss = 1.84362 (* 1 = 1.84362 loss)
I0520 10:38:35.546950 15139 solver.cpp:231] Iteration 75000, loss = 1.25652
I0520 10:38:35.547031 15139 solver.cpp:247]     Train net output #0: loss = 1.25652 (* 1 = 1.25652 loss)
I0520 10:38:35.547050 15139 sgd_solver.cpp:106] Iteration 75000, lr = 0.0001
I0520 10:38:35.709772 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8302	3.125	82.7663	0	91.2712	6.25	89.3485	0	85.4669	0	86.8938	0	80.1374	0	31.8853	2.9	
I0520 10:38:35.790933 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:38:35.793583 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:38:35.793623 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:38:35.794244 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25652
I0520 10:39:57.491991 15139 solver.cpp:231] Iteration 75200, loss = 1.15294
I0520 10:39:57.492261 15139 solver.cpp:247]     Train net output #0: loss = 1.15294 (* 1 = 1.15294 loss)
I0520 10:39:57.492283 15139 sgd_solver.cpp:106] Iteration 75200, lr = 0.0001
I0520 10:39:57.651954 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8331	3.125	82.7669	0	91.2712	6.25	89.3485	0	85.4669	0	86.8938	0	80.1374	0	31.8853	2.9	
I0520 10:39:57.729635 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:39:57.732254 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:39:57.732290 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:39:57.732828 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15294
I0520 10:41:20.559746 15139 solver.cpp:231] Iteration 75400, loss = 1.17783
I0520 10:41:20.561621 15139 solver.cpp:247]     Train net output #0: loss = 1.17783 (* 1 = 1.17783 loss)
I0520 10:41:20.561646 15139 sgd_solver.cpp:106] Iteration 75400, lr = 0.0001
I0520 10:41:20.721324 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8331	3.125	82.7669	0	91.2712	6.25	89.3485	0	85.4669	0	86.8938	0	80.1375	0	31.8854	2.9	
I0520 10:41:20.796738 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:41:20.800117 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:41:20.800146 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:41:20.800632 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17783
I0520 10:42:20.552774 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:42:55.526896 15139 solver.cpp:231] Iteration 75600, loss = 1.38639
I0520 10:42:55.527174 15139 solver.cpp:247]     Train net output #0: loss = 1.38639 (* 1 = 1.38639 loss)
I0520 10:42:55.527197 15139 sgd_solver.cpp:106] Iteration 75600, lr = 0.0001
I0520 10:42:55.685956 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8331	3.125	82.7669	0	91.2712	6.25	89.3485	0	85.4669	0	86.8938	0	80.1375	0	31.8854	2.9	
I0520 10:42:55.761338 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:42:55.764165 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:42:55.764209 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:42:55.764719 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.38639
I0520 10:44:25.335608 15139 solver.cpp:231] Iteration 75800, loss = 1.15555
I0520 10:44:25.335952 15139 solver.cpp:247]     Train net output #0: loss = 1.15555 (* 1 = 1.15555 loss)
I0520 10:44:25.335973 15139 sgd_solver.cpp:106] Iteration 75800, lr = 0.0001
I0520 10:44:25.496613 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8331	3.125	82.7669	0	91.2712	6.25	89.3485	0	85.4669	0	86.8938	0	80.1375	0	31.8855	2.9	
I0520 10:44:25.572763 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:44:25.575968 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:44:25.576001 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:44:25.576481 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15555
I0520 10:46:09.923692 15139 solver.cpp:348] Iteration 76000, Testing net (#0)
I0520 10:46:51.227918 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:47:30.748814 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57088
I0520 10:47:30.749174 15139 solver.cpp:415]     Test net output #1: loss = 1.84333 (* 1 = 1.84333 loss)
I0520 10:47:30.839855 15139 solver.cpp:231] Iteration 76000, loss = 1.18403
I0520 10:47:30.839936 15139 solver.cpp:247]     Train net output #0: loss = 1.18403 (* 1 = 1.18403 loss)
I0520 10:47:30.839954 15139 sgd_solver.cpp:106] Iteration 76000, lr = 0.0001
I0520 10:47:31.006778 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.836	3.125	82.7673	0	91.2712	6.25	89.3485	0	85.4669	0	86.8938	0	80.1375	0	31.8856	2.9	
I0520 10:47:31.082545 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:47:31.085718 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:47:31.085783 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:47:31.086581 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18403
I0520 10:48:46.985705 15139 solver.cpp:231] Iteration 76200, loss = 1.23722
I0520 10:48:46.986029 15139 solver.cpp:247]     Train net output #0: loss = 1.23722 (* 1 = 1.23722 loss)
I0520 10:48:46.986160 15139 sgd_solver.cpp:106] Iteration 76200, lr = 0.0001
I0520 10:48:47.145628 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.836	3.125	82.7673	0	91.2712	6.25	89.3485	0	85.4669	0	86.8939	0	80.1376	0	31.8857	2.9	
I0520 10:48:47.221745 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:48:47.224942 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:48:47.224988 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:48:47.225641 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23722
I0520 10:50:09.460597 15139 solver.cpp:231] Iteration 76400, loss = 1.1909
I0520 10:50:09.462137 15139 solver.cpp:247]     Train net output #0: loss = 1.1909 (* 1 = 1.1909 loss)
I0520 10:50:09.462162 15139 sgd_solver.cpp:106] Iteration 76400, lr = 0.0001
I0520 10:50:09.620380 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.836	3.125	82.7673	0	91.2712	6.25	89.3485	0	85.4669	0	86.8939	0	80.1376	0	31.8858	2.9	
I0520 10:50:09.695858 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:50:09.698750 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:50:09.698793 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:50:09.699316 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1909
I0520 10:51:05.370350 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:51:28.519197 15139 solver.cpp:231] Iteration 76600, loss = 1.15009
I0520 10:51:28.519282 15139 solver.cpp:247]     Train net output #0: loss = 1.15009 (* 1 = 1.15009 loss)
I0520 10:51:28.519299 15139 sgd_solver.cpp:106] Iteration 76600, lr = 0.0001
I0520 10:51:28.679005 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8388	3.125	82.7673	0	91.2712	6.25	89.3485	0	85.4669	0	86.8939	0	80.1376	0	31.8858	2.9	
I0520 10:51:28.754379 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:51:28.757243 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:51:28.757282 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:51:28.757913 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15009
I0520 10:52:50.165319 15139 solver.cpp:231] Iteration 76800, loss = 1.20411
I0520 10:52:50.165534 15139 solver.cpp:247]     Train net output #0: loss = 1.20411 (* 1 = 1.20411 loss)
I0520 10:52:50.165565 15139 sgd_solver.cpp:106] Iteration 76800, lr = 0.0001
I0520 10:52:50.325505 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8388	3.125	82.7676	0	91.2712	6.25	89.3485	0	85.4669	0	86.8939	0	80.1376	0	31.8859	2.9	
I0520 10:52:50.401262 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:52:50.404017 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:52:50.404063 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:52:50.404593 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20411
I0520 10:54:10.087692 15139 solver.cpp:348] Iteration 77000, Testing net (#0)
I0520 10:54:54.511006 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:55:31.312095 15139 solver.cpp:415]     Test net output #0: accuracy = 0.570919
I0520 10:55:31.312428 15139 solver.cpp:415]     Test net output #1: loss = 1.84437 (* 1 = 1.84437 loss)
I0520 10:55:31.402035 15139 solver.cpp:231] Iteration 77000, loss = 1.07323
I0520 10:55:31.402112 15139 solver.cpp:247]     Train net output #0: loss = 1.07323 (* 1 = 1.07323 loss)
I0520 10:55:31.402132 15139 sgd_solver.cpp:106] Iteration 77000, lr = 0.0001
I0520 10:55:31.561730 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8417	3.125	82.7676	0	91.2712	6.25	89.3485	0	85.4669	0	86.8939	0	80.1377	0	31.886	2.9	
I0520 10:55:31.639071 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:55:31.642141 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:55:31.642191 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:55:31.642871 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.07323
I0520 10:56:45.539405 15139 solver.cpp:231] Iteration 77200, loss = 1.22772
I0520 10:56:45.539728 15139 solver.cpp:247]     Train net output #0: loss = 1.22772 (* 1 = 1.22772 loss)
I0520 10:56:45.539749 15139 sgd_solver.cpp:106] Iteration 77200, lr = 0.0001
I0520 10:56:45.706430 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8417	3.125	82.7679	0	91.2712	6.25	89.3485	0	85.4669	0	86.894	0	80.1377	0	31.886	2.9	
I0520 10:56:45.785812 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:56:45.788825 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:56:45.788894 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:56:45.789829 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22772
I0520 10:58:09.386121 15139 solver.cpp:231] Iteration 77400, loss = 1.22704
I0520 10:58:09.386473 15139 solver.cpp:247]     Train net output #0: loss = 1.22704 (* 1 = 1.22704 loss)
I0520 10:58:09.386505 15139 sgd_solver.cpp:106] Iteration 77400, lr = 0.0001
I0520 10:58:09.548022 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8417	3.125	82.7679	0	91.2712	6.25	89.3485	0	85.4669	0	86.894	0	80.1377	0	31.8861	2.9	
I0520 10:58:09.623220 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:58:09.624987 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:58:09.625025 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:58:09.625636 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22704
I0520 10:59:14.451599 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 10:59:36.854507 15139 solver.cpp:231] Iteration 77600, loss = 1.21469
I0520 10:59:36.854640 15139 solver.cpp:247]     Train net output #0: loss = 1.21469 (* 1 = 1.21469 loss)
I0520 10:59:36.854670 15139 sgd_solver.cpp:106] Iteration 77600, lr = 0.0001
I0520 10:59:37.014142 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8446	3.125	82.7679	0	91.2712	6.25	89.3487	0	85.4669	0	86.894	0	80.1378	0	31.8862	2.9	
I0520 10:59:37.089247 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 10:59:37.096498 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 10:59:37.096560 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 10:59:37.097405 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21469
I0520 11:01:03.818547 15139 solver.cpp:231] Iteration 77800, loss = 1.22475
I0520 11:01:03.821694 15139 solver.cpp:247]     Train net output #0: loss = 1.22475 (* 1 = 1.22475 loss)
I0520 11:01:03.821724 15139 sgd_solver.cpp:106] Iteration 77800, lr = 0.0001
I0520 11:01:03.979141 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8446	3.125	82.7686	0	91.2712	6.25	89.3487	0	85.4669	0	86.894	0	80.1378	0	31.8863	2.9	
I0520 11:01:04.054657 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:01:04.057801 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:01:04.057848 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:01:04.058436 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22475
I0520 11:02:27.761549 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_78000.caffemodel
I0520 11:03:22.189064 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_78000.solverstate
I0520 11:03:22.942720 15139 solver.cpp:348] Iteration 78000, Testing net (#0)
I0520 11:04:05.472229 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:04:42.790112 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57168
I0520 11:04:42.790547 15139 solver.cpp:415]     Test net output #1: loss = 1.84292 (* 1 = 1.84292 loss)
I0520 11:04:42.879459 15139 solver.cpp:231] Iteration 78000, loss = 1.37803
I0520 11:04:42.879534 15139 solver.cpp:247]     Train net output #0: loss = 1.37803 (* 1 = 1.37803 loss)
I0520 11:04:42.879557 15139 sgd_solver.cpp:106] Iteration 78000, lr = 0.0001
I0520 11:04:43.046655 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8503	3.125	82.7689	0	91.2712	6.25	89.3487	0	85.4669	0	86.894	0	80.1378	0	31.8864	2.9	
I0520 11:04:43.049650 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:04:43.052729 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:04:43.052770 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:04:43.053678 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.37803
I0520 11:06:02.740978 15139 solver.cpp:231] Iteration 78200, loss = 1.18917
I0520 11:06:02.741329 15139 solver.cpp:247]     Train net output #0: loss = 1.18917 (* 1 = 1.18917 loss)
I0520 11:06:02.741353 15139 sgd_solver.cpp:106] Iteration 78200, lr = 0.0001
I0520 11:06:02.900873 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8503	3.125	82.7692	0	91.2712	6.25	89.349	0	85.4669	0	86.894	0	80.1379	0	31.8865	2.9	
I0520 11:06:02.976331 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:06:02.978597 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:06:02.978643 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:06:02.979176 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18917
I0520 11:07:33.681804 15139 solver.cpp:231] Iteration 78400, loss = 1.18014
I0520 11:07:33.682080 15139 solver.cpp:247]     Train net output #0: loss = 1.18014 (* 1 = 1.18014 loss)
I0520 11:07:33.682103 15139 sgd_solver.cpp:106] Iteration 78400, lr = 0.0001
I0520 11:07:33.841892 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8503	3.125	82.7695	0	91.2712	6.25	89.349	0	85.4669	0	86.8941	0	80.1379	0	31.8865	2.9	
I0520 11:07:33.917115 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:07:33.920017 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:07:33.920058 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:07:33.920552 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18014
I0520 11:08:55.287328 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:09:15.508702 15139 solver.cpp:231] Iteration 78600, loss = 1.20369
I0520 11:09:15.508800 15139 solver.cpp:247]     Train net output #0: loss = 1.20369 (* 1 = 1.20369 loss)
I0520 11:09:15.508821 15139 sgd_solver.cpp:106] Iteration 78600, lr = 0.0001
I0520 11:09:15.667315 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8561	3.125	82.7695	0	91.2713	6.25	89.349	0	85.4669	0	86.8941	0	80.1379	0	31.8866	2.9	
I0520 11:09:15.743084 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:09:15.745724 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:09:15.745789 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:09:15.746461 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20369
I0520 11:10:29.144682 15139 solver.cpp:231] Iteration 78800, loss = 1.39345
I0520 11:10:29.149667 15139 solver.cpp:247]     Train net output #0: loss = 1.39345 (* 1 = 1.39345 loss)
I0520 11:10:29.149701 15139 sgd_solver.cpp:106] Iteration 78800, lr = 0.0001
I0520 11:10:29.306030 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8561	3.125	82.7705	0	91.2713	6.25	89.349	0	85.4669	0	86.8941	0	80.1379	0	31.8866	2.9	
I0520 11:10:29.381266 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:10:29.383929 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:10:29.383978 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:10:29.384534 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.39345
I0520 11:11:51.542749 15139 solver.cpp:348] Iteration 79000, Testing net (#0)
I0520 11:12:37.628265 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:13:14.664099 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57098
I0520 11:13:14.664427 15139 solver.cpp:415]     Test net output #1: loss = 1.84231 (* 1 = 1.84231 loss)
I0520 11:13:14.751929 15139 solver.cpp:231] Iteration 79000, loss = 1.20326
I0520 11:13:14.752035 15139 solver.cpp:247]     Train net output #0: loss = 1.20326 (* 1 = 1.20326 loss)
I0520 11:13:14.752063 15139 sgd_solver.cpp:106] Iteration 79000, lr = 0.0001
I0520 11:13:14.911953 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8618	3.125	82.7708	0	91.2713	6.25	89.349	0	85.4669	0	86.8941	0	80.138	0	31.8866	2.9	
I0520 11:13:14.988739 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:13:14.991643 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:13:14.991690 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:13:14.992357 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20326
I0520 11:14:35.833537 15139 solver.cpp:231] Iteration 79200, loss = 1.11835
I0520 11:14:35.833843 15139 solver.cpp:247]     Train net output #0: loss = 1.11835 (* 1 = 1.11835 loss)
I0520 11:14:35.833865 15139 sgd_solver.cpp:106] Iteration 79200, lr = 0.0001
I0520 11:14:35.996706 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8675	3.125	82.7708	0	91.2714	6.25	89.349	0	85.4669	0	86.8941	0	80.138	0	31.8866	2.9	
I0520 11:14:36.071696 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:14:36.074033 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:14:36.074072 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:14:36.074543 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11835
I0520 11:15:57.167708 15139 solver.cpp:231] Iteration 79400, loss = 1.34963
I0520 11:15:57.168087 15139 solver.cpp:247]     Train net output #0: loss = 1.34963 (* 1 = 1.34963 loss)
I0520 11:15:57.168108 15139 sgd_solver.cpp:106] Iteration 79400, lr = 0.0001
I0520 11:15:57.328152 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8704	3.125	82.7708	0	91.2714	6.25	89.349	0	85.4669	0	86.8941	0	80.138	0	31.8867	2.9	
I0520 11:15:57.407119 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:15:57.409461 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:15:57.409493 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:15:57.410020 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34963
I0520 11:17:12.201813 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:17:26.189888 15139 solver.cpp:231] Iteration 79600, loss = 1.21035
I0520 11:17:26.189970 15139 solver.cpp:247]     Train net output #0: loss = 1.21035 (* 1 = 1.21035 loss)
I0520 11:17:26.189990 15139 sgd_solver.cpp:106] Iteration 79600, lr = 0.0001
I0520 11:17:26.349711 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8733	3.125	82.7708	0	91.2715	6.25	89.349	0	85.4671	0	86.8941	0	80.138	0	31.8867	2.9	
I0520 11:17:26.425319 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:17:26.427093 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:17:26.427124 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:17:26.427698 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21035
I0520 11:18:42.922034 15139 solver.cpp:231] Iteration 79800, loss = 1.16465
I0520 11:18:42.922309 15139 solver.cpp:247]     Train net output #0: loss = 1.16465 (* 1 = 1.16465 loss)
I0520 11:18:42.922332 15139 sgd_solver.cpp:106] Iteration 79800, lr = 0.0001
I0520 11:18:43.081873 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8733	3.125	82.7708	0	91.2715	6.25	89.349	0	85.4671	0	86.8941	0	80.1381	0	31.8868	2.9	
I0520 11:18:43.156980 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:18:43.159860 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:18:43.159934 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:18:43.160425 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16465
I0520 11:20:15.190810 15139 solver.cpp:348] Iteration 80000, Testing net (#0)
I0520 11:21:04.139976 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:21:40.385597 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5719
I0520 11:21:40.386064 15139 solver.cpp:415]     Test net output #1: loss = 1.84324 (* 1 = 1.84324 loss)
I0520 11:21:40.474270 15139 solver.cpp:231] Iteration 80000, loss = 1.17295
I0520 11:21:40.474354 15139 solver.cpp:247]     Train net output #0: loss = 1.17295 (* 1 = 1.17295 loss)
I0520 11:21:40.474372 15139 sgd_solver.cpp:106] Iteration 80000, lr = 0.0001
I0520 11:21:40.638666 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8761	3.125	82.7708	0	91.2715	6.25	89.349	0	85.4671	0	86.8942	0	80.1381	0	31.8868	2.9	
I0520 11:21:40.714900 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:21:40.723808 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:21:40.723891 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:21:40.724794 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17295
I0520 11:23:01.335561 15139 solver.cpp:231] Iteration 80200, loss = 1.18167
I0520 11:23:01.336446 15139 solver.cpp:247]     Train net output #0: loss = 1.18167 (* 1 = 1.18167 loss)
I0520 11:23:01.336467 15139 sgd_solver.cpp:106] Iteration 80200, lr = 0.0001
I0520 11:23:01.496585 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8761	3.125	82.7712	0	91.2715	6.25	89.349	0	85.4671	0	86.8942	0	80.1381	0	31.8868	2.9	
I0520 11:23:01.572578 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:23:01.574847 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:23:01.574884 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:23:01.575587 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18167
I0520 11:24:20.012998 15139 solver.cpp:231] Iteration 80400, loss = 1.0019
I0520 11:24:20.013252 15139 solver.cpp:247]     Train net output #0: loss = 1.0019 (* 1 = 1.0019 loss)
I0520 11:24:20.013275 15139 sgd_solver.cpp:106] Iteration 80400, lr = 0.0001
I0520 11:24:20.172782 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8761	3.125	82.7715	0	91.2715	6.25	89.349	0	85.4671	0	86.8942	0	80.1381	0	31.887	2.9	
I0520 11:24:20.248108 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:24:20.250332 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:24:20.250378 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:24:20.250897 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.0019
I0520 11:25:27.231509 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:25:40.670971 15139 solver.cpp:231] Iteration 80600, loss = 1.30225
I0520 11:25:40.671051 15139 solver.cpp:247]     Train net output #0: loss = 1.30225 (* 1 = 1.30225 loss)
I0520 11:25:40.671069 15139 sgd_solver.cpp:106] Iteration 80600, lr = 0.0001
I0520 11:25:40.830916 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8761	3.125	82.7715	0	91.2715	6.25	89.349	0	85.4671	0	86.8942	0	80.1382	0	31.8871	2.9	
I0520 11:25:40.905639 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:25:40.907501 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:25:40.907534 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:25:40.908023 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30225
I0520 11:26:58.285209 15139 solver.cpp:231] Iteration 80800, loss = 1.40049
I0520 11:26:58.289646 15139 solver.cpp:247]     Train net output #0: loss = 1.40049 (* 1 = 1.40049 loss)
I0520 11:26:58.289687 15139 sgd_solver.cpp:106] Iteration 80800, lr = 0.0001
I0520 11:26:58.447103 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.879	3.125	82.7715	0	91.2715	6.25	89.349	0	85.4671	0	86.8942	0	80.1382	0	31.8872	2.9	
I0520 11:26:58.522943 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:26:58.525238 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:26:58.525277 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:26:58.526037 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.40049
I0520 11:28:16.189530 15139 solver.cpp:348] Iteration 81000, Testing net (#0)
I0520 11:28:57.458899 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:29:33.308073 15139 solver.cpp:415]     Test net output #0: accuracy = 0.571479
I0520 11:29:33.308396 15139 solver.cpp:415]     Test net output #1: loss = 1.84409 (* 1 = 1.84409 loss)
I0520 11:29:33.396752 15139 solver.cpp:231] Iteration 81000, loss = 1.04318
I0520 11:29:33.396854 15139 solver.cpp:247]     Train net output #0: loss = 1.04318 (* 1 = 1.04318 loss)
I0520 11:29:33.396877 15139 sgd_solver.cpp:106] Iteration 81000, lr = 0.0001
I0520 11:29:33.561871 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.879	3.125	82.7715	0	91.2715	6.25	89.349	0	85.4671	0	86.8942	0	80.1382	0	31.8873	2.9	
I0520 11:29:33.637855 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:29:33.640543 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:29:33.640584 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:29:33.641500 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04318
I0520 11:30:48.512460 15139 solver.cpp:231] Iteration 81200, loss = 1.27919
I0520 11:30:48.512738 15139 solver.cpp:247]     Train net output #0: loss = 1.27919 (* 1 = 1.27919 loss)
I0520 11:30:48.512759 15139 sgd_solver.cpp:106] Iteration 81200, lr = 0.0001
I0520 11:30:48.672479 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.879	3.125	82.7715	0	91.2715	6.25	89.349	0	85.4673	0	86.8943	0	80.1382	0	31.8873	2.9	
I0520 11:30:48.749649 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:30:48.751817 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:30:48.751857 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:30:48.752586 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27919
I0520 11:32:07.460528 15139 solver.cpp:231] Iteration 81400, loss = 1.21577
I0520 11:32:07.460799 15139 solver.cpp:247]     Train net output #0: loss = 1.21577 (* 1 = 1.21577 loss)
I0520 11:32:07.460819 15139 sgd_solver.cpp:106] Iteration 81400, lr = 0.0001
I0520 11:32:07.620671 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8819	3.125	82.7718	0	91.2715	6.25	89.349	0	85.4673	0	86.8943	0	80.1383	0	31.8874	2.9	
I0520 11:32:07.695633 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:32:07.697542 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:32:07.697594 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:32:07.698051 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21577
I0520 11:33:15.062137 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:33:25.042127 15139 solver.cpp:231] Iteration 81600, loss = 1.04434
I0520 11:33:25.042212 15139 solver.cpp:247]     Train net output #0: loss = 1.04434 (* 1 = 1.04434 loss)
I0520 11:33:25.042230 15139 sgd_solver.cpp:106] Iteration 81600, lr = 0.0001
I0520 11:33:25.203202 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8819	3.125	82.7718	0	91.2715	6.25	89.349	0	85.4673	0	86.8943	0	80.1383	0	31.8875	2.9	
I0520 11:33:25.278300 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:33:25.280531 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:33:25.280582 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:33:25.281185 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04434
I0520 11:34:57.121222 15139 solver.cpp:231] Iteration 81800, loss = 1.33104
I0520 11:34:57.121681 15139 solver.cpp:247]     Train net output #0: loss = 1.33104 (* 1 = 1.33104 loss)
I0520 11:34:57.121706 15139 sgd_solver.cpp:106] Iteration 81800, lr = 0.0001
I0520 11:34:57.282446 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8819	3.125	82.7718	0	91.2715	6.25	89.349	0	85.4673	0	86.8943	0	80.1383	0	31.8875	2.9	
I0520 11:34:57.370863 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:34:57.373776 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:34:57.373821 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:34:57.374323 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33104
I0520 11:36:24.394428 15139 solver.cpp:348] Iteration 82000, Testing net (#0)
I0520 11:37:15.168118 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:37:48.175915 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57112
I0520 11:37:48.176292 15139 solver.cpp:415]     Test net output #1: loss = 1.8414 (* 1 = 1.8414 loss)
I0520 11:37:48.264417 15139 solver.cpp:231] Iteration 82000, loss = 1.04804
I0520 11:37:48.264492 15139 solver.cpp:247]     Train net output #0: loss = 1.04804 (* 1 = 1.04804 loss)
I0520 11:37:48.264509 15139 sgd_solver.cpp:106] Iteration 82000, lr = 0.0001
I0520 11:37:48.429497 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8819	3.125	82.7718	0	91.2716	6.25	89.349	0	85.4673	0	86.8943	0	80.1384	0	31.8876	2.9	
I0520 11:37:48.504477 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:37:48.506407 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:37:48.506435 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:37:48.507014 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04804
I0520 11:39:28.935292 15139 solver.cpp:231] Iteration 82200, loss = 1.17824
I0520 11:39:28.935595 15139 solver.cpp:247]     Train net output #0: loss = 1.17824 (* 1 = 1.17824 loss)
I0520 11:39:28.935621 15139 sgd_solver.cpp:106] Iteration 82200, lr = 0.0001
I0520 11:39:29.095767 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8876	3.125	82.7721	0	91.2716	6.25	89.349	0	85.4673	0	86.8943	0	80.1384	0	31.8876	2.9	
I0520 11:39:29.171103 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:39:29.173002 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:39:29.173037 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:39:29.173540 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17824
I0520 11:40:51.748647 15139 solver.cpp:231] Iteration 82400, loss = 1.1187
I0520 11:40:51.748920 15139 solver.cpp:247]     Train net output #0: loss = 1.1187 (* 1 = 1.1187 loss)
I0520 11:40:51.748940 15139 sgd_solver.cpp:106] Iteration 82400, lr = 0.0001
I0520 11:40:51.907322 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8905	3.125	82.7721	0	91.2716	6.25	89.349	0	85.4673	0	86.8944	0	80.1384	0	31.8877	2.9	
I0520 11:40:51.982015 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:40:51.983944 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:40:51.984004 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:40:51.984498 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1187
I0520 11:42:10.545439 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:42:17.504283 15139 solver.cpp:231] Iteration 82600, loss = 1.54779
I0520 11:42:17.504359 15139 solver.cpp:247]     Train net output #0: loss = 1.54779 (* 1 = 1.54779 loss)
I0520 11:42:17.504377 15139 sgd_solver.cpp:106] Iteration 82600, lr = 0.0001
I0520 11:42:17.663305 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8934	3.125	82.7721	0	91.2716	6.25	89.349	0	85.4673	0	86.8944	0	80.1384	0	31.8878	2.9	
I0520 11:42:17.738006 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:42:17.739828 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:42:17.739859 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:42:17.740418 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.54779
I0520 11:43:41.457669 15139 solver.cpp:231] Iteration 82800, loss = 1.30361
I0520 11:43:41.458358 15139 solver.cpp:247]     Train net output #0: loss = 1.30361 (* 1 = 1.30361 loss)
I0520 11:43:41.458384 15139 sgd_solver.cpp:106] Iteration 82800, lr = 0.0001
I0520 11:43:41.616466 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8934	3.125	82.7721	0	91.2716	6.25	89.349	0	85.4675	0	86.8944	0	80.1384	0	31.8879	2.9	
I0520 11:43:41.691431 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:43:41.693496 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:43:41.693521 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:43:41.694016 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30361
I0520 11:45:02.026978 15139 solver.cpp:348] Iteration 83000, Testing net (#0)
I0520 11:45:53.076066 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:46:24.103413 15139 solver.cpp:415]     Test net output #0: accuracy = 0.571879
I0520 11:46:24.103807 15139 solver.cpp:415]     Test net output #1: loss = 1.8406 (* 1 = 1.8406 loss)
I0520 11:46:24.191364 15139 solver.cpp:231] Iteration 83000, loss = 1.13054
I0520 11:46:24.191443 15139 solver.cpp:247]     Train net output #0: loss = 1.13054 (* 1 = 1.13054 loss)
I0520 11:46:24.191462 15139 sgd_solver.cpp:106] Iteration 83000, lr = 0.0001
I0520 11:46:24.359351 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8934	3.125	82.7725	0	91.2716	6.25	89.349	0	85.4675	0	86.8944	0	80.1385	0	31.8879	2.9	
I0520 11:46:24.434942 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:46:24.436879 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:46:24.436911 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:46:24.437444 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13054
I0520 11:47:52.755919 15139 solver.cpp:231] Iteration 83200, loss = 1.08765
I0520 11:47:52.756278 15139 solver.cpp:247]     Train net output #0: loss = 1.08765 (* 1 = 1.08765 loss)
I0520 11:47:52.756301 15139 sgd_solver.cpp:106] Iteration 83200, lr = 0.0001
I0520 11:47:52.929365 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8934	3.125	82.7725	0	91.2716	6.25	89.349	0	85.4675	0	86.8944	0	80.1385	0	31.888	2.9	
I0520 11:47:53.004189 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:47:53.005951 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:47:53.005985 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:47:53.006494 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08765
I0520 11:49:17.177737 15139 solver.cpp:231] Iteration 83400, loss = 1.13979
I0520 11:49:17.178171 15139 solver.cpp:247]     Train net output #0: loss = 1.13979 (* 1 = 1.13979 loss)
I0520 11:49:17.178231 15139 sgd_solver.cpp:106] Iteration 83400, lr = 0.0001
I0520 11:49:17.338698 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8934	3.125	82.7728	0	91.2716	6.25	89.349	0	85.4675	0	86.8944	0	80.1385	0	31.8881	2.9	
I0520 11:49:17.414752 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:49:17.417251 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:49:17.417291 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:49:17.418162 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13979
I0520 11:50:32.904031 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:50:37.574017 15139 solver.cpp:231] Iteration 83600, loss = 1.15632
I0520 11:50:37.574092 15139 solver.cpp:247]     Train net output #0: loss = 1.15632 (* 1 = 1.15632 loss)
I0520 11:50:37.574111 15139 sgd_solver.cpp:106] Iteration 83600, lr = 0.0001
I0520 11:50:37.734148 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8934	3.125	82.7728	0	91.2716	6.25	89.349	0	85.4675	0	86.8945	0	80.1385	0	31.8881	2.9	
I0520 11:50:37.809039 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:50:37.811224 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:50:37.811265 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:50:37.811770 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15632
I0520 11:52:04.973335 15139 solver.cpp:231] Iteration 83800, loss = 1.19199
I0520 11:52:04.973675 15139 solver.cpp:247]     Train net output #0: loss = 1.19199 (* 1 = 1.19199 loss)
I0520 11:52:04.973711 15139 sgd_solver.cpp:106] Iteration 83800, lr = 0.0001
I0520 11:52:05.134632 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8962	3.125	82.7728	0	91.2716	6.25	89.349	0	85.4675	0	86.8945	0	80.1385	0	31.8881	2.9	
I0520 11:52:05.209784 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:52:05.212057 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:52:05.212090 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:52:05.212730 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19199
I0520 11:53:26.920474 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_84000.caffemodel
I0520 11:54:38.277520 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_84000.solverstate
I0520 11:54:38.855598 15139 solver.cpp:348] Iteration 84000, Testing net (#0)
I0520 11:55:28.444321 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 11:56:02.491900 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57172
I0520 11:56:02.492177 15139 solver.cpp:415]     Test net output #1: loss = 1.84175 (* 1 = 1.84175 loss)
I0520 11:56:02.583176 15139 solver.cpp:231] Iteration 84000, loss = 1.01454
I0520 11:56:02.583252 15139 solver.cpp:247]     Train net output #0: loss = 1.01454 (* 1 = 1.01454 loss)
I0520 11:56:02.583272 15139 sgd_solver.cpp:106] Iteration 84000, lr = 0.0001
I0520 11:56:02.743604 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8962	3.125	82.7728	0	91.2717	6.25	89.349	0	85.4675	0	86.8945	0	80.1385	0	31.8882	2.9	
I0520 11:56:02.745540 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:56:02.748006 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:56:02.748047 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:56:02.748610 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.01454
I0520 11:57:29.625619 15139 solver.cpp:231] Iteration 84200, loss = 1.04715
I0520 11:57:29.625993 15139 solver.cpp:247]     Train net output #0: loss = 1.04715 (* 1 = 1.04715 loss)
I0520 11:57:29.626013 15139 sgd_solver.cpp:106] Iteration 84200, lr = 0.0001
I0520 11:57:29.786046 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8962	3.125	82.7728	0	91.2717	6.25	89.349	0	85.4675	0	86.8945	0	80.1386	0	31.8883	2.9	
I0520 11:57:29.860965 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:57:29.863193 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:57:29.863240 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:57:29.863780 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04715
I0520 11:58:52.426316 15139 solver.cpp:231] Iteration 84400, loss = 1.1082
I0520 11:58:52.428092 15139 solver.cpp:247]     Train net output #0: loss = 1.1082 (* 1 = 1.1082 loss)
I0520 11:58:52.428122 15139 sgd_solver.cpp:106] Iteration 84400, lr = 0.0001
I0520 11:58:52.587924 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8962	3.125	82.7728	0	91.2717	6.25	89.349	0	85.4675	0	86.8945	0	80.1386	0	31.8883	2.9	
I0520 11:58:52.663194 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 11:58:52.666052 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 11:58:52.666097 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 11:58:52.666767 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1082
I0520 12:00:20.621400 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:00:22.776484 15139 solver.cpp:231] Iteration 84600, loss = 1.01267
I0520 12:00:22.776556 15139 solver.cpp:247]     Train net output #0: loss = 1.01267 (* 1 = 1.01267 loss)
I0520 12:00:22.776573 15139 sgd_solver.cpp:106] Iteration 84600, lr = 0.0001
I0520 12:00:22.935257 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8962	3.125	82.7734	0	91.2717	6.25	89.349	0	85.4675	0	86.8945	0	80.1386	0	31.8884	2.9	
I0520 12:00:23.011400 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:00:23.013715 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:00:23.013753 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:00:23.014386 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.01267
I0520 12:01:45.727640 15139 solver.cpp:231] Iteration 84800, loss = 1.24273
I0520 12:01:45.729635 15139 solver.cpp:247]     Train net output #0: loss = 1.24273 (* 1 = 1.24273 loss)
I0520 12:01:45.729661 15139 sgd_solver.cpp:106] Iteration 84800, lr = 0.0001
I0520 12:01:45.887892 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8991	3.125	82.7738	0	91.2717	6.25	89.349	0	85.4675	0	86.8945	0	80.1386	0	31.8885	2.9	
I0520 12:01:45.964028 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:01:45.967200 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:01:45.967242 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:01:45.968013 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24273
I0520 12:03:06.987880 15139 solver.cpp:348] Iteration 85000, Testing net (#0)
I0520 12:03:58.776046 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:04:28.849952 15139 solver.cpp:415]     Test net output #0: accuracy = 0.571859
I0520 12:04:28.850188 15139 solver.cpp:415]     Test net output #1: loss = 1.84365 (* 1 = 1.84365 loss)
I0520 12:04:28.937858 15139 solver.cpp:231] Iteration 85000, loss = 1.09128
I0520 12:04:28.937933 15139 solver.cpp:247]     Train net output #0: loss = 1.09128 (* 1 = 1.09128 loss)
I0520 12:04:28.937953 15139 sgd_solver.cpp:106] Iteration 85000, lr = 0.0001
I0520 12:04:29.103386 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8991	3.125	82.7738	0	91.2719	6.25	89.3491	0	85.4675	0	86.8945	0	80.1387	0	31.8885	2.9	
I0520 12:04:29.178725 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:04:29.180701 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:04:29.180735 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:04:29.181334 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09128
I0520 12:05:54.762112 15139 solver.cpp:231] Iteration 85200, loss = 1.06755
I0520 12:05:54.762449 15139 solver.cpp:247]     Train net output #0: loss = 1.06755 (* 1 = 1.06755 loss)
I0520 12:05:54.762471 15139 sgd_solver.cpp:106] Iteration 85200, lr = 0.0001
I0520 12:05:54.921201 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8991	3.125	82.7741	0	91.2719	6.25	89.3491	0	85.4675	0	86.8946	0	80.1387	0	31.8886	2.9	
I0520 12:05:54.996224 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:05:54.998553 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:05:54.998595 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:05:54.999091 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.06755
I0520 12:07:19.940707 15139 solver.cpp:231] Iteration 85400, loss = 1.24564
I0520 12:07:19.941041 15139 solver.cpp:247]     Train net output #0: loss = 1.24564 (* 1 = 1.24564 loss)
I0520 12:07:19.941067 15139 sgd_solver.cpp:106] Iteration 85400, lr = 0.0001
I0520 12:07:20.101496 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8991	3.125	82.7744	0	91.2719	6.25	89.3491	0	85.4675	0	86.8946	0	80.1387	0	31.8887	2.9	
I0520 12:07:20.177757 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:07:20.180219 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:07:20.180258 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:07:20.180982 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24564
I0520 12:08:40.914748 15139 solver.cpp:231] Iteration 85600, loss = 1.22135
I0520 12:08:40.915006 15139 solver.cpp:247]     Train net output #0: loss = 1.22135 (* 1 = 1.22135 loss)
I0520 12:08:40.915027 15139 sgd_solver.cpp:106] Iteration 85600, lr = 0.0001
I0520 12:08:41.076581 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8991	3.125	82.7744	0	91.2719	6.25	89.3493	0	85.4675	0	86.8946	0	80.1387	0	31.8887	2.9	
I0520 12:08:41.152318 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:08:41.154389 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:08:41.154423 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:08:41.154983 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22135
I0520 12:08:41.997681 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:09:56.717401 15139 solver.cpp:231] Iteration 85800, loss = 1.25439
I0520 12:09:56.717768 15139 solver.cpp:247]     Train net output #0: loss = 1.25439 (* 1 = 1.25439 loss)
I0520 12:09:56.717797 15139 sgd_solver.cpp:106] Iteration 85800, lr = 0.0001
I0520 12:09:56.879335 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8991	3.125	82.7751	0	91.2719	6.25	89.3493	0	85.4678	0	86.8946	0	80.1387	0	31.8888	2.9	
I0520 12:09:56.955354 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:09:56.957093 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:09:56.957119 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:09:56.957748 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25439
I0520 12:11:10.462815 15139 solver.cpp:348] Iteration 86000, Testing net (#0)
I0520 12:11:54.831383 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:12:25.247213 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57158
I0520 12:12:25.247526 15139 solver.cpp:415]     Test net output #1: loss = 1.84291 (* 1 = 1.84291 loss)
I0520 12:12:25.337560 15139 solver.cpp:231] Iteration 86000, loss = 1.27383
I0520 12:12:25.337632 15139 solver.cpp:247]     Train net output #0: loss = 1.27383 (* 1 = 1.27383 loss)
I0520 12:12:25.337651 15139 sgd_solver.cpp:106] Iteration 86000, lr = 0.0001
I0520 12:12:25.503989 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.8991	3.125	82.7751	0	91.272	6.25	89.3493	0	85.4678	0	86.8946	0	80.1388	0	31.8889	2.9	
I0520 12:12:25.578660 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:12:25.580235 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:12:25.580257 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:12:25.580767 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27383
I0520 12:13:37.881070 15139 solver.cpp:231] Iteration 86200, loss = 0.958003
I0520 12:13:37.881458 15139 solver.cpp:247]     Train net output #0: loss = 0.958003 (* 1 = 0.958003 loss)
I0520 12:13:37.881477 15139 sgd_solver.cpp:106] Iteration 86200, lr = 0.0001
I0520 12:13:38.041702 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.902	3.125	82.7751	0	91.272	6.25	89.3493	0	85.4678	0	86.8946	0	80.1388	0	31.889	2.9	
I0520 12:13:38.118002 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:13:38.119770 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:13:38.119788 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:13:38.120322 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.958003
I0520 12:14:52.493391 15139 solver.cpp:231] Iteration 86400, loss = 1.21349
I0520 12:14:52.497658 15139 solver.cpp:247]     Train net output #0: loss = 1.21349 (* 1 = 1.21349 loss)
I0520 12:14:52.497692 15139 sgd_solver.cpp:106] Iteration 86400, lr = 0.0001
I0520 12:14:52.653740 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.902	3.125	82.7751	0	91.272	6.25	89.3493	0	85.4678	0	86.8947	0	80.1388	0	31.8891	2.9	
I0520 12:14:52.729975 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:14:52.732496 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:14:52.732543 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:14:52.733346 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21349
I0520 12:16:04.380594 15139 solver.cpp:231] Iteration 86600, loss = 1.24323
I0520 12:16:04.380910 15139 solver.cpp:247]     Train net output #0: loss = 1.24323 (* 1 = 1.24323 loss)
I0520 12:16:04.380934 15139 sgd_solver.cpp:106] Iteration 86600, lr = 0.0001
I0520 12:16:04.543671 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.902	3.125	82.7754	0	91.272	6.25	89.3494	0	85.4678	0	86.8947	0	80.1388	0	31.8891	2.9	
I0520 12:16:04.620093 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:16:04.622897 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:16:04.622939 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:16:04.623678 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24323
I0520 12:16:08.024899 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:17:17.316392 15139 solver.cpp:231] Iteration 86800, loss = 1.17252
I0520 12:17:17.316602 15139 solver.cpp:247]     Train net output #0: loss = 1.17252 (* 1 = 1.17252 loss)
I0520 12:17:17.316622 15139 sgd_solver.cpp:106] Iteration 86800, lr = 0.0001
I0520 12:17:17.478766 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.902	3.125	82.7754	0	91.272	6.25	89.3494	0	85.4678	0	86.8947	0	80.1388	0	31.8892	2.9	
I0520 12:17:17.554698 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:17:17.556452 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:17:17.556466 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:17:17.557026 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17252
I0520 12:18:29.731726 15139 solver.cpp:348] Iteration 87000, Testing net (#0)
I0520 12:19:12.509064 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:19:39.096185 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57162
I0520 12:19:39.096271 15139 solver.cpp:415]     Test net output #1: loss = 1.84113 (* 1 = 1.84113 loss)
I0520 12:19:39.183435 15139 solver.cpp:231] Iteration 87000, loss = 1.05361
I0520 12:19:39.183509 15139 solver.cpp:247]     Train net output #0: loss = 1.05361 (* 1 = 1.05361 loss)
I0520 12:19:39.183526 15139 sgd_solver.cpp:106] Iteration 87000, lr = 0.0001
I0520 12:19:39.350512 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.902	3.125	82.7754	0	91.272	6.25	89.3494	0	85.4678	0	86.8947	0	80.1389	0	31.8892	2.9	
I0520 12:19:39.426218 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:19:39.428031 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:19:39.428056 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:19:39.428632 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.05361
I0520 12:20:52.209966 15139 solver.cpp:231] Iteration 87200, loss = 1.27402
I0520 12:20:52.210386 15139 solver.cpp:247]     Train net output #0: loss = 1.27402 (* 1 = 1.27402 loss)
I0520 12:20:52.210405 15139 sgd_solver.cpp:106] Iteration 87200, lr = 0.0001
I0520 12:20:52.371776 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.902	3.125	82.7754	0	91.272	6.25	89.3494	0	85.4678	0	86.8947	0	80.1389	0	31.8893	2.9	
I0520 12:20:52.449523 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:20:52.451508 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:20:52.451547 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:20:52.452096 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27402
I0520 12:22:08.597148 15139 solver.cpp:231] Iteration 87400, loss = 1.10665
I0520 12:22:08.597384 15139 solver.cpp:247]     Train net output #0: loss = 1.10665 (* 1 = 1.10665 loss)
I0520 12:22:08.597404 15139 sgd_solver.cpp:106] Iteration 87400, lr = 0.0001
I0520 12:22:08.759100 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.902	3.125	82.7754	0	91.272	6.25	89.3494	0	85.4678	0	86.8947	0	80.1389	0	31.8895	2.9	
I0520 12:22:08.833889 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:22:08.835825 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:22:08.835850 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:22:08.836567 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10665
I0520 12:23:25.761384 15139 solver.cpp:231] Iteration 87600, loss = 1.30561
I0520 12:23:25.761787 15139 solver.cpp:247]     Train net output #0: loss = 1.30561 (* 1 = 1.30561 loss)
I0520 12:23:25.761808 15139 sgd_solver.cpp:106] Iteration 87600, lr = 0.0001
I0520 12:23:25.920888 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9048	3.125	82.7754	0	91.272	6.25	89.3494	0	85.4678	0	86.8947	0	80.1389	0	31.8895	2.9	
I0520 12:23:25.997004 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:23:25.999410 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:23:25.999430 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:23:26.000190 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30561
I0520 12:23:32.513154 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:24:41.757817 15139 solver.cpp:231] Iteration 87800, loss = 1.00865
I0520 12:24:41.758096 15139 solver.cpp:247]     Train net output #0: loss = 1.00865 (* 1 = 1.00865 loss)
I0520 12:24:41.758117 15139 sgd_solver.cpp:106] Iteration 87800, lr = 0.0001
I0520 12:24:41.918979 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9048	3.125	82.7754	0	91.272	6.25	89.3494	0	85.4678	0	86.8948	0	80.139	0	31.8896	2.9	
I0520 12:24:41.997874 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:24:41.999786 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:24:41.999811 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:24:42.000387 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.00865
I0520 12:25:56.759630 15139 solver.cpp:348] Iteration 88000, Testing net (#0)
I0520 12:26:41.070377 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:27:07.190845 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57222
I0520 12:27:07.190935 15139 solver.cpp:415]     Test net output #1: loss = 1.84123 (* 1 = 1.84123 loss)
I0520 12:27:07.279357 15139 solver.cpp:231] Iteration 88000, loss = 1.12194
I0520 12:27:07.279439 15139 solver.cpp:247]     Train net output #0: loss = 1.12194 (* 1 = 1.12194 loss)
I0520 12:27:07.279463 15139 sgd_solver.cpp:106] Iteration 88000, lr = 0.0001
I0520 12:27:07.440423 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9077	3.125	82.7754	0	91.272	6.25	89.3494	0	85.4678	0	86.8948	0	80.139	0	31.8896	2.9	
I0520 12:27:07.516258 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:27:07.519124 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:27:07.519165 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:27:07.519759 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12194
I0520 12:28:33.325510 15139 solver.cpp:231] Iteration 88200, loss = 1.09864
I0520 12:28:33.328122 15139 solver.cpp:247]     Train net output #0: loss = 1.09864 (* 1 = 1.09864 loss)
I0520 12:28:33.328153 15139 sgd_solver.cpp:106] Iteration 88200, lr = 0.0001
I0520 12:28:33.486984 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9077	3.125	82.7757	0	91.272	6.25	89.3496	0	85.4678	0	86.8948	0	80.139	0	31.8897	2.9	
I0520 12:28:33.563107 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:28:33.566936 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:28:33.567001 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:28:33.567592 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09864
I0520 12:29:50.377336 15139 solver.cpp:231] Iteration 88400, loss = 1.08408
I0520 12:29:50.377720 15139 solver.cpp:247]     Train net output #0: loss = 1.08408 (* 1 = 1.08408 loss)
I0520 12:29:50.377756 15139 sgd_solver.cpp:106] Iteration 88400, lr = 0.0001
I0520 12:29:50.540205 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9106	3.125	82.7757	0	91.2721	6.25	89.3496	0	85.4678	0	86.8948	0	80.139	0	31.8897	2.9	
I0520 12:29:50.615947 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:29:50.619127 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:29:50.619182 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:29:50.619706 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08408
I0520 12:31:10.147852 15139 solver.cpp:231] Iteration 88600, loss = 1.10123
I0520 12:31:10.148231 15139 solver.cpp:247]     Train net output #0: loss = 1.10123 (* 1 = 1.10123 loss)
I0520 12:31:10.148270 15139 sgd_solver.cpp:106] Iteration 88600, lr = 0.0001
I0520 12:31:10.308236 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9163	3.125	82.7757	0	91.2721	6.25	89.3496	0	85.4678	0	86.8948	0	80.139	0	31.8898	2.9	
I0520 12:31:10.384655 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:31:10.388120 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:31:10.388162 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:31:10.388900 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10123
I0520 12:31:19.623555 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:32:29.139819 15139 solver.cpp:231] Iteration 88800, loss = 1.28386
I0520 12:32:29.140255 15139 solver.cpp:247]     Train net output #0: loss = 1.28386 (* 1 = 1.28386 loss)
I0520 12:32:29.140277 15139 sgd_solver.cpp:106] Iteration 88800, lr = 0.0001
I0520 12:32:29.299736 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9192	3.125	82.7757	0	91.2721	6.25	89.3497	0	85.4678	0	86.8948	0	80.1391	0	31.8899	2.9	
I0520 12:32:29.376338 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:32:29.379570 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:32:29.379614 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:32:29.380501 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28386
I0520 12:33:46.044178 15139 solver.cpp:348] Iteration 89000, Testing net (#0)
I0520 12:34:31.556339 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:34:57.614763 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57096
I0520 12:34:57.614863 15139 solver.cpp:415]     Test net output #1: loss = 1.842 (* 1 = 1.842 loss)
I0520 12:34:57.702558 15139 solver.cpp:231] Iteration 89000, loss = 1.03687
I0520 12:34:57.702734 15139 solver.cpp:247]     Train net output #0: loss = 1.03687 (* 1 = 1.03687 loss)
I0520 12:34:57.702755 15139 sgd_solver.cpp:106] Iteration 89000, lr = 0.0001
I0520 12:34:57.867830 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9192	3.125	82.7757	0	91.2721	6.25	89.3497	0	85.4678	0	86.8948	0	80.1391	0	31.8899	2.9	
I0520 12:34:57.943068 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:34:57.945257 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:34:57.945292 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:34:57.945902 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.03687
I0520 12:36:24.394716 15139 solver.cpp:231] Iteration 89200, loss = 1.30722
I0520 12:36:24.397635 15139 solver.cpp:247]     Train net output #0: loss = 1.30722 (* 1 = 1.30722 loss)
I0520 12:36:24.397662 15139 sgd_solver.cpp:106] Iteration 89200, lr = 0.0001
I0520 12:36:24.555207 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9221	3.125	82.7757	0	91.2721	6.25	89.3497	0	85.4678	0	86.8948	0	80.1391	0	31.89	2.9	
I0520 12:36:24.630115 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:36:24.631834 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:36:24.631860 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:36:24.632392 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30722
I0520 12:37:38.629650 15139 solver.cpp:231] Iteration 89400, loss = 1.09316
I0520 12:37:38.629995 15139 solver.cpp:247]     Train net output #0: loss = 1.09316 (* 1 = 1.09316 loss)
I0520 12:37:38.630017 15139 sgd_solver.cpp:106] Iteration 89400, lr = 0.0001
I0520 12:37:38.790515 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9221	3.125	82.776	0	91.2721	6.25	89.3497	0	85.468	0	86.8949	0	80.1392	0	31.8901	2.9	
I0520 12:37:38.866236 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:37:38.868564 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:37:38.868607 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:37:38.869218 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09316
I0520 12:38:54.737798 15139 solver.cpp:231] Iteration 89600, loss = 1.25743
I0520 12:38:54.738040 15139 solver.cpp:247]     Train net output #0: loss = 1.25743 (* 1 = 1.25743 loss)
I0520 12:38:54.738065 15139 sgd_solver.cpp:106] Iteration 89600, lr = 0.0001
I0520 12:38:54.899693 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9221	3.125	82.776	0	91.2721	6.25	89.3497	0	85.468	0	86.8949	0	80.1392	0	31.8901	2.9	
I0520 12:38:54.977952 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:38:54.980052 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:38:54.980078 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:38:54.980708 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25743
I0520 12:39:06.577673 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:40:09.185668 15139 solver.cpp:231] Iteration 89800, loss = 1.17593
I0520 12:40:09.188781 15139 solver.cpp:247]     Train net output #0: loss = 1.17593 (* 1 = 1.17593 loss)
I0520 12:40:09.188819 15139 sgd_solver.cpp:106] Iteration 89800, lr = 0.0001
I0520 12:40:09.347723 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9221	3.125	82.7764	0	91.2721	6.25	89.3497	0	85.468	0	86.8949	0	80.1392	0	31.8903	2.9	
I0520 12:40:09.427621 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:40:09.430860 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:40:09.430912 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:40:09.431697 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17593
I0520 12:41:22.025493 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_90000.caffemodel
I0520 12:41:55.849548 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_90000.solverstate
I0520 12:41:56.343503 15139 solver.cpp:348] Iteration 90000, Testing net (#0)
I0520 12:42:43.419004 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:43:10.376570 15139 solver.cpp:415]     Test net output #0: accuracy = 0.571919
I0520 12:43:10.376669 15139 solver.cpp:415]     Test net output #1: loss = 1.84416 (* 1 = 1.84416 loss)
I0520 12:43:10.469380 15139 solver.cpp:231] Iteration 90000, loss = 1.18519
I0520 12:43:10.469471 15139 solver.cpp:247]     Train net output #0: loss = 1.18519 (* 1 = 1.18519 loss)
I0520 12:43:10.469491 15139 sgd_solver.cpp:106] Iteration 90000, lr = 0.0001
I0520 12:43:10.635397 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9278	3.125	82.7764	0	91.2721	6.25	89.3497	0	85.468	0	86.8949	0	80.1392	0	31.8905	2.9	
I0520 12:43:10.637711 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:43:10.640048 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:43:10.640080 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:43:10.640640 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18519
I0520 12:44:33.615758 15139 solver.cpp:231] Iteration 90200, loss = 1.14327
I0520 12:44:33.621659 15139 solver.cpp:247]     Train net output #0: loss = 1.14327 (* 1 = 1.14327 loss)
I0520 12:44:33.621692 15139 sgd_solver.cpp:106] Iteration 90200, lr = 0.0001
I0520 12:44:33.774988 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9278	3.125	82.7764	0	91.2721	6.25	89.3497	0	85.468	0	86.8949	0	80.1392	0	31.8906	2.9	
I0520 12:44:33.849900 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:44:33.852093 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:44:33.852129 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:44:33.852604 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14327
I0520 12:45:56.023474 15139 solver.cpp:231] Iteration 90400, loss = 1.16078
I0520 12:45:56.025651 15139 solver.cpp:247]     Train net output #0: loss = 1.16078 (* 1 = 1.16078 loss)
I0520 12:45:56.025684 15139 sgd_solver.cpp:106] Iteration 90400, lr = 0.0001
I0520 12:45:56.183476 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9307	3.125	82.7764	0	91.2721	6.25	89.3497	0	85.468	0	86.8949	0	80.1393	0	31.8907	2.9	
I0520 12:45:56.258836 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:45:56.261096 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:45:56.261138 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:45:56.261997 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16078
I0520 12:47:19.829579 15139 solver.cpp:231] Iteration 90600, loss = 1.1159
I0520 12:47:19.830811 15139 solver.cpp:247]     Train net output #0: loss = 1.1159 (* 1 = 1.1159 loss)
I0520 12:47:19.830833 15139 sgd_solver.cpp:106] Iteration 90600, lr = 0.0001
I0520 12:47:19.989204 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9364	3.125	82.7764	0	91.2722	6.25	89.3497	0	85.468	0	86.8949	0	80.1393	0	31.8908	2.9	
I0520 12:47:20.063995 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:47:20.066149 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:47:20.066185 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:47:20.066659 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1159
I0520 12:47:35.865695 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:48:40.508533 15139 solver.cpp:231] Iteration 90800, loss = 1.11339
I0520 12:48:40.509578 15139 solver.cpp:247]     Train net output #0: loss = 1.11339 (* 1 = 1.11339 loss)
I0520 12:48:40.509603 15139 sgd_solver.cpp:106] Iteration 90800, lr = 0.0001
I0520 12:48:40.668423 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9393	3.125	82.7764	0	91.2722	6.25	89.3497	0	85.468	0	86.8949	0	80.1393	0	31.8909	2.9	
I0520 12:48:40.744289 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:48:40.746467 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:48:40.746515 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:48:40.747372 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11339
I0520 12:50:05.140789 15139 solver.cpp:348] Iteration 91000, Testing net (#0)
I0520 12:50:56.393415 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:51:24.368105 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5721
I0520 12:51:24.368202 15139 solver.cpp:415]     Test net output #1: loss = 1.84175 (* 1 = 1.84175 loss)
I0520 12:51:24.455265 15139 solver.cpp:231] Iteration 91000, loss = 1.35518
I0520 12:51:24.455358 15139 solver.cpp:247]     Train net output #0: loss = 1.35518 (* 1 = 1.35518 loss)
I0520 12:51:24.455377 15139 sgd_solver.cpp:106] Iteration 91000, lr = 0.0001
I0520 12:51:24.615270 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9393	3.125	82.7764	0	91.2722	6.25	89.3497	0	85.468	0	86.8949	0	80.1393	0	31.891	2.9	
I0520 12:51:24.695221 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:51:24.697993 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:51:24.698081 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:51:24.698618 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35518
I0520 12:52:49.785914 15139 solver.cpp:231] Iteration 91200, loss = 1.18584
I0520 12:52:49.786301 15139 solver.cpp:247]     Train net output #0: loss = 1.18584 (* 1 = 1.18584 loss)
I0520 12:52:49.786324 15139 sgd_solver.cpp:106] Iteration 91200, lr = 0.0001
I0520 12:52:49.946167 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9393	3.125	82.7764	0	91.2722	6.25	89.3497	0	85.468	0	86.895	0	80.1394	0	31.891	2.9	
I0520 12:52:50.021941 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:52:50.024886 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:52:50.024914 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:52:50.025460 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18584
I0520 12:54:13.313947 15139 solver.cpp:231] Iteration 91400, loss = 1.23826
I0520 12:54:13.317659 15139 solver.cpp:247]     Train net output #0: loss = 1.23826 (* 1 = 1.23826 loss)
I0520 12:54:13.317690 15139 sgd_solver.cpp:106] Iteration 91400, lr = 0.0001
I0520 12:54:13.473814 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9393	3.125	82.7764	0	91.2722	6.25	89.3497	0	85.468	0	86.895	0	80.1394	0	31.8911	2.9	
I0520 12:54:13.549036 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:54:13.551916 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:54:13.551939 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:54:13.552422 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23826
I0520 12:55:57.883904 15139 solver.cpp:231] Iteration 91600, loss = 1.28028
I0520 12:55:57.884124 15139 solver.cpp:247]     Train net output #0: loss = 1.28028 (* 1 = 1.28028 loss)
I0520 12:55:57.884145 15139 sgd_solver.cpp:106] Iteration 91600, lr = 0.0001
I0520 12:55:58.043531 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9421	3.125	82.7764	0	91.2722	6.25	89.3497	0	85.468	0	86.895	0	80.1394	0	31.8912	2.9	
I0520 12:55:58.118458 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:55:58.120240 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:55:58.120271 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:55:58.120807 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28028
I0520 12:56:21.041360 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 12:57:23.625689 15139 solver.cpp:231] Iteration 91800, loss = 1.10503
I0520 12:57:23.626888 15139 solver.cpp:247]     Train net output #0: loss = 1.10503 (* 1 = 1.10503 loss)
I0520 12:57:23.626910 15139 sgd_solver.cpp:106] Iteration 91800, lr = 0.0001
I0520 12:57:23.788044 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9421	3.125	82.7764	0	91.2722	6.25	89.3497	0	85.468	0	86.895	0	80.1394	0	31.8912	2.9	
I0520 12:57:23.863543 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 12:57:23.866691 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 12:57:23.866732 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 12:57:23.867281 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10503
I0520 12:58:47.481983 15139 solver.cpp:348] Iteration 92000, Testing net (#0)
I0520 12:59:42.494529 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:00:11.176004 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57098
I0520 13:00:11.176097 15139 solver.cpp:415]     Test net output #1: loss = 1.84129 (* 1 = 1.84129 loss)
I0520 13:00:11.263028 15139 solver.cpp:231] Iteration 92000, loss = 1.05714
I0520 13:00:11.263145 15139 solver.cpp:247]     Train net output #0: loss = 1.05714 (* 1 = 1.05714 loss)
I0520 13:00:11.263164 15139 sgd_solver.cpp:106] Iteration 92000, lr = 0.0001
I0520 13:00:11.430522 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9421	3.125	82.7767	0	91.2722	6.25	89.3497	0	85.468	0	86.895	0	80.1395	0	31.8913	2.9	
I0520 13:00:11.505738 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:00:11.508463 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:00:11.508503 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:00:11.509011 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.05714
I0520 13:01:34.158612 15139 solver.cpp:231] Iteration 92200, loss = 1.1742
I0520 13:01:34.161641 15139 solver.cpp:247]     Train net output #0: loss = 1.1742 (* 1 = 1.1742 loss)
I0520 13:01:34.161672 15139 sgd_solver.cpp:106] Iteration 92200, lr = 0.0001
I0520 13:01:34.318197 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9421	3.125	82.777	0	91.2722	6.25	89.3497	0	85.468	0	86.895	0	80.1395	0	31.8913	2.9	
I0520 13:01:34.393404 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:01:34.396369 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:01:34.396406 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:01:34.396977 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1742
I0520 13:02:58.272685 15139 solver.cpp:231] Iteration 92400, loss = 1.08259
I0520 13:02:58.273100 15139 solver.cpp:247]     Train net output #0: loss = 1.08259 (* 1 = 1.08259 loss)
I0520 13:02:58.273129 15139 sgd_solver.cpp:106] Iteration 92400, lr = 0.0001
I0520 13:02:58.432027 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9421	3.125	82.777	0	91.2722	6.25	89.3499	0	85.468	0	86.895	0	80.1395	0	31.8914	2.9	
I0520 13:02:58.506858 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:02:58.509412 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:02:58.509449 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:02:58.510051 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08259
I0520 13:04:24.685407 15139 solver.cpp:231] Iteration 92600, loss = 1.15154
I0520 13:04:24.685837 15139 solver.cpp:247]     Train net output #0: loss = 1.15154 (* 1 = 1.15154 loss)
I0520 13:04:24.685860 15139 sgd_solver.cpp:106] Iteration 92600, lr = 0.0001
I0520 13:04:24.844483 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.945	3.125	82.777	0	91.2722	6.25	89.3499	0	85.468	0	86.895	0	80.1395	0	31.8915	2.9	
I0520 13:04:24.919750 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:04:24.922588 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:04:24.922636 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:04:24.923152 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15154
I0520 13:04:47.012418 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:05:49.570612 15139 solver.cpp:231] Iteration 92800, loss = 1.09409
I0520 13:05:49.573647 15139 solver.cpp:247]     Train net output #0: loss = 1.09409 (* 1 = 1.09409 loss)
I0520 13:05:49.573678 15139 sgd_solver.cpp:106] Iteration 92800, lr = 0.0001
I0520 13:05:49.732288 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9508	3.125	82.777	0	91.2722	6.25	89.3499	0	85.4682	0	86.8951	0	80.1395	0	31.8916	2.9	
I0520 13:05:49.808400 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:05:49.811450 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:05:49.811494 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:05:49.812120 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09409
I0520 13:07:12.625705 15139 solver.cpp:348] Iteration 93000, Testing net (#0)
I0520 13:08:06.922082 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:08:32.807579 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57286
I0520 13:08:32.807672 15139 solver.cpp:415]     Test net output #1: loss = 1.84028 (* 1 = 1.84028 loss)
I0520 13:08:32.894903 15139 solver.cpp:231] Iteration 93000, loss = 1.02521
I0520 13:08:32.894981 15139 solver.cpp:247]     Train net output #0: loss = 1.02521 (* 1 = 1.02521 loss)
I0520 13:08:32.895000 15139 sgd_solver.cpp:106] Iteration 93000, lr = 0.0001
I0520 13:08:33.059161 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9508	3.125	82.777	0	91.2722	6.25	89.3499	0	85.4682	0	86.8951	0	80.1396	0	31.8916	2.9	
I0520 13:08:33.134474 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:08:33.137713 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:08:33.137763 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:08:33.138275 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.02521
I0520 13:09:53.268379 15139 solver.cpp:231] Iteration 93200, loss = 1.17544
I0520 13:09:53.268712 15139 solver.cpp:247]     Train net output #0: loss = 1.17544 (* 1 = 1.17544 loss)
I0520 13:09:53.268736 15139 sgd_solver.cpp:106] Iteration 93200, lr = 0.0001
I0520 13:09:53.429342 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9565	3.125	82.777	0	91.2722	6.25	89.3499	0	85.4682	0	86.8951	0	80.1396	0	31.8917	2.9	
I0520 13:09:53.504475 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:09:53.507227 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:09:53.507263 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:09:53.507742 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17544
I0520 13:11:20.687928 15139 solver.cpp:231] Iteration 93400, loss = 1.23236
I0520 13:11:20.688218 15139 solver.cpp:247]     Train net output #0: loss = 1.23236 (* 1 = 1.23236 loss)
I0520 13:11:20.688238 15139 sgd_solver.cpp:106] Iteration 93400, lr = 0.0001
I0520 13:11:20.862989 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9565	3.125	82.7773	0	91.2722	6.25	89.3499	0	85.4682	0	86.8951	0	80.1396	0	31.8917	2.9	
I0520 13:11:20.938834 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:11:20.941377 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:11:20.941407 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:11:20.942080 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23236
I0520 13:12:38.456977 15139 solver.cpp:231] Iteration 93600, loss = 1.14789
I0520 13:12:38.461748 15139 solver.cpp:247]     Train net output #0: loss = 1.14789 (* 1 = 1.14789 loss)
I0520 13:12:38.461781 15139 sgd_solver.cpp:106] Iteration 93600, lr = 0.0001
I0520 13:12:38.618278 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9565	3.125	82.7777	0	91.2722	6.25	89.3499	0	85.4682	0	86.8951	0	80.1396	0	31.8918	2.9	
I0520 13:12:38.697640 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:12:38.700379 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:12:38.700412 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:12:38.700968 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14789
I0520 13:13:03.228315 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:14:02.416589 15139 solver.cpp:231] Iteration 93800, loss = 1.28145
I0520 13:14:02.421663 15139 solver.cpp:247]     Train net output #0: loss = 1.28145 (* 1 = 1.28145 loss)
I0520 13:14:02.421715 15139 sgd_solver.cpp:106] Iteration 93800, lr = 0.0001
I0520 13:14:02.576679 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9565	3.125	82.7777	0	91.2722	6.25	89.3499	0	85.4682	0	86.8951	0	80.1396	0	31.8919	2.9	
I0520 13:14:02.651880 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:14:02.654806 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:14:02.654846 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:14:02.655381 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28145
I0520 13:15:25.053158 15139 solver.cpp:348] Iteration 94000, Testing net (#0)
I0520 13:16:14.211971 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:16:40.438849 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57274
I0520 13:16:40.438943 15139 solver.cpp:415]     Test net output #1: loss = 1.84135 (* 1 = 1.84135 loss)
I0520 13:16:40.526439 15139 solver.cpp:231] Iteration 94000, loss = 1.14515
I0520 13:16:40.526511 15139 solver.cpp:247]     Train net output #0: loss = 1.14515 (* 1 = 1.14515 loss)
I0520 13:16:40.526533 15139 sgd_solver.cpp:106] Iteration 94000, lr = 0.0001
I0520 13:16:40.694489 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9565	3.125	82.7777	0	91.2722	6.25	89.3499	0	85.4682	0	86.8952	0	80.1397	0	31.892	2.9	
I0520 13:16:40.770653 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:16:40.772375 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:16:40.772403 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:16:40.773103 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14515
I0520 13:18:04.160006 15139 solver.cpp:231] Iteration 94200, loss = 1.25682
I0520 13:18:04.160362 15139 solver.cpp:247]     Train net output #0: loss = 1.25682 (* 1 = 1.25682 loss)
I0520 13:18:04.160387 15139 sgd_solver.cpp:106] Iteration 94200, lr = 0.0001
I0520 13:18:04.320025 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9565	3.125	82.778	0	91.2722	6.25	89.3499	0	85.4682	0	86.8952	0	80.1397	0	31.8921	2.9	
I0520 13:18:04.395562 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:18:04.398216 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:18:04.398259 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:18:04.398905 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25682
I0520 13:19:22.343931 15139 solver.cpp:231] Iteration 94400, loss = 1.25398
I0520 13:19:22.344239 15139 solver.cpp:247]     Train net output #0: loss = 1.25398 (* 1 = 1.25398 loss)
I0520 13:19:22.344259 15139 sgd_solver.cpp:106] Iteration 94400, lr = 0.0001
I0520 13:19:22.504192 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9565	3.125	82.778	0	91.2722	6.25	89.3499	0	85.4682	0	86.8952	0	80.1397	0	31.8922	2.9	
I0520 13:19:22.580116 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:19:22.582542 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:19:22.582577 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:19:22.583155 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25398
I0520 13:20:49.342227 15139 solver.cpp:231] Iteration 94600, loss = 1.12687
I0520 13:20:49.342480 15139 solver.cpp:247]     Train net output #0: loss = 1.12687 (* 1 = 1.12687 loss)
I0520 13:20:49.342515 15139 sgd_solver.cpp:106] Iteration 94600, lr = 0.0001
I0520 13:20:49.501417 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9565	3.125	82.778	0	91.2723	6.25	89.3499	0	85.4682	0	86.8952	0	80.1397	0	31.8923	2.9	
I0520 13:20:49.576133 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:20:49.577875 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:20:49.577904 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:20:49.578699 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12687
I0520 13:21:16.517338 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:22:09.365258 15139 solver.cpp:231] Iteration 94800, loss = 1.34628
I0520 13:22:09.365643 15139 solver.cpp:247]     Train net output #0: loss = 1.34628 (* 1 = 1.34628 loss)
I0520 13:22:09.365665 15139 sgd_solver.cpp:106] Iteration 94800, lr = 0.0001
I0520 13:22:09.525326 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9565	3.125	82.778	0	91.2723	6.25	89.3499	0	85.4682	0	86.8952	0	80.1397	0	31.8925	2.9	
I0520 13:22:09.600287 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:22:09.602599 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:22:09.602639 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:22:09.603145 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34628
I0520 13:23:30.615229 15139 solver.cpp:348] Iteration 95000, Testing net (#0)
I0520 13:24:20.835374 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:24:44.264313 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57178
I0520 13:24:44.264408 15139 solver.cpp:415]     Test net output #1: loss = 1.84312 (* 1 = 1.84312 loss)
I0520 13:24:44.351832 15139 solver.cpp:231] Iteration 95000, loss = 1.00798
I0520 13:24:44.351919 15139 solver.cpp:247]     Train net output #0: loss = 1.00798 (* 1 = 1.00798 loss)
I0520 13:24:44.351958 15139 sgd_solver.cpp:106] Iteration 95000, lr = 0.0001
I0520 13:24:44.512210 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9565	3.125	82.7783	0	91.2723	6.25	89.3499	0	85.4682	0	86.8952	0	80.1398	0	31.8926	2.9	
I0520 13:24:44.589130 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:24:44.591250 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:24:44.591290 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:24:44.591877 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.00798
I0520 13:25:57.405519 15139 solver.cpp:231] Iteration 95200, loss = 1.07056
I0520 13:25:57.405900 15139 solver.cpp:247]     Train net output #0: loss = 1.07056 (* 1 = 1.07056 loss)
I0520 13:25:57.405930 15139 sgd_solver.cpp:106] Iteration 95200, lr = 0.0001
I0520 13:25:57.565068 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9565	3.125	82.7786	0	91.2723	6.25	89.3499	0	85.4682	0	86.8952	0	80.1398	0	31.8927	2.9	
I0520 13:25:57.642031 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:25:57.643822 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:25:57.643865 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:25:57.644567 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.07056
I0520 13:27:12.444361 15139 solver.cpp:231] Iteration 95400, loss = 1.07268
I0520 13:27:12.444707 15139 solver.cpp:247]     Train net output #0: loss = 1.07268 (* 1 = 1.07268 loss)
I0520 13:27:12.444746 15139 sgd_solver.cpp:106] Iteration 95400, lr = 0.0001
I0520 13:27:12.604493 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9594	3.125	82.7786	0	91.2723	6.25	89.3499	0	85.4682	0	86.8952	0	80.1398	0	31.8927	2.9	
I0520 13:27:12.680483 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:27:12.683086 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:27:12.683130 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:27:12.683935 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.07268
I0520 13:28:28.682415 15139 solver.cpp:231] Iteration 95600, loss = 1.15311
I0520 13:28:28.682775 15139 solver.cpp:247]     Train net output #0: loss = 1.15311 (* 1 = 1.15311 loss)
I0520 13:28:28.682796 15139 sgd_solver.cpp:106] Iteration 95600, lr = 0.0001
I0520 13:28:28.844521 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9622	3.125	82.7786	0	91.2723	6.25	89.3499	0	85.4682	0	86.8953	0	80.1398	0	31.8927	2.9	
I0520 13:28:28.919592 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:28:28.922236 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:28:28.922276 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:28:28.922785 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15311
I0520 13:28:56.074043 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:29:41.981478 15139 solver.cpp:231] Iteration 95800, loss = 1.2979
I0520 13:29:41.983899 15139 solver.cpp:247]     Train net output #0: loss = 1.2979 (* 1 = 1.2979 loss)
I0520 13:29:41.983935 15139 sgd_solver.cpp:106] Iteration 95800, lr = 0.0001
I0520 13:29:42.144253 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9651	3.125	82.7786	0	91.2723	6.25	89.3499	0	85.4682	0	86.8953	0	80.1398	0	31.8928	2.9	
I0520 13:29:42.220196 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:29:42.222300 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:29:42.222332 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:29:42.222916 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2979
I0520 13:30:55.918637 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_96000.caffemodel
I0520 13:31:59.028575 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_96000.solverstate
I0520 13:31:59.718142 15139 solver.cpp:348] Iteration 96000, Testing net (#0)
I0520 13:32:53.408176 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:33:20.590214 15139 solver.cpp:415]     Test net output #0: accuracy = 0.572279
I0520 13:33:20.590302 15139 solver.cpp:415]     Test net output #1: loss = 1.84098 (* 1 = 1.84098 loss)
I0520 13:33:20.679188 15139 solver.cpp:231] Iteration 96000, loss = 1.1854
I0520 13:33:20.679260 15139 solver.cpp:247]     Train net output #0: loss = 1.1854 (* 1 = 1.1854 loss)
I0520 13:33:20.679280 15139 sgd_solver.cpp:106] Iteration 96000, lr = 0.0001
I0520 13:33:20.842372 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9651	3.125	82.779	0	91.2723	6.25	89.3499	0	85.4682	0	86.8953	0	80.1399	0	31.8928	2.9	
I0520 13:33:20.844128 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:33:20.845871 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:33:20.845901 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:33:20.846395 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1854
I0520 13:34:40.000165 15139 solver.cpp:231] Iteration 96200, loss = 1.05127
I0520 13:34:40.000401 15139 solver.cpp:247]     Train net output #0: loss = 1.05127 (* 1 = 1.05127 loss)
I0520 13:34:40.000423 15139 sgd_solver.cpp:106] Iteration 96200, lr = 0.0001
I0520 13:34:40.173334 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9651	3.125	82.779	0	91.2723	6.25	89.3499	0	85.4682	0	86.8953	0	80.1399	0	31.893	2.9	
I0520 13:34:40.249362 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:34:40.251773 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:34:40.251822 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:34:40.252427 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.05127
I0520 13:36:03.880563 15139 solver.cpp:231] Iteration 96400, loss = 1.12661
I0520 13:36:03.881131 15139 solver.cpp:247]     Train net output #0: loss = 1.12661 (* 1 = 1.12661 loss)
I0520 13:36:03.881155 15139 sgd_solver.cpp:106] Iteration 96400, lr = 0.0001
I0520 13:36:04.042114 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.968	3.125	82.7796	0	91.2723	6.25	89.3499	0	85.4682	0	86.8953	0	80.1399	0	31.893	2.9	
I0520 13:36:04.116991 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:36:04.119076 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:36:04.119110 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:36:04.119602 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12661
I0520 13:37:26.062646 15139 solver.cpp:231] Iteration 96600, loss = 1.0809
I0520 13:37:26.063730 15139 solver.cpp:247]     Train net output #0: loss = 1.0809 (* 1 = 1.0809 loss)
I0520 13:37:26.063757 15139 sgd_solver.cpp:106] Iteration 96600, lr = 0.0001
I0520 13:37:26.222091 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.968	3.125	82.7796	0	91.2723	6.25	89.3499	0	85.4682	0	86.8953	0	80.14	0	31.893	2.9	
I0520 13:37:26.297907 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:37:26.300148 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:37:26.300185 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:37:26.300734 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.0809
I0520 13:37:58.932924 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:38:48.571707 15139 solver.cpp:231] Iteration 96800, loss = 1.2414
I0520 13:38:48.572021 15139 solver.cpp:247]     Train net output #0: loss = 1.2414 (* 1 = 1.2414 loss)
I0520 13:38:48.572042 15139 sgd_solver.cpp:106] Iteration 96800, lr = 0.0001
I0520 13:38:48.732573 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.968	3.125	82.7796	0	91.2723	6.25	89.3499	0	85.4682	0	86.8954	0	80.14	0	31.8931	2.9	
I0520 13:38:48.807584 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:38:48.809811 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:38:48.809839 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:38:48.810309 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2414
I0520 13:40:09.824467 15139 solver.cpp:348] Iteration 97000, Testing net (#0)
I0520 13:41:09.520053 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:41:36.020150 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57142
I0520 13:41:36.020233 15139 solver.cpp:415]     Test net output #1: loss = 1.84016 (* 1 = 1.84016 loss)
I0520 13:41:36.107448 15139 solver.cpp:231] Iteration 97000, loss = 1.24225
I0520 13:41:36.107524 15139 solver.cpp:247]     Train net output #0: loss = 1.24225 (* 1 = 1.24225 loss)
I0520 13:41:36.107542 15139 sgd_solver.cpp:106] Iteration 97000, lr = 0.0001
I0520 13:41:36.267906 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9708	3.125	82.7796	0	91.2723	6.25	89.3499	0	85.4682	0	86.8954	0	80.14	0	31.8933	2.9	
I0520 13:41:36.344475 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:41:36.347074 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:41:36.347122 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:41:36.347661 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24225
I0520 13:43:01.489365 15139 solver.cpp:231] Iteration 97200, loss = 1.17018
I0520 13:43:01.489734 15139 solver.cpp:247]     Train net output #0: loss = 1.17018 (* 1 = 1.17018 loss)
I0520 13:43:01.489770 15139 sgd_solver.cpp:106] Iteration 97200, lr = 0.0001
I0520 13:43:01.651326 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9737	3.125	82.7796	0	91.2723	6.25	89.3499	0	85.4682	0	86.8954	0	80.14	0	31.8934	2.9	
I0520 13:43:01.726311 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:43:01.728647 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:43:01.728688 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:43:01.729207 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17018
I0520 13:44:31.872867 15139 solver.cpp:231] Iteration 97400, loss = 1.1362
I0520 13:44:31.873189 15139 solver.cpp:247]     Train net output #0: loss = 1.1362 (* 1 = 1.1362 loss)
I0520 13:44:31.873213 15139 sgd_solver.cpp:106] Iteration 97400, lr = 0.0001
I0520 13:44:32.033627 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9737	3.125	82.7796	0	91.2723	6.25	89.3499	0	85.4682	0	86.8954	0	80.14	0	31.8934	2.9	
I0520 13:44:32.108552 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:44:32.110716 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:44:32.110754 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:44:32.111251 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1362
I0520 13:46:03.733573 15139 solver.cpp:231] Iteration 97600, loss = 1.27698
I0520 13:46:03.733885 15139 solver.cpp:247]     Train net output #0: loss = 1.27698 (* 1 = 1.27698 loss)
I0520 13:46:03.733906 15139 sgd_solver.cpp:106] Iteration 97600, lr = 0.0001
I0520 13:46:03.892419 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9766	3.125	82.7796	0	91.2723	6.25	89.3499	0	85.4682	0	86.8954	0	80.14	0	31.8935	2.9	
I0520 13:46:03.967384 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:46:03.969679 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:46:03.969714 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:46:03.970226 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27698
I0520 13:46:37.819905 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:47:23.753013 15139 solver.cpp:231] Iteration 97800, loss = 1.351
I0520 13:47:23.753280 15139 solver.cpp:247]     Train net output #0: loss = 1.351 (* 1 = 1.351 loss)
I0520 13:47:23.753499 15139 sgd_solver.cpp:106] Iteration 97800, lr = 0.0001
I0520 13:47:23.913831 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9766	3.125	82.7799	0	91.2723	6.25	89.35	0	85.4682	0	86.8954	0	80.1401	0	31.8936	2.9	
I0520 13:47:23.989610 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:47:23.995582 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:47:23.995647 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:47:23.996464 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.351
I0520 13:48:53.546190 15139 solver.cpp:348] Iteration 98000, Testing net (#0)
I0520 13:49:46.653002 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:50:09.694075 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5718
I0520 13:50:09.694182 15139 solver.cpp:415]     Test net output #1: loss = 1.84073 (* 1 = 1.84073 loss)
I0520 13:50:09.799751 15139 solver.cpp:231] Iteration 98000, loss = 1.11053
I0520 13:50:09.799824 15139 solver.cpp:247]     Train net output #0: loss = 1.11053 (* 1 = 1.11053 loss)
I0520 13:50:09.799844 15139 sgd_solver.cpp:106] Iteration 98000, lr = 0.0001
I0520 13:50:09.970888 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9795	3.125	82.7799	0	91.2723	6.25	89.35	0	85.4682	0	86.8955	0	80.1401	0	31.8936	2.9	
I0520 13:50:10.045935 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:50:10.047627 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:50:10.047655 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:50:10.048224 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11053
I0520 13:51:28.840410 15139 solver.cpp:231] Iteration 98200, loss = 1.14574
I0520 13:51:28.840800 15139 solver.cpp:247]     Train net output #0: loss = 1.14574 (* 1 = 1.14574 loss)
I0520 13:51:28.840821 15139 sgd_solver.cpp:106] Iteration 98200, lr = 0.0001
I0520 13:51:29.001364 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9823	3.125	82.7799	0	91.2723	6.25	89.35	0	85.4682	0	86.8955	0	80.1401	0	31.8936	2.9	
I0520 13:51:29.076351 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:51:29.078174 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:51:29.078202 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:51:29.078748 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14574
I0520 13:53:03.379940 15139 solver.cpp:231] Iteration 98400, loss = 1.1563
I0520 13:53:03.381629 15139 solver.cpp:247]     Train net output #0: loss = 1.1563 (* 1 = 1.1563 loss)
I0520 13:53:03.381690 15139 sgd_solver.cpp:106] Iteration 98400, lr = 0.0001
I0520 13:53:03.538671 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9852	3.125	82.7799	0	91.2723	6.25	89.35	0	85.4682	0	86.8955	0	80.1401	0	31.8936	2.9	
I0520 13:53:03.613826 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:53:03.616068 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:53:03.616111 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:53:03.616861 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1563
I0520 13:54:38.503285 15139 solver.cpp:231] Iteration 98600, loss = 1.08513
I0520 13:54:38.503609 15139 solver.cpp:247]     Train net output #0: loss = 1.08513 (* 1 = 1.08513 loss)
I0520 13:54:38.503648 15139 sgd_solver.cpp:106] Iteration 98600, lr = 0.0001
I0520 13:54:38.662926 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9852	3.125	82.7803	0	91.2723	6.25	89.35	0	85.4682	0	86.8955	0	80.1402	0	31.8937	2.9	
I0520 13:54:38.738421 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:54:38.741144 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:54:38.741174 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:54:38.741853 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08513
I0520 13:55:16.872123 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:56:00.231744 15139 solver.cpp:231] Iteration 98800, loss = 1.15731
I0520 13:56:00.233508 15139 solver.cpp:247]     Train net output #0: loss = 1.15731 (* 1 = 1.15731 loss)
I0520 13:56:00.233530 15139 sgd_solver.cpp:106] Iteration 98800, lr = 0.0001
I0520 13:56:00.391849 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9852	3.125	82.7803	0	91.2723	6.25	89.3502	0	85.4684	0	86.8955	0	80.1402	0	31.8937	2.9	
I0520 13:56:00.466568 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:56:00.468891 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:56:00.468914 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:56:00.469352 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15731
I0520 13:57:19.570611 15139 solver.cpp:348] Iteration 99000, Testing net (#0)
I0520 13:58:08.347749 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 13:58:29.691275 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57276
I0520 13:58:29.691421 15139 solver.cpp:415]     Test net output #1: loss = 1.83939 (* 1 = 1.83939 loss)
I0520 13:58:29.778877 15139 solver.cpp:231] Iteration 99000, loss = 1.03304
I0520 13:58:29.778960 15139 solver.cpp:247]     Train net output #0: loss = 1.03304 (* 1 = 1.03304 loss)
I0520 13:58:29.778978 15139 sgd_solver.cpp:106] Iteration 99000, lr = 0.0001
I0520 13:58:29.943850 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9852	3.125	82.7803	0	91.2724	6.25	89.3502	0	85.4684	0	86.8955	0	80.1402	0	31.8938	2.9	
I0520 13:58:30.018951 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:58:30.021492 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:58:30.021517 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:58:30.022158 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.03304
I0520 13:59:51.705801 15139 solver.cpp:231] Iteration 99200, loss = 1.07665
I0520 13:59:51.706086 15139 solver.cpp:247]     Train net output #0: loss = 1.07665 (* 1 = 1.07665 loss)
I0520 13:59:51.706107 15139 sgd_solver.cpp:106] Iteration 99200, lr = 0.0001
I0520 13:59:51.867614 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9852	3.125	82.7803	0	91.2724	6.25	89.3502	0	85.4684	0	86.8955	0	80.1403	0	31.8939	2.9	
I0520 13:59:51.942872 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 13:59:51.945200 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 13:59:51.945241 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 13:59:51.945794 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.07665
I0520 14:01:19.895238 15139 solver.cpp:231] Iteration 99400, loss = 1.14716
I0520 14:01:19.895534 15139 solver.cpp:247]     Train net output #0: loss = 1.14716 (* 1 = 1.14716 loss)
I0520 14:01:19.895555 15139 sgd_solver.cpp:106] Iteration 99400, lr = 0.0001
I0520 14:01:20.055930 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9852	3.125	82.7803	0	91.2724	6.25	89.3503	0	85.4684	0	86.8955	0	80.1403	0	31.894	2.9	
I0520 14:01:20.131145 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:01:20.133636 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:01:20.133714 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:01:20.134240 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14716
I0520 14:02:47.673883 15139 solver.cpp:231] Iteration 99600, loss = 1.01316
I0520 14:02:47.674165 15139 solver.cpp:247]     Train net output #0: loss = 1.01316 (* 1 = 1.01316 loss)
I0520 14:02:47.674186 15139 sgd_solver.cpp:106] Iteration 99600, lr = 0.0001
I0520 14:02:47.833375 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9852	3.125	82.7803	0	91.2724	6.25	89.3503	0	85.4684	0	86.8956	0	80.1403	0	31.8941	2.9	
I0520 14:02:47.908417 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:02:47.910878 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:02:47.910928 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:02:47.911475 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.01316
I0520 14:03:29.929934 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:04:11.065315 15139 solver.cpp:231] Iteration 99800, loss = 1.19355
I0520 14:04:11.065649 15139 solver.cpp:247]     Train net output #0: loss = 1.19355 (* 1 = 1.19355 loss)
I0520 14:04:11.065675 15139 sgd_solver.cpp:106] Iteration 99800, lr = 0.0001
I0520 14:04:11.228164 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9909	3.125	82.7803	0	91.2725	6.25	89.3503	0	85.4684	0	86.8956	0	80.1403	0	31.8942	2.9	
I0520 14:04:11.303179 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:04:11.305580 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:04:11.305627 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:04:11.306123 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19355
I0520 14:05:38.049275 15139 solver.cpp:348] Iteration 100000, Testing net (#0)
I0520 14:06:33.520939 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:06:56.156684 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5715
I0520 14:06:56.156795 15139 solver.cpp:415]     Test net output #1: loss = 1.84187 (* 1 = 1.84187 loss)
I0520 14:06:56.244454 15139 solver.cpp:231] Iteration 100000, loss = 1.13851
I0520 14:06:56.244549 15139 solver.cpp:247]     Train net output #0: loss = 1.13851 (* 1 = 1.13851 loss)
I0520 14:06:56.244571 15139 sgd_solver.cpp:106] Iteration 100000, lr = 0.0001
I0520 14:06:56.410444 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9938	3.125	82.7803	0	91.2725	6.25	89.3503	0	85.4684	0	86.8956	0	80.1404	0	31.8942	2.9	
I0520 14:06:56.487087 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:06:56.490721 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:06:56.490782 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:06:56.491633 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13851
I0520 14:08:25.848528 15139 solver.cpp:231] Iteration 100200, loss = 1.21057
I0520 14:08:25.848873 15139 solver.cpp:247]     Train net output #0: loss = 1.21057 (* 1 = 1.21057 loss)
I0520 14:08:25.848893 15139 sgd_solver.cpp:106] Iteration 100200, lr = 0.0001
I0520 14:08:26.009220 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9938	3.125	82.7803	0	91.2725	6.25	89.3503	0	85.4684	0	86.8956	0	80.1404	0	31.8942	2.9	
I0520 14:08:26.084836 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:08:26.088394 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:08:26.088444 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:08:26.088979 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21057
I0520 14:09:57.820860 15139 solver.cpp:231] Iteration 100400, loss = 1.32949
I0520 14:09:57.821185 15139 solver.cpp:247]     Train net output #0: loss = 1.32949 (* 1 = 1.32949 loss)
I0520 14:09:57.821207 15139 sgd_solver.cpp:106] Iteration 100400, lr = 0.0001
I0520 14:09:57.979989 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9938	3.125	82.7803	0	91.2725	6.25	89.3503	0	85.4684	0	86.8956	0	80.1404	0	31.8944	2.9	
I0520 14:09:58.055513 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:09:58.058933 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:09:58.058979 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:09:58.059496 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32949
I0520 14:11:21.036481 15139 solver.cpp:231] Iteration 100600, loss = 1.03487
I0520 14:11:21.036752 15139 solver.cpp:247]     Train net output #0: loss = 1.03487 (* 1 = 1.03487 loss)
I0520 14:11:21.036772 15139 sgd_solver.cpp:106] Iteration 100600, lr = 0.0001
I0520 14:11:21.195711 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9938	3.125	82.7803	0	91.2725	6.25	89.3503	0	85.4684	0	86.8956	0	80.1404	0	31.8944	2.9	
I0520 14:11:21.270519 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:11:21.272408 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:11:21.272433 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:11:21.272886 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.03487
I0520 14:12:03.748934 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:12:40.158213 15139 solver.cpp:231] Iteration 100800, loss = 1.00536
I0520 14:12:40.158632 15139 solver.cpp:247]     Train net output #0: loss = 1.00536 (* 1 = 1.00536 loss)
I0520 14:12:40.158653 15139 sgd_solver.cpp:106] Iteration 100800, lr = 0.0001
I0520 14:12:40.318717 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9938	3.125	82.7803	0	91.2725	6.25	89.3503	0	85.4684	0	86.8957	0	80.1404	0	31.8945	2.9	
I0520 14:12:40.393980 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:12:40.396553 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:12:40.396591 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:12:40.397122 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.00536
I0520 14:13:57.316377 15139 solver.cpp:348] Iteration 101000, Testing net (#0)
I0520 14:14:52.190976 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:15:15.052139 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57308
I0520 14:15:15.052242 15139 solver.cpp:415]     Test net output #1: loss = 1.84058 (* 1 = 1.84058 loss)
I0520 14:15:15.140132 15139 solver.cpp:231] Iteration 101000, loss = 1.10163
I0520 14:15:15.140204 15139 solver.cpp:247]     Train net output #0: loss = 1.10163 (* 1 = 1.10163 loss)
I0520 14:15:15.140223 15139 sgd_solver.cpp:106] Iteration 101000, lr = 0.0001
I0520 14:15:15.300010 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9938	3.125	82.7803	0	91.2725	6.25	89.3503	0	85.4684	0	86.8957	0	80.1404	0	31.8946	2.9	
I0520 14:15:15.376874 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:15:15.379082 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:15:15.379113 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:15:15.379657 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10163
I0520 14:16:29.244904 15139 solver.cpp:231] Iteration 101200, loss = 1.14962
I0520 14:16:29.245219 15139 solver.cpp:247]     Train net output #0: loss = 1.14962 (* 1 = 1.14962 loss)
I0520 14:16:29.245255 15139 sgd_solver.cpp:106] Iteration 101200, lr = 0.0001
I0520 14:16:29.401664 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9967	3.125	82.7803	0	91.2725	6.25	89.3503	0	85.4684	0	86.8957	0	80.1404	0	31.8947	2.9	
I0520 14:16:29.477067 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:16:29.480319 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:16:29.480379 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:16:29.480954 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14962
I0520 14:17:47.737171 15139 solver.cpp:231] Iteration 101400, loss = 1.12582
I0520 14:17:47.737591 15139 solver.cpp:247]     Train net output #0: loss = 1.12582 (* 1 = 1.12582 loss)
I0520 14:17:47.737612 15139 sgd_solver.cpp:106] Iteration 101400, lr = 0.0001
I0520 14:17:47.897423 15139 sgd_solver.cpp:120]     Element Sparsity %: 
16.9995	3.125	82.7803	0	91.2727	6.25	89.3503	0	85.4684	0	86.8957	0	80.1405	0	31.8948	2.9	
I0520 14:17:47.972527 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:17:47.975174 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:17:47.975211 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:17:47.975713 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12582
I0520 14:19:12.734391 15139 solver.cpp:231] Iteration 101600, loss = 1.30755
I0520 14:19:12.741663 15139 solver.cpp:247]     Train net output #0: loss = 1.30755 (* 1 = 1.30755 loss)
I0520 14:19:12.741694 15139 sgd_solver.cpp:106] Iteration 101600, lr = 0.0001
I0520 14:19:12.895038 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0024	3.125	82.7803	0	91.2727	6.25	89.3503	0	85.4684	0	86.8957	0	80.1405	0	31.8948	2.9	
I0520 14:19:12.971904 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:19:12.973831 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:19:12.973861 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:19:12.974320 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30755
I0520 14:19:58.901007 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:20:34.285729 15139 solver.cpp:231] Iteration 101800, loss = 1.20456
I0520 14:20:34.286146 15139 solver.cpp:247]     Train net output #0: loss = 1.20456 (* 1 = 1.20456 loss)
I0520 14:20:34.286169 15139 sgd_solver.cpp:106] Iteration 101800, lr = 0.0001
I0520 14:20:34.447013 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0024	3.125	82.7809	0	91.2727	6.25	89.3503	0	85.4687	0	86.8957	0	80.1405	0	31.895	2.9	
I0520 14:20:34.521998 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:20:34.523941 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:20:34.523969 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:20:34.524504 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20456
I0520 14:21:56.134552 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_102000.caffemodel
I0520 14:23:13.144289 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_102000.solverstate
I0520 14:23:13.682227 15139 solver.cpp:348] Iteration 102000, Testing net (#0)
I0520 14:24:14.338858 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:24:34.694890 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57212
I0520 14:24:34.694977 15139 solver.cpp:415]     Test net output #1: loss = 1.84095 (* 1 = 1.84095 loss)
I0520 14:24:34.784005 15139 solver.cpp:231] Iteration 102000, loss = 1.32953
I0520 14:24:34.784080 15139 solver.cpp:247]     Train net output #0: loss = 1.32953 (* 1 = 1.32953 loss)
I0520 14:24:34.784101 15139 sgd_solver.cpp:106] Iteration 102000, lr = 0.0001
I0520 14:24:34.951742 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0053	3.125	82.7809	0	91.2727	6.25	89.3503	0	85.4687	0	86.8957	0	80.1405	0	31.895	2.9	
I0520 14:24:34.953563 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:24:34.955601 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:24:34.955629 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:24:34.956110 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32953
I0520 14:25:53.697015 15139 solver.cpp:231] Iteration 102200, loss = 1.14401
I0520 14:25:53.697299 15139 solver.cpp:247]     Train net output #0: loss = 1.14401 (* 1 = 1.14401 loss)
I0520 14:25:53.697319 15139 sgd_solver.cpp:106] Iteration 102200, lr = 0.0001
I0520 14:25:53.858479 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0053	3.125	82.7809	0	91.2727	6.25	89.3503	0	85.4687	0	86.8958	0	80.1406	0	31.895	2.9	
I0520 14:25:53.933109 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:25:53.934969 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:25:53.934998 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:25:53.935436 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14401
I0520 14:27:12.969784 15139 solver.cpp:231] Iteration 102400, loss = 1.24913
I0520 14:27:12.970552 15139 solver.cpp:247]     Train net output #0: loss = 1.24913 (* 1 = 1.24913 loss)
I0520 14:27:12.970587 15139 sgd_solver.cpp:106] Iteration 102400, lr = 0.0001
I0520 14:27:13.129601 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0053	3.125	82.7809	0	91.2727	6.25	89.3503	0	85.4687	0	86.8958	0	80.1406	0	31.8951	2.9	
I0520 14:27:13.205132 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:27:13.208037 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:27:13.208079 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:27:13.208588 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24913
I0520 14:28:29.282660 15139 solver.cpp:231] Iteration 102600, loss = 1.16648
I0520 14:28:29.282919 15139 solver.cpp:247]     Train net output #0: loss = 1.16648 (* 1 = 1.16648 loss)
I0520 14:28:29.282939 15139 sgd_solver.cpp:106] Iteration 102600, lr = 0.0001
I0520 14:28:29.443022 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0053	3.125	82.7809	0	91.2727	6.25	89.3503	0	85.4687	0	86.8958	0	80.1406	0	31.8952	2.9	
I0520 14:28:29.520807 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:28:29.523561 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:28:29.523594 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:28:29.524160 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16648
I0520 14:29:15.633304 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:29:46.075081 15139 solver.cpp:231] Iteration 102800, loss = 1.2149
I0520 14:29:46.075450 15139 solver.cpp:247]     Train net output #0: loss = 1.2149 (* 1 = 1.2149 loss)
I0520 14:29:46.075474 15139 sgd_solver.cpp:106] Iteration 102800, lr = 0.0001
I0520 14:29:46.241252 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0082	3.125	82.7809	0	91.2727	6.25	89.3503	0	85.4687	0	86.8958	0	80.1406	0	31.8952	2.9	
I0520 14:29:46.317214 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:29:46.319885 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:29:46.319931 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:29:46.320514 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2149
I0520 14:31:05.181238 15139 solver.cpp:348] Iteration 103000, Testing net (#0)
I0520 14:32:05.286483 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:32:28.057801 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57362
I0520 14:32:28.057895 15139 solver.cpp:415]     Test net output #1: loss = 1.83953 (* 1 = 1.83953 loss)
I0520 14:32:28.149215 15139 solver.cpp:231] Iteration 103000, loss = 1.43177
I0520 14:32:28.149291 15139 solver.cpp:247]     Train net output #0: loss = 1.43177 (* 1 = 1.43177 loss)
I0520 14:32:28.149309 15139 sgd_solver.cpp:106] Iteration 103000, lr = 0.0001
I0520 14:32:28.315776 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0082	3.125	82.7809	0	91.2727	6.25	89.3503	0	85.4687	0	86.8958	0	80.1407	0	31.8952	2.9	
I0520 14:32:28.391731 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:32:28.394434 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:32:28.394479 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:32:28.395162 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.43177
I0520 14:33:53.368332 15139 solver.cpp:231] Iteration 103200, loss = 1.16518
I0520 14:33:53.368703 15139 solver.cpp:247]     Train net output #0: loss = 1.16518 (* 1 = 1.16518 loss)
I0520 14:33:53.368734 15139 sgd_solver.cpp:106] Iteration 103200, lr = 0.0001
I0520 14:33:53.528313 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0082	3.125	82.7809	0	91.2727	6.25	89.3505	0	85.4687	0	86.8958	0	80.1407	0	31.8953	2.9	
I0520 14:33:53.603155 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:33:53.605212 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:33:53.605242 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:33:53.605875 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16518
I0520 14:35:16.667794 15139 solver.cpp:231] Iteration 103400, loss = 1.1396
I0520 14:35:16.668948 15139 solver.cpp:247]     Train net output #0: loss = 1.1396 (* 1 = 1.1396 loss)
I0520 14:35:16.668972 15139 sgd_solver.cpp:106] Iteration 103400, lr = 0.0001
I0520 14:35:16.828784 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0082	3.125	82.7809	0	91.2727	6.25	89.3505	0	85.4687	0	86.8959	0	80.1407	0	31.8955	2.9	
I0520 14:35:16.905866 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:35:16.908823 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:35:16.908874 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:35:16.909595 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1396
I0520 14:36:37.450510 15139 solver.cpp:231] Iteration 103600, loss = 1.1507
I0520 14:36:37.453650 15139 solver.cpp:247]     Train net output #0: loss = 1.1507 (* 1 = 1.1507 loss)
I0520 14:36:37.453676 15139 sgd_solver.cpp:106] Iteration 103600, lr = 0.0001
I0520 14:36:37.611464 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0082	3.125	82.7809	0	91.2729	6.25	89.3505	0	85.4687	0	86.8959	0	80.1407	0	31.8956	2.9	
I0520 14:36:37.686614 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:36:37.689424 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:36:37.689460 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:36:37.689965 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1507
I0520 14:37:32.033849 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:38:03.639726 15139 solver.cpp:231] Iteration 103800, loss = 1.03232
I0520 14:38:03.640009 15139 solver.cpp:247]     Train net output #0: loss = 1.03232 (* 1 = 1.03232 loss)
I0520 14:38:03.640030 15139 sgd_solver.cpp:106] Iteration 103800, lr = 0.0001
I0520 14:38:03.800740 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0082	3.125	82.7809	0	91.2729	6.25	89.3505	0	85.4687	0	86.8959	0	80.1407	0	31.8956	2.9	
I0520 14:38:03.875617 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:38:03.877168 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:38:03.877192 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:38:03.877738 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.03232
I0520 14:39:28.518488 15139 solver.cpp:348] Iteration 104000, Testing net (#0)
I0520 14:40:28.561451 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:40:49.050755 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57124
I0520 14:40:49.050846 15139 solver.cpp:415]     Test net output #1: loss = 1.84188 (* 1 = 1.84188 loss)
I0520 14:40:49.141598 15139 solver.cpp:231] Iteration 104000, loss = 1.10213
I0520 14:40:49.141691 15139 solver.cpp:247]     Train net output #0: loss = 1.10213 (* 1 = 1.10213 loss)
I0520 14:40:49.141711 15139 sgd_solver.cpp:106] Iteration 104000, lr = 0.0001
I0520 14:40:49.310861 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0082	3.125	82.7809	0	91.2729	6.25	89.3505	0	85.4687	0	86.8959	0	80.1408	0	31.8957	2.9	
I0520 14:40:49.386420 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:40:49.390970 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:40:49.391031 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:40:49.391685 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10213
I0520 14:42:22.310727 15139 solver.cpp:231] Iteration 104200, loss = 1.23397
I0520 14:42:22.311076 15139 solver.cpp:247]     Train net output #0: loss = 1.23397 (* 1 = 1.23397 loss)
I0520 14:42:22.311100 15139 sgd_solver.cpp:106] Iteration 104200, lr = 0.0001
I0520 14:42:22.471101 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.011	3.125	82.7809	0	91.2729	6.25	89.3505	0	85.4687	0	86.8959	0	80.1408	0	31.8959	2.9	
I0520 14:42:22.549098 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:42:22.553275 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:42:22.553345 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:42:22.554244 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23397
I0520 14:43:47.888975 15139 solver.cpp:231] Iteration 104400, loss = 1.23596
I0520 14:43:47.889219 15139 solver.cpp:247]     Train net output #0: loss = 1.23596 (* 1 = 1.23596 loss)
I0520 14:43:47.889237 15139 sgd_solver.cpp:106] Iteration 104400, lr = 0.0001
I0520 14:43:48.048518 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.011	3.125	82.7809	0	91.273	6.25	89.3505	0	85.4687	0	86.8959	0	80.1408	0	31.8959	2.9	
I0520 14:43:48.123811 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:43:48.126962 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:43:48.127013 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:43:48.127540 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23596
I0520 14:45:10.212831 15139 solver.cpp:231] Iteration 104600, loss = 1.14624
I0520 14:45:10.213588 15139 solver.cpp:247]     Train net output #0: loss = 1.14624 (* 1 = 1.14624 loss)
I0520 14:45:10.213610 15139 sgd_solver.cpp:106] Iteration 104600, lr = 0.0001
I0520 14:45:10.372998 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.011	3.125	82.7809	0	91.273	6.25	89.3506	0	85.4687	0	86.8959	0	80.1408	0	31.896	2.9	
I0520 14:45:10.448333 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:45:10.451544 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:45:10.451587 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:45:10.452128 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14624
I0520 14:46:03.823516 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:46:28.582087 15139 solver.cpp:231] Iteration 104800, loss = 1.0035
I0520 14:46:28.582176 15139 solver.cpp:247]     Train net output #0: loss = 1.0035 (* 1 = 1.0035 loss)
I0520 14:46:28.582197 15139 sgd_solver.cpp:106] Iteration 104800, lr = 0.0001
I0520 14:46:28.744376 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.011	3.125	82.7812	0	91.2731	6.25	89.3506	0	85.4687	0	86.896	0	80.1408	0	31.896	2.9	
I0520 14:46:28.819473 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:46:28.821669 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:46:28.821701 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:46:28.822363 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.0035
I0520 14:47:52.919188 15139 solver.cpp:348] Iteration 105000, Testing net (#0)
I0520 14:48:51.714944 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:49:13.128139 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57154
I0520 14:49:13.128419 15139 solver.cpp:415]     Test net output #1: loss = 1.8413 (* 1 = 1.8413 loss)
I0520 14:49:13.216212 15139 solver.cpp:231] Iteration 105000, loss = 1.00976
I0520 14:49:13.216322 15139 solver.cpp:247]     Train net output #0: loss = 1.00976 (* 1 = 1.00976 loss)
I0520 14:49:13.216377 15139 sgd_solver.cpp:106] Iteration 105000, lr = 0.0001
I0520 14:49:13.381790 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.011	3.125	82.7812	0	91.2731	6.25	89.3506	0	85.4687	0	86.896	0	80.1409	0	31.8961	2.9	
I0520 14:49:13.459570 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:49:13.462431 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:49:13.462477 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:49:13.463075 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.00976
I0520 14:50:37.501212 15139 solver.cpp:231] Iteration 105200, loss = 1.08215
I0520 14:50:37.501746 15139 solver.cpp:247]     Train net output #0: loss = 1.08215 (* 1 = 1.08215 loss)
I0520 14:50:37.501768 15139 sgd_solver.cpp:106] Iteration 105200, lr = 0.0001
I0520 14:50:37.661455 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.011	3.125	82.7812	0	91.2731	6.25	89.3506	0	85.4687	0	86.896	0	80.1409	0	31.8961	2.9	
I0520 14:50:37.737709 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:50:37.741533 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:50:37.741600 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:50:37.742394 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08215
I0520 14:52:01.277977 15139 solver.cpp:231] Iteration 105400, loss = 0.988853
I0520 14:52:01.278275 15139 solver.cpp:247]     Train net output #0: loss = 0.988853 (* 1 = 0.988853 loss)
I0520 14:52:01.278295 15139 sgd_solver.cpp:106] Iteration 105400, lr = 0.0001
I0520 14:52:01.438499 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.011	3.125	82.7812	0	91.2731	6.25	89.3506	0	85.4687	0	86.896	0	80.1409	0	31.8963	2.9	
I0520 14:52:01.513727 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:52:01.518782 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:52:01.518854 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:52:01.519575 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.988853
I0520 14:53:30.563525 15139 solver.cpp:231] Iteration 105600, loss = 1.31109
I0520 14:53:30.564018 15139 solver.cpp:247]     Train net output #0: loss = 1.31109 (* 1 = 1.31109 loss)
I0520 14:53:30.564039 15139 sgd_solver.cpp:106] Iteration 105600, lr = 0.0001
I0520 14:53:30.723953 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.011	3.125	82.7812	0	91.2731	6.25	89.3506	0	85.4687	0	86.896	0	80.141	0	31.8963	2.9	
I0520 14:53:30.799427 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:53:30.802826 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:53:30.802867 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:53:30.803437 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31109
I0520 14:54:33.310895 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:54:56.926072 15139 solver.cpp:231] Iteration 105800, loss = 1.10879
I0520 14:54:56.926172 15139 solver.cpp:247]     Train net output #0: loss = 1.10879 (* 1 = 1.10879 loss)
I0520 14:54:56.926192 15139 sgd_solver.cpp:106] Iteration 105800, lr = 0.0001
I0520 14:54:57.074561 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.011	3.125	82.7812	0	91.2731	6.25	89.3506	0	85.4687	0	86.896	0	80.141	0	31.8965	2.9	
I0520 14:54:57.153587 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:54:57.156535 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:54:57.156574 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:54:57.157153 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10879
I0520 14:56:21.646561 15139 solver.cpp:348] Iteration 106000, Testing net (#0)
I0520 14:57:23.418864 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 14:57:44.230362 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57208
I0520 14:57:44.230456 15139 solver.cpp:415]     Test net output #1: loss = 1.83954 (* 1 = 1.83954 loss)
I0520 14:57:44.319993 15139 solver.cpp:231] Iteration 106000, loss = 1.12957
I0520 14:57:44.320077 15139 solver.cpp:247]     Train net output #0: loss = 1.12957 (* 1 = 1.12957 loss)
I0520 14:57:44.320098 15139 sgd_solver.cpp:106] Iteration 106000, lr = 0.0001
I0520 14:57:44.481309 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0139	3.125	82.7812	0	91.2731	6.25	89.3506	0	85.4687	0	86.8961	0	80.141	0	31.8966	2.9	
I0520 14:57:44.556105 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:57:44.558540 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:57:44.558575 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:57:44.559031 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12957
I0520 14:59:11.084484 15139 solver.cpp:231] Iteration 106200, loss = 1.11507
I0520 14:59:11.085618 15139 solver.cpp:247]     Train net output #0: loss = 1.11507 (* 1 = 1.11507 loss)
I0520 14:59:11.085641 15139 sgd_solver.cpp:106] Iteration 106200, lr = 0.0001
I0520 14:59:11.245497 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0139	3.125	82.7812	0	91.2731	6.25	89.3506	0	85.4689	0	86.8961	0	80.141	0	31.8966	2.9	
I0520 14:59:11.320904 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 14:59:11.324754 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 14:59:11.324805 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 14:59:11.325403 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11507
I0520 15:00:38.154916 15139 solver.cpp:231] Iteration 106400, loss = 1.05236
I0520 15:00:38.155141 15139 solver.cpp:247]     Train net output #0: loss = 1.05236 (* 1 = 1.05236 loss)
I0520 15:00:38.155164 15139 sgd_solver.cpp:106] Iteration 106400, lr = 0.0001
I0520 15:00:38.314827 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0196	3.125	82.7816	0	91.2731	6.25	89.3506	0	85.4689	0	86.8961	0	80.1411	0	31.8968	2.9	
I0520 15:00:38.390394 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:00:38.393419 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:00:38.393465 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:00:38.393986 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.05236
I0520 15:02:00.643553 15139 solver.cpp:231] Iteration 106600, loss = 1.15327
I0520 15:02:00.643815 15139 solver.cpp:247]     Train net output #0: loss = 1.15327 (* 1 = 1.15327 loss)
I0520 15:02:00.643836 15139 sgd_solver.cpp:106] Iteration 106600, lr = 0.0001
I0520 15:02:00.803249 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0196	3.125	82.7816	0	91.2731	6.25	89.3506	0	85.4689	0	86.8961	0	80.1411	0	31.8969	2.9	
I0520 15:02:00.878201 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:02:00.881480 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:02:00.881517 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:02:00.882232 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15327
I0520 15:03:00.050165 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:03:19.040101 15139 solver.cpp:231] Iteration 106800, loss = 1.23621
I0520 15:03:19.040206 15139 solver.cpp:247]     Train net output #0: loss = 1.23621 (* 1 = 1.23621 loss)
I0520 15:03:19.040227 15139 sgd_solver.cpp:106] Iteration 106800, lr = 0.0001
I0520 15:03:19.202525 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0196	3.125	82.7819	0	91.2731	6.25	89.3506	0	85.4689	0	86.8961	0	80.1411	0	31.8969	2.9	
I0520 15:03:19.279166 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:03:19.282454 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:03:19.282513 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:03:19.283154 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23621
I0520 15:04:45.940331 15139 solver.cpp:348] Iteration 107000, Testing net (#0)
I0520 15:05:48.474449 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:06:07.816607 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57206
I0520 15:06:07.816697 15139 solver.cpp:415]     Test net output #1: loss = 1.84101 (* 1 = 1.84101 loss)
I0520 15:06:07.904805 15139 solver.cpp:231] Iteration 107000, loss = 1.22249
I0520 15:06:07.904892 15139 solver.cpp:247]     Train net output #0: loss = 1.22249 (* 1 = 1.22249 loss)
I0520 15:06:07.904916 15139 sgd_solver.cpp:106] Iteration 107000, lr = 0.0001
I0520 15:06:08.064726 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0196	3.125	82.7819	0	91.2731	6.25	89.3506	0	85.4689	0	86.8961	0	80.1411	0	31.897	2.9	
I0520 15:06:08.140571 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:06:08.142757 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:06:08.142802 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:06:08.143606 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22249
I0520 15:07:55.449095 15139 solver.cpp:231] Iteration 107200, loss = 1.34319
I0520 15:07:55.449383 15139 solver.cpp:247]     Train net output #0: loss = 1.34319 (* 1 = 1.34319 loss)
I0520 15:07:55.449407 15139 sgd_solver.cpp:106] Iteration 107200, lr = 0.0001
I0520 15:07:55.608088 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0196	3.125	82.7819	0	91.2731	6.25	89.3506	0	85.4689	0	86.8961	0	80.1412	0	31.8971	2.9	
I0520 15:07:55.684378 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:07:55.687501 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:07:55.687542 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:07:55.688102 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34319
I0520 15:09:14.590664 15139 solver.cpp:231] Iteration 107400, loss = 1.0519
I0520 15:09:14.590920 15139 solver.cpp:247]     Train net output #0: loss = 1.0519 (* 1 = 1.0519 loss)
I0520 15:09:14.590944 15139 sgd_solver.cpp:106] Iteration 107400, lr = 0.0001
I0520 15:09:14.750041 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0196	3.125	82.7822	0	91.2731	6.25	89.3506	0	85.4689	0	86.8961	0	80.1412	0	31.8972	2.9	
I0520 15:09:14.825706 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:09:14.829196 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:09:14.829272 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:09:14.830045 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.0519
I0520 15:10:46.740900 15139 solver.cpp:231] Iteration 107600, loss = 1.11141
I0520 15:10:46.741186 15139 solver.cpp:247]     Train net output #0: loss = 1.11141 (* 1 = 1.11141 loss)
I0520 15:10:46.741207 15139 sgd_solver.cpp:106] Iteration 107600, lr = 0.0001
I0520 15:10:46.901628 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0196	3.125	82.7822	0	91.2731	6.25	89.3508	0	85.4689	0	86.8961	0	80.1412	0	31.8972	2.9	
I0520 15:10:46.976922 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:10:46.980715 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:10:46.980829 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:10:46.981655 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11141
I0520 15:11:55.045440 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:12:11.335448 15139 solver.cpp:231] Iteration 107800, loss = 1.23395
I0520 15:12:11.335541 15139 solver.cpp:247]     Train net output #0: loss = 1.23395 (* 1 = 1.23395 loss)
I0520 15:12:11.335559 15139 sgd_solver.cpp:106] Iteration 107800, lr = 0.0001
I0520 15:12:11.496673 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0225	3.125	82.7822	0	91.2731	6.25	89.3508	0	85.4689	0	86.8962	0	80.1413	0	31.8972	2.9	
I0520 15:12:11.571095 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:12:11.573436 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:12:11.573462 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:12:11.573904 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23395
I0520 15:13:47.568140 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_108000.caffemodel
I0520 15:15:02.514178 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_108000.solverstate
I0520 15:15:03.239976 15139 solver.cpp:348] Iteration 108000, Testing net (#0)
I0520 15:16:12.664192 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:16:33.554044 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5721
I0520 15:16:33.554124 15139 solver.cpp:415]     Test net output #1: loss = 1.83845 (* 1 = 1.83845 loss)
I0520 15:16:33.642472 15139 solver.cpp:231] Iteration 108000, loss = 1.1694
I0520 15:16:33.642555 15139 solver.cpp:247]     Train net output #0: loss = 1.1694 (* 1 = 1.1694 loss)
I0520 15:16:33.642572 15139 sgd_solver.cpp:106] Iteration 108000, lr = 0.0001
I0520 15:16:33.807521 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0225	3.125	82.7826	0	91.2731	6.25	89.3508	0	85.4691	0	86.8962	0	80.1413	0	31.8973	2.9	
I0520 15:16:33.810151 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:16:33.813365 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:16:33.813416 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:16:33.813972 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1694
I0520 15:18:07.396451 15139 solver.cpp:231] Iteration 108200, loss = 1.16043
I0520 15:18:07.396656 15139 solver.cpp:247]     Train net output #0: loss = 1.16043 (* 1 = 1.16043 loss)
I0520 15:18:07.396677 15139 sgd_solver.cpp:106] Iteration 108200, lr = 0.0001
I0520 15:18:07.556975 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0225	3.125	82.7826	0	91.2731	6.25	89.3508	0	85.4691	0	86.8962	0	80.1413	0	31.8973	2.9	
I0520 15:18:07.632190 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:18:07.635316 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:18:07.635365 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:18:07.635846 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16043
I0520 15:19:27.300107 15139 solver.cpp:231] Iteration 108400, loss = 1.09759
I0520 15:19:27.303475 15139 solver.cpp:247]     Train net output #0: loss = 1.09759 (* 1 = 1.09759 loss)
I0520 15:19:27.303508 15139 sgd_solver.cpp:106] Iteration 108400, lr = 0.0001
I0520 15:19:27.460711 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0254	3.125	82.7826	0	91.2731	6.25	89.3508	0	85.4691	0	86.8962	0	80.1413	0	31.8974	2.9	
I0520 15:19:27.535675 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:19:27.538372 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:19:27.538403 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:19:27.538921 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09759
I0520 15:20:51.538940 15139 solver.cpp:231] Iteration 108600, loss = 1.18772
I0520 15:20:51.539783 15139 solver.cpp:247]     Train net output #0: loss = 1.18772 (* 1 = 1.18772 loss)
I0520 15:20:51.539803 15139 sgd_solver.cpp:106] Iteration 108600, lr = 0.0001
I0520 15:20:51.699734 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0254	3.125	82.7829	0	91.2731	6.25	89.3508	0	85.4691	0	86.8962	0	80.1413	0	31.8975	2.9	
I0520 15:20:51.775403 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:20:51.778697 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:20:51.778743 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:20:51.779243 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18772
I0520 15:21:57.488173 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:22:13.411881 15139 solver.cpp:231] Iteration 108800, loss = 1.33972
I0520 15:22:13.412004 15139 solver.cpp:247]     Train net output #0: loss = 1.33972 (* 1 = 1.33972 loss)
I0520 15:22:13.412025 15139 sgd_solver.cpp:106] Iteration 108800, lr = 0.0001
I0520 15:22:13.571142 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0282	3.125	82.7829	0	91.2731	6.25	89.3508	0	85.4691	0	86.8962	0	80.1413	0	31.8975	2.9	
I0520 15:22:13.646528 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:22:13.649384 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:22:13.649425 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:22:13.649953 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.33972
I0520 15:23:36.128927 15139 solver.cpp:348] Iteration 109000, Testing net (#0)
I0520 15:24:39.592083 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:24:58.438807 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57246
I0520 15:24:58.438902 15139 solver.cpp:415]     Test net output #1: loss = 1.84092 (* 1 = 1.84092 loss)
I0520 15:24:58.529170 15139 solver.cpp:231] Iteration 109000, loss = 1.25067
I0520 15:24:58.529276 15139 solver.cpp:247]     Train net output #0: loss = 1.25067 (* 1 = 1.25067 loss)
I0520 15:24:58.529300 15139 sgd_solver.cpp:106] Iteration 109000, lr = 0.0001
I0520 15:24:58.692924 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0282	3.125	82.7829	0	91.2732	6.25	89.3509	0	85.4691	0	86.8963	0	80.1413	0	31.8977	2.9	
I0520 15:24:58.768883 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:24:58.771124 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:24:58.771167 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:24:58.771891 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25067
I0520 15:26:17.170353 15139 solver.cpp:231] Iteration 109200, loss = 1.12219
I0520 15:26:17.170616 15139 solver.cpp:247]     Train net output #0: loss = 1.12219 (* 1 = 1.12219 loss)
I0520 15:26:17.170637 15139 sgd_solver.cpp:106] Iteration 109200, lr = 0.0001
I0520 15:26:17.330554 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0282	3.125	82.7832	0	91.2732	6.25	89.3509	0	85.4691	0	86.8963	0	80.1414	0	31.8977	2.9	
I0520 15:26:17.405275 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:26:17.406947 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:26:17.406978 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:26:17.407517 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12219
I0520 15:27:43.232576 15139 solver.cpp:231] Iteration 109400, loss = 1.04656
I0520 15:27:43.233002 15139 solver.cpp:247]     Train net output #0: loss = 1.04656 (* 1 = 1.04656 loss)
I0520 15:27:43.233034 15139 sgd_solver.cpp:106] Iteration 109400, lr = 0.0001
I0520 15:27:43.392338 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0282	3.125	82.7832	0	91.2733	6.25	89.3509	0	85.4691	0	86.8963	0	80.1414	0	31.8978	2.9	
I0520 15:27:43.474819 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:27:43.477514 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:27:43.477582 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:27:43.478150 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04656
I0520 15:29:12.971137 15139 solver.cpp:231] Iteration 109600, loss = 1.14442
I0520 15:29:12.971487 15139 solver.cpp:247]     Train net output #0: loss = 1.14442 (* 1 = 1.14442 loss)
I0520 15:29:12.971521 15139 sgd_solver.cpp:106] Iteration 109600, lr = 0.0001
I0520 15:29:13.131124 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0311	3.125	82.7832	0	91.2733	6.25	89.3509	0	85.4691	0	86.8963	0	80.1414	0	31.8978	2.9	
I0520 15:29:13.205971 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:29:13.208034 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:29:13.208081 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:29:13.208868 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14442
I0520 15:30:29.380666 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:30:42.324077 15139 solver.cpp:231] Iteration 109800, loss = 1.1633
I0520 15:30:42.324162 15139 solver.cpp:247]     Train net output #0: loss = 1.1633 (* 1 = 1.1633 loss)
I0520 15:30:42.324183 15139 sgd_solver.cpp:106] Iteration 109800, lr = 0.0001
I0520 15:30:42.483669 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.034	3.125	82.7832	0	91.2733	6.25	89.3509	0	85.4691	0	86.8963	0	80.1415	0	31.8979	2.9	
I0520 15:30:42.558956 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:30:42.560595 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:30:42.560631 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:30:42.561197 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1633
I0520 15:32:10.525771 15139 solver.cpp:348] Iteration 110000, Testing net (#0)
I0520 15:33:13.244792 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:33:32.576136 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5719
I0520 15:33:32.576239 15139 solver.cpp:415]     Test net output #1: loss = 1.84188 (* 1 = 1.84188 loss)
I0520 15:33:32.663846 15139 solver.cpp:231] Iteration 110000, loss = 1.14015
I0520 15:33:32.663930 15139 solver.cpp:247]     Train net output #0: loss = 1.14015 (* 1 = 1.14015 loss)
I0520 15:33:32.663950 15139 sgd_solver.cpp:106] Iteration 110000, lr = 0.0001
I0520 15:33:32.829445 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.034	3.125	82.7832	0	91.2733	6.25	89.3509	0	85.4691	0	86.8963	0	80.1415	0	31.898	2.9	
I0520 15:33:32.904772 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:33:32.909988 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:33:32.910046 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:33:32.910579 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14015
I0520 15:35:02.300120 15139 solver.cpp:231] Iteration 110200, loss = 1.12172
I0520 15:35:02.300431 15139 solver.cpp:247]     Train net output #0: loss = 1.12172 (* 1 = 1.12172 loss)
I0520 15:35:02.300463 15139 sgd_solver.cpp:106] Iteration 110200, lr = 0.0001
I0520 15:35:02.461700 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.034	3.125	82.7832	0	91.2733	6.25	89.3509	0	85.4691	0	86.8963	0	80.1415	0	31.8981	2.9	
I0520 15:35:02.536993 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:35:02.539733 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:35:02.539777 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:35:02.540292 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12172
I0520 15:36:30.329144 15139 solver.cpp:231] Iteration 110400, loss = 1.28101
I0520 15:36:30.333685 15139 solver.cpp:247]     Train net output #0: loss = 1.28101 (* 1 = 1.28101 loss)
I0520 15:36:30.333746 15139 sgd_solver.cpp:106] Iteration 110400, lr = 0.0001
I0520 15:36:30.490543 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.034	3.125	82.7832	0	91.2733	6.25	89.3509	0	85.4691	0	86.8963	0	80.1415	0	31.8983	2.9	
I0520 15:36:30.565877 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:36:30.568989 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:36:30.569036 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:36:30.569594 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28101
I0520 15:37:53.545868 15139 solver.cpp:231] Iteration 110600, loss = 1.14522
I0520 15:37:53.546087 15139 solver.cpp:247]     Train net output #0: loss = 1.14522 (* 1 = 1.14522 loss)
I0520 15:37:53.546113 15139 sgd_solver.cpp:106] Iteration 110600, lr = 0.0001
I0520 15:37:53.705071 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.034	3.125	82.7832	0	91.2733	6.25	89.3509	0	85.4691	0	86.8964	0	80.1416	0	31.8984	2.9	
I0520 15:37:53.781186 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:37:53.784298 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:37:53.784353 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:37:53.785107 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14522
I0520 15:39:12.731618 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:39:22.251030 15139 solver.cpp:231] Iteration 110800, loss = 1.22275
I0520 15:39:22.251132 15139 solver.cpp:247]     Train net output #0: loss = 1.22275 (* 1 = 1.22275 loss)
I0520 15:39:22.251157 15139 sgd_solver.cpp:106] Iteration 110800, lr = 0.0001
I0520 15:39:22.411288 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.034	3.125	82.7832	0	91.2733	6.25	89.3509	0	85.4691	0	86.8964	0	80.1416	0	31.8985	2.9	
I0520 15:39:22.486804 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:39:22.488832 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:39:22.488879 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:39:22.489450 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22275
I0520 15:40:50.802790 15139 solver.cpp:348] Iteration 111000, Testing net (#0)
I0520 15:41:58.160310 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:42:18.565367 15139 solver.cpp:415]     Test net output #0: accuracy = 0.571639
I0520 15:42:18.565480 15139 solver.cpp:415]     Test net output #1: loss = 1.83866 (* 1 = 1.83866 loss)
I0520 15:42:18.657467 15139 solver.cpp:231] Iteration 111000, loss = 1.19214
I0520 15:42:18.657578 15139 solver.cpp:247]     Train net output #0: loss = 1.19214 (* 1 = 1.19214 loss)
I0520 15:42:18.657603 15139 sgd_solver.cpp:106] Iteration 111000, lr = 0.0001
I0520 15:42:18.817250 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0397	3.125	82.7832	0	91.2733	6.25	89.3509	0	85.4691	0	86.8964	0	80.1416	0	31.8986	2.9	
I0520 15:42:18.894618 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:42:18.897740 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:42:18.897791 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:42:18.898394 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19214
I0520 15:43:51.870059 15139 solver.cpp:231] Iteration 111200, loss = 1.1425
I0520 15:43:51.870959 15139 solver.cpp:247]     Train net output #0: loss = 1.1425 (* 1 = 1.1425 loss)
I0520 15:43:51.870987 15139 sgd_solver.cpp:106] Iteration 111200, lr = 0.0001
I0520 15:43:52.029644 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0397	3.125	82.7832	0	91.2733	6.25	89.3509	0	85.4691	0	86.8964	0	80.1416	0	31.8987	2.9	
I0520 15:43:52.105145 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:43:52.108816 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:43:52.108886 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:43:52.109792 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1425
I0520 15:45:44.436280 15139 solver.cpp:231] Iteration 111400, loss = 1.16211
I0520 15:45:44.436528 15139 solver.cpp:247]     Train net output #0: loss = 1.16211 (* 1 = 1.16211 loss)
I0520 15:45:44.436563 15139 sgd_solver.cpp:106] Iteration 111400, lr = 0.0001
I0520 15:45:44.596745 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0397	3.125	82.7832	0	91.2733	6.25	89.3509	0	85.4691	0	86.8964	0	80.1416	0	31.8987	2.9	
I0520 15:45:44.672161 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:45:44.674697 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:45:44.674749 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:45:44.675416 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16211
I0520 15:47:15.844285 15139 solver.cpp:231] Iteration 111600, loss = 1.2785
I0520 15:47:15.844596 15139 solver.cpp:247]     Train net output #0: loss = 1.2785 (* 1 = 1.2785 loss)
I0520 15:47:15.844795 15139 sgd_solver.cpp:106] Iteration 111600, lr = 0.0001
I0520 15:47:16.004274 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0426	3.125	82.7835	0	91.2733	6.25	89.3509	0	85.4691	0	86.8964	0	80.1417	0	31.8989	2.9	
I0520 15:47:16.079527 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:47:16.082564 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:47:16.082617 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:47:16.083163 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2785
I0520 15:48:35.210809 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:48:40.680869 15139 solver.cpp:231] Iteration 111800, loss = 1.15562
I0520 15:48:40.680963 15139 solver.cpp:247]     Train net output #0: loss = 1.15562 (* 1 = 1.15562 loss)
I0520 15:48:40.680982 15139 sgd_solver.cpp:106] Iteration 111800, lr = 0.0001
I0520 15:48:40.841630 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0455	3.125	82.7839	0	91.2733	6.25	89.3509	0	85.4691	0	86.8965	0	80.1417	0	31.8989	2.9	
I0520 15:48:40.917135 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:48:40.919837 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:48:40.919896 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:48:40.920434 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15562
I0520 15:49:58.831697 15139 solver.cpp:348] Iteration 112000, Testing net (#0)
I0520 15:51:01.173993 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:51:18.936720 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5723
I0520 15:51:18.936854 15139 solver.cpp:415]     Test net output #1: loss = 1.83857 (* 1 = 1.83857 loss)
I0520 15:51:19.024194 15139 solver.cpp:231] Iteration 112000, loss = 1.14281
I0520 15:51:19.024281 15139 solver.cpp:247]     Train net output #0: loss = 1.14281 (* 1 = 1.14281 loss)
I0520 15:51:19.024299 15139 sgd_solver.cpp:106] Iteration 112000, lr = 0.0001
I0520 15:51:19.190019 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0455	3.125	82.7842	0	91.2733	6.25	89.3509	0	85.4691	0	86.8965	0	80.1417	0	31.8989	2.9	
I0520 15:51:19.265358 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:51:19.268198 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:51:19.268245 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:51:19.268780 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14281
I0520 15:52:34.372735 15139 solver.cpp:231] Iteration 112200, loss = 1.08189
I0520 15:52:34.373037 15139 solver.cpp:247]     Train net output #0: loss = 1.08189 (* 1 = 1.08189 loss)
I0520 15:52:34.373057 15139 sgd_solver.cpp:106] Iteration 112200, lr = 0.0001
I0520 15:52:34.531843 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0455	3.125	82.7842	0	91.2733	6.25	89.3509	0	85.4691	0	86.8965	0	80.1417	0	31.899	2.9	
I0520 15:52:34.607367 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:52:34.609361 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:52:34.609401 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:52:34.609928 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08189
I0520 15:53:57.134851 15139 solver.cpp:231] Iteration 112400, loss = 1.16902
I0520 15:53:57.135123 15139 solver.cpp:247]     Train net output #0: loss = 1.16902 (* 1 = 1.16902 loss)
I0520 15:53:57.135144 15139 sgd_solver.cpp:106] Iteration 112400, lr = 0.0001
I0520 15:53:57.295652 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0455	3.125	82.7842	0	91.2733	6.25	89.3509	0	85.4691	0	86.8965	0	80.1417	0	31.8991	2.9	
I0520 15:53:57.370827 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:53:57.372916 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:53:57.372958 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:53:57.373478 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16902
I0520 15:55:24.705917 15139 solver.cpp:231] Iteration 112600, loss = 1.24474
I0520 15:55:24.709687 15139 solver.cpp:247]     Train net output #0: loss = 1.24474 (* 1 = 1.24474 loss)
I0520 15:55:24.709722 15139 sgd_solver.cpp:106] Iteration 112600, lr = 0.0001
I0520 15:55:24.858088 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0455	3.125	82.7845	0	91.2733	6.25	89.3509	0	85.4691	0	86.8965	0	80.1417	0	31.8991	2.9	
I0520 15:55:24.937669 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:55:24.939900 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:55:24.939937 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:55:24.940465 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24474
I0520 15:56:44.576715 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:56:48.233783 15139 solver.cpp:231] Iteration 112800, loss = 1.20912
I0520 15:56:48.233865 15139 solver.cpp:247]     Train net output #0: loss = 1.20912 (* 1 = 1.20912 loss)
I0520 15:56:48.233886 15139 sgd_solver.cpp:106] Iteration 112800, lr = 0.0001
I0520 15:56:48.397024 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0455	3.125	82.7845	0	91.2734	6.25	89.3509	0	85.4691	0	86.8965	0	80.1417	0	31.8992	2.9	
I0520 15:56:48.477458 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:56:48.479626 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:56:48.479668 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:56:48.480309 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20912
I0520 15:58:10.995882 15139 solver.cpp:348] Iteration 113000, Testing net (#0)
I0520 15:59:14.860151 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 15:59:30.614923 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57262
I0520 15:59:30.615005 15139 solver.cpp:415]     Test net output #1: loss = 1.84018 (* 1 = 1.84018 loss)
I0520 15:59:30.702606 15139 solver.cpp:231] Iteration 113000, loss = 1.02158
I0520 15:59:30.702683 15139 solver.cpp:247]     Train net output #0: loss = 1.02158 (* 1 = 1.02158 loss)
I0520 15:59:30.702705 15139 sgd_solver.cpp:106] Iteration 113000, lr = 0.0001
I0520 15:59:30.873975 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0455	3.125	82.7848	0	91.2736	6.25	89.3509	0	85.4691	0	86.8966	0	80.1418	0	31.8993	2.9	
I0520 15:59:30.951699 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 15:59:30.954087 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 15:59:30.954140 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 15:59:30.954680 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.02158
I0520 16:00:56.138406 15139 solver.cpp:231] Iteration 113200, loss = 1.02876
I0520 16:00:56.141494 15139 solver.cpp:247]     Train net output #0: loss = 1.02876 (* 1 = 1.02876 loss)
I0520 16:00:56.141525 15139 sgd_solver.cpp:106] Iteration 113200, lr = 0.0001
I0520 16:00:56.297721 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0455	3.125	82.7848	0	91.2736	6.25	89.3509	0	85.4691	0	86.8966	0	80.1418	0	31.8995	2.9	
I0520 16:00:56.372866 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:00:56.374388 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:00:56.374405 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:00:56.374832 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.02876
I0520 16:02:20.721812 15139 solver.cpp:231] Iteration 113400, loss = 1.36124
I0520 16:02:20.722180 15139 solver.cpp:247]     Train net output #0: loss = 1.36124 (* 1 = 1.36124 loss)
I0520 16:02:20.722203 15139 sgd_solver.cpp:106] Iteration 113400, lr = 0.0001
I0520 16:02:20.882822 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0455	3.125	82.7848	0	91.2736	6.25	89.3509	0	85.4691	0	86.8966	0	80.1418	0	31.8995	2.9	
I0520 16:02:20.968663 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:02:20.971137 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:02:20.971171 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:02:20.971778 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.36124
I0520 16:03:44.277889 15139 solver.cpp:231] Iteration 113600, loss = 1.01287
I0520 16:03:44.284976 15139 solver.cpp:247]     Train net output #0: loss = 1.01287 (* 1 = 1.01287 loss)
I0520 16:03:44.285012 15139 sgd_solver.cpp:106] Iteration 113600, lr = 0.0001
I0520 16:03:44.438781 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0455	3.125	82.7852	0	91.2736	6.25	89.3509	0	85.4691	0	86.8966	0	80.1418	0	31.8996	2.9	
I0520 16:03:44.513636 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:03:44.515570 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:03:44.515604 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:03:44.516131 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.01287
I0520 16:05:09.318106 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:05:09.701262 15139 solver.cpp:231] Iteration 113800, loss = 1.14435
I0520 16:05:09.701345 15139 solver.cpp:247]     Train net output #0: loss = 1.14435 (* 1 = 1.14435 loss)
I0520 16:05:09.701364 15139 sgd_solver.cpp:106] Iteration 113800, lr = 0.0001
I0520 16:05:09.861572 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0512	3.125	82.7852	0	91.2736	6.25	89.3509	0	85.4691	0	86.8966	0	80.1418	0	31.8998	2.9	
I0520 16:05:09.936504 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:05:09.938885 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:05:09.938930 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:05:09.939417 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14435
I0520 16:06:34.052522 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_114000.caffemodel
I0520 16:08:51.990634 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_114000.solverstate
I0520 16:08:52.694097 15139 solver.cpp:348] Iteration 114000, Testing net (#0)
I0520 16:09:55.970540 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:10:14.132297 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5718
I0520 16:10:14.132398 15139 solver.cpp:415]     Test net output #1: loss = 1.83948 (* 1 = 1.83948 loss)
I0520 16:10:14.220526 15139 solver.cpp:231] Iteration 114000, loss = 1.22965
I0520 16:10:14.220600 15139 solver.cpp:247]     Train net output #0: loss = 1.22965 (* 1 = 1.22965 loss)
I0520 16:10:14.220620 15139 sgd_solver.cpp:106] Iteration 114000, lr = 0.0001
I0520 16:10:14.390946 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0512	3.125	82.7852	0	91.2736	6.25	89.3509	0	85.4691	0	86.8966	0	80.1419	0	31.8999	2.9	
I0520 16:10:14.392946 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:10:14.395179 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:10:14.395216 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:10:14.395830 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22965
I0520 16:11:31.188817 15139 solver.cpp:231] Iteration 114200, loss = 1.31709
I0520 16:11:31.193658 15139 solver.cpp:247]     Train net output #0: loss = 1.31709 (* 1 = 1.31709 loss)
I0520 16:11:31.193692 15139 sgd_solver.cpp:106] Iteration 114200, lr = 0.0001
I0520 16:11:31.349293 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0512	3.125	82.7852	0	91.2736	6.25	89.3511	0	85.4691	0	86.8966	0	80.1419	0	31.9	2.9	
I0520 16:11:31.424931 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:11:31.427913 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:11:31.427961 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:11:31.428467 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31709
I0520 16:12:45.700199 15139 solver.cpp:231] Iteration 114400, loss = 1.10534
I0520 16:12:45.701624 15139 solver.cpp:247]     Train net output #0: loss = 1.10534 (* 1 = 1.10534 loss)
I0520 16:12:45.701648 15139 sgd_solver.cpp:106] Iteration 114400, lr = 0.0001
I0520 16:12:45.860148 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0512	3.125	82.7852	0	91.2736	6.25	89.3511	0	85.4691	0	86.8967	0	80.1419	0	31.9	2.9	
I0520 16:12:45.936586 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:12:45.939523 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:12:45.939566 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:12:45.940294 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10534
I0520 16:14:17.799068 15139 solver.cpp:231] Iteration 114600, loss = 1.16946
I0520 16:14:17.799417 15139 solver.cpp:247]     Train net output #0: loss = 1.16946 (* 1 = 1.16946 loss)
I0520 16:14:17.799437 15139 sgd_solver.cpp:106] Iteration 114600, lr = 0.0001
I0520 16:14:17.959693 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0541	3.125	82.7852	0	91.2736	6.25	89.3511	0	85.4691	0	86.8967	0	80.1419	0	31.9001	2.9	
I0520 16:14:18.034700 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:14:18.036725 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:14:18.036756 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:14:18.037261 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16946
I0520 16:15:47.523537 15139 solver.cpp:231] Iteration 114800, loss = 1.13352
I0520 16:15:47.523823 15139 solver.cpp:247]     Train net output #0: loss = 1.13352 (* 1 = 1.13352 loss)
I0520 16:15:47.523841 15139 sgd_solver.cpp:106] Iteration 114800, lr = 0.0001
I0520 16:15:47.684293 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0541	3.125	82.7852	0	91.2736	6.25	89.3511	0	85.4691	0	86.8967	0	80.1419	0	31.9003	2.9	
I0520 16:15:47.760102 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:15:47.762954 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:15:47.763000 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:15:47.763505 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13352
I0520 16:15:50.516641 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:17:07.635283 15139 solver.cpp:348] Iteration 115000, Testing net (#0)
I0520 16:18:07.104125 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:18:21.132215 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5721
I0520 16:18:21.132320 15139 solver.cpp:415]     Test net output #1: loss = 1.83965 (* 1 = 1.83965 loss)
I0520 16:18:21.219782 15139 solver.cpp:231] Iteration 115000, loss = 1.20696
I0520 16:18:21.219861 15139 solver.cpp:247]     Train net output #0: loss = 1.20696 (* 1 = 1.20696 loss)
I0520 16:18:21.219880 15139 sgd_solver.cpp:106] Iteration 115000, lr = 0.0001
I0520 16:18:21.385027 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0541	3.125	82.7852	0	91.2736	6.25	89.3511	0	85.4691	0	86.8967	0	80.1419	0	31.9003	2.9	
I0520 16:18:21.461163 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:18:21.464346 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:18:21.464397 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:18:21.465047 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20696
I0520 16:19:50.213604 15139 solver.cpp:231] Iteration 115200, loss = 1.07204
I0520 16:19:50.213987 15139 solver.cpp:247]     Train net output #0: loss = 1.07204 (* 1 = 1.07204 loss)
I0520 16:19:50.214010 15139 sgd_solver.cpp:106] Iteration 115200, lr = 0.0001
I0520 16:19:50.374168 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0569	3.125	82.7852	0	91.2736	6.25	89.3511	0	85.4691	0	86.8967	0	80.1419	0	31.9004	2.9	
I0520 16:19:50.449544 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:19:50.457109 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:19:50.457149 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:19:50.457706 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.07204
I0520 16:21:12.817458 15139 solver.cpp:231] Iteration 115400, loss = 1.12677
I0520 16:21:12.817989 15139 solver.cpp:247]     Train net output #0: loss = 1.12677 (* 1 = 1.12677 loss)
I0520 16:21:12.818028 15139 sgd_solver.cpp:106] Iteration 115400, lr = 0.0001
I0520 16:21:12.977298 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0627	3.125	82.7852	0	91.2736	6.25	89.3511	0	85.4691	0	86.8967	0	80.142	0	31.9005	2.9	
I0520 16:21:13.052911 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:21:13.056357 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:21:13.056407 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:21:13.056949 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12677
I0520 16:22:31.669030 15139 solver.cpp:231] Iteration 115600, loss = 1.16194
I0520 16:22:31.669378 15139 solver.cpp:247]     Train net output #0: loss = 1.16194 (* 1 = 1.16194 loss)
I0520 16:22:31.669404 15139 sgd_solver.cpp:106] Iteration 115600, lr = 0.0001
I0520 16:22:31.829926 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0627	3.125	82.7852	0	91.2736	6.25	89.3511	0	85.4691	0	86.8967	0	80.142	0	31.9007	2.9	
I0520 16:22:31.905450 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:22:31.908395 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:22:31.908447 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:22:31.909001 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16194
I0520 16:23:51.892137 15139 solver.cpp:231] Iteration 115800, loss = 1.23021
I0520 16:23:51.892468 15139 solver.cpp:247]     Train net output #0: loss = 1.23021 (* 1 = 1.23021 loss)
I0520 16:23:51.892493 15139 sgd_solver.cpp:106] Iteration 115800, lr = 0.0001
I0520 16:23:52.051684 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0627	3.125	82.7852	0	91.2736	6.25	89.3511	0	85.4691	0	86.8968	0	80.142	0	31.9008	2.9	
I0520 16:23:52.127809 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:23:52.132395 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:23:52.132462 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:23:52.133137 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23021
I0520 16:23:59.082978 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:25:32.441800 15139 solver.cpp:348] Iteration 116000, Testing net (#0)
I0520 16:26:42.599622 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:26:58.991832 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57184
I0520 16:26:58.991932 15139 solver.cpp:415]     Test net output #1: loss = 1.84074 (* 1 = 1.84074 loss)
I0520 16:26:59.092469 15139 solver.cpp:231] Iteration 116000, loss = 1.04066
I0520 16:26:59.092564 15139 solver.cpp:247]     Train net output #0: loss = 1.04066 (* 1 = 1.04066 loss)
I0520 16:26:59.092591 15139 sgd_solver.cpp:106] Iteration 116000, lr = 0.0001
I0520 16:26:59.260088 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0627	3.125	82.7852	0	91.2736	6.25	89.3511	0	85.4691	0	86.8968	0	80.142	0	31.9008	2.9	
I0520 16:26:59.335259 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:26:59.337191 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:26:59.337224 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:26:59.337811 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04066
I0520 16:28:49.025384 15139 solver.cpp:231] Iteration 116200, loss = 1.23864
I0520 16:28:49.025748 15139 solver.cpp:247]     Train net output #0: loss = 1.23864 (* 1 = 1.23864 loss)
I0520 16:28:49.025773 15139 sgd_solver.cpp:106] Iteration 116200, lr = 0.0001
I0520 16:28:49.184212 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2736	6.25	89.3511	0	85.4691	0	86.8968	0	80.1421	0	31.9009	2.9	
I0520 16:28:49.260047 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:28:49.263906 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:28:49.264123 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:28:49.264719 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23864
I0520 16:30:23.906523 15139 solver.cpp:231] Iteration 116400, loss = 1.07911
I0520 16:30:23.907032 15139 solver.cpp:247]     Train net output #0: loss = 1.07911 (* 1 = 1.07911 loss)
I0520 16:30:23.907068 15139 sgd_solver.cpp:106] Iteration 116400, lr = 0.0001
I0520 16:30:24.067003 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2736	6.25	89.3512	0	85.4691	0	86.8968	0	80.1421	0	31.9011	2.9	
I0520 16:30:24.142458 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:30:24.145812 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:30:24.145864 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:30:24.146397 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.07911
I0520 16:31:57.151262 15139 solver.cpp:231] Iteration 116600, loss = 1.22019
I0520 16:31:57.151686 15139 solver.cpp:247]     Train net output #0: loss = 1.22019 (* 1 = 1.22019 loss)
I0520 16:31:57.151718 15139 sgd_solver.cpp:106] Iteration 116600, lr = 0.0001
I0520 16:31:57.311298 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2736	6.25	89.3512	0	85.4691	0	86.8968	0	80.1421	0	31.9011	2.9	
I0520 16:31:57.386577 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:31:57.389716 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:31:57.389766 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:31:57.390310 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22019
I0520 16:33:28.922441 15139 solver.cpp:231] Iteration 116800, loss = 1.11729
I0520 16:33:28.922745 15139 solver.cpp:247]     Train net output #0: loss = 1.11729 (* 1 = 1.11729 loss)
I0520 16:33:28.922766 15139 sgd_solver.cpp:106] Iteration 116800, lr = 0.0001
I0520 16:33:29.084734 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2736	6.25	89.3514	0	85.4691	0	86.8968	0	80.1421	0	31.9012	2.9	
I0520 16:33:29.160552 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:33:29.163686 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:33:29.163743 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:33:29.164340 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11729
I0520 16:33:37.480093 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:35:01.273388 15139 solver.cpp:348] Iteration 117000, Testing net (#0)
I0520 16:36:29.508169 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:36:48.736896 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57156
I0520 16:36:48.736995 15139 solver.cpp:415]     Test net output #1: loss = 1.84058 (* 1 = 1.84058 loss)
I0520 16:36:48.828245 15139 solver.cpp:231] Iteration 117000, loss = 1.02352
I0520 16:36:48.828336 15139 solver.cpp:247]     Train net output #0: loss = 1.02352 (* 1 = 1.02352 loss)
I0520 16:36:48.828356 15139 sgd_solver.cpp:106] Iteration 117000, lr = 0.0001
I0520 16:36:48.987941 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2736	6.25	89.3514	0	85.4691	0	86.8968	0	80.1421	0	31.9013	2.9	
I0520 16:36:49.063756 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:36:49.067209 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:36:49.067260 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:36:49.067873 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.02352
I0520 16:38:22.519194 15139 solver.cpp:231] Iteration 117200, loss = 1.08424
I0520 16:38:22.520071 15139 solver.cpp:247]     Train net output #0: loss = 1.08424 (* 1 = 1.08424 loss)
I0520 16:38:22.520104 15139 sgd_solver.cpp:106] Iteration 117200, lr = 0.0001
I0520 16:38:22.680202 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2736	6.25	89.3514	0	85.4691	0	86.8969	0	80.1421	0	31.9014	2.9	
I0520 16:38:22.756438 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:38:22.760447 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:38:22.760507 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:38:22.761044 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08424
I0520 16:40:04.546129 15139 solver.cpp:231] Iteration 117400, loss = 1.04232
I0520 16:40:04.546463 15139 solver.cpp:247]     Train net output #0: loss = 1.04232 (* 1 = 1.04232 loss)
I0520 16:40:04.546484 15139 sgd_solver.cpp:106] Iteration 117400, lr = 0.0001
I0520 16:40:04.706084 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2736	6.25	89.3514	0	85.4691	0	86.8969	0	80.1421	0	31.9014	2.9	
I0520 16:40:04.781497 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:40:04.784678 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:40:04.784737 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:40:04.785287 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04232
I0520 16:41:27.764623 15139 solver.cpp:231] Iteration 117600, loss = 1.06588
I0520 16:41:27.765002 15139 solver.cpp:247]     Train net output #0: loss = 1.06588 (* 1 = 1.06588 loss)
I0520 16:41:27.765023 15139 sgd_solver.cpp:106] Iteration 117600, lr = 0.0001
I0520 16:41:27.923537 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2736	6.25	89.3514	0	85.4691	0	86.8969	0	80.1421	0	31.9015	2.9	
I0520 16:41:27.998806 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:41:28.002260 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:41:28.002315 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:41:28.002900 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.06588
I0520 16:42:54.083796 15139 solver.cpp:231] Iteration 117800, loss = 1.25767
I0520 16:42:54.084116 15139 solver.cpp:247]     Train net output #0: loss = 1.25767 (* 1 = 1.25767 loss)
I0520 16:42:54.084139 15139 sgd_solver.cpp:106] Iteration 117800, lr = 0.0001
I0520 16:42:54.243659 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2737	6.25	89.3514	0	85.4691	0	86.8969	0	80.1422	0	31.9016	2.9	
I0520 16:42:54.318851 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:42:54.321120 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:42:54.321162 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:42:54.321988 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25767
I0520 16:43:06.674311 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:44:25.305090 15139 solver.cpp:348] Iteration 118000, Testing net (#0)
I0520 16:45:37.730454 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:45:52.993347 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57156
I0520 16:45:52.993528 15139 solver.cpp:415]     Test net output #1: loss = 1.83834 (* 1 = 1.83834 loss)
I0520 16:45:53.082991 15139 solver.cpp:231] Iteration 118000, loss = 1.14471
I0520 16:45:53.083078 15139 solver.cpp:247]     Train net output #0: loss = 1.14471 (* 1 = 1.14471 loss)
I0520 16:45:53.083130 15139 sgd_solver.cpp:106] Iteration 118000, lr = 0.0001
I0520 16:45:53.248379 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2737	6.25	89.3514	0	85.4691	0	86.8969	0	80.1422	0	31.9016	2.9	
I0520 16:45:53.324147 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:45:53.328121 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:45:53.328178 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:45:53.328935 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14471
I0520 16:47:24.993917 15139 solver.cpp:231] Iteration 118200, loss = 1.21998
I0520 16:47:24.994530 15139 solver.cpp:247]     Train net output #0: loss = 1.21998 (* 1 = 1.21998 loss)
I0520 16:47:24.994554 15139 sgd_solver.cpp:106] Iteration 118200, lr = 0.0001
I0520 16:47:25.153353 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2737	6.25	89.3514	0	85.4691	0	86.8969	0	80.1422	0	31.9017	2.9	
I0520 16:47:25.229198 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:47:25.232926 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:47:25.232980 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:47:25.233496 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21998
I0520 16:49:00.311650 15139 solver.cpp:231] Iteration 118400, loss = 1.23998
I0520 16:49:00.311944 15139 solver.cpp:247]     Train net output #0: loss = 1.23998 (* 1 = 1.23998 loss)
I0520 16:49:00.311965 15139 sgd_solver.cpp:106] Iteration 118400, lr = 0.0001
I0520 16:49:00.471303 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2737	6.25	89.3514	0	85.4691	0	86.8969	0	80.1422	0	31.9017	2.9	
I0520 16:49:00.546519 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:49:00.549820 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:49:00.549883 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:49:00.550560 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23998
I0520 16:50:22.891978 15139 solver.cpp:231] Iteration 118600, loss = 1.22903
I0520 16:50:22.892405 15139 solver.cpp:247]     Train net output #0: loss = 1.22903 (* 1 = 1.22903 loss)
I0520 16:50:22.892439 15139 sgd_solver.cpp:106] Iteration 118600, lr = 0.0001
I0520 16:50:23.053586 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2738	6.25	89.3514	0	85.4691	0	86.897	0	80.1423	0	31.9018	2.9	
I0520 16:50:23.129649 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:50:23.132586 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:50:23.132627 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:50:23.133390 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22903
I0520 16:51:46.516371 15139 solver.cpp:231] Iteration 118800, loss = 1.36326
I0520 16:51:46.516683 15139 solver.cpp:247]     Train net output #0: loss = 1.36326 (* 1 = 1.36326 loss)
I0520 16:51:46.516703 15139 sgd_solver.cpp:106] Iteration 118800, lr = 0.0001
I0520 16:51:46.676709 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0684	3.125	82.7852	0	91.2738	6.25	89.3514	0	85.4691	0	86.897	0	80.1423	0	31.9019	2.9	
I0520 16:51:46.751585 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:51:46.753669 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:51:46.753701 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:51:46.754189 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.36326
I0520 16:52:00.667707 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:53:11.335063 15139 solver.cpp:348] Iteration 119000, Testing net (#0)
I0520 16:54:18.215059 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 16:54:31.200248 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57236
I0520 16:54:31.200364 15139 solver.cpp:415]     Test net output #1: loss = 1.84082 (* 1 = 1.84082 loss)
I0520 16:54:31.288467 15139 solver.cpp:231] Iteration 119000, loss = 1.17438
I0520 16:54:31.288563 15139 solver.cpp:247]     Train net output #0: loss = 1.17438 (* 1 = 1.17438 loss)
I0520 16:54:31.288592 15139 sgd_solver.cpp:106] Iteration 119000, lr = 0.0001
I0520 16:54:31.447324 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0713	3.125	82.7855	0	91.2738	6.25	89.3514	0	85.4691	0	86.897	0	80.1423	0	31.902	2.9	
I0520 16:54:31.524348 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:54:31.527385 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:54:31.527431 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:54:31.527986 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17438
I0520 16:55:58.220234 15139 solver.cpp:231] Iteration 119200, loss = 1.13429
I0520 16:55:58.220569 15139 solver.cpp:247]     Train net output #0: loss = 1.13429 (* 1 = 1.13429 loss)
I0520 16:55:58.220598 15139 sgd_solver.cpp:106] Iteration 119200, lr = 0.0001
I0520 16:55:58.381449 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0713	3.125	82.7855	0	91.2738	6.25	89.3514	0	85.4691	0	86.897	0	80.1423	0	31.902	2.9	
I0520 16:55:58.456526 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:55:58.459230 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:55:58.459277 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:55:58.459950 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13429
I0520 16:57:29.418458 15139 solver.cpp:231] Iteration 119400, loss = 1.23075
I0520 16:57:29.418756 15139 solver.cpp:247]     Train net output #0: loss = 1.23075 (* 1 = 1.23075 loss)
I0520 16:57:29.418777 15139 sgd_solver.cpp:106] Iteration 119400, lr = 0.0001
I0520 16:57:29.578302 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0713	3.125	82.7855	0	91.2738	6.25	89.3514	0	85.4691	0	86.897	0	80.1423	0	31.9021	2.9	
I0520 16:57:29.653735 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:57:29.656538 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:57:29.656584 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:57:29.657155 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23075
I0520 16:58:54.172873 15139 solver.cpp:231] Iteration 119600, loss = 1.18201
I0520 16:58:54.173310 15139 solver.cpp:247]     Train net output #0: loss = 1.18201 (* 1 = 1.18201 loss)
I0520 16:58:54.173333 15139 sgd_solver.cpp:106] Iteration 119600, lr = 0.0001
I0520 16:58:54.333700 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0713	3.125	82.7855	0	91.2738	6.25	89.3514	0	85.4691	0	86.897	0	80.1424	0	31.9022	2.9	
I0520 16:58:54.410123 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 16:58:54.413558 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 16:58:54.413645 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 16:58:54.414428 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18201
I0520 17:00:30.137222 15139 solver.cpp:231] Iteration 119800, loss = 1.04036
I0520 17:00:30.137516 15139 solver.cpp:247]     Train net output #0: loss = 1.04036 (* 1 = 1.04036 loss)
I0520 17:00:30.137537 15139 sgd_solver.cpp:106] Iteration 119800, lr = 0.0001
I0520 17:00:30.302397 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2738	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9023	2.9	
I0520 17:00:30.377516 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:00:30.379961 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:00:30.380000 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:00:30.380528 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04036
I0520 17:00:45.904992 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:01:46.253115 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_120000.caffemodel
I0520 17:02:45.588388 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_120000.solverstate
I0520 17:02:46.291373 15139 solver.cpp:348] Iteration 120000, Testing net (#0)
I0520 17:03:52.759372 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:04:03.756059 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57242
I0520 17:04:03.756150 15139 solver.cpp:415]     Test net output #1: loss = 1.83895 (* 1 = 1.83895 loss)
I0520 17:04:03.843391 15139 solver.cpp:231] Iteration 120000, loss = 1.301
I0520 17:04:03.843493 15139 solver.cpp:247]     Train net output #0: loss = 1.301 (* 1 = 1.301 loss)
I0520 17:04:03.843513 15139 sgd_solver.cpp:46] MultiStep Status: Iteration 120000, step = 2
I0520 17:04:03.843520 15139 sgd_solver.cpp:106] Iteration 120000, lr = 1e-05
I0520 17:04:04.004374 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:04:04.007307 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:04:04.010548 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:04:04.010591 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:04:04.011138 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.301
I0520 17:05:30.008568 15139 solver.cpp:231] Iteration 120200, loss = 0.984037
I0520 17:05:30.009611 15139 solver.cpp:247]     Train net output #0: loss = 0.984037 (* 1 = 0.984037 loss)
I0520 17:05:30.009632 15139 sgd_solver.cpp:106] Iteration 120200, lr = 1e-05
I0520 17:05:30.169025 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:05:30.243954 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:05:30.246203 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:05:30.246232 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:05:30.246706 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.984037
I0520 17:06:49.737282 15139 solver.cpp:231] Iteration 120400, loss = 1.2534
I0520 17:06:49.737691 15139 solver.cpp:247]     Train net output #0: loss = 1.2534 (* 1 = 1.2534 loss)
I0520 17:06:49.737735 15139 sgd_solver.cpp:106] Iteration 120400, lr = 1e-05
I0520 17:06:49.897523 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:06:49.973105 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:06:49.975741 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:06:49.975798 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:06:49.976510 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.2534
I0520 17:08:07.455646 15139 solver.cpp:231] Iteration 120600, loss = 1.21905
I0520 17:08:07.456082 15139 solver.cpp:247]     Train net output #0: loss = 1.21905 (* 1 = 1.21905 loss)
I0520 17:08:07.456105 15139 sgd_solver.cpp:106] Iteration 120600, lr = 1e-05
I0520 17:08:07.618433 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:08:07.694685 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:08:07.697662 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:08:07.697724 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:08:07.698436 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21905
I0520 17:09:39.718632 15139 solver.cpp:231] Iteration 120800, loss = 1.22224
I0520 17:09:39.718919 15139 solver.cpp:247]     Train net output #0: loss = 1.22224 (* 1 = 1.22224 loss)
I0520 17:09:39.718940 15139 sgd_solver.cpp:106] Iteration 120800, lr = 1e-05
I0520 17:09:39.879701 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:09:39.954684 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:09:39.957862 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:09:39.957907 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:09:39.958425 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22224
I0520 17:10:05.887678 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:11:23.438035 15139 solver.cpp:348] Iteration 121000, Testing net (#0)
I0520 17:12:25.156000 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:12:35.433446 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57282
I0520 17:12:35.433527 15139 solver.cpp:415]     Test net output #1: loss = 1.83687 (* 1 = 1.83687 loss)
I0520 17:12:35.521003 15139 solver.cpp:231] Iteration 121000, loss = 1.05968
I0520 17:12:35.521087 15139 solver.cpp:247]     Train net output #0: loss = 1.05968 (* 1 = 1.05968 loss)
I0520 17:12:35.521116 15139 sgd_solver.cpp:106] Iteration 121000, lr = 1e-05
I0520 17:12:35.689713 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:12:35.764597 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:12:35.767315 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:12:35.767369 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:12:35.768087 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.05968
I0520 17:13:54.077850 15139 solver.cpp:231] Iteration 121200, loss = 1.00622
I0520 17:13:54.078157 15139 solver.cpp:247]     Train net output #0: loss = 1.00622 (* 1 = 1.00622 loss)
I0520 17:13:54.078191 15139 sgd_solver.cpp:106] Iteration 121200, lr = 1e-05
I0520 17:13:54.245280 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:13:54.321246 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:13:54.325297 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:13:54.325361 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:13:54.326140 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.00622
I0520 17:15:44.471184 15139 solver.cpp:231] Iteration 121400, loss = 1.04881
I0520 17:15:44.471462 15139 solver.cpp:247]     Train net output #0: loss = 1.04881 (* 1 = 1.04881 loss)
I0520 17:15:44.471479 15139 sgd_solver.cpp:106] Iteration 121400, lr = 1e-05
I0520 17:15:44.632275 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:15:44.706871 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:15:44.708837 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:15:44.708864 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:15:44.709280 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04881
I0520 17:17:16.796721 15139 solver.cpp:231] Iteration 121600, loss = 1.02412
I0520 17:17:16.797174 15139 solver.cpp:247]     Train net output #0: loss = 1.02412 (* 1 = 1.02412 loss)
I0520 17:17:16.797199 15139 sgd_solver.cpp:106] Iteration 121600, lr = 1e-05
I0520 17:17:16.956976 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:17:17.032625 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:17:17.037570 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:17:17.037642 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:17:17.038269 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.02412
I0520 17:18:47.565397 15139 solver.cpp:231] Iteration 121800, loss = 1.29018
I0520 17:18:47.565801 15139 solver.cpp:247]     Train net output #0: loss = 1.29018 (* 1 = 1.29018 loss)
I0520 17:18:47.565825 15139 sgd_solver.cpp:106] Iteration 121800, lr = 1e-05
I0520 17:18:47.724086 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:18:47.799947 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:18:47.803617 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:18:47.803683 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:18:47.804505 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.29018
I0520 17:19:10.857311 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:20:12.662184 15139 solver.cpp:348] Iteration 122000, Testing net (#0)
I0520 17:21:45.805027 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:22:01.078481 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57288
I0520 17:22:01.078593 15139 solver.cpp:415]     Test net output #1: loss = 1.8358 (* 1 = 1.8358 loss)
I0520 17:22:01.179699 15139 solver.cpp:231] Iteration 122000, loss = 1.14779
I0520 17:22:01.179808 15139 solver.cpp:247]     Train net output #0: loss = 1.14779 (* 1 = 1.14779 loss)
I0520 17:22:01.179838 15139 sgd_solver.cpp:106] Iteration 122000, lr = 1e-05
I0520 17:22:01.358651 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:22:01.434892 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:22:01.437332 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:22:01.437381 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:22:01.438267 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14779
I0520 17:23:24.253002 15139 solver.cpp:231] Iteration 122200, loss = 1.01066
I0520 17:23:24.253455 15139 solver.cpp:247]     Train net output #0: loss = 1.01066 (* 1 = 1.01066 loss)
I0520 17:23:24.253500 15139 sgd_solver.cpp:106] Iteration 122200, lr = 1e-05
I0520 17:23:24.417039 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:23:24.492758 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:23:24.496197 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:23:24.496295 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:23:24.497151 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.01066
I0520 17:24:49.730686 15139 solver.cpp:231] Iteration 122400, loss = 1.04036
I0520 17:24:49.731174 15139 solver.cpp:247]     Train net output #0: loss = 1.04036 (* 1 = 1.04036 loss)
I0520 17:24:49.731207 15139 sgd_solver.cpp:106] Iteration 122400, lr = 1e-05
I0520 17:24:49.888411 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:24:49.964357 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:24:49.967773 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:24:49.967833 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:24:49.968499 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04036
I0520 17:26:35.861511 15139 solver.cpp:231] Iteration 122600, loss = 1.17523
I0520 17:26:35.861830 15139 solver.cpp:247]     Train net output #0: loss = 1.17523 (* 1 = 1.17523 loss)
I0520 17:26:35.861851 15139 sgd_solver.cpp:106] Iteration 122600, lr = 1e-05
I0520 17:26:36.022475 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:26:36.097935 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:26:36.101351 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:26:36.101397 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:26:36.102007 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17523
I0520 17:28:18.611127 15139 solver.cpp:231] Iteration 122800, loss = 1.08534
I0520 17:28:18.612006 15139 solver.cpp:247]     Train net output #0: loss = 1.08534 (* 1 = 1.08534 loss)
I0520 17:28:18.612033 15139 sgd_solver.cpp:106] Iteration 122800, lr = 1e-05
I0520 17:28:18.771395 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:28:18.847241 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:28:18.850911 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:28:18.850965 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:28:18.851660 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08534
I0520 17:28:50.635637 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:29:54.661196 15139 solver.cpp:348] Iteration 123000, Testing net (#0)
I0520 17:31:14.683509 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:31:26.707056 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57282
I0520 17:31:26.707164 15139 solver.cpp:415]     Test net output #1: loss = 1.8361 (* 1 = 1.8361 loss)
I0520 17:31:26.794292 15139 solver.cpp:231] Iteration 123000, loss = 1.43446
I0520 17:31:26.794404 15139 solver.cpp:247]     Train net output #0: loss = 1.43446 (* 1 = 1.43446 loss)
I0520 17:31:26.794426 15139 sgd_solver.cpp:106] Iteration 123000, lr = 1e-05
I0520 17:31:26.953932 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:31:27.030769 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:31:27.033812 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:31:27.033860 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:31:27.034420 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.43446
I0520 17:33:00.031888 15139 solver.cpp:231] Iteration 123200, loss = 1.20025
I0520 17:33:00.032385 15139 solver.cpp:247]     Train net output #0: loss = 1.20025 (* 1 = 1.20025 loss)
I0520 17:33:00.032418 15139 sgd_solver.cpp:106] Iteration 123200, lr = 1e-05
I0520 17:33:00.205296 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:33:00.299909 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:33:00.303261 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:33:00.303321 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:33:00.303977 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20025
I0520 17:34:25.842725 15139 solver.cpp:231] Iteration 123400, loss = 1.10272
I0520 17:34:25.843097 15139 solver.cpp:247]     Train net output #0: loss = 1.10272 (* 1 = 1.10272 loss)
I0520 17:34:25.843123 15139 sgd_solver.cpp:106] Iteration 123400, lr = 1e-05
I0520 17:34:26.003159 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:34:26.078765 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:34:26.081920 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:34:26.081979 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:34:26.082576 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10272
I0520 17:35:58.006774 15139 solver.cpp:231] Iteration 123600, loss = 1.21968
I0520 17:35:58.007185 15139 solver.cpp:247]     Train net output #0: loss = 1.21968 (* 1 = 1.21968 loss)
I0520 17:35:58.007212 15139 sgd_solver.cpp:106] Iteration 123600, lr = 1e-05
I0520 17:35:58.165654 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:35:58.241232 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:35:58.244647 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:35:58.244705 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:35:58.245285 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21968
I0520 17:37:30.994858 15139 solver.cpp:231] Iteration 123800, loss = 1.1176
I0520 17:37:30.995259 15139 solver.cpp:247]     Train net output #0: loss = 1.1176 (* 1 = 1.1176 loss)
I0520 17:37:30.995285 15139 sgd_solver.cpp:106] Iteration 123800, lr = 1e-05
I0520 17:37:31.153249 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:37:31.229213 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:37:31.232269 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:37:31.232336 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:37:31.232936 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1176
I0520 17:38:04.490968 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:39:05.563730 15139 solver.cpp:348] Iteration 124000, Testing net (#0)
I0520 17:40:24.616224 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:40:35.392103 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57222
I0520 17:40:35.392212 15139 solver.cpp:415]     Test net output #1: loss = 1.8368 (* 1 = 1.8368 loss)
I0520 17:40:35.479812 15139 solver.cpp:231] Iteration 124000, loss = 1.19521
I0520 17:40:35.479923 15139 solver.cpp:247]     Train net output #0: loss = 1.19521 (* 1 = 1.19521 loss)
I0520 17:40:35.479943 15139 sgd_solver.cpp:106] Iteration 124000, lr = 1e-05
I0520 17:40:35.649328 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:40:35.725163 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:40:35.727839 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:40:35.727887 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:40:35.728587 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19521
I0520 17:42:04.131217 15139 solver.cpp:231] Iteration 124200, loss = 1.23697
I0520 17:42:04.131685 15139 solver.cpp:247]     Train net output #0: loss = 1.23697 (* 1 = 1.23697 loss)
I0520 17:42:04.131705 15139 sgd_solver.cpp:106] Iteration 124200, lr = 1e-05
I0520 17:42:04.290657 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:42:04.367547 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:42:04.370060 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:42:04.370115 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:42:04.370919 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23697
I0520 17:43:29.105000 15139 solver.cpp:231] Iteration 124400, loss = 1.00212
I0520 17:43:29.105372 15139 solver.cpp:247]     Train net output #0: loss = 1.00212 (* 1 = 1.00212 loss)
I0520 17:43:29.105396 15139 sgd_solver.cpp:106] Iteration 124400, lr = 1e-05
I0520 17:43:29.264645 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:43:29.340018 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:43:29.342542 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:43:29.342597 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:43:29.343217 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.00212
I0520 17:44:55.545481 15139 solver.cpp:231] Iteration 124600, loss = 1.07624
I0520 17:44:55.545821 15139 solver.cpp:247]     Train net output #0: loss = 1.07624 (* 1 = 1.07624 loss)
I0520 17:44:55.545842 15139 sgd_solver.cpp:106] Iteration 124600, lr = 1e-05
I0520 17:44:55.706042 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:44:55.782559 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:44:55.785529 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:44:55.785584 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:44:55.786067 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.07624
I0520 17:46:20.534454 15139 solver.cpp:231] Iteration 124800, loss = 1.18355
I0520 17:46:20.534719 15139 solver.cpp:247]     Train net output #0: loss = 1.18355 (* 1 = 1.18355 loss)
I0520 17:46:20.534739 15139 sgd_solver.cpp:106] Iteration 124800, lr = 1e-05
I0520 17:46:20.694715 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:46:20.771133 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:46:20.775063 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:46:20.775123 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:46:20.775771 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18355
I0520 17:46:51.521451 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:47:43.733291 15139 solver.cpp:348] Iteration 125000, Testing net (#0)
I0520 17:48:57.700279 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:49:06.922103 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57242
I0520 17:49:06.922448 15139 solver.cpp:415]     Test net output #1: loss = 1.83609 (* 1 = 1.83609 loss)
I0520 17:49:07.015910 15139 solver.cpp:231] Iteration 125000, loss = 1.21455
I0520 17:49:07.016007 15139 solver.cpp:247]     Train net output #0: loss = 1.21455 (* 1 = 1.21455 loss)
I0520 17:49:07.016027 15139 sgd_solver.cpp:106] Iteration 125000, lr = 1e-05
I0520 17:49:07.183840 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:49:07.259934 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:49:07.262956 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:49:07.262997 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:49:07.263528 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21455
I0520 17:50:28.277459 15139 solver.cpp:231] Iteration 125200, loss = 1.10996
I0520 17:50:28.277833 15139 solver.cpp:247]     Train net output #0: loss = 1.10996 (* 1 = 1.10996 loss)
I0520 17:50:28.277858 15139 sgd_solver.cpp:106] Iteration 125200, lr = 1e-05
I0520 17:50:28.438920 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:50:28.515655 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:50:28.518738 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:50:28.518790 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:50:28.519364 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10996
I0520 17:51:53.273141 15139 solver.cpp:231] Iteration 125400, loss = 1.30316
I0520 17:51:53.273691 15139 solver.cpp:247]     Train net output #0: loss = 1.30316 (* 1 = 1.30316 loss)
I0520 17:51:53.273720 15139 sgd_solver.cpp:106] Iteration 125400, lr = 1e-05
I0520 17:51:53.432751 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:51:53.508267 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:51:53.511561 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:51:53.511615 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:51:53.512208 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30316
I0520 17:53:18.745808 15139 solver.cpp:231] Iteration 125600, loss = 1.23457
I0520 17:53:18.746075 15139 solver.cpp:247]     Train net output #0: loss = 1.23457 (* 1 = 1.23457 loss)
I0520 17:53:18.746098 15139 sgd_solver.cpp:106] Iteration 125600, lr = 1e-05
I0520 17:53:18.904093 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:53:18.979534 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:53:18.982689 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:53:18.982734 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:53:18.983269 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23457
I0520 17:54:42.380333 15139 solver.cpp:231] Iteration 125800, loss = 1.31943
I0520 17:54:42.380754 15139 solver.cpp:247]     Train net output #0: loss = 1.31943 (* 1 = 1.31943 loss)
I0520 17:54:42.380782 15139 sgd_solver.cpp:106] Iteration 125800, lr = 1e-05
I0520 17:54:42.539926 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:54:42.615627 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:54:42.619758 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:54:42.619822 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:54:42.620435 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31943
I0520 17:55:19.165123 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:56:13.258460 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_126000.caffemodel
I0520 17:58:25.917980 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_126000.solverstate
I0520 17:58:26.629537 15139 solver.cpp:348] Iteration 126000, Testing net (#0)
I0520 17:59:36.618667 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 17:59:46.810678 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57302
I0520 17:59:46.810852 15139 solver.cpp:415]     Test net output #1: loss = 1.83614 (* 1 = 1.83614 loss)
I0520 17:59:46.898591 15139 solver.cpp:231] Iteration 126000, loss = 1.27425
I0520 17:59:46.898679 15139 solver.cpp:247]     Train net output #0: loss = 1.27425 (* 1 = 1.27425 loss)
I0520 17:59:46.898705 15139 sgd_solver.cpp:106] Iteration 126000, lr = 1e-05
I0520 17:59:47.063731 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 17:59:47.066360 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 17:59:47.069432 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 17:59:47.069483 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 17:59:47.070076 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27425
I0520 18:01:37.747493 15139 solver.cpp:231] Iteration 126200, loss = 1.18619
I0520 18:01:37.747833 15139 solver.cpp:247]     Train net output #0: loss = 1.18619 (* 1 = 1.18619 loss)
I0520 18:01:37.747884 15139 sgd_solver.cpp:106] Iteration 126200, lr = 1e-05
I0520 18:01:37.907740 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:01:37.983690 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:01:37.987078 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:01:37.987129 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:01:37.987700 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18619
I0520 18:03:24.281445 15139 solver.cpp:231] Iteration 126400, loss = 1.12534
I0520 18:03:24.285677 15139 solver.cpp:247]     Train net output #0: loss = 1.12534 (* 1 = 1.12534 loss)
I0520 18:03:24.285712 15139 sgd_solver.cpp:106] Iteration 126400, lr = 1e-05
I0520 18:03:24.442301 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:03:24.517760 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:03:24.520680 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:03:24.520746 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:03:24.521428 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12534
I0520 18:04:53.142669 15139 solver.cpp:231] Iteration 126600, loss = 1.28567
I0520 18:04:53.144595 15139 solver.cpp:247]     Train net output #0: loss = 1.28567 (* 1 = 1.28567 loss)
I0520 18:04:53.144629 15139 sgd_solver.cpp:106] Iteration 126600, lr = 1e-05
I0520 18:04:53.302232 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:04:53.377617 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:04:53.380678 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:04:53.380724 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:04:53.381295 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28567
I0520 18:06:16.636205 15139 solver.cpp:231] Iteration 126800, loss = 1.19098
I0520 18:06:16.636917 15139 solver.cpp:247]     Train net output #0: loss = 1.19098 (* 1 = 1.19098 loss)
I0520 18:06:16.636967 15139 sgd_solver.cpp:106] Iteration 126800, lr = 1e-05
I0520 18:06:16.793011 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:06:16.868816 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:06:16.871785 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:06:16.871840 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:06:16.872522 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19098
I0520 18:06:53.485363 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:07:39.832106 15139 solver.cpp:348] Iteration 127000, Testing net (#0)
I0520 18:08:53.650280 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:09:02.297410 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57322
I0520 18:09:02.297529 15139 solver.cpp:415]     Test net output #1: loss = 1.83615 (* 1 = 1.83615 loss)
I0520 18:09:02.387933 15139 solver.cpp:231] Iteration 127000, loss = 1.13965
I0520 18:09:02.388031 15139 solver.cpp:247]     Train net output #0: loss = 1.13965 (* 1 = 1.13965 loss)
I0520 18:09:02.388053 15139 sgd_solver.cpp:106] Iteration 127000, lr = 1e-05
I0520 18:09:02.553791 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:09:02.629791 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:09:02.632908 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:09:02.632964 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:09:02.633625 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13965
I0520 18:10:26.842689 15139 solver.cpp:231] Iteration 127200, loss = 1.0015
I0520 18:10:26.843035 15139 solver.cpp:247]     Train net output #0: loss = 1.0015 (* 1 = 1.0015 loss)
I0520 18:10:26.843060 15139 sgd_solver.cpp:106] Iteration 127200, lr = 1e-05
I0520 18:10:27.003039 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:10:27.078289 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:10:27.080371 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:10:27.080426 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:10:27.080968 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.0015
I0520 18:11:59.755805 15139 solver.cpp:231] Iteration 127400, loss = 1.35456
I0520 18:11:59.756314 15139 solver.cpp:247]     Train net output #0: loss = 1.35456 (* 1 = 1.35456 loss)
I0520 18:11:59.756337 15139 sgd_solver.cpp:106] Iteration 127400, lr = 1e-05
I0520 18:11:59.916412 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:11:59.992184 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:11:59.995352 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:11:59.995471 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:11:59.996078 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35456
I0520 18:13:30.328644 15139 solver.cpp:231] Iteration 127600, loss = 1.20842
I0520 18:13:30.329187 15139 solver.cpp:247]     Train net output #0: loss = 1.20842 (* 1 = 1.20842 loss)
I0520 18:13:30.329213 15139 sgd_solver.cpp:106] Iteration 127600, lr = 1e-05
I0520 18:13:30.488100 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:13:30.564375 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:13:30.569267 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:13:30.569344 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:13:30.570031 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20842
I0520 18:15:22.102154 15139 solver.cpp:231] Iteration 127800, loss = 1.13089
I0520 18:15:22.102479 15139 solver.cpp:247]     Train net output #0: loss = 1.13089 (* 1 = 1.13089 loss)
I0520 18:15:22.102504 15139 sgd_solver.cpp:106] Iteration 127800, lr = 1e-05
I0520 18:15:22.261960 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:15:22.338909 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:15:22.342056 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:15:22.342115 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:15:22.342699 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13089
I0520 18:16:15.519659 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:17:11.675676 15139 solver.cpp:348] Iteration 128000, Testing net (#0)
I0520 18:18:22.787297 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:18:30.068152 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57236
I0520 18:18:30.068289 15139 solver.cpp:415]     Test net output #1: loss = 1.83619 (* 1 = 1.83619 loss)
I0520 18:18:30.160502 15139 solver.cpp:231] Iteration 128000, loss = 1.18286
I0520 18:18:30.160585 15139 solver.cpp:247]     Train net output #0: loss = 1.18286 (* 1 = 1.18286 loss)
I0520 18:18:30.160607 15139 sgd_solver.cpp:106] Iteration 128000, lr = 1e-05
I0520 18:18:30.320415 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:18:30.395988 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:18:30.398299 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:18:30.398349 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:18:30.399168 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18286
I0520 18:19:48.355264 15139 solver.cpp:231] Iteration 128200, loss = 1.09954
I0520 18:19:48.359858 15139 solver.cpp:247]     Train net output #0: loss = 1.09954 (* 1 = 1.09954 loss)
I0520 18:19:48.359891 15139 sgd_solver.cpp:106] Iteration 128200, lr = 1e-05
I0520 18:19:48.515820 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:19:48.591331 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:19:48.593791 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:19:48.593840 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:19:48.594413 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09954
I0520 18:21:09.657706 15139 solver.cpp:231] Iteration 128400, loss = 1.15071
I0520 18:21:09.662343 15139 solver.cpp:247]     Train net output #0: loss = 1.15071 (* 1 = 1.15071 loss)
I0520 18:21:09.662389 15139 sgd_solver.cpp:106] Iteration 128400, lr = 1e-05
I0520 18:21:09.819032 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:21:09.895206 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:21:09.898600 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:21:09.898668 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:21:09.899462 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15071
I0520 18:22:32.041863 15139 solver.cpp:231] Iteration 128600, loss = 1.19769
I0520 18:22:32.042176 15139 solver.cpp:247]     Train net output #0: loss = 1.19769 (* 1 = 1.19769 loss)
I0520 18:22:32.042199 15139 sgd_solver.cpp:106] Iteration 128600, lr = 1e-05
I0520 18:22:32.202615 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:22:32.278807 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:22:32.282508 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:22:32.282565 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:22:32.283193 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19769
I0520 18:23:50.524758 15139 solver.cpp:231] Iteration 128800, loss = 1.16451
I0520 18:23:50.525094 15139 solver.cpp:247]     Train net output #0: loss = 1.16451 (* 1 = 1.16451 loss)
I0520 18:23:50.525125 15139 sgd_solver.cpp:106] Iteration 128800, lr = 1e-05
I0520 18:23:50.684839 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:23:50.762044 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:23:50.763763 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:23:50.763795 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:23:50.764443 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16451
I0520 18:24:28.411036 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:25:02.807008 15139 solver.cpp:348] Iteration 129000, Testing net (#0)
I0520 18:26:16.159579 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:26:23.968154 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57226
I0520 18:26:23.968248 15139 solver.cpp:415]     Test net output #1: loss = 1.83711 (* 1 = 1.83711 loss)
I0520 18:26:24.056399 15139 solver.cpp:231] Iteration 129000, loss = 1.21441
I0520 18:26:24.056471 15139 solver.cpp:247]     Train net output #0: loss = 1.21441 (* 1 = 1.21441 loss)
I0520 18:26:24.056491 15139 sgd_solver.cpp:106] Iteration 129000, lr = 1e-05
I0520 18:26:24.216838 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:26:24.293673 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:26:24.295804 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:26:24.295847 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:26:24.296386 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21441
I0520 18:27:59.941058 15139 solver.cpp:231] Iteration 129200, loss = 1.11313
I0520 18:27:59.941342 15139 solver.cpp:247]     Train net output #0: loss = 1.11313 (* 1 = 1.11313 loss)
I0520 18:27:59.941372 15139 sgd_solver.cpp:106] Iteration 129200, lr = 1e-05
I0520 18:28:00.101294 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:28:00.176065 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:28:00.178270 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:28:00.178313 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:28:00.178863 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11313
I0520 18:29:18.852161 15139 solver.cpp:231] Iteration 129400, loss = 1.13406
I0520 18:29:18.852773 15139 solver.cpp:247]     Train net output #0: loss = 1.13406 (* 1 = 1.13406 loss)
I0520 18:29:18.852802 15139 sgd_solver.cpp:106] Iteration 129400, lr = 1e-05
I0520 18:29:19.012859 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:29:19.087978 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:29:19.090416 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:29:19.090450 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:29:19.090884 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13406
I0520 18:30:51.467412 15139 solver.cpp:231] Iteration 129600, loss = 1.23015
I0520 18:30:51.467681 15139 solver.cpp:247]     Train net output #0: loss = 1.23015 (* 1 = 1.23015 loss)
I0520 18:30:51.467703 15139 sgd_solver.cpp:106] Iteration 129600, lr = 1e-05
I0520 18:30:51.625825 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:30:51.701351 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:30:51.703824 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:30:51.703876 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:30:51.704521 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23015
I0520 18:32:22.000632 15139 solver.cpp:231] Iteration 129800, loss = 1.28779
I0520 18:32:22.001013 15139 solver.cpp:247]     Train net output #0: loss = 1.28779 (* 1 = 1.28779 loss)
I0520 18:32:22.001042 15139 sgd_solver.cpp:106] Iteration 129800, lr = 1e-05
I0520 18:32:22.162657 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:32:22.238801 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:32:22.242012 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:32:22.242066 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:32:22.242702 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28779
I0520 18:33:12.143286 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:33:55.481941 15139 solver.cpp:348] Iteration 130000, Testing net (#0)
I0520 18:35:12.642982 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:35:20.656184 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57302
I0520 18:35:20.656296 15139 solver.cpp:415]     Test net output #1: loss = 1.8363 (* 1 = 1.8363 loss)
I0520 18:35:20.743811 15139 solver.cpp:231] Iteration 130000, loss = 1.09602
I0520 18:35:20.743901 15139 solver.cpp:247]     Train net output #0: loss = 1.09602 (* 1 = 1.09602 loss)
I0520 18:35:20.743921 15139 sgd_solver.cpp:106] Iteration 130000, lr = 1e-05
I0520 18:35:20.912547 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:35:20.988324 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:35:20.992148 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:35:20.992233 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:35:20.992806 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09602
I0520 18:36:56.593096 15139 solver.cpp:231] Iteration 130200, loss = 1.0587
I0520 18:36:56.593545 15139 solver.cpp:247]     Train net output #0: loss = 1.0587 (* 1 = 1.0587 loss)
I0520 18:36:56.593583 15139 sgd_solver.cpp:106] Iteration 130200, lr = 1e-05
I0520 18:36:56.752280 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:36:56.827919 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:36:56.831203 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:36:56.831257 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:36:56.831812 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.0587
I0520 18:38:36.857269 15139 solver.cpp:231] Iteration 130400, loss = 1.24896
I0520 18:38:36.857626 15139 solver.cpp:247]     Train net output #0: loss = 1.24896 (* 1 = 1.24896 loss)
I0520 18:38:36.857650 15139 sgd_solver.cpp:106] Iteration 130400, lr = 1e-05
I0520 18:38:37.015846 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:38:37.091332 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:38:37.094599 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:38:37.094646 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:38:37.095161 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24896
I0520 18:40:06.961386 15139 solver.cpp:231] Iteration 130600, loss = 1.13481
I0520 18:40:06.961961 15139 solver.cpp:247]     Train net output #0: loss = 1.13481 (* 1 = 1.13481 loss)
I0520 18:40:06.961980 15139 sgd_solver.cpp:106] Iteration 130600, lr = 1e-05
I0520 18:40:07.122519 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:40:07.197659 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:40:07.200628 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:40:07.200722 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:40:07.201508 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13481
I0520 18:41:33.496093 15139 solver.cpp:231] Iteration 130800, loss = 1.28421
I0520 18:41:33.496498 15139 solver.cpp:247]     Train net output #0: loss = 1.28421 (* 1 = 1.28421 loss)
I0520 18:41:33.496529 15139 sgd_solver.cpp:106] Iteration 130800, lr = 1e-05
I0520 18:41:33.655727 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:41:33.730620 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:41:33.732720 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:41:33.732753 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:41:33.733268 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28421
I0520 18:42:24.691792 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:43:04.193620 15139 solver.cpp:348] Iteration 131000, Testing net (#0)
I0520 18:44:36.629235 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:44:41.977434 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57258
I0520 18:44:41.977519 15139 solver.cpp:415]     Test net output #1: loss = 1.83655 (* 1 = 1.83655 loss)
I0520 18:44:42.064680 15139 solver.cpp:231] Iteration 131000, loss = 1.24026
I0520 18:44:42.064748 15139 solver.cpp:247]     Train net output #0: loss = 1.24026 (* 1 = 1.24026 loss)
I0520 18:44:42.064766 15139 sgd_solver.cpp:106] Iteration 131000, lr = 1e-05
I0520 18:44:42.227069 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:44:42.302510 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:44:42.304188 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:44:42.304214 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:44:42.304790 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24026
I0520 18:46:17.904422 15139 solver.cpp:231] Iteration 131200, loss = 1.27881
I0520 18:46:17.905536 15139 solver.cpp:247]     Train net output #0: loss = 1.27881 (* 1 = 1.27881 loss)
I0520 18:46:17.905575 15139 sgd_solver.cpp:106] Iteration 131200, lr = 1e-05
I0520 18:46:18.063963 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:46:18.138792 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:46:18.140611 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:46:18.140641 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:46:18.141142 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27881
I0520 18:47:34.404745 15139 solver.cpp:231] Iteration 131400, loss = 1.08938
I0520 18:47:34.405032 15139 solver.cpp:247]     Train net output #0: loss = 1.08938 (* 1 = 1.08938 loss)
I0520 18:47:34.405053 15139 sgd_solver.cpp:106] Iteration 131400, lr = 1e-05
I0520 18:47:34.565759 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:47:34.641991 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:47:34.644129 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:47:34.644155 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:47:34.644984 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08938
I0520 18:48:51.903053 15139 solver.cpp:231] Iteration 131600, loss = 1.29107
I0520 18:48:51.903385 15139 solver.cpp:247]     Train net output #0: loss = 1.29107 (* 1 = 1.29107 loss)
I0520 18:48:51.903409 15139 sgd_solver.cpp:106] Iteration 131600, lr = 1e-05
I0520 18:48:52.062973 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:48:52.138658 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:48:52.140449 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:48:52.140486 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:48:52.141310 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.29107
I0520 18:50:22.988744 15139 solver.cpp:231] Iteration 131800, loss = 1.24959
I0520 18:50:22.989022 15139 solver.cpp:247]     Train net output #0: loss = 1.24959 (* 1 = 1.24959 loss)
I0520 18:50:22.989044 15139 sgd_solver.cpp:106] Iteration 131800, lr = 1e-05
I0520 18:50:23.148465 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:50:23.223165 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:50:23.224993 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:50:23.225023 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:50:23.225548 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.24959
I0520 18:51:14.892696 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:51:45.487812 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_132000.caffemodel
I0520 18:52:31.168232 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_132000.solverstate
I0520 18:52:31.755931 15139 solver.cpp:348] Iteration 132000, Testing net (#0)
I0520 18:53:40.798238 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 18:53:46.589684 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57268
I0520 18:53:46.589786 15139 solver.cpp:415]     Test net output #1: loss = 1.83545 (* 1 = 1.83545 loss)
I0520 18:53:46.677839 15139 solver.cpp:231] Iteration 132000, loss = 1.30335
I0520 18:53:46.677908 15139 solver.cpp:247]     Train net output #0: loss = 1.30335 (* 1 = 1.30335 loss)
I0520 18:53:46.677927 15139 sgd_solver.cpp:106] Iteration 132000, lr = 1e-05
I0520 18:53:46.847606 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:53:46.849413 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:53:46.851398 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:53:46.851421 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:53:46.851968 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30335
I0520 18:55:03.989204 15139 solver.cpp:231] Iteration 132200, loss = 1.22994
I0520 18:55:03.989531 15139 solver.cpp:247]     Train net output #0: loss = 1.22994 (* 1 = 1.22994 loss)
I0520 18:55:03.989586 15139 sgd_solver.cpp:106] Iteration 132200, lr = 1e-05
I0520 18:55:04.150166 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:55:04.225862 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:55:04.228490 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:55:04.228530 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:55:04.229120 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22994
I0520 18:56:29.229521 15139 solver.cpp:231] Iteration 132400, loss = 0.99605
I0520 18:56:29.229841 15139 solver.cpp:247]     Train net output #0: loss = 0.99605 (* 1 = 0.99605 loss)
I0520 18:56:29.229862 15139 sgd_solver.cpp:106] Iteration 132400, lr = 1e-05
I0520 18:56:29.389876 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:56:29.465936 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:56:29.467983 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:56:29.468011 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:56:29.468864 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.99605
I0520 18:57:47.169272 15139 solver.cpp:231] Iteration 132600, loss = 1.3048
I0520 18:57:47.169747 15139 solver.cpp:247]     Train net output #0: loss = 1.3048 (* 1 = 1.3048 loss)
I0520 18:57:47.169770 15139 sgd_solver.cpp:106] Iteration 132600, lr = 1e-05
I0520 18:57:47.327821 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9024	2.9	
I0520 18:57:47.402899 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:57:47.405062 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:57:47.405122 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:57:47.405733 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.3048
I0520 18:59:10.102901 15139 solver.cpp:231] Iteration 132800, loss = 1.29161
I0520 18:59:10.105657 15139 solver.cpp:247]     Train net output #0: loss = 1.29161 (* 1 = 1.29161 loss)
I0520 18:59:10.105686 15139 sgd_solver.cpp:106] Iteration 132800, lr = 1e-05
I0520 18:59:10.262545 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 18:59:10.341655 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 18:59:10.344383 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 18:59:10.344418 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 18:59:10.345033 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.29161
I0520 19:00:03.558774 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:00:28.304608 15139 solver.cpp:348] Iteration 133000, Testing net (#0)
I0520 19:01:39.031978 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:01:43.964056 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57262
I0520 19:01:43.964154 15139 solver.cpp:415]     Test net output #1: loss = 1.83625 (* 1 = 1.83625 loss)
I0520 19:01:44.051271 15139 solver.cpp:231] Iteration 133000, loss = 0.927994
I0520 19:01:44.051378 15139 solver.cpp:247]     Train net output #0: loss = 0.927994 (* 1 = 0.927994 loss)
I0520 19:01:44.051578 15139 sgd_solver.cpp:106] Iteration 133000, lr = 1e-05
I0520 19:01:44.214974 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:01:44.291854 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:01:44.293689 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:01:44.293720 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:01:44.294289 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.927994
I0520 19:03:07.841687 15139 solver.cpp:231] Iteration 133200, loss = 1.04711
I0520 19:03:07.841867 15139 solver.cpp:247]     Train net output #0: loss = 1.04711 (* 1 = 1.04711 loss)
I0520 19:03:07.841889 15139 sgd_solver.cpp:106] Iteration 133200, lr = 1e-05
I0520 19:03:08.003116 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:03:08.078192 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:03:08.080209 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:03:08.080242 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:03:08.080765 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04711
I0520 19:04:42.105015 15139 solver.cpp:231] Iteration 133400, loss = 1.22279
I0520 19:04:42.105315 15139 solver.cpp:247]     Train net output #0: loss = 1.22279 (* 1 = 1.22279 loss)
I0520 19:04:42.105337 15139 sgd_solver.cpp:106] Iteration 133400, lr = 1e-05
I0520 19:04:42.266705 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:04:42.342231 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:04:42.344147 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:04:42.344177 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:04:42.344903 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22279
I0520 19:05:59.473018 15139 solver.cpp:231] Iteration 133600, loss = 1.17958
I0520 19:05:59.473350 15139 solver.cpp:247]     Train net output #0: loss = 1.17958 (* 1 = 1.17958 loss)
I0520 19:05:59.473372 15139 sgd_solver.cpp:106] Iteration 133600, lr = 1e-05
I0520 19:05:59.632773 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:05:59.707705 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:05:59.709800 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:05:59.709836 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:05:59.710330 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17958
I0520 19:07:17.759276 15139 solver.cpp:231] Iteration 133800, loss = 1.03791
I0520 19:07:17.759534 15139 solver.cpp:247]     Train net output #0: loss = 1.03791 (* 1 = 1.03791 loss)
I0520 19:07:17.759555 15139 sgd_solver.cpp:106] Iteration 133800, lr = 1e-05
I0520 19:07:17.919638 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:07:17.994729 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:07:17.996301 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:07:17.996322 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:07:17.996907 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.03791
I0520 19:08:20.172848 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:08:52.221077 15139 solver.cpp:348] Iteration 134000, Testing net (#0)
I0520 19:10:08.098434 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:10:12.028045 15139 solver.cpp:415]     Test net output #0: accuracy = 0.572179
I0520 19:10:12.028131 15139 solver.cpp:415]     Test net output #1: loss = 1.8369 (* 1 = 1.8369 loss)
I0520 19:10:12.115218 15139 solver.cpp:231] Iteration 134000, loss = 1.15394
I0520 19:10:12.115306 15139 solver.cpp:247]     Train net output #0: loss = 1.15394 (* 1 = 1.15394 loss)
I0520 19:10:12.115325 15139 sgd_solver.cpp:106] Iteration 134000, lr = 1e-05
I0520 19:10:12.279067 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:10:12.354257 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:10:12.356878 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:10:12.356916 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:10:12.357460 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15394
I0520 19:11:31.890262 15139 solver.cpp:231] Iteration 134200, loss = 1.04727
I0520 19:11:31.890581 15139 solver.cpp:247]     Train net output #0: loss = 1.04727 (* 1 = 1.04727 loss)
I0520 19:11:31.890616 15139 sgd_solver.cpp:106] Iteration 134200, lr = 1e-05
I0520 19:11:32.051198 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:11:32.126241 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:11:32.127976 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:11:32.128008 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:11:32.128623 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04727
I0520 19:13:10.769064 15139 solver.cpp:231] Iteration 134400, loss = 0.935096
I0520 19:13:10.769300 15139 solver.cpp:247]     Train net output #0: loss = 0.935096 (* 1 = 0.935096 loss)
I0520 19:13:10.769323 15139 sgd_solver.cpp:106] Iteration 134400, lr = 1e-05
I0520 19:13:10.929461 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:13:11.004361 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:13:11.006033 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:13:11.006058 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:13:11.006562 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.935096
I0520 19:14:30.784610 15139 solver.cpp:231] Iteration 134600, loss = 1.27054
I0520 19:14:30.784976 15139 solver.cpp:247]     Train net output #0: loss = 1.27054 (* 1 = 1.27054 loss)
I0520 19:14:30.785006 15139 sgd_solver.cpp:106] Iteration 134600, lr = 1e-05
I0520 19:14:30.945407 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:14:31.020390 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:14:31.022519 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:14:31.022541 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:14:31.023165 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27054
I0520 19:15:52.715054 15139 solver.cpp:231] Iteration 134800, loss = 1.12835
I0520 19:15:52.717633 15139 solver.cpp:247]     Train net output #0: loss = 1.12835 (* 1 = 1.12835 loss)
I0520 19:15:52.717665 15139 sgd_solver.cpp:106] Iteration 134800, lr = 1e-05
I0520 19:15:52.875759 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:15:52.951287 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:15:52.953464 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:15:52.953495 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:15:52.954007 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12835
I0520 19:16:47.334270 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:17:09.256363 15139 solver.cpp:348] Iteration 135000, Testing net (#0)
I0520 19:18:22.140669 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:18:25.592918 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57198
I0520 19:18:25.593025 15139 solver.cpp:415]     Test net output #1: loss = 1.83627 (* 1 = 1.83627 loss)
I0520 19:18:25.680867 15139 solver.cpp:231] Iteration 135000, loss = 1.30572
I0520 19:18:25.680948 15139 solver.cpp:247]     Train net output #0: loss = 1.30572 (* 1 = 1.30572 loss)
I0520 19:18:25.680965 15139 sgd_solver.cpp:106] Iteration 135000, lr = 1e-05
I0520 19:18:25.838361 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:18:25.914968 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:18:25.917443 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:18:25.917479 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:18:25.918292 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30572
I0520 19:19:48.313174 15139 solver.cpp:231] Iteration 135200, loss = 1.22418
I0520 19:19:48.313436 15139 solver.cpp:247]     Train net output #0: loss = 1.22418 (* 1 = 1.22418 loss)
I0520 19:19:48.313458 15139 sgd_solver.cpp:106] Iteration 135200, lr = 1e-05
I0520 19:19:48.472790 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:19:48.548866 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:19:48.551605 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:19:48.551666 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:19:48.552196 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22418
I0520 19:21:09.241262 15139 solver.cpp:231] Iteration 135400, loss = 1.08234
I0520 19:21:09.245658 15139 solver.cpp:247]     Train net output #0: loss = 1.08234 (* 1 = 1.08234 loss)
I0520 19:21:09.245687 15139 sgd_solver.cpp:106] Iteration 135400, lr = 1e-05
I0520 19:21:09.401768 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:21:09.477022 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:21:09.479814 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:21:09.479856 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:21:09.480355 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08234
I0520 19:22:32.193280 15139 solver.cpp:231] Iteration 135600, loss = 1.06989
I0520 19:22:32.193584 15139 solver.cpp:247]     Train net output #0: loss = 1.06989 (* 1 = 1.06989 loss)
I0520 19:22:32.193605 15139 sgd_solver.cpp:106] Iteration 135600, lr = 1e-05
I0520 19:22:32.352725 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:22:32.430039 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:22:32.432245 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:22:32.432271 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:22:32.432770 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.06989
I0520 19:23:49.495905 15139 solver.cpp:231] Iteration 135800, loss = 1.16801
I0520 19:23:49.496143 15139 solver.cpp:247]     Train net output #0: loss = 1.16801 (* 1 = 1.16801 loss)
I0520 19:23:49.496165 15139 sgd_solver.cpp:106] Iteration 135800, lr = 1e-05
I0520 19:23:49.655191 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:23:49.730433 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:23:49.733506 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:23:49.733559 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:23:49.734093 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16801
I0520 19:24:52.944149 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:25:12.045277 15139 solver.cpp:348] Iteration 136000, Testing net (#0)
I0520 19:26:23.256093 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:26:27.178338 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57252
I0520 19:26:27.178426 15139 solver.cpp:415]     Test net output #1: loss = 1.83618 (* 1 = 1.83618 loss)
I0520 19:26:27.265239 15139 solver.cpp:231] Iteration 136000, loss = 1.04854
I0520 19:26:27.265316 15139 solver.cpp:247]     Train net output #0: loss = 1.04854 (* 1 = 1.04854 loss)
I0520 19:26:27.265333 15139 sgd_solver.cpp:106] Iteration 136000, lr = 1e-05
I0520 19:26:27.425258 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:26:27.500022 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:26:27.502509 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:26:27.502552 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:26:27.503186 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04854
I0520 19:27:49.160414 15139 solver.cpp:231] Iteration 136200, loss = 1.02315
I0520 19:27:49.161612 15139 solver.cpp:247]     Train net output #0: loss = 1.02315 (* 1 = 1.02315 loss)
I0520 19:27:49.161634 15139 sgd_solver.cpp:106] Iteration 136200, lr = 1e-05
I0520 19:27:49.319641 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:27:49.395531 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:27:49.397570 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:27:49.397593 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:27:49.398033 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.02315
I0520 19:29:10.499282 15139 solver.cpp:231] Iteration 136400, loss = 1.16537
I0520 19:29:10.499591 15139 solver.cpp:247]     Train net output #0: loss = 1.16537 (* 1 = 1.16537 loss)
I0520 19:29:10.499691 15139 sgd_solver.cpp:106] Iteration 136400, lr = 1e-05
I0520 19:29:10.659485 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:29:10.735373 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:29:10.737996 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:29:10.738026 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:29:10.738582 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16537
I0520 19:30:28.237247 15139 solver.cpp:231] Iteration 136600, loss = 1.32766
I0520 19:30:28.238466 15139 solver.cpp:247]     Train net output #0: loss = 1.32766 (* 1 = 1.32766 loss)
I0520 19:30:28.238499 15139 sgd_solver.cpp:106] Iteration 136600, lr = 1e-05
I0520 19:30:28.396170 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:30:28.471387 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:30:28.474434 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:30:28.474478 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:30:28.474988 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32766
I0520 19:31:52.880241 15139 solver.cpp:231] Iteration 136800, loss = 1.19945
I0520 19:31:52.880560 15139 solver.cpp:247]     Train net output #0: loss = 1.19945 (* 1 = 1.19945 loss)
I0520 19:31:52.880590 15139 sgd_solver.cpp:106] Iteration 136800, lr = 1e-05
I0520 19:31:53.040010 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:31:53.114408 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:31:53.115983 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:31:53.116001 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:31:53.116430 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19945
I0520 19:33:00.781893 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:33:16.055490 15139 solver.cpp:348] Iteration 137000, Testing net (#0)
I0520 19:34:33.806871 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:34:36.885607 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57304
I0520 19:34:36.885694 15139 solver.cpp:415]     Test net output #1: loss = 1.83605 (* 1 = 1.83605 loss)
I0520 19:34:36.975622 15139 solver.cpp:231] Iteration 137000, loss = 1.20645
I0520 19:34:36.975682 15139 solver.cpp:247]     Train net output #0: loss = 1.20645 (* 1 = 1.20645 loss)
I0520 19:34:36.975697 15139 sgd_solver.cpp:106] Iteration 137000, lr = 1e-05
I0520 19:34:37.135989 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:34:37.210373 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:34:37.211901 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:34:37.211922 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:34:37.212277 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20645
I0520 19:36:07.317925 15139 solver.cpp:231] Iteration 137200, loss = 1.1234
I0520 19:36:07.318272 15139 solver.cpp:247]     Train net output #0: loss = 1.1234 (* 1 = 1.1234 loss)
I0520 19:36:07.318296 15139 sgd_solver.cpp:106] Iteration 137200, lr = 1e-05
I0520 19:36:07.478827 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:36:07.553242 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:36:07.555321 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:36:07.555342 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:36:07.555758 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1234
I0520 19:37:28.432974 15139 solver.cpp:231] Iteration 137400, loss = 1.26333
I0520 19:37:28.433301 15139 solver.cpp:247]     Train net output #0: loss = 1.26333 (* 1 = 1.26333 loss)
I0520 19:37:28.433326 15139 sgd_solver.cpp:106] Iteration 137400, lr = 1e-05
I0520 19:37:28.592767 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:37:28.668447 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:37:28.670114 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:37:28.670145 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:37:28.670871 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26333
I0520 19:38:50.965031 15139 solver.cpp:231] Iteration 137600, loss = 1.03447
I0520 19:38:50.965294 15139 solver.cpp:247]     Train net output #0: loss = 1.03447 (* 1 = 1.03447 loss)
I0520 19:38:50.965317 15139 sgd_solver.cpp:106] Iteration 137600, lr = 1e-05
I0520 19:38:51.125428 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:38:51.200309 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:38:51.202064 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:38:51.202095 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:38:51.202584 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.03447
I0520 19:40:16.151531 15139 solver.cpp:231] Iteration 137800, loss = 1.27782
I0520 19:40:16.151787 15139 solver.cpp:247]     Train net output #0: loss = 1.27782 (* 1 = 1.27782 loss)
I0520 19:40:16.151813 15139 sgd_solver.cpp:106] Iteration 137800, lr = 1e-05
I0520 19:40:16.312490 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:40:16.387218 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:40:16.388830 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:40:16.388855 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:40:16.389364 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27782
I0520 19:41:23.120257 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:41:35.926578 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_138000.caffemodel
I0520 19:42:01.256060 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_138000.solverstate
I0520 19:42:01.737771 15139 solver.cpp:348] Iteration 138000, Testing net (#0)
I0520 19:43:20.291947 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:43:23.042364 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57258
I0520 19:43:23.042476 15139 solver.cpp:415]     Test net output #1: loss = 1.83583 (* 1 = 1.83583 loss)
I0520 19:43:23.129546 15139 solver.cpp:231] Iteration 138000, loss = 1.04546
I0520 19:43:23.129632 15139 solver.cpp:247]     Train net output #0: loss = 1.04546 (* 1 = 1.04546 loss)
I0520 19:43:23.129652 15139 sgd_solver.cpp:106] Iteration 138000, lr = 1e-05
I0520 19:43:23.294234 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:43:23.296440 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:43:23.299096 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:43:23.299120 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:43:23.299804 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04546
I0520 19:44:43.640601 15139 solver.cpp:231] Iteration 138200, loss = 1.06714
I0520 19:44:43.641600 15139 solver.cpp:247]     Train net output #0: loss = 1.06714 (* 1 = 1.06714 loss)
I0520 19:44:43.641620 15139 sgd_solver.cpp:106] Iteration 138200, lr = 1e-05
I0520 19:44:43.800770 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:44:43.876816 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:44:43.879668 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:44:43.879709 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:44:43.880300 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.06714
I0520 19:46:02.415215 15139 solver.cpp:231] Iteration 138400, loss = 1.19705
I0520 19:46:02.415459 15139 solver.cpp:247]     Train net output #0: loss = 1.19705 (* 1 = 1.19705 loss)
I0520 19:46:02.415479 15139 sgd_solver.cpp:106] Iteration 138400, lr = 1e-05
I0520 19:46:02.575343 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:46:02.651420 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:46:02.653816 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:46:02.653851 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:46:02.654398 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19705
I0520 19:47:25.726194 15139 solver.cpp:231] Iteration 138600, loss = 1.12104
I0520 19:47:25.726439 15139 solver.cpp:247]     Train net output #0: loss = 1.12104 (* 1 = 1.12104 loss)
I0520 19:47:25.726459 15139 sgd_solver.cpp:106] Iteration 138600, lr = 1e-05
I0520 19:47:25.885149 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:47:25.960165 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:47:25.962890 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:47:25.962931 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:47:25.963433 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12104
I0520 19:48:47.974021 15139 solver.cpp:231] Iteration 138800, loss = 1.08009
I0520 19:48:47.974331 15139 solver.cpp:247]     Train net output #0: loss = 1.08009 (* 1 = 1.08009 loss)
I0520 19:48:47.974355 15139 sgd_solver.cpp:106] Iteration 138800, lr = 1e-05
I0520 19:48:48.133765 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:48:48.209378 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:48:48.211015 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:48:48.211040 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:48:48.211793 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08009
I0520 19:49:57.793674 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:50:08.170006 15139 solver.cpp:348] Iteration 139000, Testing net (#0)
I0520 19:51:24.172082 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:51:25.974964 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57262
I0520 19:51:25.975054 15139 solver.cpp:415]     Test net output #1: loss = 1.83677 (* 1 = 1.83677 loss)
I0520 19:51:26.064625 15139 solver.cpp:231] Iteration 139000, loss = 0.99092
I0520 19:51:26.064702 15139 solver.cpp:247]     Train net output #0: loss = 0.99092 (* 1 = 0.99092 loss)
I0520 19:51:26.064720 15139 sgd_solver.cpp:106] Iteration 139000, lr = 1e-05
I0520 19:51:26.224151 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:51:26.300565 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:51:26.302803 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:51:26.302840 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:51:26.303444 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.99092
I0520 19:52:48.909276 15139 solver.cpp:231] Iteration 139200, loss = 1.23757
I0520 19:52:48.909566 15139 solver.cpp:247]     Train net output #0: loss = 1.23757 (* 1 = 1.23757 loss)
I0520 19:52:48.909587 15139 sgd_solver.cpp:106] Iteration 139200, lr = 1e-05
I0520 19:52:49.070487 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:52:49.146509 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:52:49.149315 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:52:49.149354 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:52:49.151995 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23757
I0520 19:54:11.445822 15139 solver.cpp:231] Iteration 139400, loss = 1.18478
I0520 19:54:11.446082 15139 solver.cpp:247]     Train net output #0: loss = 1.18478 (* 1 = 1.18478 loss)
I0520 19:54:11.446106 15139 sgd_solver.cpp:106] Iteration 139400, lr = 1e-05
I0520 19:54:11.604965 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:54:11.680827 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:54:11.683365 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:54:11.683404 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:54:11.683990 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18478
I0520 19:55:33.369089 15139 solver.cpp:231] Iteration 139600, loss = 1.36401
I0520 19:55:33.373636 15139 solver.cpp:247]     Train net output #0: loss = 1.36401 (* 1 = 1.36401 loss)
I0520 19:55:33.373664 15139 sgd_solver.cpp:106] Iteration 139600, lr = 1e-05
I0520 19:55:33.529053 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:55:33.604091 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:55:33.606861 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:55:33.606902 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:55:33.607399 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.36401
I0520 19:56:52.925901 15139 solver.cpp:231] Iteration 139800, loss = 1.04148
I0520 19:56:52.926256 15139 solver.cpp:247]     Train net output #0: loss = 1.04148 (* 1 = 1.04148 loss)
I0520 19:56:52.926278 15139 sgd_solver.cpp:106] Iteration 139800, lr = 1e-05
I0520 19:56:53.086402 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:56:53.161350 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:56:53.163928 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:56:53.163960 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:56:53.164471 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04148
I0520 19:58:04.380728 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:58:11.569175 15139 solver.cpp:348] Iteration 140000, Testing net (#0)
I0520 19:59:29.810858 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 19:59:31.220965 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57264
I0520 19:59:31.221057 15139 solver.cpp:415]     Test net output #1: loss = 1.8365 (* 1 = 1.8365 loss)
I0520 19:59:31.309031 15139 solver.cpp:231] Iteration 140000, loss = 1.25578
I0520 19:59:31.309111 15139 solver.cpp:247]     Train net output #0: loss = 1.25578 (* 1 = 1.25578 loss)
I0520 19:59:31.309129 15139 sgd_solver.cpp:106] Iteration 140000, lr = 1e-05
I0520 19:59:31.468256 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 19:59:31.544922 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 19:59:31.547718 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 19:59:31.547768 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 19:59:31.548416 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25578
I0520 20:00:52.676162 15139 solver.cpp:231] Iteration 140200, loss = 1.16784
I0520 20:00:52.676434 15139 solver.cpp:247]     Train net output #0: loss = 1.16784 (* 1 = 1.16784 loss)
I0520 20:00:52.676455 15139 sgd_solver.cpp:106] Iteration 140200, lr = 1e-05
I0520 20:00:52.837172 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:00:52.912550 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:00:52.914785 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:00:52.914835 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:00:52.915526 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16784
I0520 20:02:11.048740 15139 solver.cpp:231] Iteration 140400, loss = 1.25072
I0520 20:02:11.048987 15139 solver.cpp:247]     Train net output #0: loss = 1.25072 (* 1 = 1.25072 loss)
I0520 20:02:11.049010 15139 sgd_solver.cpp:106] Iteration 140400, lr = 1e-05
I0520 20:02:11.208732 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:02:11.284584 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:02:11.286974 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:02:11.287047 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:02:11.287618 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25072
I0520 20:03:35.637354 15139 solver.cpp:231] Iteration 140600, loss = 0.99239
I0520 20:03:35.637776 15139 solver.cpp:247]     Train net output #0: loss = 0.99239 (* 1 = 0.99239 loss)
I0520 20:03:35.637797 15139 sgd_solver.cpp:106] Iteration 140600, lr = 1e-05
I0520 20:03:35.796938 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:03:35.871888 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:03:35.874478 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:03:35.874513 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:03:35.875006 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.99239
I0520 20:04:57.012917 15139 solver.cpp:231] Iteration 140800, loss = 1.13394
I0520 20:04:57.013159 15139 solver.cpp:247]     Train net output #0: loss = 1.13394 (* 1 = 1.13394 loss)
I0520 20:04:57.013190 15139 sgd_solver.cpp:106] Iteration 140800, lr = 1e-05
I0520 20:04:57.173152 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:04:57.247915 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:04:57.249565 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:04:57.249593 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:04:57.250116 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13394
I0520 20:06:15.673203 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:06:19.942351 15139 solver.cpp:348] Iteration 141000, Testing net (#0)
I0520 20:07:39.382071 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:07:40.157624 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57232
I0520 20:07:40.157721 15139 solver.cpp:415]     Test net output #1: loss = 1.83636 (* 1 = 1.83636 loss)
I0520 20:07:40.244802 15139 solver.cpp:231] Iteration 141000, loss = 1.25564
I0520 20:07:40.244882 15139 solver.cpp:247]     Train net output #0: loss = 1.25564 (* 1 = 1.25564 loss)
I0520 20:07:40.244899 15139 sgd_solver.cpp:106] Iteration 141000, lr = 1e-05
I0520 20:07:40.409561 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:07:40.484454 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:07:40.486943 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:07:40.486981 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:07:40.487462 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25564
I0520 20:08:59.301482 15139 solver.cpp:231] Iteration 141200, loss = 1.08178
I0520 20:08:59.301759 15139 solver.cpp:247]     Train net output #0: loss = 1.08178 (* 1 = 1.08178 loss)
I0520 20:08:59.301779 15139 sgd_solver.cpp:106] Iteration 141200, lr = 1e-05
I0520 20:08:59.462345 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:08:59.538130 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:08:59.540132 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:08:59.540158 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:08:59.540683 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08178
I0520 20:10:16.639525 15139 solver.cpp:231] Iteration 141400, loss = 1.05802
I0520 20:10:16.639900 15139 solver.cpp:247]     Train net output #0: loss = 1.05802 (* 1 = 1.05802 loss)
I0520 20:10:16.639921 15139 sgd_solver.cpp:106] Iteration 141400, lr = 1e-05
I0520 20:10:16.799477 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:10:16.874502 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:10:16.876416 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:10:16.876444 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:10:16.876929 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.05802
I0520 20:11:34.778149 15139 solver.cpp:231] Iteration 141600, loss = 1.26266
I0520 20:11:34.778412 15139 solver.cpp:247]     Train net output #0: loss = 1.26266 (* 1 = 1.26266 loss)
I0520 20:11:34.778432 15139 sgd_solver.cpp:106] Iteration 141600, lr = 1e-05
I0520 20:11:34.937650 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:11:35.011988 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:11:35.013706 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:11:35.013730 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:11:35.014224 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26266
I0520 20:12:53.589928 15139 solver.cpp:231] Iteration 141800, loss = 1.27931
I0520 20:12:53.590330 15139 solver.cpp:247]     Train net output #0: loss = 1.27931 (* 1 = 1.27931 loss)
I0520 20:12:53.590351 15139 sgd_solver.cpp:106] Iteration 141800, lr = 1e-05
I0520 20:12:53.750207 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:12:53.824987 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:12:53.826954 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:12:53.826980 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:12:53.827457 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27931
I0520 20:14:09.214537 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:14:11.112609 15139 solver.cpp:348] Iteration 142000, Testing net (#0)
I0520 20:15:27.052212 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:15:27.152168 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57278
I0520 20:15:27.152243 15139 solver.cpp:415]     Test net output #1: loss = 1.83553 (* 1 = 1.83553 loss)
I0520 20:15:27.239734 15139 solver.cpp:231] Iteration 142000, loss = 1.21136
I0520 20:15:27.239799 15139 solver.cpp:247]     Train net output #0: loss = 1.21136 (* 1 = 1.21136 loss)
I0520 20:15:27.239816 15139 sgd_solver.cpp:106] Iteration 142000, lr = 1e-05
I0520 20:15:27.399253 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:15:27.473976 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:15:27.475921 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:15:27.475956 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:15:27.476449 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21136
I0520 20:16:46.288496 15139 solver.cpp:231] Iteration 142200, loss = 1.21263
I0520 20:16:46.289607 15139 solver.cpp:247]     Train net output #0: loss = 1.21263 (* 1 = 1.21263 loss)
I0520 20:16:46.289628 15139 sgd_solver.cpp:106] Iteration 142200, lr = 1e-05
I0520 20:16:46.449126 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:16:46.523814 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:16:46.525679 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:16:46.525707 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:16:46.526235 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21263
I0520 20:18:03.922525 15139 solver.cpp:231] Iteration 142400, loss = 1.23829
I0520 20:18:03.922826 15139 solver.cpp:247]     Train net output #0: loss = 1.23829 (* 1 = 1.23829 loss)
I0520 20:18:03.922847 15139 sgd_solver.cpp:106] Iteration 142400, lr = 1e-05
I0520 20:18:04.081197 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:18:04.155342 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:18:04.157136 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:18:04.157163 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:18:04.157670 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23829
I0520 20:19:23.688375 15139 solver.cpp:231] Iteration 142600, loss = 1.21725
I0520 20:19:23.688668 15139 solver.cpp:247]     Train net output #0: loss = 1.21725 (* 1 = 1.21725 loss)
I0520 20:19:23.688702 15139 sgd_solver.cpp:106] Iteration 142600, lr = 1e-05
I0520 20:19:23.849649 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:19:23.926203 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:19:23.928333 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:19:23.928365 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:19:23.929111 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21725
I0520 20:20:44.865089 15139 solver.cpp:231] Iteration 142800, loss = 1.02542
I0520 20:20:44.869638 15139 solver.cpp:247]     Train net output #0: loss = 1.02542 (* 1 = 1.02542 loss)
I0520 20:20:44.869668 15139 sgd_solver.cpp:106] Iteration 142800, lr = 1e-05
I0520 20:20:45.025460 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:20:45.100169 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:20:45.102332 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:20:45.102372 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:20:45.102879 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.02542
I0520 20:22:06.658979 15139 solver.cpp:348] Iteration 143000, Testing net (#0)
I0520 20:22:07.155517 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:23:25.257110 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57222
I0520 20:23:25.257318 15139 solver.cpp:415]     Test net output #1: loss = 1.83591 (* 1 = 1.83591 loss)
I0520 20:23:25.348898 15139 solver.cpp:231] Iteration 143000, loss = 1.23586
I0520 20:23:25.348966 15139 solver.cpp:247]     Train net output #0: loss = 1.23586 (* 1 = 1.23586 loss)
I0520 20:23:25.348984 15139 sgd_solver.cpp:106] Iteration 143000, lr = 1e-05
I0520 20:23:25.520401 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:23:25.595211 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:23:25.597388 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:23:25.597452 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:23:25.598095 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.23586
I0520 20:23:28.542407 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:24:45.440107 15139 solver.cpp:231] Iteration 143200, loss = 1.26055
I0520 20:24:45.441618 15139 solver.cpp:247]     Train net output #0: loss = 1.26055 (* 1 = 1.26055 loss)
I0520 20:24:45.441644 15139 sgd_solver.cpp:106] Iteration 143200, lr = 1e-05
I0520 20:24:45.598984 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:24:45.673655 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:24:45.675451 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:24:45.675477 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:24:45.675971 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.26055
I0520 20:26:07.962988 15139 solver.cpp:231] Iteration 143400, loss = 1.04806
I0520 20:26:07.963227 15139 solver.cpp:247]     Train net output #0: loss = 1.04806 (* 1 = 1.04806 loss)
I0520 20:26:07.963248 15139 sgd_solver.cpp:106] Iteration 143400, lr = 1e-05
I0520 20:26:08.122884 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:26:08.197697 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:26:08.199540 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:26:08.199566 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:26:08.200098 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04806
I0520 20:27:27.353396 15139 solver.cpp:231] Iteration 143600, loss = 1.11649
I0520 20:27:27.353601 15139 solver.cpp:247]     Train net output #0: loss = 1.11649 (* 1 = 1.11649 loss)
I0520 20:27:27.353621 15139 sgd_solver.cpp:106] Iteration 143600, lr = 1e-05
I0520 20:27:27.513051 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:27:27.592097 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:27:27.594082 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:27:27.594107 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:27:27.594645 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11649
I0520 20:28:39.641430 15139 solver.cpp:231] Iteration 143800, loss = 1.19839
I0520 20:28:39.641671 15139 solver.cpp:247]     Train net output #0: loss = 1.19839 (* 1 = 1.19839 loss)
I0520 20:28:39.641693 15139 sgd_solver.cpp:106] Iteration 143800, lr = 1e-05
I0520 20:28:39.802141 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:28:39.877106 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:28:39.879619 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:28:39.879660 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:28:39.880441 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19839
I0520 20:29:51.010589 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_144000.caffemodel
I0520 20:30:25.901787 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_144000.solverstate
I0520 20:30:26.380956 15139 solver.cpp:348] Iteration 144000, Testing net (#0)
I0520 20:30:27.308027 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:31:36.194444 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57228
I0520 20:31:36.194674 15139 solver.cpp:415]     Test net output #1: loss = 1.83634 (* 1 = 1.83634 loss)
I0520 20:31:36.284504 15139 solver.cpp:231] Iteration 144000, loss = 1.18455
I0520 20:31:36.284586 15139 solver.cpp:247]     Train net output #0: loss = 1.18455 (* 1 = 1.18455 loss)
I0520 20:31:36.284606 15139 sgd_solver.cpp:106] Iteration 144000, lr = 1e-05
I0520 20:31:36.454932 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9025	2.9	
I0520 20:31:36.456900 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:31:36.459318 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:31:36.459347 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:31:36.459869 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18455
I0520 20:31:42.162086 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:32:48.242862 15139 solver.cpp:231] Iteration 144200, loss = 1.01422
I0520 20:32:48.243100 15139 solver.cpp:247]     Train net output #0: loss = 1.01422 (* 1 = 1.01422 loss)
I0520 20:32:48.243120 15139 sgd_solver.cpp:106] Iteration 144200, lr = 1e-05
I0520 20:32:48.403093 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:32:48.478060 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:32:48.480804 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:32:48.480849 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:32:48.481338 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.01422
I0520 20:34:00.826623 15139 solver.cpp:231] Iteration 144400, loss = 0.904761
I0520 20:34:00.826869 15139 solver.cpp:247]     Train net output #0: loss = 0.904761 (* 1 = 0.904761 loss)
I0520 20:34:00.826890 15139 sgd_solver.cpp:106] Iteration 144400, lr = 1e-05
I0520 20:34:00.987143 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:34:01.063165 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:34:01.065778 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:34:01.065809 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:34:01.066534 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.904761
I0520 20:35:11.934098 15139 solver.cpp:231] Iteration 144600, loss = 0.91414
I0520 20:35:11.937634 15139 solver.cpp:247]     Train net output #0: loss = 0.91414 (* 1 = 0.91414 loss)
I0520 20:35:11.937664 15139 sgd_solver.cpp:106] Iteration 144600, lr = 1e-05
I0520 20:35:12.092944 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:35:12.167819 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:35:12.169692 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:35:12.169718 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:35:12.170264 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.91414
I0520 20:36:24.571281 15139 solver.cpp:231] Iteration 144800, loss = 1.25666
I0520 20:36:24.571532 15139 solver.cpp:247]     Train net output #0: loss = 1.25666 (* 1 = 1.25666 loss)
I0520 20:36:24.571554 15139 sgd_solver.cpp:106] Iteration 144800, lr = 1e-05
I0520 20:36:24.730780 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:36:24.806762 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:36:24.808575 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:36:24.808611 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:36:24.809201 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25666
I0520 20:37:35.483217 15139 solver.cpp:348] Iteration 145000, Testing net (#0)
I0520 20:37:37.076537 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:38:46.364310 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57246
I0520 20:38:46.364526 15139 solver.cpp:415]     Test net output #1: loss = 1.83623 (* 1 = 1.83623 loss)
I0520 20:38:46.467003 15139 solver.cpp:231] Iteration 145000, loss = 1.16013
I0520 20:38:46.467077 15139 solver.cpp:247]     Train net output #0: loss = 1.16013 (* 1 = 1.16013 loss)
I0520 20:38:46.467093 15139 sgd_solver.cpp:106] Iteration 145000, lr = 1e-05
I0520 20:38:46.634611 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:38:46.708716 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:38:46.710119 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:38:46.710134 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:38:46.710479 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16013
I0520 20:38:55.055263 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:39:58.188280 15139 solver.cpp:231] Iteration 145200, loss = 1.31651
I0520 20:39:58.188493 15139 solver.cpp:247]     Train net output #0: loss = 1.31651 (* 1 = 1.31651 loss)
I0520 20:39:58.188513 15139 sgd_solver.cpp:106] Iteration 145200, lr = 1e-05
I0520 20:39:58.348794 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:39:58.424453 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:39:58.426401 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:39:58.426427 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:39:58.426951 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.31651
I0520 20:41:09.262056 15139 solver.cpp:231] Iteration 145400, loss = 1.20135
I0520 20:41:09.262248 15139 solver.cpp:247]     Train net output #0: loss = 1.20135 (* 1 = 1.20135 loss)
I0520 20:41:09.262267 15139 sgd_solver.cpp:106] Iteration 145400, lr = 1e-05
I0520 20:41:09.422796 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:41:09.497913 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:41:09.499411 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:41:09.499428 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:41:09.499877 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20135
I0520 20:42:20.270088 15139 solver.cpp:231] Iteration 145600, loss = 1.07646
I0520 20:42:20.270259 15139 solver.cpp:247]     Train net output #0: loss = 1.07646 (* 1 = 1.07646 loss)
I0520 20:42:20.270279 15139 sgd_solver.cpp:106] Iteration 145600, lr = 1e-05
I0520 20:42:20.429543 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:42:20.504751 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:42:20.506403 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:42:20.506448 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:42:20.506923 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.07646
I0520 20:43:31.853936 15139 solver.cpp:231] Iteration 145800, loss = 1.20504
I0520 20:43:31.854209 15139 solver.cpp:247]     Train net output #0: loss = 1.20504 (* 1 = 1.20504 loss)
I0520 20:43:31.854354 15139 sgd_solver.cpp:106] Iteration 145800, lr = 1e-05
I0520 20:43:32.015728 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:43:32.089841 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:43:32.091248 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:43:32.091262 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:43:32.091599 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.20504
I0520 20:44:43.680881 15139 solver.cpp:348] Iteration 146000, Testing net (#0)
I0520 20:44:46.076699 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:45:53.312501 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57278
I0520 20:45:53.312760 15139 solver.cpp:415]     Test net output #1: loss = 1.83615 (* 1 = 1.83615 loss)
I0520 20:45:53.399989 15139 solver.cpp:231] Iteration 146000, loss = 1.30565
I0520 20:45:53.400053 15139 solver.cpp:247]     Train net output #0: loss = 1.30565 (* 1 = 1.30565 loss)
I0520 20:45:53.400071 15139 sgd_solver.cpp:106] Iteration 146000, lr = 1e-05
I0520 20:45:53.564201 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:45:53.638571 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:45:53.640135 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:45:53.640153 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:45:53.640560 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30565
I0520 20:46:04.387084 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:47:03.948168 15139 solver.cpp:231] Iteration 146200, loss = 1.13576
I0520 20:47:03.948351 15139 solver.cpp:247]     Train net output #0: loss = 1.13576 (* 1 = 1.13576 loss)
I0520 20:47:03.948372 15139 sgd_solver.cpp:106] Iteration 146200, lr = 1e-05
I0520 20:47:04.110326 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:47:04.185854 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:47:04.187789 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:47:04.187808 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:47:04.188356 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13576
I0520 20:48:15.996660 15139 solver.cpp:231] Iteration 146400, loss = 1.01872
I0520 20:48:15.996850 15139 solver.cpp:247]     Train net output #0: loss = 1.01872 (* 1 = 1.01872 loss)
I0520 20:48:15.996865 15139 sgd_solver.cpp:106] Iteration 146400, lr = 1e-05
I0520 20:48:16.156402 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:48:16.231351 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:48:16.232766 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:48:16.232779 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:48:16.233175 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.01872
I0520 20:49:28.665220 15139 solver.cpp:231] Iteration 146600, loss = 1.16037
I0520 20:49:28.665489 15139 solver.cpp:247]     Train net output #0: loss = 1.16037 (* 1 = 1.16037 loss)
I0520 20:49:28.665509 15139 sgd_solver.cpp:106] Iteration 146600, lr = 1e-05
I0520 20:49:28.825984 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:49:28.901335 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:49:28.902794 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:49:28.902812 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:49:28.903225 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16037
I0520 20:50:39.746279 15139 solver.cpp:231] Iteration 146800, loss = 1.16831
I0520 20:50:39.746480 15139 solver.cpp:247]     Train net output #0: loss = 1.16831 (* 1 = 1.16831 loss)
I0520 20:50:39.746502 15139 sgd_solver.cpp:106] Iteration 146800, lr = 1e-05
I0520 20:50:39.906239 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:50:39.984675 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:50:39.986155 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:50:39.986172 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:50:39.986610 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16831
I0520 20:51:51.063083 15139 solver.cpp:348] Iteration 147000, Testing net (#0)
I0520 20:51:53.606955 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:52:59.895906 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57264
I0520 20:52:59.896198 15139 solver.cpp:415]     Test net output #1: loss = 1.83563 (* 1 = 1.83563 loss)
I0520 20:52:59.986624 15139 solver.cpp:231] Iteration 147000, loss = 1.27265
I0520 20:52:59.986686 15139 solver.cpp:247]     Train net output #0: loss = 1.27265 (* 1 = 1.27265 loss)
I0520 20:52:59.986706 15139 sgd_solver.cpp:106] Iteration 147000, lr = 1e-05
I0520 20:53:00.154129 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:53:00.232568 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:53:00.233994 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:53:00.234007 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:53:00.234431 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.27265
I0520 20:53:13.870640 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 20:54:12.799154 15139 solver.cpp:231] Iteration 147200, loss = 1.17291
I0520 20:54:12.799387 15139 solver.cpp:247]     Train net output #0: loss = 1.17291 (* 1 = 1.17291 loss)
I0520 20:54:12.799407 15139 sgd_solver.cpp:106] Iteration 147200, lr = 1e-05
I0520 20:54:12.959064 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:54:13.034315 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:54:13.035735 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:54:13.035749 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:54:13.036157 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17291
I0520 20:55:24.665984 15139 solver.cpp:231] Iteration 147400, loss = 1.1816
I0520 20:55:24.666163 15139 solver.cpp:247]     Train net output #0: loss = 1.1816 (* 1 = 1.1816 loss)
I0520 20:55:24.666183 15139 sgd_solver.cpp:106] Iteration 147400, lr = 1e-05
I0520 20:55:24.826308 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:55:24.901659 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:55:24.903156 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:55:24.903177 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:55:24.903584 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.1816
I0520 20:56:36.578716 15139 solver.cpp:231] Iteration 147600, loss = 1.16039
I0520 20:56:36.578984 15139 solver.cpp:247]     Train net output #0: loss = 1.16039 (* 1 = 1.16039 loss)
I0520 20:56:36.579004 15139 sgd_solver.cpp:106] Iteration 147600, lr = 1e-05
I0520 20:56:36.738584 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:56:36.813741 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:56:36.815232 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:56:36.815249 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:56:36.815740 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16039
I0520 20:57:48.072988 15139 solver.cpp:231] Iteration 147800, loss = 1.08081
I0520 20:57:48.073225 15139 solver.cpp:247]     Train net output #0: loss = 1.08081 (* 1 = 1.08081 loss)
I0520 20:57:48.073245 15139 sgd_solver.cpp:106] Iteration 147800, lr = 1e-05
I0520 20:57:48.232825 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 20:57:48.306944 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 20:57:48.308404 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 20:57:48.308424 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 20:57:48.308774 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08081
I0520 20:59:00.773843 15139 solver.cpp:348] Iteration 148000, Testing net (#0)
I0520 20:59:03.825156 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:00:09.353245 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57276
I0520 21:00:09.353440 15139 solver.cpp:415]     Test net output #1: loss = 1.83569 (* 1 = 1.83569 loss)
I0520 21:00:09.440433 15139 solver.cpp:231] Iteration 148000, loss = 1.19073
I0520 21:00:09.440495 15139 solver.cpp:247]     Train net output #0: loss = 1.19073 (* 1 = 1.19073 loss)
I0520 21:00:09.440511 15139 sgd_solver.cpp:106] Iteration 148000, lr = 1e-05
I0520 21:00:09.604900 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:00:09.679224 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:00:09.680642 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:00:09.680655 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:00:09.681020 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19073
I0520 21:00:26.505437 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:01:22.587044 15139 solver.cpp:231] Iteration 148200, loss = 1.14515
I0520 21:01:22.587234 15139 solver.cpp:247]     Train net output #0: loss = 1.14515 (* 1 = 1.14515 loss)
I0520 21:01:22.587252 15139 sgd_solver.cpp:106] Iteration 148200, lr = 1e-05
I0520 21:01:22.747942 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:01:22.823132 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:01:22.824698 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:01:22.824714 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:01:22.825187 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14515
I0520 21:02:33.955430 15139 solver.cpp:231] Iteration 148400, loss = 1.05087
I0520 21:02:33.955698 15139 solver.cpp:247]     Train net output #0: loss = 1.05087 (* 1 = 1.05087 loss)
I0520 21:02:33.955718 15139 sgd_solver.cpp:106] Iteration 148400, lr = 1e-05
I0520 21:02:34.115595 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:02:34.190083 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:02:34.191500 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:02:34.191516 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:02:34.191875 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.05087
I0520 21:03:45.903270 15139 solver.cpp:231] Iteration 148600, loss = 1.19674
I0520 21:03:45.903461 15139 solver.cpp:247]     Train net output #0: loss = 1.19674 (* 1 = 1.19674 loss)
I0520 21:03:45.903481 15139 sgd_solver.cpp:106] Iteration 148600, lr = 1e-05
I0520 21:03:46.063297 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:03:46.138439 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:03:46.139961 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:03:46.139982 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:03:46.140460 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19674
I0520 21:04:57.368922 15139 solver.cpp:231] Iteration 148800, loss = 1.3261
I0520 21:04:57.369161 15139 solver.cpp:247]     Train net output #0: loss = 1.3261 (* 1 = 1.3261 loss)
I0520 21:04:57.369179 15139 sgd_solver.cpp:106] Iteration 148800, lr = 1e-05
I0520 21:04:57.531023 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:04:57.606204 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:04:57.607709 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:04:57.607734 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:04:57.608157 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.3261
I0520 21:06:09.327270 15139 solver.cpp:348] Iteration 149000, Testing net (#0)
I0520 21:06:13.001473 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:07:18.216848 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57232
I0520 21:07:18.217025 15139 solver.cpp:415]     Test net output #1: loss = 1.83678 (* 1 = 1.83678 loss)
I0520 21:07:18.303980 15139 solver.cpp:231] Iteration 149000, loss = 1.18134
I0520 21:07:18.304049 15139 solver.cpp:247]     Train net output #0: loss = 1.18134 (* 1 = 1.18134 loss)
I0520 21:07:18.304064 15139 sgd_solver.cpp:106] Iteration 149000, lr = 1e-05
I0520 21:07:18.465499 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:07:18.540277 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:07:18.541775 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:07:18.541793 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:07:18.542296 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18134
I0520 21:07:37.786852 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:08:29.173205 15139 solver.cpp:231] Iteration 149200, loss = 1.28272
I0520 21:08:29.173497 15139 solver.cpp:247]     Train net output #0: loss = 1.28272 (* 1 = 1.28272 loss)
I0520 21:08:29.173517 15139 sgd_solver.cpp:106] Iteration 149200, lr = 1e-05
I0520 21:08:29.333153 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:08:29.408377 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:08:29.409837 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:08:29.409852 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:08:29.410286 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.28272
I0520 21:09:40.414532 15139 solver.cpp:231] Iteration 149400, loss = 1.30854
I0520 21:09:40.414758 15139 solver.cpp:247]     Train net output #0: loss = 1.30854 (* 1 = 1.30854 loss)
I0520 21:09:40.414780 15139 sgd_solver.cpp:106] Iteration 149400, lr = 1e-05
I0520 21:09:40.573369 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:09:40.653491 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:09:40.654876 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:09:40.654891 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:09:40.655302 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30854
I0520 21:10:51.397186 15139 solver.cpp:231] Iteration 149600, loss = 0.981249
I0520 21:10:51.397363 15139 solver.cpp:247]     Train net output #0: loss = 0.981249 (* 1 = 0.981249 loss)
I0520 21:10:51.397383 15139 sgd_solver.cpp:106] Iteration 149600, lr = 1e-05
I0520 21:10:51.557373 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:10:51.632647 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:10:51.634171 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:10:51.634191 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:10:51.634685 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.981249
I0520 21:12:04.413794 15139 solver.cpp:231] Iteration 149800, loss = 1.21467
I0520 21:12:04.414001 15139 solver.cpp:247]     Train net output #0: loss = 1.21467 (* 1 = 1.21467 loss)
I0520 21:12:04.414021 15139 sgd_solver.cpp:106] Iteration 149800, lr = 1e-05
I0520 21:12:04.575458 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:12:04.650606 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:12:04.652098 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:12:04.652115 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:12:04.652582 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21467
I0520 21:13:16.228765 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_150000.caffemodel
I0520 21:14:42.747114 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_150000.solverstate
I0520 21:14:43.445178 15139 solver.cpp:348] Iteration 150000, Testing net (#0)
I0520 21:14:47.682588 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:15:53.979410 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57282
I0520 21:15:53.979671 15139 solver.cpp:415]     Test net output #1: loss = 1.83575 (* 1 = 1.83575 loss)
I0520 21:15:54.066865 15139 solver.cpp:231] Iteration 150000, loss = 1.11494
I0520 21:15:54.066954 15139 solver.cpp:247]     Train net output #0: loss = 1.11494 (* 1 = 1.11494 loss)
I0520 21:15:54.066973 15139 sgd_solver.cpp:46] MultiStep Status: Iteration 150000, step = 3
I0520 21:15:54.066982 15139 sgd_solver.cpp:106] Iteration 150000, lr = 1e-06
I0520 21:15:54.231886 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:15:54.233058 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:15:54.234452 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:15:54.234465 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:15:54.234809 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11494
I0520 21:16:16.147758 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:17:06.156102 15139 solver.cpp:231] Iteration 150200, loss = 1.0278
I0520 21:17:06.156349 15139 solver.cpp:247]     Train net output #0: loss = 1.0278 (* 1 = 1.0278 loss)
I0520 21:17:06.156366 15139 sgd_solver.cpp:106] Iteration 150200, lr = 1e-06
I0520 21:17:06.316143 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:17:06.391760 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:17:06.393154 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:17:06.393168 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:17:06.393563 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.0278
I0520 21:18:19.001112 15139 solver.cpp:231] Iteration 150400, loss = 1.25889
I0520 21:18:19.006070 15139 solver.cpp:247]     Train net output #0: loss = 1.25889 (* 1 = 1.25889 loss)
I0520 21:18:19.006099 15139 sgd_solver.cpp:106] Iteration 150400, lr = 1e-06
I0520 21:18:19.162924 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:18:19.241374 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:18:19.242832 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:18:19.242848 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:18:19.243244 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25889
I0520 21:19:35.485232 15139 solver.cpp:231] Iteration 150600, loss = 1.10422
I0520 21:19:35.485467 15139 solver.cpp:247]     Train net output #0: loss = 1.10422 (* 1 = 1.10422 loss)
I0520 21:19:35.485488 15139 sgd_solver.cpp:106] Iteration 150600, lr = 1e-06
I0520 21:19:35.645946 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:19:35.725540 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:19:35.727013 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:19:35.727031 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:19:35.727461 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10422
I0520 21:20:47.358979 15139 solver.cpp:231] Iteration 150800, loss = 1.22861
I0520 21:20:47.359194 15139 solver.cpp:247]     Train net output #0: loss = 1.22861 (* 1 = 1.22861 loss)
I0520 21:20:47.359215 15139 sgd_solver.cpp:106] Iteration 150800, lr = 1e-06
I0520 21:20:47.518697 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:20:47.593961 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:20:47.595445 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:20:47.595464 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:20:47.595885 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22861
I0520 21:21:59.434517 15139 solver.cpp:348] Iteration 151000, Testing net (#0)
I0520 21:22:04.126358 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:23:08.144340 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57274
I0520 21:23:08.144523 15139 solver.cpp:415]     Test net output #1: loss = 1.8357 (* 1 = 1.8357 loss)
I0520 21:23:08.231395 15139 solver.cpp:231] Iteration 151000, loss = 1.15528
I0520 21:23:08.231461 15139 solver.cpp:247]     Train net output #0: loss = 1.15528 (* 1 = 1.15528 loss)
I0520 21:23:08.231477 15139 sgd_solver.cpp:106] Iteration 151000, lr = 1e-06
I0520 21:23:08.395632 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:23:08.470381 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:23:08.471969 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:23:08.471987 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:23:08.472460 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15528
I0520 21:23:32.215875 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:24:18.527802 15139 solver.cpp:231] Iteration 151200, loss = 1.08848
I0520 21:24:18.527967 15139 solver.cpp:247]     Train net output #0: loss = 1.08848 (* 1 = 1.08848 loss)
I0520 21:24:18.527987 15139 sgd_solver.cpp:106] Iteration 151200, lr = 1e-06
I0520 21:24:18.687228 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:24:18.762373 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:24:18.763852 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:24:18.763870 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:24:18.764350 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.08848
I0520 21:25:29.444802 15139 solver.cpp:231] Iteration 151400, loss = 1.01932
I0520 21:25:29.444993 15139 solver.cpp:247]     Train net output #0: loss = 1.01932 (* 1 = 1.01932 loss)
I0520 21:25:29.445010 15139 sgd_solver.cpp:106] Iteration 151400, lr = 1e-06
I0520 21:25:29.604425 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:25:29.679416 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:25:29.680837 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:25:29.680851 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:25:29.681249 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.01932
I0520 21:26:43.763624 15139 solver.cpp:231] Iteration 151600, loss = 1.30764
I0520 21:26:43.763857 15139 solver.cpp:247]     Train net output #0: loss = 1.30764 (* 1 = 1.30764 loss)
I0520 21:26:43.763877 15139 sgd_solver.cpp:106] Iteration 151600, lr = 1e-06
I0520 21:26:43.925869 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:26:44.001262 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:26:44.002748 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:26:44.002770 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:26:44.003216 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30764
I0520 21:27:56.308650 15139 solver.cpp:231] Iteration 151800, loss = 1.19493
I0520 21:27:56.308903 15139 solver.cpp:247]     Train net output #0: loss = 1.19493 (* 1 = 1.19493 loss)
I0520 21:27:56.308923 15139 sgd_solver.cpp:106] Iteration 151800, lr = 1e-06
I0520 21:27:56.467212 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:27:56.542387 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:27:56.543897 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:27:56.543912 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:27:56.544370 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19493
I0520 21:29:06.860082 15139 solver.cpp:348] Iteration 152000, Testing net (#0)
I0520 21:29:12.031426 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:30:16.137274 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5726
I0520 21:30:16.137491 15139 solver.cpp:415]     Test net output #1: loss = 1.83567 (* 1 = 1.83567 loss)
I0520 21:30:16.224776 15139 solver.cpp:231] Iteration 152000, loss = 1.15367
I0520 21:30:16.224843 15139 solver.cpp:247]     Train net output #0: loss = 1.15367 (* 1 = 1.15367 loss)
I0520 21:30:16.224863 15139 sgd_solver.cpp:106] Iteration 152000, lr = 1e-06
I0520 21:30:16.389816 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:30:16.464059 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:30:16.465579 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:30:16.465595 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:30:16.465950 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.15367
I0520 21:30:43.148923 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:31:28.017339 15139 solver.cpp:231] Iteration 152200, loss = 1.32607
I0520 21:31:28.017568 15139 solver.cpp:247]     Train net output #0: loss = 1.32607 (* 1 = 1.32607 loss)
I0520 21:31:28.017590 15139 sgd_solver.cpp:106] Iteration 152200, lr = 1e-06
I0520 21:31:28.176910 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:31:28.250996 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:31:28.252379 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:31:28.252393 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:31:28.252739 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.32607
I0520 21:32:40.964411 15139 solver.cpp:231] Iteration 152400, loss = 0.91995
I0520 21:32:40.964640 15139 solver.cpp:247]     Train net output #0: loss = 0.91995 (* 1 = 0.91995 loss)
I0520 21:32:40.964673 15139 sgd_solver.cpp:106] Iteration 152400, lr = 1e-06
I0520 21:32:41.126811 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:32:41.202112 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:32:41.203555 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:32:41.203572 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:32:41.203994 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.91995
I0520 21:33:54.296035 15139 solver.cpp:231] Iteration 152600, loss = 1.14651
I0520 21:33:54.296288 15139 solver.cpp:247]     Train net output #0: loss = 1.14651 (* 1 = 1.14651 loss)
I0520 21:33:54.296314 15139 sgd_solver.cpp:106] Iteration 152600, lr = 1e-06
I0520 21:33:54.456965 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:33:54.531196 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:33:54.532634 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:33:54.532655 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:33:54.533051 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14651
I0520 21:35:08.090340 15139 solver.cpp:231] Iteration 152800, loss = 1.09357
I0520 21:35:08.090534 15139 solver.cpp:247]     Train net output #0: loss = 1.09357 (* 1 = 1.09357 loss)
I0520 21:35:08.090553 15139 sgd_solver.cpp:106] Iteration 152800, lr = 1e-06
I0520 21:35:08.249572 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:35:08.324764 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:35:08.326295 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:35:08.326315 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:35:08.326802 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09357
I0520 21:36:18.561307 15139 solver.cpp:348] Iteration 153000, Testing net (#0)
I0520 21:36:24.327378 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:37:27.982305 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57264
I0520 21:37:27.982504 15139 solver.cpp:415]     Test net output #1: loss = 1.83561 (* 1 = 1.83561 loss)
I0520 21:37:28.069821 15139 solver.cpp:231] Iteration 153000, loss = 1.16042
I0520 21:37:28.069888 15139 solver.cpp:247]     Train net output #0: loss = 1.16042 (* 1 = 1.16042 loss)
I0520 21:37:28.069908 15139 sgd_solver.cpp:106] Iteration 153000, lr = 1e-06
I0520 21:37:28.230829 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:37:28.305563 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:37:28.306967 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:37:28.306982 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:37:28.307333 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16042
I0520 21:37:58.067628 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:38:39.251776 15139 solver.cpp:231] Iteration 153200, loss = 1.18271
I0520 21:38:39.251991 15139 solver.cpp:247]     Train net output #0: loss = 1.18271 (* 1 = 1.18271 loss)
I0520 21:38:39.252010 15139 sgd_solver.cpp:106] Iteration 153200, lr = 1e-06
I0520 21:38:39.413130 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:38:39.488471 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:38:39.489979 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:38:39.490005 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:38:39.490427 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18271
I0520 21:39:51.149448 15139 solver.cpp:231] Iteration 153400, loss = 1.25737
I0520 21:39:51.149649 15139 solver.cpp:247]     Train net output #0: loss = 1.25737 (* 1 = 1.25737 loss)
I0520 21:39:51.149669 15139 sgd_solver.cpp:106] Iteration 153400, lr = 1e-06
I0520 21:39:51.310468 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:39:51.389139 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:39:51.390605 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:39:51.390619 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:39:51.391044 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.25737
I0520 21:41:02.956583 15139 solver.cpp:231] Iteration 153600, loss = 1.03917
I0520 21:41:02.956827 15139 solver.cpp:247]     Train net output #0: loss = 1.03917 (* 1 = 1.03917 loss)
I0520 21:41:02.956847 15139 sgd_solver.cpp:106] Iteration 153600, lr = 1e-06
I0520 21:41:03.116524 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:41:03.191741 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:41:03.193272 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:41:03.193287 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:41:03.193765 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.03917
I0520 21:42:14.354367 15139 solver.cpp:231] Iteration 153800, loss = 1.09436
I0520 21:42:14.354552 15139 solver.cpp:247]     Train net output #0: loss = 1.09436 (* 1 = 1.09436 loss)
I0520 21:42:14.354570 15139 sgd_solver.cpp:106] Iteration 153800, lr = 1e-06
I0520 21:42:14.514127 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:42:14.588474 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:42:14.589872 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:42:14.589886 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:42:14.590246 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09436
I0520 21:43:25.338124 15139 solver.cpp:348] Iteration 154000, Testing net (#0)
I0520 21:43:31.615485 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:44:34.325884 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57244
I0520 21:44:34.326064 15139 solver.cpp:415]     Test net output #1: loss = 1.83564 (* 1 = 1.83564 loss)
I0520 21:44:34.413184 15139 solver.cpp:231] Iteration 154000, loss = 0.912972
I0520 21:44:34.413264 15139 solver.cpp:247]     Train net output #0: loss = 0.912972 (* 1 = 0.912972 loss)
I0520 21:44:34.413283 15139 sgd_solver.cpp:106] Iteration 154000, lr = 1e-06
I0520 21:44:34.580351 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:44:34.655947 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:44:34.657431 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:44:34.657451 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:44:34.658066 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.912972
I0520 21:45:07.326771 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:45:46.265072 15139 solver.cpp:231] Iteration 154200, loss = 1.05626
I0520 21:45:46.265274 15139 solver.cpp:247]     Train net output #0: loss = 1.05626 (* 1 = 1.05626 loss)
I0520 21:45:46.265293 15139 sgd_solver.cpp:106] Iteration 154200, lr = 1e-06
I0520 21:45:46.424573 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:45:46.499739 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:45:46.501296 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:45:46.501312 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:45:46.501816 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.05626
I0520 21:46:57.620549 15139 solver.cpp:231] Iteration 154400, loss = 1.29191
I0520 21:46:57.620785 15139 solver.cpp:247]     Train net output #0: loss = 1.29191 (* 1 = 1.29191 loss)
I0520 21:46:57.620805 15139 sgd_solver.cpp:106] Iteration 154400, lr = 1e-06
I0520 21:46:57.780190 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:46:57.855192 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:46:57.856638 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:46:57.856657 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:46:57.857060 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.29191
I0520 21:48:09.724019 15139 solver.cpp:231] Iteration 154600, loss = 1.10973
I0520 21:48:09.724243 15139 solver.cpp:247]     Train net output #0: loss = 1.10973 (* 1 = 1.10973 loss)
I0520 21:48:09.724264 15139 sgd_solver.cpp:106] Iteration 154600, lr = 1e-06
I0520 21:48:09.883482 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:48:09.958778 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:48:09.960175 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:48:09.960191 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:48:09.960607 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.10973
I0520 21:49:22.560540 15139 solver.cpp:231] Iteration 154800, loss = 1.22197
I0520 21:49:22.563246 15139 solver.cpp:247]     Train net output #0: loss = 1.22197 (* 1 = 1.22197 loss)
I0520 21:49:22.563268 15139 sgd_solver.cpp:106] Iteration 154800, lr = 1e-06
I0520 21:49:22.722041 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:49:22.797143 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:49:22.800812 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:49:22.800846 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:49:22.801285 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22197
I0520 21:50:34.377924 15139 solver.cpp:348] Iteration 155000, Testing net (#0)
I0520 21:50:41.028296 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:51:43.272353 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57268
I0520 21:51:43.272603 15139 solver.cpp:415]     Test net output #1: loss = 1.83561 (* 1 = 1.83561 loss)
I0520 21:51:43.359684 15139 solver.cpp:231] Iteration 155000, loss = 1.21762
I0520 21:51:43.359750 15139 solver.cpp:247]     Train net output #0: loss = 1.21762 (* 1 = 1.21762 loss)
I0520 21:51:43.359766 15139 sgd_solver.cpp:106] Iteration 155000, lr = 1e-06
I0520 21:51:43.527003 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:51:43.602008 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:51:43.603426 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:51:43.603441 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:51:43.603857 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21762
I0520 21:52:19.625488 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 21:52:57.144421 15139 solver.cpp:231] Iteration 155200, loss = 1.04741
I0520 21:52:57.144616 15139 solver.cpp:247]     Train net output #0: loss = 1.04741 (* 1 = 1.04741 loss)
I0520 21:52:57.144654 15139 sgd_solver.cpp:106] Iteration 155200, lr = 1e-06
I0520 21:52:57.303771 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:52:57.378448 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:52:57.380059 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:52:57.380080 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:52:57.380590 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.04741
I0520 21:54:12.445457 15139 solver.cpp:231] Iteration 155400, loss = 1.18672
I0520 21:54:12.445670 15139 solver.cpp:247]     Train net output #0: loss = 1.18672 (* 1 = 1.18672 loss)
I0520 21:54:12.445690 15139 sgd_solver.cpp:106] Iteration 155400, lr = 1e-06
I0520 21:54:12.606626 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:54:12.681818 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:54:12.683311 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:54:12.683327 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:54:12.683801 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.18672
I0520 21:55:23.903398 15139 solver.cpp:231] Iteration 155600, loss = 1.13842
I0520 21:55:23.903585 15139 solver.cpp:247]     Train net output #0: loss = 1.13842 (* 1 = 1.13842 loss)
I0520 21:55:23.903605 15139 sgd_solver.cpp:106] Iteration 155600, lr = 1e-06
I0520 21:55:24.064056 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:55:24.138447 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:55:24.139888 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:55:24.139904 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:55:24.140262 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.13842
I0520 21:56:34.944272 15139 solver.cpp:231] Iteration 155800, loss = 1.14002
I0520 21:56:34.944434 15139 solver.cpp:247]     Train net output #0: loss = 1.14002 (* 1 = 1.14002 loss)
I0520 21:56:34.944452 15139 sgd_solver.cpp:106] Iteration 155800, lr = 1e-06
I0520 21:56:35.104784 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 21:56:35.179869 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 21:56:35.181334 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 21:56:35.181349 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 21:56:35.181772 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14002
I0520 21:57:45.867162 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_156000.caffemodel
I0520 21:59:06.838816 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_156000.solverstate
I0520 21:59:07.386605 15139 solver.cpp:348] Iteration 156000, Testing net (#0)
I0520 21:59:14.569322 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 22:00:15.974913 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57256
I0520 22:00:15.975219 15139 solver.cpp:415]     Test net output #1: loss = 1.83572 (* 1 = 1.83572 loss)
I0520 22:00:16.062682 15139 solver.cpp:231] Iteration 156000, loss = 1.21425
I0520 22:00:16.062752 15139 solver.cpp:247]     Train net output #0: loss = 1.21425 (* 1 = 1.21425 loss)
I0520 22:00:16.062799 15139 sgd_solver.cpp:106] Iteration 156000, lr = 1e-06
I0520 22:00:16.227643 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:00:16.228932 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:00:16.230342 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:00:16.230356 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:00:16.230726 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21425
I0520 22:00:53.518851 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 22:01:26.511353 15139 solver.cpp:231] Iteration 156200, loss = 1.02625
I0520 22:01:26.511620 15139 solver.cpp:247]     Train net output #0: loss = 1.02625 (* 1 = 1.02625 loss)
I0520 22:01:26.511656 15139 sgd_solver.cpp:106] Iteration 156200, lr = 1e-06
I0520 22:01:26.671422 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:01:26.746649 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:01:26.748191 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:01:26.748214 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:01:26.748679 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.02625
I0520 22:02:39.543761 15139 solver.cpp:231] Iteration 156400, loss = 1.30054
I0520 22:02:39.543985 15139 solver.cpp:247]     Train net output #0: loss = 1.30054 (* 1 = 1.30054 loss)
I0520 22:02:39.544004 15139 sgd_solver.cpp:106] Iteration 156400, lr = 1e-06
I0520 22:02:39.703197 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:02:39.778535 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:02:39.779973 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:02:39.779988 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:02:39.780395 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.30054
I0520 22:03:51.157048 15139 solver.cpp:231] Iteration 156600, loss = 1.11582
I0520 22:03:51.157270 15139 solver.cpp:247]     Train net output #0: loss = 1.11582 (* 1 = 1.11582 loss)
I0520 22:03:51.157290 15139 sgd_solver.cpp:106] Iteration 156600, lr = 1e-06
I0520 22:03:51.317874 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:03:51.392004 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:03:51.393419 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:03:51.393434 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:03:51.393791 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.11582
I0520 22:05:02.294919 15139 solver.cpp:231] Iteration 156800, loss = 1.17937
I0520 22:05:02.295120 15139 solver.cpp:247]     Train net output #0: loss = 1.17937 (* 1 = 1.17937 loss)
I0520 22:05:02.295320 15139 sgd_solver.cpp:106] Iteration 156800, lr = 1e-06
I0520 22:05:02.457286 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:05:02.532483 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:05:02.534061 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:05:02.534085 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:05:02.534595 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.17937
I0520 22:06:14.732305 15139 solver.cpp:348] Iteration 157000, Testing net (#0)
I0520 22:06:22.471737 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 22:07:24.170112 15139 solver.cpp:415]     Test net output #0: accuracy = 0.57262
I0520 22:07:24.170308 15139 solver.cpp:415]     Test net output #1: loss = 1.83567 (* 1 = 1.83567 loss)
I0520 22:07:24.256971 15139 solver.cpp:231] Iteration 157000, loss = 1.19996
I0520 22:07:24.257030 15139 solver.cpp:247]     Train net output #0: loss = 1.19996 (* 1 = 1.19996 loss)
I0520 22:07:24.257045 15139 sgd_solver.cpp:106] Iteration 157000, lr = 1e-06
I0520 22:07:24.423387 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:07:24.497887 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:07:24.499399 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:07:24.499418 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:07:24.499819 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19996
I0520 22:08:04.843006 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 22:08:34.939038 15139 solver.cpp:231] Iteration 157200, loss = 1.21919
I0520 22:08:34.939214 15139 solver.cpp:247]     Train net output #0: loss = 1.21919 (* 1 = 1.21919 loss)
I0520 22:08:34.939234 15139 sgd_solver.cpp:106] Iteration 157200, lr = 1e-06
I0520 22:08:35.098934 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:08:35.174036 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:08:35.175668 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:08:35.175694 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:08:35.176170 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21919
I0520 22:09:45.602560 15139 solver.cpp:231] Iteration 157400, loss = 1.35505
I0520 22:09:45.602735 15139 solver.cpp:247]     Train net output #0: loss = 1.35505 (* 1 = 1.35505 loss)
I0520 22:09:45.602754 15139 sgd_solver.cpp:106] Iteration 157400, lr = 1e-06
I0520 22:09:45.762660 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:09:45.837784 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:09:45.839493 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:09:45.839520 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:09:45.840044 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.35505
I0520 22:10:56.872428 15139 solver.cpp:231] Iteration 157600, loss = 1.19661
I0520 22:10:56.872617 15139 solver.cpp:247]     Train net output #0: loss = 1.19661 (* 1 = 1.19661 loss)
I0520 22:10:56.872634 15139 sgd_solver.cpp:106] Iteration 157600, lr = 1e-06
I0520 22:10:57.033359 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:10:57.108628 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:10:57.110119 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:10:57.110136 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:10:57.110605 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.19661
I0520 22:12:08.018775 15139 solver.cpp:231] Iteration 157800, loss = 1.16468
I0520 22:12:08.019037 15139 solver.cpp:247]     Train net output #0: loss = 1.16468 (* 1 = 1.16468 loss)
I0520 22:12:08.019068 15139 sgd_solver.cpp:106] Iteration 157800, lr = 1e-06
I0520 22:12:08.177569 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:12:08.251670 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:12:08.253073 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:12:08.253089 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:12:08.253440 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.16468
I0520 22:13:18.939795 15139 solver.cpp:348] Iteration 158000, Testing net (#0)
I0520 22:13:27.272006 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 22:14:28.106359 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5727
I0520 22:14:28.106559 15139 solver.cpp:415]     Test net output #1: loss = 1.83558 (* 1 = 1.83558 loss)
I0520 22:14:28.193662 15139 solver.cpp:231] Iteration 158000, loss = 1.34814
I0520 22:14:28.193717 15139 solver.cpp:247]     Train net output #0: loss = 1.34814 (* 1 = 1.34814 loss)
I0520 22:14:28.193730 15139 sgd_solver.cpp:106] Iteration 158000, lr = 1e-06
I0520 22:14:28.361775 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:14:28.436357 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:14:28.437919 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:14:28.437947 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:14:28.438398 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.34814
I0520 22:15:11.578917 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 22:15:38.918706 15139 solver.cpp:231] Iteration 158200, loss = 1.09634
I0520 22:15:38.918783 15139 solver.cpp:247]     Train net output #0: loss = 1.09634 (* 1 = 1.09634 loss)
I0520 22:15:38.918800 15139 sgd_solver.cpp:106] Iteration 158200, lr = 1e-06
I0520 22:15:39.078837 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:15:39.154073 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:15:39.155514 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:15:39.155529 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:15:39.155938 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.09634
I0520 22:16:49.750288 15139 solver.cpp:231] Iteration 158400, loss = 1.21807
I0520 22:16:49.750499 15139 solver.cpp:247]     Train net output #0: loss = 1.21807 (* 1 = 1.21807 loss)
I0520 22:16:49.750519 15139 sgd_solver.cpp:106] Iteration 158400, lr = 1e-06
I0520 22:16:49.910152 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:16:49.991089 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:16:49.992594 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:16:49.992609 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:16:49.993080 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21807
I0520 22:18:00.587170 15139 solver.cpp:231] Iteration 158600, loss = 1.22718
I0520 22:18:00.587368 15139 solver.cpp:247]     Train net output #0: loss = 1.22718 (* 1 = 1.22718 loss)
I0520 22:18:00.587388 15139 sgd_solver.cpp:106] Iteration 158600, lr = 1e-06
I0520 22:18:00.747966 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:18:00.823210 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:18:00.824789 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:18:00.824810 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:18:00.825304 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.22718
I0520 22:19:11.707319 15139 solver.cpp:231] Iteration 158800, loss = 1.14463
I0520 22:19:11.707561 15139 solver.cpp:247]     Train net output #0: loss = 1.14463 (* 1 = 1.14463 loss)
I0520 22:19:11.707581 15139 sgd_solver.cpp:106] Iteration 158800, lr = 1e-06
I0520 22:19:11.867163 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:19:11.942350 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:19:11.943881 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:19:11.943897 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:19:11.944406 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.14463
I0520 22:20:22.148841 15139 solver.cpp:348] Iteration 159000, Testing net (#0)
I0520 22:20:31.229457 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 22:21:31.890508 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5727
I0520 22:21:31.890702 15139 solver.cpp:415]     Test net output #1: loss = 1.83569 (* 1 = 1.83569 loss)
I0520 22:21:31.977565 15139 solver.cpp:231] Iteration 159000, loss = 1.12364
I0520 22:21:31.977635 15139 solver.cpp:247]     Train net output #0: loss = 1.12364 (* 1 = 1.12364 loss)
I0520 22:21:31.977653 15139 sgd_solver.cpp:106] Iteration 159000, lr = 1e-06
I0520 22:21:32.138752 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:21:32.213384 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:21:32.214809 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:21:32.214828 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:21:32.215209 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.12364
I0520 22:22:17.833096 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 22:22:43.155372 15139 solver.cpp:231] Iteration 159200, loss = 0.953419
I0520 22:22:43.155441 15139 solver.cpp:247]     Train net output #0: loss = 0.953419 (* 1 = 0.953419 loss)
I0520 22:22:43.155457 15139 sgd_solver.cpp:106] Iteration 159200, lr = 1e-06
I0520 22:22:43.314803 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:22:43.390039 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:22:43.391672 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:22:43.391695 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:22:43.392156 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 0.953419
I0520 22:23:54.696581 15139 solver.cpp:231] Iteration 159400, loss = 1.01596
I0520 22:23:54.696812 15139 solver.cpp:247]     Train net output #0: loss = 1.01596 (* 1 = 1.01596 loss)
I0520 22:23:54.696831 15139 sgd_solver.cpp:106] Iteration 159400, lr = 1e-06
I0520 22:23:54.856456 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:23:54.931588 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:23:54.933104 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:23:54.933122 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:23:54.933622 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.01596
I0520 22:25:05.424664 15139 solver.cpp:231] Iteration 159600, loss = 1.07093
I0520 22:25:05.424880 15139 solver.cpp:247]     Train net output #0: loss = 1.07093 (* 1 = 1.07093 loss)
I0520 22:25:05.424901 15139 sgd_solver.cpp:106] Iteration 159600, lr = 1e-06
I0520 22:25:05.587560 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:25:05.666398 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:25:05.668042 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:25:05.668071 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:25:05.668499 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.07093
I0520 22:26:16.131608 15139 solver.cpp:231] Iteration 159800, loss = 1.21232
I0520 22:26:16.131819 15139 solver.cpp:247]     Train net output #0: loss = 1.21232 (* 1 = 1.21232 loss)
I0520 22:26:16.132040 15139 sgd_solver.cpp:106] Iteration 159800, lr = 1e-06
I0520 22:26:16.291960 15139 sgd_solver.cpp:120]     Element Sparsity %: 
17.0742	3.125	82.7855	0	91.2739	6.25	89.3514	0	85.4691	0	86.8971	0	80.1424	0	31.9026	2.9	
I0520 22:26:16.366013 15139 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0520 22:26:16.367455 15139 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	6.25	0	0	0	0	0	0	0	0	0	2.9	
I0520 22:26:16.367472 15139 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0520 22:26:16.367840 15139 solver.cpp:260]     Total regularization terms: 0 loss+regular. : 1.21232
I0520 22:27:32.508059 15139 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_160000.caffemodel
I0520 22:28:08.804024 15139 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0_0.0_0.0_0.0_Fri_May_20_00-08-10_PDT_2016/caffenet_train_iter_160000.solverstate
I0520 22:28:09.502166 15139 solver.cpp:328] Iteration 160000, loss = 1.12214
I0520 22:28:09.502229 15139 solver.cpp:348] Iteration 160000, Testing net (#0)
I0520 22:28:18.860265 15139 blocking_queue.cpp:50] Data layer prefetch queue empty
I0520 22:29:18.464200 15139 solver.cpp:415]     Test net output #0: accuracy = 0.5726
I0520 22:29:18.464435 15139 solver.cpp:415]     Test net output #1: loss = 1.83565 (* 1 = 1.83565 loss)
I0520 22:29:18.464454 15139 solver.cpp:333] Optimization Done.
I0520 22:29:18.464468 15139 caffe.cpp:223] Optimization Done.
