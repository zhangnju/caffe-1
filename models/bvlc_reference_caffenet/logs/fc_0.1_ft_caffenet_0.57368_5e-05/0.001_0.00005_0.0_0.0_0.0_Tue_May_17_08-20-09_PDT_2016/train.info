I0517 08:20:10.048575  4008 caffe.cpp:186] Using GPUs 5
I0517 08:20:10.149207  4008 caffe.cpp:191] GPU 5: GeForce GTX TITAN X
I0517 08:20:12.141549  4008 solver.cpp:50] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.001
display: 200
max_iter: 450000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 5e-05
snapshot: 6000
snapshot_prefix: "models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train"
solver_mode: GPU
device_id: 5
net: "models/bvlc_reference_caffenet/train_val_fc_0.1.prototxt"
regularization_type: "L1"
stepvalue: 300000
stepvalue: 360000
breadth_decay: 0
kernel_shape_decay: 0
block_group_decay: 0
I0517 08:20:12.141923  4008 solver.cpp:94] Creating training net from net file: models/bvlc_reference_caffenet/train_val_fc_0.1.prototxt
I0517 08:20:12.142877  4008 net.cpp:315] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0517 08:20:12.142917  4008 net.cpp:315] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0517 08:20:12.142935  4008 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "examples/imagenet/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L2"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 0.1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 0.1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L2"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0517 08:20:12.143347  4008 layer_factory.hpp:77] Creating layer data
I0517 08:20:12.144224  4008 net.cpp:93] Creating Layer data
I0517 08:20:12.144250  4008 net.cpp:401] data -> data
I0517 08:20:12.144294  4008 net.cpp:401] data -> label
I0517 08:20:12.144314  4008 data_transformer.cpp:25] Loading mean file from: data/ilsvrc12/imagenet_mean.binaryproto
I0517 08:20:12.146472  4011 db_lmdb.cpp:38] Opened lmdb examples/imagenet/ilsvrc12_train_lmdb
I0517 08:20:12.839583  4008 data_layer.cpp:41] output data size: 256,3,227,227
I0517 08:20:13.320523  4008 net.cpp:143] Setting up data
I0517 08:20:13.320570  4008 net.cpp:150] Top shape: 256 3 227 227 (39574272)
I0517 08:20:13.320585  4008 net.cpp:150] Top shape: 256 (256)
I0517 08:20:13.320590  4008 net.cpp:158] Memory required for data: 158298112
I0517 08:20:13.320611  4008 layer_factory.hpp:77] Creating layer conv1
I0517 08:20:13.320643  4008 net.cpp:93] Creating Layer conv1
I0517 08:20:13.320650  4008 net.cpp:427] conv1 <- data
I0517 08:20:13.320669  4008 net.cpp:401] conv1 -> conv1
I0517 08:20:15.757992  4008 net.cpp:143] Setting up conv1
I0517 08:20:15.758064  4008 net.cpp:150] Top shape: 256 96 55 55 (74342400)
I0517 08:20:15.758081  4008 net.cpp:158] Memory required for data: 455667712
I0517 08:20:15.758141  4008 layer_factory.hpp:77] Creating layer relu1
I0517 08:20:15.758165  4008 net.cpp:93] Creating Layer relu1
I0517 08:20:15.758174  4008 net.cpp:427] relu1 <- conv1
I0517 08:20:15.758189  4008 net.cpp:388] relu1 -> conv1 (in-place)
I0517 08:20:15.758744  4008 net.cpp:143] Setting up relu1
I0517 08:20:15.758764  4008 net.cpp:150] Top shape: 256 96 55 55 (74342400)
I0517 08:20:15.758775  4008 net.cpp:158] Memory required for data: 753037312
I0517 08:20:15.758785  4008 layer_factory.hpp:77] Creating layer pool1
I0517 08:20:15.758800  4008 net.cpp:93] Creating Layer pool1
I0517 08:20:15.758808  4008 net.cpp:427] pool1 <- conv1
I0517 08:20:15.758846  4008 net.cpp:401] pool1 -> pool1
I0517 08:20:15.885149  4008 net.cpp:143] Setting up pool1
I0517 08:20:15.885198  4008 net.cpp:150] Top shape: 256 96 27 27 (17915904)
I0517 08:20:15.885211  4008 net.cpp:158] Memory required for data: 824700928
I0517 08:20:15.885221  4008 layer_factory.hpp:77] Creating layer norm1
I0517 08:20:15.885251  4008 net.cpp:93] Creating Layer norm1
I0517 08:20:15.885257  4008 net.cpp:427] norm1 <- pool1
I0517 08:20:15.885267  4008 net.cpp:401] norm1 -> norm1
I0517 08:20:16.005388  4008 net.cpp:143] Setting up norm1
I0517 08:20:16.005436  4008 net.cpp:150] Top shape: 256 96 27 27 (17915904)
I0517 08:20:16.005448  4008 net.cpp:158] Memory required for data: 896364544
I0517 08:20:16.005457  4008 layer_factory.hpp:77] Creating layer conv2
I0517 08:20:16.005481  4008 net.cpp:93] Creating Layer conv2
I0517 08:20:16.005487  4008 net.cpp:427] conv2 <- norm1
I0517 08:20:16.005498  4008 net.cpp:401] conv2 -> conv2
I0517 08:20:17.701287  4008 net.cpp:143] Setting up conv2
I0517 08:20:17.701340  4008 net.cpp:150] Top shape: 256 256 27 27 (47775744)
I0517 08:20:17.701356  4008 net.cpp:158] Memory required for data: 1087467520
I0517 08:20:17.701388  4008 layer_factory.hpp:77] Creating layer relu2
I0517 08:20:17.701406  4008 net.cpp:93] Creating Layer relu2
I0517 08:20:17.701414  4008 net.cpp:427] relu2 <- conv2
I0517 08:20:17.701426  4008 net.cpp:388] relu2 -> conv2 (in-place)
I0517 08:20:17.701827  4008 net.cpp:143] Setting up relu2
I0517 08:20:17.701844  4008 net.cpp:150] Top shape: 256 256 27 27 (47775744)
I0517 08:20:17.701855  4008 net.cpp:158] Memory required for data: 1278570496
I0517 08:20:17.701864  4008 layer_factory.hpp:77] Creating layer pool2
I0517 08:20:17.701879  4008 net.cpp:93] Creating Layer pool2
I0517 08:20:17.701886  4008 net.cpp:427] pool2 <- conv2
I0517 08:20:17.701899  4008 net.cpp:401] pool2 -> pool2
I0517 08:20:17.770042  4008 net.cpp:143] Setting up pool2
I0517 08:20:17.770086  4008 net.cpp:150] Top shape: 256 256 13 13 (11075584)
I0517 08:20:17.770098  4008 net.cpp:158] Memory required for data: 1322872832
I0517 08:20:17.770107  4008 layer_factory.hpp:77] Creating layer norm2
I0517 08:20:17.770133  4008 net.cpp:93] Creating Layer norm2
I0517 08:20:17.770139  4008 net.cpp:427] norm2 <- pool2
I0517 08:20:17.770151  4008 net.cpp:401] norm2 -> norm2
I0517 08:20:17.842864  4008 net.cpp:143] Setting up norm2
I0517 08:20:17.842905  4008 net.cpp:150] Top shape: 256 256 13 13 (11075584)
I0517 08:20:17.842916  4008 net.cpp:158] Memory required for data: 1367175168
I0517 08:20:17.842923  4008 layer_factory.hpp:77] Creating layer conv3
I0517 08:20:17.842949  4008 net.cpp:93] Creating Layer conv3
I0517 08:20:17.842957  4008 net.cpp:427] conv3 <- norm2
I0517 08:20:17.842967  4008 net.cpp:401] conv3 -> conv3
I0517 08:20:18.258940  4008 net.cpp:143] Setting up conv3
I0517 08:20:18.258982  4008 net.cpp:150] Top shape: 256 384 13 13 (16613376)
I0517 08:20:18.258998  4008 net.cpp:158] Memory required for data: 1433628672
I0517 08:20:18.259019  4008 layer_factory.hpp:77] Creating layer relu3
I0517 08:20:18.259033  4008 net.cpp:93] Creating Layer relu3
I0517 08:20:18.259039  4008 net.cpp:427] relu3 <- conv3
I0517 08:20:18.259049  4008 net.cpp:388] relu3 -> conv3 (in-place)
I0517 08:20:18.259320  4008 net.cpp:143] Setting up relu3
I0517 08:20:18.259330  4008 net.cpp:150] Top shape: 256 384 13 13 (16613376)
I0517 08:20:18.259337  4008 net.cpp:158] Memory required for data: 1500082176
I0517 08:20:18.259343  4008 layer_factory.hpp:77] Creating layer conv4
I0517 08:20:18.259363  4008 net.cpp:93] Creating Layer conv4
I0517 08:20:18.259368  4008 net.cpp:427] conv4 <- conv3
I0517 08:20:18.259378  4008 net.cpp:401] conv4 -> conv4
I0517 08:20:18.870573  4008 net.cpp:143] Setting up conv4
I0517 08:20:18.870632  4008 net.cpp:150] Top shape: 256 384 13 13 (16613376)
I0517 08:20:18.870648  4008 net.cpp:158] Memory required for data: 1566535680
I0517 08:20:18.870672  4008 layer_factory.hpp:77] Creating layer relu4
I0517 08:20:18.870692  4008 net.cpp:93] Creating Layer relu4
I0517 08:20:18.870714  4008 net.cpp:427] relu4 <- conv4
I0517 08:20:18.870743  4008 net.cpp:388] relu4 -> conv4 (in-place)
I0517 08:20:18.871058  4008 net.cpp:143] Setting up relu4
I0517 08:20:18.871073  4008 net.cpp:150] Top shape: 256 384 13 13 (16613376)
I0517 08:20:18.871083  4008 net.cpp:158] Memory required for data: 1632989184
I0517 08:20:18.871090  4008 layer_factory.hpp:77] Creating layer conv5
I0517 08:20:18.871119  4008 net.cpp:93] Creating Layer conv5
I0517 08:20:18.871127  4008 net.cpp:427] conv5 <- conv4
I0517 08:20:18.871141  4008 net.cpp:401] conv5 -> conv5
I0517 08:20:19.468652  4008 net.cpp:143] Setting up conv5
I0517 08:20:19.468703  4008 net.cpp:150] Top shape: 256 256 13 13 (11075584)
I0517 08:20:19.468716  4008 net.cpp:158] Memory required for data: 1677291520
I0517 08:20:19.468740  4008 layer_factory.hpp:77] Creating layer relu5
I0517 08:20:19.468757  4008 net.cpp:93] Creating Layer relu5
I0517 08:20:19.468765  4008 net.cpp:427] relu5 <- conv5
I0517 08:20:19.468773  4008 net.cpp:388] relu5 -> conv5 (in-place)
I0517 08:20:19.469053  4008 net.cpp:143] Setting up relu5
I0517 08:20:19.469063  4008 net.cpp:150] Top shape: 256 256 13 13 (11075584)
I0517 08:20:19.469071  4008 net.cpp:158] Memory required for data: 1721593856
I0517 08:20:19.469076  4008 layer_factory.hpp:77] Creating layer pool5
I0517 08:20:19.469084  4008 net.cpp:93] Creating Layer pool5
I0517 08:20:19.469089  4008 net.cpp:427] pool5 <- conv5
I0517 08:20:19.469099  4008 net.cpp:401] pool5 -> pool5
I0517 08:20:19.482535  4008 net.cpp:143] Setting up pool5
I0517 08:20:19.482581  4008 net.cpp:150] Top shape: 256 256 6 6 (2359296)
I0517 08:20:19.482594  4008 net.cpp:158] Memory required for data: 1731031040
I0517 08:20:19.482604  4008 layer_factory.hpp:77] Creating layer fc6
I0517 08:20:19.482630  4008 net.cpp:93] Creating Layer fc6
I0517 08:20:19.482640  4008 net.cpp:427] fc6 <- pool5
I0517 08:20:19.482661  4008 net.cpp:401] fc6 -> fc6
I0517 08:20:20.178741  4008 net.cpp:143] Setting up fc6
I0517 08:20:20.178786  4008 net.cpp:150] Top shape: 256 4096 (1048576)
I0517 08:20:20.178797  4008 net.cpp:158] Memory required for data: 1735225344
I0517 08:20:20.178815  4008 layer_factory.hpp:77] Creating layer relu6
I0517 08:20:20.178828  4008 net.cpp:93] Creating Layer relu6
I0517 08:20:20.178834  4008 net.cpp:427] relu6 <- fc6
I0517 08:20:20.178846  4008 net.cpp:388] relu6 -> fc6 (in-place)
I0517 08:20:20.179361  4008 net.cpp:143] Setting up relu6
I0517 08:20:20.179376  4008 net.cpp:150] Top shape: 256 4096 (1048576)
I0517 08:20:20.179384  4008 net.cpp:158] Memory required for data: 1739419648
I0517 08:20:20.179389  4008 layer_factory.hpp:77] Creating layer drop6
I0517 08:20:20.179399  4008 net.cpp:93] Creating Layer drop6
I0517 08:20:20.179404  4008 net.cpp:427] drop6 <- fc6
I0517 08:20:20.179412  4008 net.cpp:388] drop6 -> fc6 (in-place)
I0517 08:20:20.182162  4008 net.cpp:143] Setting up drop6
I0517 08:20:20.182183  4008 net.cpp:150] Top shape: 256 4096 (1048576)
I0517 08:20:20.182193  4008 net.cpp:158] Memory required for data: 1743613952
I0517 08:20:20.182200  4008 layer_factory.hpp:77] Creating layer fc7
I0517 08:20:20.182215  4008 net.cpp:93] Creating Layer fc7
I0517 08:20:20.182220  4008 net.cpp:427] fc7 <- fc6
I0517 08:20:20.182230  4008 net.cpp:401] fc7 -> fc7
I0517 08:20:20.613090  4008 net.cpp:143] Setting up fc7
I0517 08:20:20.613157  4008 net.cpp:150] Top shape: 256 4096 (1048576)
I0517 08:20:20.613178  4008 net.cpp:158] Memory required for data: 1747808256
I0517 08:20:20.613207  4008 layer_factory.hpp:77] Creating layer relu7
I0517 08:20:20.613231  4008 net.cpp:93] Creating Layer relu7
I0517 08:20:20.613246  4008 net.cpp:427] relu7 <- fc7
I0517 08:20:20.613262  4008 net.cpp:388] relu7 -> fc7 (in-place)
I0517 08:20:20.613695  4008 net.cpp:143] Setting up relu7
I0517 08:20:20.613718  4008 net.cpp:150] Top shape: 256 4096 (1048576)
I0517 08:20:20.613736  4008 net.cpp:158] Memory required for data: 1752002560
I0517 08:20:20.613749  4008 layer_factory.hpp:77] Creating layer drop7
I0517 08:20:20.613767  4008 net.cpp:93] Creating Layer drop7
I0517 08:20:20.613795  4008 net.cpp:427] drop7 <- fc7
I0517 08:20:20.613828  4008 net.cpp:388] drop7 -> fc7 (in-place)
I0517 08:20:20.617667  4008 net.cpp:143] Setting up drop7
I0517 08:20:20.617708  4008 net.cpp:150] Top shape: 256 4096 (1048576)
I0517 08:20:20.617727  4008 net.cpp:158] Memory required for data: 1756196864
I0517 08:20:20.617740  4008 layer_factory.hpp:77] Creating layer fc8
I0517 08:20:20.617766  4008 net.cpp:93] Creating Layer fc8
I0517 08:20:20.617780  4008 net.cpp:427] fc8 <- fc7
I0517 08:20:20.617799  4008 net.cpp:401] fc8 -> fc8
I0517 08:20:20.706200  4008 net.cpp:143] Setting up fc8
I0517 08:20:20.706251  4008 net.cpp:150] Top shape: 256 1000 (256000)
I0517 08:20:20.706264  4008 net.cpp:158] Memory required for data: 1757220864
I0517 08:20:20.706282  4008 layer_factory.hpp:77] Creating layer loss
I0517 08:20:20.706302  4008 net.cpp:93] Creating Layer loss
I0517 08:20:20.706311  4008 net.cpp:427] loss <- fc8
I0517 08:20:20.706321  4008 net.cpp:427] loss <- label
I0517 08:20:20.706336  4008 net.cpp:401] loss -> loss
I0517 08:20:20.706377  4008 layer_factory.hpp:77] Creating layer loss
I0517 08:20:20.708853  4008 net.cpp:143] Setting up loss
I0517 08:20:20.708878  4008 net.cpp:150] Top shape: (1)
I0517 08:20:20.708887  4008 net.cpp:153]     with loss weight 1
I0517 08:20:20.708933  4008 net.cpp:158] Memory required for data: 1757220868
I0517 08:20:20.708942  4008 net.cpp:219] loss needs backward computation.
I0517 08:20:20.708952  4008 net.cpp:219] fc8 needs backward computation.
I0517 08:20:20.708959  4008 net.cpp:219] drop7 needs backward computation.
I0517 08:20:20.708964  4008 net.cpp:219] relu7 needs backward computation.
I0517 08:20:20.708969  4008 net.cpp:219] fc7 needs backward computation.
I0517 08:20:20.708976  4008 net.cpp:219] drop6 needs backward computation.
I0517 08:20:20.708981  4008 net.cpp:219] relu6 needs backward computation.
I0517 08:20:20.708986  4008 net.cpp:219] fc6 needs backward computation.
I0517 08:20:20.708993  4008 net.cpp:219] pool5 needs backward computation.
I0517 08:20:20.708999  4008 net.cpp:219] relu5 needs backward computation.
I0517 08:20:20.709005  4008 net.cpp:219] conv5 needs backward computation.
I0517 08:20:20.709012  4008 net.cpp:219] relu4 needs backward computation.
I0517 08:20:20.709017  4008 net.cpp:219] conv4 needs backward computation.
I0517 08:20:20.709023  4008 net.cpp:219] relu3 needs backward computation.
I0517 08:20:20.709028  4008 net.cpp:219] conv3 needs backward computation.
I0517 08:20:20.709034  4008 net.cpp:219] norm2 needs backward computation.
I0517 08:20:20.709040  4008 net.cpp:219] pool2 needs backward computation.
I0517 08:20:20.709046  4008 net.cpp:219] relu2 needs backward computation.
I0517 08:20:20.709053  4008 net.cpp:219] conv2 needs backward computation.
I0517 08:20:20.709059  4008 net.cpp:219] norm1 needs backward computation.
I0517 08:20:20.709067  4008 net.cpp:219] pool1 needs backward computation.
I0517 08:20:20.709074  4008 net.cpp:219] relu1 needs backward computation.
I0517 08:20:20.709079  4008 net.cpp:219] conv1 needs backward computation.
I0517 08:20:20.709084  4008 net.cpp:221] data does not need backward computation.
I0517 08:20:20.709091  4008 net.cpp:263] This network produces output loss
I0517 08:20:20.709107  4008 net.cpp:276] Network initialization done.
I0517 08:20:20.709801  4008 solver.cpp:184] Creating test net (#0) specified by net file: models/bvlc_reference_caffenet/train_val_fc_0.1.prototxt
I0517 08:20:20.709864  4008 net.cpp:315] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0517 08:20:20.709892  4008 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "data/ilsvrc12/imagenet_mean.binaryproto"
  }
  data_param {
    source: "examples/imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L2"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 0.1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 0.1
    regularization_type: "L1"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
    regularization_type: "L2"
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0517 08:20:20.710211  4008 layer_factory.hpp:77] Creating layer data
I0517 08:20:20.710321  4008 net.cpp:93] Creating Layer data
I0517 08:20:20.710388  4008 net.cpp:401] data -> data
I0517 08:20:20.710417  4008 net.cpp:401] data -> label
I0517 08:20:20.710438  4008 data_transformer.cpp:25] Loading mean file from: data/ilsvrc12/imagenet_mean.binaryproto
I0517 08:20:20.713593  4016 db_lmdb.cpp:38] Opened lmdb examples/imagenet/ilsvrc12_val_lmdb
I0517 08:20:20.849247  4008 data_layer.cpp:41] output data size: 50,3,227,227
I0517 08:20:20.963309  4008 net.cpp:143] Setting up data
I0517 08:20:20.963359  4008 net.cpp:150] Top shape: 50 3 227 227 (7729350)
I0517 08:20:20.963373  4008 net.cpp:150] Top shape: 50 (50)
I0517 08:20:20.963382  4008 net.cpp:158] Memory required for data: 30917600
I0517 08:20:20.963390  4008 layer_factory.hpp:77] Creating layer label_data_1_split
I0517 08:20:20.963405  4008 net.cpp:93] Creating Layer label_data_1_split
I0517 08:20:20.963414  4008 net.cpp:427] label_data_1_split <- label
I0517 08:20:20.963425  4008 net.cpp:401] label_data_1_split -> label_data_1_split_0
I0517 08:20:20.963441  4008 net.cpp:401] label_data_1_split -> label_data_1_split_1
I0517 08:20:20.963800  4008 net.cpp:143] Setting up label_data_1_split
I0517 08:20:20.963819  4008 net.cpp:150] Top shape: 50 (50)
I0517 08:20:20.963829  4008 net.cpp:150] Top shape: 50 (50)
I0517 08:20:20.963835  4008 net.cpp:158] Memory required for data: 30918000
I0517 08:20:20.963843  4008 layer_factory.hpp:77] Creating layer conv1
I0517 08:20:20.963865  4008 net.cpp:93] Creating Layer conv1
I0517 08:20:20.963873  4008 net.cpp:427] conv1 <- data
I0517 08:20:20.963883  4008 net.cpp:401] conv1 -> conv1
I0517 08:20:21.234864  4008 net.cpp:143] Setting up conv1
I0517 08:20:21.234938  4008 net.cpp:150] Top shape: 50 96 55 55 (14520000)
I0517 08:20:21.234956  4008 net.cpp:158] Memory required for data: 88998000
I0517 08:20:21.234989  4008 layer_factory.hpp:77] Creating layer relu1
I0517 08:20:21.235013  4008 net.cpp:93] Creating Layer relu1
I0517 08:20:21.235023  4008 net.cpp:427] relu1 <- conv1
I0517 08:20:21.235038  4008 net.cpp:388] relu1 -> conv1 (in-place)
I0517 08:20:21.235431  4008 net.cpp:143] Setting up relu1
I0517 08:20:21.235455  4008 net.cpp:150] Top shape: 50 96 55 55 (14520000)
I0517 08:20:21.235471  4008 net.cpp:158] Memory required for data: 147078000
I0517 08:20:21.235479  4008 layer_factory.hpp:77] Creating layer pool1
I0517 08:20:21.235496  4008 net.cpp:93] Creating Layer pool1
I0517 08:20:21.235509  4008 net.cpp:427] pool1 <- conv1
I0517 08:20:21.235525  4008 net.cpp:401] pool1 -> pool1
I0517 08:20:21.262795  4008 net.cpp:143] Setting up pool1
I0517 08:20:21.262859  4008 net.cpp:150] Top shape: 50 96 27 27 (3499200)
I0517 08:20:21.262877  4008 net.cpp:158] Memory required for data: 161074800
I0517 08:20:21.262892  4008 layer_factory.hpp:77] Creating layer norm1
I0517 08:20:21.262914  4008 net.cpp:93] Creating Layer norm1
I0517 08:20:21.262928  4008 net.cpp:427] norm1 <- pool1
I0517 08:20:21.262943  4008 net.cpp:401] norm1 -> norm1
I0517 08:20:21.295527  4008 net.cpp:143] Setting up norm1
I0517 08:20:21.295605  4008 net.cpp:150] Top shape: 50 96 27 27 (3499200)
I0517 08:20:21.295625  4008 net.cpp:158] Memory required for data: 175071600
I0517 08:20:21.295642  4008 layer_factory.hpp:77] Creating layer conv2
I0517 08:20:21.295707  4008 net.cpp:93] Creating Layer conv2
I0517 08:20:21.295742  4008 net.cpp:427] conv2 <- norm1
I0517 08:20:21.295765  4008 net.cpp:401] conv2 -> conv2
I0517 08:20:21.717317  4008 net.cpp:143] Setting up conv2
I0517 08:20:21.717386  4008 net.cpp:150] Top shape: 50 256 27 27 (9331200)
I0517 08:20:21.717403  4008 net.cpp:158] Memory required for data: 212396400
I0517 08:20:21.717437  4008 layer_factory.hpp:77] Creating layer relu2
I0517 08:20:21.717464  4008 net.cpp:93] Creating Layer relu2
I0517 08:20:21.717475  4008 net.cpp:427] relu2 <- conv2
I0517 08:20:21.717489  4008 net.cpp:388] relu2 -> conv2 (in-place)
I0517 08:20:21.717821  4008 net.cpp:143] Setting up relu2
I0517 08:20:21.717840  4008 net.cpp:150] Top shape: 50 256 27 27 (9331200)
I0517 08:20:21.717851  4008 net.cpp:158] Memory required for data: 249721200
I0517 08:20:21.717857  4008 layer_factory.hpp:77] Creating layer pool2
I0517 08:20:21.717870  4008 net.cpp:93] Creating Layer pool2
I0517 08:20:21.717876  4008 net.cpp:427] pool2 <- conv2
I0517 08:20:21.717890  4008 net.cpp:401] pool2 -> pool2
I0517 08:20:21.734263  4008 net.cpp:143] Setting up pool2
I0517 08:20:21.734331  4008 net.cpp:150] Top shape: 50 256 13 13 (2163200)
I0517 08:20:21.734349  4008 net.cpp:158] Memory required for data: 258374000
I0517 08:20:21.734362  4008 layer_factory.hpp:77] Creating layer norm2
I0517 08:20:21.734395  4008 net.cpp:93] Creating Layer norm2
I0517 08:20:21.734405  4008 net.cpp:427] norm2 <- pool2
I0517 08:20:21.734421  4008 net.cpp:401] norm2 -> norm2
I0517 08:20:21.751879  4008 net.cpp:143] Setting up norm2
I0517 08:20:21.751946  4008 net.cpp:150] Top shape: 50 256 13 13 (2163200)
I0517 08:20:21.751965  4008 net.cpp:158] Memory required for data: 267026800
I0517 08:20:21.751982  4008 layer_factory.hpp:77] Creating layer conv3
I0517 08:20:21.752022  4008 net.cpp:93] Creating Layer conv3
I0517 08:20:21.752034  4008 net.cpp:427] conv3 <- norm2
I0517 08:20:21.752053  4008 net.cpp:401] conv3 -> conv3
I0517 08:20:21.870615  4008 net.cpp:143] Setting up conv3
I0517 08:20:21.870667  4008 net.cpp:150] Top shape: 50 384 13 13 (3244800)
I0517 08:20:21.870681  4008 net.cpp:158] Memory required for data: 280006000
I0517 08:20:21.870704  4008 layer_factory.hpp:77] Creating layer relu3
I0517 08:20:21.870721  4008 net.cpp:93] Creating Layer relu3
I0517 08:20:21.870728  4008 net.cpp:427] relu3 <- conv3
I0517 08:20:21.870739  4008 net.cpp:388] relu3 -> conv3 (in-place)
I0517 08:20:21.871276  4008 net.cpp:143] Setting up relu3
I0517 08:20:21.871295  4008 net.cpp:150] Top shape: 50 384 13 13 (3244800)
I0517 08:20:21.871306  4008 net.cpp:158] Memory required for data: 292985200
I0517 08:20:21.871312  4008 layer_factory.hpp:77] Creating layer conv4
I0517 08:20:21.871337  4008 net.cpp:93] Creating Layer conv4
I0517 08:20:21.871352  4008 net.cpp:427] conv4 <- conv3
I0517 08:20:21.871371  4008 net.cpp:401] conv4 -> conv4
I0517 08:20:22.019747  4008 net.cpp:143] Setting up conv4
I0517 08:20:22.019819  4008 net.cpp:150] Top shape: 50 384 13 13 (3244800)
I0517 08:20:22.019840  4008 net.cpp:158] Memory required for data: 305964400
I0517 08:20:22.019871  4008 layer_factory.hpp:77] Creating layer relu4
I0517 08:20:22.019896  4008 net.cpp:93] Creating Layer relu4
I0517 08:20:22.019906  4008 net.cpp:427] relu4 <- conv4
I0517 08:20:22.019919  4008 net.cpp:388] relu4 -> conv4 (in-place)
I0517 08:20:22.020311  4008 net.cpp:143] Setting up relu4
I0517 08:20:22.020334  4008 net.cpp:150] Top shape: 50 384 13 13 (3244800)
I0517 08:20:22.020349  4008 net.cpp:158] Memory required for data: 318943600
I0517 08:20:22.020359  4008 layer_factory.hpp:77] Creating layer conv5
I0517 08:20:22.020383  4008 net.cpp:93] Creating Layer conv5
I0517 08:20:22.020393  4008 net.cpp:427] conv5 <- conv4
I0517 08:20:22.020413  4008 net.cpp:401] conv5 -> conv5
I0517 08:20:22.158221  4008 net.cpp:143] Setting up conv5
I0517 08:20:22.158295  4008 net.cpp:150] Top shape: 50 256 13 13 (2163200)
I0517 08:20:22.158318  4008 net.cpp:158] Memory required for data: 327596400
I0517 08:20:22.158350  4008 layer_factory.hpp:77] Creating layer relu5
I0517 08:20:22.158411  4008 net.cpp:93] Creating Layer relu5
I0517 08:20:22.158422  4008 net.cpp:427] relu5 <- conv5
I0517 08:20:22.158437  4008 net.cpp:388] relu5 -> conv5 (in-place)
I0517 08:20:22.158797  4008 net.cpp:143] Setting up relu5
I0517 08:20:22.158817  4008 net.cpp:150] Top shape: 50 256 13 13 (2163200)
I0517 08:20:22.158831  4008 net.cpp:158] Memory required for data: 336249200
I0517 08:20:22.158839  4008 layer_factory.hpp:77] Creating layer pool5
I0517 08:20:22.158860  4008 net.cpp:93] Creating Layer pool5
I0517 08:20:22.158874  4008 net.cpp:427] pool5 <- conv5
I0517 08:20:22.158890  4008 net.cpp:401] pool5 -> pool5
I0517 08:20:22.162493  4008 net.cpp:143] Setting up pool5
I0517 08:20:22.162524  4008 net.cpp:150] Top shape: 50 256 6 6 (460800)
I0517 08:20:22.162539  4008 net.cpp:158] Memory required for data: 338092400
I0517 08:20:22.162551  4008 layer_factory.hpp:77] Creating layer fc6
I0517 08:20:22.162575  4008 net.cpp:93] Creating Layer fc6
I0517 08:20:22.162585  4008 net.cpp:427] fc6 <- pool5
I0517 08:20:22.162597  4008 net.cpp:401] fc6 -> fc6
I0517 08:20:22.870576  4008 net.cpp:143] Setting up fc6
I0517 08:20:22.870625  4008 net.cpp:150] Top shape: 50 4096 (204800)
I0517 08:20:22.870638  4008 net.cpp:158] Memory required for data: 338911600
I0517 08:20:22.870656  4008 layer_factory.hpp:77] Creating layer relu6
I0517 08:20:22.870671  4008 net.cpp:93] Creating Layer relu6
I0517 08:20:22.870681  4008 net.cpp:427] relu6 <- fc6
I0517 08:20:22.870690  4008 net.cpp:388] relu6 -> fc6 (in-place)
I0517 08:20:22.871259  4008 net.cpp:143] Setting up relu6
I0517 08:20:22.871279  4008 net.cpp:150] Top shape: 50 4096 (204800)
I0517 08:20:22.871289  4008 net.cpp:158] Memory required for data: 339730800
I0517 08:20:22.871294  4008 layer_factory.hpp:77] Creating layer drop6
I0517 08:20:22.871307  4008 net.cpp:93] Creating Layer drop6
I0517 08:20:22.871314  4008 net.cpp:427] drop6 <- fc6
I0517 08:20:22.871321  4008 net.cpp:388] drop6 -> fc6 (in-place)
I0517 08:20:22.872269  4008 net.cpp:143] Setting up drop6
I0517 08:20:22.872288  4008 net.cpp:150] Top shape: 50 4096 (204800)
I0517 08:20:22.872297  4008 net.cpp:158] Memory required for data: 340550000
I0517 08:20:22.872305  4008 layer_factory.hpp:77] Creating layer fc7
I0517 08:20:22.872319  4008 net.cpp:93] Creating Layer fc7
I0517 08:20:22.872325  4008 net.cpp:427] fc7 <- fc6
I0517 08:20:22.872334  4008 net.cpp:401] fc7 -> fc7
I0517 08:20:23.187232  4008 net.cpp:143] Setting up fc7
I0517 08:20:23.187283  4008 net.cpp:150] Top shape: 50 4096 (204800)
I0517 08:20:23.187301  4008 net.cpp:158] Memory required for data: 341369200
I0517 08:20:23.187319  4008 layer_factory.hpp:77] Creating layer relu7
I0517 08:20:23.187333  4008 net.cpp:93] Creating Layer relu7
I0517 08:20:23.187343  4008 net.cpp:427] relu7 <- fc7
I0517 08:20:23.187352  4008 net.cpp:388] relu7 -> fc7 (in-place)
I0517 08:20:23.187682  4008 net.cpp:143] Setting up relu7
I0517 08:20:23.187700  4008 net.cpp:150] Top shape: 50 4096 (204800)
I0517 08:20:23.187707  4008 net.cpp:158] Memory required for data: 342188400
I0517 08:20:23.187712  4008 layer_factory.hpp:77] Creating layer drop7
I0517 08:20:23.187727  4008 net.cpp:93] Creating Layer drop7
I0517 08:20:23.187733  4008 net.cpp:427] drop7 <- fc7
I0517 08:20:23.187741  4008 net.cpp:388] drop7 -> fc7 (in-place)
I0517 08:20:23.188755  4008 net.cpp:143] Setting up drop7
I0517 08:20:23.188777  4008 net.cpp:150] Top shape: 50 4096 (204800)
I0517 08:20:23.188789  4008 net.cpp:158] Memory required for data: 343007600
I0517 08:20:23.188796  4008 layer_factory.hpp:77] Creating layer fc8
I0517 08:20:23.188810  4008 net.cpp:93] Creating Layer fc8
I0517 08:20:23.188817  4008 net.cpp:427] fc8 <- fc7
I0517 08:20:23.188827  4008 net.cpp:401] fc8 -> fc8
I0517 08:20:23.264744  4008 net.cpp:143] Setting up fc8
I0517 08:20:23.264822  4008 net.cpp:150] Top shape: 50 1000 (50000)
I0517 08:20:23.264838  4008 net.cpp:158] Memory required for data: 343207600
I0517 08:20:23.264863  4008 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0517 08:20:23.264904  4008 net.cpp:93] Creating Layer fc8_fc8_0_split
I0517 08:20:23.264930  4008 net.cpp:427] fc8_fc8_0_split <- fc8
I0517 08:20:23.264945  4008 net.cpp:401] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0517 08:20:23.264960  4008 net.cpp:401] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0517 08:20:23.265218  4008 net.cpp:143] Setting up fc8_fc8_0_split
I0517 08:20:23.265231  4008 net.cpp:150] Top shape: 50 1000 (50000)
I0517 08:20:23.265242  4008 net.cpp:150] Top shape: 50 1000 (50000)
I0517 08:20:23.265251  4008 net.cpp:158] Memory required for data: 343607600
I0517 08:20:23.265259  4008 layer_factory.hpp:77] Creating layer accuracy
I0517 08:20:23.265276  4008 net.cpp:93] Creating Layer accuracy
I0517 08:20:23.265283  4008 net.cpp:427] accuracy <- fc8_fc8_0_split_0
I0517 08:20:23.265292  4008 net.cpp:427] accuracy <- label_data_1_split_0
I0517 08:20:23.265302  4008 net.cpp:401] accuracy -> accuracy
I0517 08:20:23.265364  4008 net.cpp:143] Setting up accuracy
I0517 08:20:23.265375  4008 net.cpp:150] Top shape: (1)
I0517 08:20:23.265385  4008 net.cpp:158] Memory required for data: 343607604
I0517 08:20:23.265393  4008 layer_factory.hpp:77] Creating layer loss
I0517 08:20:23.265405  4008 net.cpp:93] Creating Layer loss
I0517 08:20:23.265413  4008 net.cpp:427] loss <- fc8_fc8_0_split_1
I0517 08:20:23.265420  4008 net.cpp:427] loss <- label_data_1_split_1
I0517 08:20:23.265432  4008 net.cpp:401] loss -> loss
I0517 08:20:23.265446  4008 layer_factory.hpp:77] Creating layer loss
I0517 08:20:23.268208  4008 net.cpp:143] Setting up loss
I0517 08:20:23.268230  4008 net.cpp:150] Top shape: (1)
I0517 08:20:23.268241  4008 net.cpp:153]     with loss weight 1
I0517 08:20:23.268257  4008 net.cpp:158] Memory required for data: 343607608
I0517 08:20:23.268263  4008 net.cpp:219] loss needs backward computation.
I0517 08:20:23.268268  4008 net.cpp:221] accuracy does not need backward computation.
I0517 08:20:23.268273  4008 net.cpp:219] fc8_fc8_0_split needs backward computation.
I0517 08:20:23.268278  4008 net.cpp:219] fc8 needs backward computation.
I0517 08:20:23.268282  4008 net.cpp:219] drop7 needs backward computation.
I0517 08:20:23.268286  4008 net.cpp:219] relu7 needs backward computation.
I0517 08:20:23.268291  4008 net.cpp:219] fc7 needs backward computation.
I0517 08:20:23.268296  4008 net.cpp:219] drop6 needs backward computation.
I0517 08:20:23.268299  4008 net.cpp:219] relu6 needs backward computation.
I0517 08:20:23.268303  4008 net.cpp:219] fc6 needs backward computation.
I0517 08:20:23.268307  4008 net.cpp:219] pool5 needs backward computation.
I0517 08:20:23.268312  4008 net.cpp:219] relu5 needs backward computation.
I0517 08:20:23.268316  4008 net.cpp:219] conv5 needs backward computation.
I0517 08:20:23.268321  4008 net.cpp:219] relu4 needs backward computation.
I0517 08:20:23.268326  4008 net.cpp:219] conv4 needs backward computation.
I0517 08:20:23.268329  4008 net.cpp:219] relu3 needs backward computation.
I0517 08:20:23.268333  4008 net.cpp:219] conv3 needs backward computation.
I0517 08:20:23.268337  4008 net.cpp:219] norm2 needs backward computation.
I0517 08:20:23.268342  4008 net.cpp:219] pool2 needs backward computation.
I0517 08:20:23.268347  4008 net.cpp:219] relu2 needs backward computation.
I0517 08:20:23.268350  4008 net.cpp:219] conv2 needs backward computation.
I0517 08:20:23.268355  4008 net.cpp:219] norm1 needs backward computation.
I0517 08:20:23.268359  4008 net.cpp:219] pool1 needs backward computation.
I0517 08:20:23.268363  4008 net.cpp:219] relu1 needs backward computation.
I0517 08:20:23.268368  4008 net.cpp:219] conv1 needs backward computation.
I0517 08:20:23.268373  4008 net.cpp:221] label_data_1_split does not need backward computation.
I0517 08:20:23.268378  4008 net.cpp:221] data does not need backward computation.
I0517 08:20:23.268381  4008 net.cpp:263] This network produces output accuracy
I0517 08:20:23.268385  4008 net.cpp:263] This network produces output loss
I0517 08:20:23.268404  4008 net.cpp:276] Network initialization done.
I0517 08:20:23.268520  4008 solver.cpp:62] Solver scaffolding done.
I0517 08:20:23.887953  4008 caffe.cpp:130] Finetuning from models/bvlc_reference_caffenet/caffenet_0.57368.caffemodel
I0517 08:21:04.211057  4008 base_conv_layer.cpp:16] layer	conv1	has sparsity of 0.0257117
I0517 08:21:04.211482  4008 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0517 08:21:04.211948  4008 base_conv_layer.cpp:16] layer	conv2	has sparsity of 0.0267155
I0517 08:21:04.215014  4008 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0517 08:21:04.216292  4008 base_conv_layer.cpp:16] layer	conv3	has sparsity of 0.0279722
I0517 08:21:04.225620  4008 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0517 08:21:04.226604  4008 base_conv_layer.cpp:16] layer	conv4	has sparsity of 0.025151
I0517 08:21:04.233683  4008 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0517 08:21:04.234338  4008 base_conv_layer.cpp:16] layer	conv5	has sparsity of 0.0245067
I0517 08:21:04.238759  4008 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0517 08:21:04.303110  4008 inner_product_layer.cpp:11] layer	fc6	has sparsity of 0.0563966
I0517 08:21:04.804994  4008 inner_product_layer.cpp:11] layer	fc7	has sparsity of 0.046737
I0517 08:21:05.047072  4008 inner_product_layer.cpp:11] layer	fc8	has sparsity of 0.0321321
I0517 08:21:48.964006  4008 base_conv_layer.cpp:16] layer	conv1	has sparsity of 0.0257117
I0517 08:21:48.965608  4008 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0517 08:21:48.966197  4008 base_conv_layer.cpp:16] layer	conv2	has sparsity of 0.0267155
I0517 08:21:48.970067  4008 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0517 08:21:48.971679  4008 base_conv_layer.cpp:16] layer	conv3	has sparsity of 0.0279722
I0517 08:21:48.983283  4008 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0517 08:21:48.984513  4008 base_conv_layer.cpp:16] layer	conv4	has sparsity of 0.025151
I0517 08:21:48.993322  4008 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0517 08:21:48.994158  4008 base_conv_layer.cpp:16] layer	conv5	has sparsity of 0.0245067
I0517 08:21:48.999830  4008 base_conv_layer.cpp:122] ConvolutionParameter ConvMode: DEFAULT
I0517 08:21:49.068248  4008 inner_product_layer.cpp:11] layer	fc6	has sparsity of 0.0563966
I0517 08:21:49.570852  4008 inner_product_layer.cpp:11] layer	fc7	has sparsity of 0.046737
I0517 08:21:49.811945  4008 inner_product_layer.cpp:11] layer	fc8	has sparsity of 0.0321321
I0517 08:21:49.921387  4008 caffe.cpp:220] Starting Optimization
I0517 08:21:49.921443  4008 solver.cpp:290] Solving CaffeNet
I0517 08:21:49.921452  4008 solver.cpp:291] Learning Rate Policy: multistep
I0517 08:21:49.932245  4008 solver.cpp:348] Iteration 0, Testing net (#0)
I0517 08:21:50.296973  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 08:23:04.831837  4008 solver.cpp:415]     Test net output #0: accuracy = 0.57346
I0517 08:23:04.832190  4008 solver.cpp:415]     Test net output #1: loss = 1.8219 (* 1 = 1.8219 loss)
I0517 08:23:04.948740  4008 solver.cpp:231] Iteration 0, loss = 1.21861
I0517 08:23:04.948799  4008 solver.cpp:247]     Train net output #0: loss = 1.21861 (* 1 = 1.21861 loss)
I0517 08:23:04.948817  4008 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0517 08:23:05.117411  4008 sgd_solver.cpp:120]     Element Sparsity %: 
2.57117	0	2.67155	0	2.79722	0	2.5151	0	2.45067	0	5.63966	0	4.6737	0	3.21321	0.3	
I0517 08:23:05.117579  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:23:05.118317  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.3	
I0517 08:23:05.118342  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:23:05.218530  4008 solver.cpp:260]     Total regularization terms: 2.7012 loss+regular. : 3.9198
I0517 08:23:07.815204  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 08:24:16.824086  4008 solver.cpp:231] Iteration 200, loss = 1.45375
I0517 08:24:16.824457  4008 solver.cpp:247]     Train net output #0: loss = 1.45375 (* 1 = 1.45375 loss)
I0517 08:24:16.824487  4008 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0517 08:24:16.985018  4008 sgd_solver.cpp:120]     Element Sparsity %: 
2.67734	0	3.16276	0	3.34224	0	2.97053	0	2.84175	0	6.2086	0	5.15445	0	3.53098	0.3	
I0517 08:24:17.058604  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:24:17.059139  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.3	
I0517 08:24:17.059149  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:24:17.074143  4008 solver.cpp:260]     Total regularization terms: 2.68998 loss+regular. : 4.14373
I0517 08:25:38.618844  4008 solver.cpp:231] Iteration 400, loss = 1.4903
I0517 08:25:38.619143  4008 solver.cpp:247]     Train net output #0: loss = 1.4903 (* 1 = 1.4903 loss)
I0517 08:25:38.619164  4008 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0517 08:25:38.780319  4008 sgd_solver.cpp:120]     Element Sparsity %: 
2.76056	0	3.66667	0	3.91936	0	3.45308	0	3.28866	0	6.77884	0	5.6478	0	3.84563	0.3	
I0517 08:25:38.854722  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:25:38.855458  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.3	
I0517 08:25:38.855479  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:25:38.869058  4008 solver.cpp:260]     Total regularization terms: 2.6784 loss+regular. : 4.1687
I0517 08:26:55.168453  4008 solver.cpp:231] Iteration 600, loss = 1.20717
I0517 08:26:55.168824  4008 solver.cpp:247]     Train net output #0: loss = 1.20717 (* 1 = 1.20717 loss)
I0517 08:26:55.168845  4008 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0517 08:26:55.328311  4008 sgd_solver.cpp:120]     Element Sparsity %: 
3.03891	0	4.1735	0	4.51796	0	3.93006	0	3.73264	0	7.30349	0	6.10999	0	4.14097	0.3	
I0517 08:26:55.401741  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:26:55.402567  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.3	
I0517 08:26:55.402586  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:26:55.412432  4008 solver.cpp:260]     Total regularization terms: 2.66696 loss+regular. : 3.87413
I0517 08:28:13.051489  4008 solver.cpp:231] Iteration 800, loss = 1.25386
I0517 08:28:13.051683  4008 solver.cpp:247]     Train net output #0: loss = 1.25386 (* 1 = 1.25386 loss)
I0517 08:28:13.051710  4008 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0517 08:28:13.214382  4008 sgd_solver.cpp:120]     Element Sparsity %: 
3.05326	0	4.65202	0	5.10683	0	4.40945	0	4.16893	0	7.79498	0	6.5387	0	4.41313	0.3	
I0517 08:28:13.287649  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:28:13.288275  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.3	
I0517 08:28:13.288288  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:28:13.301687  4008 solver.cpp:260]     Total regularization terms: 2.65557 loss+regular. : 3.90943
I0517 08:29:31.405601  4008 solver.cpp:348] Iteration 1000, Testing net (#0)
I0517 08:29:32.224131  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 08:30:48.464121  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55682
I0517 08:30:48.464375  4008 solver.cpp:415]     Test net output #1: loss = 1.90238 (* 1 = 1.90238 loss)
I0517 08:30:48.554785  4008 solver.cpp:231] Iteration 1000, loss = 1.26913
I0517 08:30:48.554855  4008 solver.cpp:247]     Train net output #0: loss = 1.26913 (* 1 = 1.26913 loss)
I0517 08:30:48.554873  4008 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0517 08:30:48.714474  4008 sgd_solver.cpp:120]     Element Sparsity %: 
3.28857	0	5.14323	0	5.70611	0	4.9009	0	4.612	0	8.25974	0	6.94079	0	4.6635	0.3	
I0517 08:30:48.792716  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:30:48.793587  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.3	
I0517 08:30:48.793637  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:30:48.803447  4008 solver.cpp:260]     Total regularization terms: 2.6443 loss+regular. : 3.91343
I0517 08:30:54.016590  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 08:32:05.653872  4008 solver.cpp:231] Iteration 1200, loss = 1.40396
I0517 08:32:05.654239  4008 solver.cpp:247]     Train net output #0: loss = 1.40396 (* 1 = 1.40396 loss)
I0517 08:32:05.654263  4008 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0517 08:32:05.817332  4008 sgd_solver.cpp:120]     Element Sparsity %: 
3.47509	0	5.66699	0	6.29578	0	5.35753	0	5.03721	0	8.69495	0	7.32353	0	4.89729	0.3	
I0517 08:32:05.890849  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:32:05.891436  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.3	
I0517 08:32:05.891454  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:32:05.903939  4008 solver.cpp:260]     Total regularization terms: 2.63312 loss+regular. : 4.03708
I0517 08:33:22.480814  4008 solver.cpp:231] Iteration 1400, loss = 1.58754
I0517 08:33:22.481221  4008 solver.cpp:247]     Train net output #0: loss = 1.58754 (* 1 = 1.58754 loss)
I0517 08:33:22.481245  4008 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0517 08:33:22.643098  4008 sgd_solver.cpp:120]     Element Sparsity %: 
3.54109	0	6.14941	0	6.86725	0	5.83376	0	5.47191	0	9.10966	0	7.68824	0	5.11626	0.3	
I0517 08:33:22.716616  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:33:22.717497  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.3	
I0517 08:33:22.717514  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:33:22.727459  4008 solver.cpp:260]     Total regularization terms: 2.62203 loss+regular. : 4.20957
I0517 08:34:44.032037  4008 solver.cpp:231] Iteration 1600, loss = 1.34444
I0517 08:34:44.032310  4008 solver.cpp:247]     Train net output #0: loss = 1.34444 (* 1 = 1.34444 loss)
I0517 08:34:44.032331  4008 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0517 08:34:44.191715  4008 sgd_solver.cpp:120]     Element Sparsity %: 
3.60135	0	6.63151	0	7.44991	0	6.31194	0	5.91272	0	9.50667	0	8.03834	0	5.325	0.4	
I0517 08:34:44.265046  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:34:44.265714  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.4	
I0517 08:34:44.265733  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:34:44.275394  4008 solver.cpp:260]     Total regularization terms: 2.611 loss+regular. : 3.95544
I0517 08:36:06.714341  4008 solver.cpp:231] Iteration 1800, loss = 1.26277
I0517 08:36:06.715966  4008 solver.cpp:247]     Train net output #0: loss = 1.26277 (* 1 = 1.26277 loss)
I0517 08:36:06.715989  4008 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0517 08:36:06.876034  4008 sgd_solver.cpp:120]     Element Sparsity %: 
3.80223	0	7.12858	0	8.03155	0	6.78816	0	6.37659	0	9.89398	0	8.37739	0	5.52847	0.4	
I0517 08:36:06.950755  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:36:06.951316  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.4	
I0517 08:36:06.951333  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:36:06.971567  4008 solver.cpp:260]     Total regularization terms: 2.6001 loss+regular. : 3.86288
I0517 08:37:30.368978  4008 solver.cpp:348] Iteration 2000, Testing net (#0)
I0517 08:37:31.523103  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 08:38:42.409483  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55396
I0517 08:38:42.409874  4008 solver.cpp:415]     Test net output #1: loss = 1.9172 (* 1 = 1.9172 loss)
I0517 08:38:42.497632  4008 solver.cpp:231] Iteration 2000, loss = 1.44306
I0517 08:38:42.497738  4008 solver.cpp:247]     Train net output #0: loss = 1.44306 (* 1 = 1.44306 loss)
I0517 08:38:42.497776  4008 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0517 08:38:42.665837  4008 sgd_solver.cpp:120]     Element Sparsity %: 
3.71901	0	7.61849	0	8.5968	0	7.26017	0	6.81469	0	10.2644	0	8.6998	0	5.71763	0.5	
I0517 08:38:42.739276  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:38:42.740203  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:38:42.740223  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:38:42.750036  4008 solver.cpp:260]     Total regularization terms: 2.58933 loss+regular. : 4.03238
I0517 08:38:50.801667  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 08:40:01.771035  4008 solver.cpp:231] Iteration 2200, loss = 1.55657
I0517 08:40:01.773360  4008 solver.cpp:247]     Train net output #0: loss = 1.55657 (* 1 = 1.55657 loss)
I0517 08:40:01.773387  4008 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0517 08:40:01.929839  4008 sgd_solver.cpp:120]     Element Sparsity %: 
3.97153	0	8.08073	0	9.15979	0	7.74287	0	7.23719	0	10.6225	0	9.01519	0	5.89441	0.5	
I0517 08:40:02.003461  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:40:02.004269  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:40:02.004287  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:40:02.015786  4008 solver.cpp:260]     Total regularization terms: 2.57861 loss+regular. : 4.13518
I0517 08:41:22.487874  4008 solver.cpp:231] Iteration 2400, loss = 1.34233
I0517 08:41:22.488174  4008 solver.cpp:247]     Train net output #0: loss = 1.34233 (* 1 = 1.34233 loss)
I0517 08:41:22.488286  4008 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0517 08:41:22.649437  4008 sgd_solver.cpp:120]     Element Sparsity %: 
3.91701	0	8.56868	0	9.70753	0	8.20689	0	7.66149	0	10.9681	0	9.32031	0	6.06614	0.5	
I0517 08:41:22.722669  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:41:22.723232  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:41:22.723244  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:41:22.733328  4008 solver.cpp:260]     Total regularization terms: 2.56803 loss+regular. : 3.91036
I0517 08:42:36.612259  4008 solver.cpp:231] Iteration 2600, loss = 1.70569
I0517 08:42:36.612511  4008 solver.cpp:247]     Train net output #0: loss = 1.70569 (* 1 = 1.70569 loss)
I0517 08:42:36.612531  4008 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0517 08:42:36.775043  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.14084	0	9.03711	0	10.2712	0	8.69321	0	8.09326	0	11.3075	0	9.61697	0	6.23025	0.5	
I0517 08:42:36.848431  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:42:36.849104  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:42:36.849120  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:42:36.864163  4008 solver.cpp:260]     Total regularization terms: 2.55749 loss+regular. : 4.26318
I0517 08:44:01.991086  4008 solver.cpp:231] Iteration 2800, loss = 1.31018
I0517 08:44:01.991315  4008 solver.cpp:247]     Train net output #0: loss = 1.31018 (* 1 = 1.31018 loss)
I0517 08:44:01.991334  4008 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0517 08:44:02.153894  4008 sgd_solver.cpp:120]     Element Sparsity %: 
3.96006	0	9.5179	0	10.8379	0	9.15301	0	8.51983	0	11.6362	0	9.90444	0	6.38962	0.5	
I0517 08:44:02.227254  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:44:02.227725  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:44:02.227736  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:44:02.237310  4008 solver.cpp:260]     Total regularization terms: 2.54698 loss+regular. : 3.85715
I0517 08:45:24.310955  4008 solver.cpp:348] Iteration 3000, Testing net (#0)
I0517 08:45:26.456831  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 08:46:35.254978  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55454
I0517 08:46:35.255287  4008 solver.cpp:415]     Test net output #1: loss = 1.90605 (* 1 = 1.90605 loss)
I0517 08:46:35.342972  4008 solver.cpp:231] Iteration 3000, loss = 1.40736
I0517 08:46:35.343052  4008 solver.cpp:247]     Train net output #0: loss = 1.40736 (* 1 = 1.40736 loss)
I0517 08:46:35.343070  4008 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0517 08:46:35.511927  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.15232	0	9.9834	0	11.3869	0	9.62713	0	8.92854	0	11.9571	0	10.1857	0	6.54119	0.5	
I0517 08:46:35.585635  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:46:35.586200  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:46:35.586218  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:46:35.596040  4008 solver.cpp:260]     Total regularization terms: 2.53657 loss+regular. : 3.94393
I0517 08:46:45.882477  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 08:47:50.126173  4008 solver.cpp:231] Iteration 3200, loss = 1.52047
I0517 08:47:50.126416  4008 solver.cpp:247]     Train net output #0: loss = 1.52047 (* 1 = 1.52047 loss)
I0517 08:47:50.126438  4008 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0517 08:47:50.289110  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.20684	0	10.4212	0	11.9363	0	10.0901	0	9.34968	0	12.2716	0	10.4607	0	6.69197	0.5	
I0517 08:47:50.362576  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:47:50.363493  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:47:50.363513  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:47:50.373383  4008 solver.cpp:260]     Total regularization terms: 2.5262 loss+regular. : 4.04667
I0517 08:49:14.947495  4008 solver.cpp:231] Iteration 3400, loss = 1.27379
I0517 08:49:14.947841  4008 solver.cpp:247]     Train net output #0: loss = 1.27379 (* 1 = 1.27379 loss)
I0517 08:49:14.947866  4008 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0517 08:49:15.111369  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.37902	0	10.8724	0	12.4899	0	10.5606	0	9.77715	0	12.5773	0	10.7259	0	6.83672	0.5	
I0517 08:49:15.186355  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:49:15.187224  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:49:15.187245  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:49:15.216886  4008 solver.cpp:260]     Total regularization terms: 2.51603 loss+regular. : 3.78982
I0517 08:50:34.416414  4008 solver.cpp:231] Iteration 3600, loss = 1.3769
I0517 08:50:34.416733  4008 solver.cpp:247]     Train net output #0: loss = 1.3769 (* 1 = 1.3769 loss)
I0517 08:50:34.416754  4008 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0517 08:50:34.576802  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.44789	0	11.3356	0	13.0396	0	11.0101	0	10.1913	0	12.8762	0	10.9873	0	6.97915	0.5	
I0517 08:50:34.650177  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:50:34.650872  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:50:34.650892  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:50:34.660714  4008 solver.cpp:260]     Total regularization terms: 2.50585 loss+regular. : 3.88275
I0517 08:51:55.393970  4008 solver.cpp:231] Iteration 3800, loss = 1.34928
I0517 08:51:55.394285  4008 solver.cpp:247]     Train net output #0: loss = 1.34928 (* 1 = 1.34928 loss)
I0517 08:51:55.394304  4008 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0517 08:51:55.557163  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.62293	0	11.8031	0	13.5857	0	11.472	0	10.631	0	13.1686	0	11.2462	0	7.11582	0.5	
I0517 08:51:55.631465  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:51:55.632266  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:51:55.632283  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:51:55.652189  4008 solver.cpp:260]     Total regularization terms: 2.49577 loss+regular. : 3.84505
I0517 08:53:13.285356  4008 solver.cpp:348] Iteration 4000, Testing net (#0)
I0517 08:53:15.732573  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 08:54:32.203450  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55642
I0517 08:54:32.206696  4008 solver.cpp:415]     Test net output #1: loss = 1.904 (* 1 = 1.904 loss)
I0517 08:54:32.296742  4008 solver.cpp:231] Iteration 4000, loss = 1.37595
I0517 08:54:32.296818  4008 solver.cpp:247]     Train net output #0: loss = 1.37595 (* 1 = 1.37595 loss)
I0517 08:54:32.296836  4008 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0517 08:54:32.470896  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.62867	0	12.2738	0	14.1359	0	11.9312	0	11.0453	0	13.4542	0	11.4942	0	7.24304	0.5	
I0517 08:54:32.544349  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:54:32.545253  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:54:32.545279  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:54:32.555173  4008 solver.cpp:260]     Total regularization terms: 2.48582 loss+regular. : 3.86178
I0517 08:54:45.473685  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 08:55:46.245723  4008 solver.cpp:231] Iteration 4200, loss = 1.55299
I0517 08:55:46.245985  4008 solver.cpp:247]     Train net output #0: loss = 1.55299 (* 1 = 1.55299 loss)
I0517 08:55:46.246004  4008 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0517 08:55:46.406057  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.59998	0	12.7262	0	14.6749	0	12.3815	0	11.4617	0	13.735	0	11.7393	0	7.37231	0.5	
I0517 08:55:46.479532  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:55:46.480259  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:55:46.480278  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:55:46.495379  4008 solver.cpp:260]     Total regularization terms: 2.47599 loss+regular. : 4.02898
I0517 08:57:04.509939  4008 solver.cpp:231] Iteration 4400, loss = 1.22485
I0517 08:57:04.513638  4008 solver.cpp:247]     Train net output #0: loss = 1.22485 (* 1 = 1.22485 loss)
I0517 08:57:04.513665  4008 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0517 08:57:04.672840  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.5885	0	13.1566	0	15.2076	0	12.8352	0	11.8501	0	14.0095	0	11.9804	0	7.49492	0.5	
I0517 08:57:04.746316  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:57:04.747238  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:57:04.747257  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:57:04.756953  4008 solver.cpp:260]     Total regularization terms: 2.46616 loss+regular. : 3.691
I0517 08:58:20.274158  4008 solver.cpp:231] Iteration 4600, loss = 1.45636
I0517 08:58:20.274402  4008 solver.cpp:247]     Train net output #0: loss = 1.45636 (* 1 = 1.45636 loss)
I0517 08:58:20.274425  4008 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0517 08:58:20.435233  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.79511	0	13.6309	0	15.7344	0	13.2769	0	12.2522	0	14.2792	0	12.2127	0	7.6158	0.5	
I0517 08:58:20.509624  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:58:20.510633  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:58:20.510654  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:58:20.531189  4008 solver.cpp:260]     Total regularization terms: 2.45631 loss+regular. : 3.91267
I0517 08:59:43.759572  4008 solver.cpp:231] Iteration 4800, loss = 1.61553
I0517 08:59:43.759876  4008 solver.cpp:247]     Train net output #0: loss = 1.61553 (* 1 = 1.61553 loss)
I0517 08:59:43.759897  4008 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0517 08:59:43.919947  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.79224	0	14.0537	0	16.2582	0	13.7212	0	12.6512	0	14.5464	0	12.4432	0	7.73542	0.5	
I0517 08:59:43.995519  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 08:59:43.996551  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 08:59:43.996572  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 08:59:44.016675  4008 solver.cpp:260]     Total regularization terms: 2.44663 loss+regular. : 4.06216
I0517 09:01:03.736802  4008 solver.cpp:348] Iteration 5000, Testing net (#0)
I0517 09:01:07.024096  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:02:28.412031  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5544
I0517 09:02:28.412338  4008 solver.cpp:415]     Test net output #1: loss = 1.91283 (* 1 = 1.91283 loss)
I0517 09:02:28.503713  4008 solver.cpp:231] Iteration 5000, loss = 1.38409
I0517 09:02:28.503794  4008 solver.cpp:247]     Train net output #0: loss = 1.38409 (* 1 = 1.38409 loss)
I0517 09:02:28.503811  4008 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0517 09:02:28.663341  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.90702	0	14.4821	0	16.7818	0	14.1599	0	13.0631	0	14.8145	0	12.673	0	7.85195	0.5	
I0517 09:02:28.736790  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:02:28.737645  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:02:28.737668  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:02:28.751241  4008 solver.cpp:260]     Total regularization terms: 2.43702 loss+regular. : 3.82112
I0517 09:02:45.010349  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:03:47.786855  4008 solver.cpp:231] Iteration 5200, loss = 1.19979
I0517 09:03:47.787179  4008 solver.cpp:247]     Train net output #0: loss = 1.19979 (* 1 = 1.19979 loss)
I0517 09:03:47.787214  4008 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0517 09:03:47.948289  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.87546	0	14.9456	0	17.3106	0	14.6117	0	13.4603	0	15.0747	0	12.8975	0	7.96331	0.5	
I0517 09:03:48.021703  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:03:48.022493  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:03:48.022521  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:03:48.032452  4008 solver.cpp:260]     Total regularization terms: 2.42762 loss+regular. : 3.62741
I0517 09:05:20.181757  4008 solver.cpp:231] Iteration 5400, loss = 1.53437
I0517 09:05:20.183061  4008 solver.cpp:247]     Train net output #0: loss = 1.53437 (* 1 = 1.53437 loss)
I0517 09:05:20.183079  4008 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0517 09:05:20.341928  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.01607	0	15.3923	0	17.8266	0	15.0427	0	13.8735	0	15.3328	0	13.1219	0	8.071	0.5	
I0517 09:05:20.415411  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:05:20.416177  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:05:20.416198  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:05:20.426085  4008 solver.cpp:260]     Total regularization terms: 2.41835 loss+regular. : 3.95272
I0517 09:06:43.664515  4008 solver.cpp:231] Iteration 5600, loss = 1.50997
I0517 09:06:43.665609  4008 solver.cpp:247]     Train net output #0: loss = 1.50997 (* 1 = 1.50997 loss)
I0517 09:06:43.665630  4008 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0517 09:06:43.824394  4008 sgd_solver.cpp:120]     Element Sparsity %: 
4.9472	0	15.793	0	18.3445	0	15.4788	0	14.2836	0	15.5875	0	13.3425	0	8.18044	0.5	
I0517 09:06:43.898777  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:06:43.899526  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:06:43.899543  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:06:43.914284  4008 solver.cpp:260]     Total regularization terms: 2.40917 loss+regular. : 3.91913
I0517 09:07:59.636905  4008 solver.cpp:231] Iteration 5800, loss = 1.40593
I0517 09:07:59.641690  4008 solver.cpp:247]     Train net output #0: loss = 1.40593 (* 1 = 1.40593 loss)
I0517 09:07:59.641719  4008 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I0517 09:07:59.797485  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.13372	0	16.2018	0	18.8574	0	15.9106	0	14.669	0	15.839	0	13.561	0	8.28909	0.5	
I0517 09:07:59.870982  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:07:59.871533  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:07:59.871551  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:07:59.881340  4008 solver.cpp:260]     Total regularization terms: 2.40011 loss+regular. : 3.80604
I0517 09:09:22.248705  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_6000.caffemodel
I0517 09:10:13.084018  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_6000.solverstate
I0517 09:10:13.576756  4008 solver.cpp:348] Iteration 6000, Testing net (#0)
I0517 09:10:17.950441  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:11:30.567685  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55674
I0517 09:11:30.567929  4008 solver.cpp:415]     Test net output #1: loss = 1.90289 (* 1 = 1.90289 loss)
I0517 09:11:30.655196  4008 solver.cpp:231] Iteration 6000, loss = 1.39123
I0517 09:11:30.655267  4008 solver.cpp:247]     Train net output #0: loss = 1.39123 (* 1 = 1.39123 loss)
I0517 09:11:30.655287  4008 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0517 09:11:30.821832  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.06772	0	16.6325	0	19.3545	0	16.3405	0	15.0574	0	16.0884	0	13.7756	0	8.39463	0.5	
I0517 09:11:30.822119  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:11:30.822706  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:11:30.822721  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:11:30.832516  4008 solver.cpp:260]     Total regularization terms: 2.39109 loss+regular. : 3.78231
I0517 09:11:50.318616  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:12:49.525250  4008 solver.cpp:231] Iteration 6200, loss = 1.26281
I0517 09:12:49.525497  4008 solver.cpp:247]     Train net output #0: loss = 1.26281 (* 1 = 1.26281 loss)
I0517 09:12:49.525518  4008 sgd_solver.cpp:106] Iteration 6200, lr = 0.001
I0517 09:12:49.686071  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.05051	0	17.0537	0	19.8605	0	16.7707	0	15.4539	0	16.3342	0	13.9886	0	8.49521	0.5	
I0517 09:12:49.759361  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:12:49.759934  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:12:49.759948  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:12:49.769563  4008 solver.cpp:260]     Total regularization terms: 2.38208 loss+regular. : 3.64489
I0517 09:14:04.949529  4008 solver.cpp:231] Iteration 6400, loss = 1.37276
I0517 09:14:04.949856  4008 solver.cpp:247]     Train net output #0: loss = 1.37276 (* 1 = 1.37276 loss)
I0517 09:14:04.949877  4008 sgd_solver.cpp:106] Iteration 6400, lr = 0.001
I0517 09:14:05.112963  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.1079	0	17.4635	0	20.3626	0	17.211	0	15.8341	0	16.5807	0	14.2006	0	8.59717	0.5	
I0517 09:14:05.186641  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:14:05.187644  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:14:05.187664  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:14:05.201961  4008 solver.cpp:260]     Total regularization terms: 2.37317 loss+regular. : 3.74593
I0517 09:15:24.929479  4008 solver.cpp:231] Iteration 6600, loss = 1.40397
I0517 09:15:24.929834  4008 solver.cpp:247]     Train net output #0: loss = 1.40397 (* 1 = 1.40397 loss)
I0517 09:15:24.929855  4008 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I0517 09:15:25.091315  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.2112	0	17.8838	0	20.8559	0	17.6277	0	16.227	0	16.8214	0	14.4062	0	8.69253	0.5	
I0517 09:15:25.164849  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:15:25.165546  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:15:25.165590  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:15:25.175396  4008 solver.cpp:260]     Total regularization terms: 2.36433 loss+regular. : 3.7683
I0517 09:16:48.330991  4008 solver.cpp:231] Iteration 6800, loss = 1.64175
I0517 09:16:48.332417  4008 solver.cpp:247]     Train net output #0: loss = 1.64175 (* 1 = 1.64175 loss)
I0517 09:16:48.332438  4008 sgd_solver.cpp:106] Iteration 6800, lr = 0.001
I0517 09:16:48.492633  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.13085	0	18.2988	0	21.3454	0.260417	18.0687	0	16.6131	0	17.0636	0	14.6145	0	8.79609	0.5	
I0517 09:16:48.566002  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:16:48.566596  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:16:48.566614  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:16:48.578366  4008 solver.cpp:260]     Total regularization terms: 2.35557 loss+regular. : 3.99732
I0517 09:18:19.024507  4008 solver.cpp:348] Iteration 7000, Testing net (#0)
I0517 09:18:22.896852  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:19:36.844318  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5539
I0517 09:19:36.844645  4008 solver.cpp:415]     Test net output #1: loss = 1.91304 (* 1 = 1.91304 loss)
I0517 09:19:36.933087  4008 solver.cpp:231] Iteration 7000, loss = 1.40558
I0517 09:19:36.933172  4008 solver.cpp:247]     Train net output #0: loss = 1.40558 (* 1 = 1.40558 loss)
I0517 09:19:36.933190  4008 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0517 09:19:37.093421  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.31738	0	18.7129	0	21.8297	0.260417	18.4783	0	16.9951	0	17.2976	0	14.8176	0	8.89272	0.5	
I0517 09:19:37.167146  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:19:37.167927  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:19:37.167945  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:19:37.179364  4008 solver.cpp:260]     Total regularization terms: 2.34682 loss+regular. : 3.75241
I0517 09:20:02.180902  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:20:55.341514  4008 solver.cpp:231] Iteration 7200, loss = 1.41943
I0517 09:20:55.341820  4008 solver.cpp:247]     Train net output #0: loss = 1.41943 (* 1 = 1.41943 loss)
I0517 09:20:55.341841  4008 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I0517 09:20:55.502568  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.36616	0	19.1328	0	22.3293	0.260417	18.9034	0	17.3579	0	17.5307	0	15.0186	0	8.98552	0.5	
I0517 09:20:55.576957  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:20:55.577702  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:20:55.577723  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:20:55.591382  4008 solver.cpp:260]     Total regularization terms: 2.33817 loss+regular. : 3.7576
I0517 09:22:08.550673  4008 solver.cpp:231] Iteration 7400, loss = 1.40307
I0517 09:22:08.551560  4008 solver.cpp:247]     Train net output #0: loss = 1.40307 (* 1 = 1.40307 loss)
I0517 09:22:08.551581  4008 sgd_solver.cpp:106] Iteration 7400, lr = 0.001
I0517 09:22:08.713187  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.39199	0	19.512	0	22.8161	0.260417	19.3248	0	17.745	0	17.762	0	15.216	0	9.07988	0.5	
I0517 09:22:08.786665  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:22:08.787365  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:22:08.787385  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:22:08.797225  4008 solver.cpp:260]     Total regularization terms: 2.32967 loss+regular. : 3.73274
I0517 09:23:28.052142  4008 solver.cpp:231] Iteration 7600, loss = 1.53032
I0517 09:23:28.055513  4008 solver.cpp:247]     Train net output #0: loss = 1.53032 (* 1 = 1.53032 loss)
I0517 09:23:28.055544  4008 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I0517 09:23:28.212781  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.37477	0	19.9277	0	23.2921	0.260417	19.7397	0	18.1202	0	17.9914	0	15.4154	0	9.17205	0.5	
I0517 09:23:28.286305  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:23:28.287214  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:23:28.287235  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:23:28.297158  4008 solver.cpp:260]     Total regularization terms: 2.32109 loss+regular. : 3.85142
I0517 09:24:57.016656  4008 solver.cpp:231] Iteration 7800, loss = 1.41599
I0517 09:24:57.016894  4008 solver.cpp:247]     Train net output #0: loss = 1.41599 (* 1 = 1.41599 loss)
I0517 09:24:57.016917  4008 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0517 09:24:57.178788  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.32599	0	20.3158	0	23.7757	0.260417	20.15	0	18.4828	0	18.2189	0	15.6104	0	9.26248	0.5	
I0517 09:24:57.252940  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:24:57.253677  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:24:57.253698  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:24:57.263572  4008 solver.cpp:260]     Total regularization terms: 2.31259 loss+regular. : 3.72858
I0517 09:26:16.217691  4008 solver.cpp:348] Iteration 8000, Testing net (#0)
I0517 09:26:20.613044  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:27:33.480140  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55824
I0517 09:27:33.480381  4008 solver.cpp:415]     Test net output #1: loss = 1.89437 (* 1 = 1.89437 loss)
I0517 09:27:33.570945  4008 solver.cpp:231] Iteration 8000, loss = 1.59747
I0517 09:27:33.571049  4008 solver.cpp:247]     Train net output #0: loss = 1.59747 (* 1 = 1.59747 loss)
I0517 09:27:33.571069  4008 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0517 09:27:33.740241  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.28868	0	20.7174	0	24.2488	0.260417	20.561	0	18.8504	0	18.443	0	15.8044	0	9.35137	0.5	
I0517 09:27:33.814244  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:27:33.815140  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:27:33.815162  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:27:33.824962  4008 solver.cpp:260]     Total regularization terms: 2.30421 loss+regular. : 3.90167
I0517 09:28:01.481775  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:28:55.183660  4008 solver.cpp:231] Iteration 8200, loss = 1.52767
I0517 09:28:55.183913  4008 solver.cpp:247]     Train net output #0: loss = 1.52767 (* 1 = 1.52767 loss)
I0517 09:28:55.183943  4008 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I0517 09:28:55.343260  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.48955	0	21.1045	0	24.7199	0.260417	20.9718	0	19.2295	0	18.6662	0	15.995	0	9.43906	0.5	
I0517 09:28:55.416752  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:28:55.417457  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:28:55.417474  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:28:55.427232  4008 solver.cpp:260]     Total regularization terms: 2.29589 loss+regular. : 3.82356
I0517 09:30:12.802304  4008 solver.cpp:231] Iteration 8400, loss = 1.55991
I0517 09:30:12.805325  4008 solver.cpp:247]     Train net output #0: loss = 1.55991 (* 1 = 1.55991 loss)
I0517 09:30:12.805361  4008 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0517 09:30:12.964754  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.36042	0	21.4928	0	25.1912	0.260417	21.3867	0	19.6036	0	18.8872	0	16.1839	0	9.52927	0.5	
I0517 09:30:13.038420  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:30:13.039149  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:30:13.039167  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:30:13.048985  4008 solver.cpp:260]     Total regularization terms: 2.2877 loss+regular. : 3.84761
I0517 09:31:31.795368  4008 solver.cpp:231] Iteration 8600, loss = 1.43525
I0517 09:31:31.795617  4008 solver.cpp:247]     Train net output #0: loss = 1.43525 (* 1 = 1.43525 loss)
I0517 09:31:31.795636  4008 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I0517 09:31:31.959316  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.48955	0	21.8926	0	25.6558	0.260417	21.7865	0	19.9784	0	19.1065	0	16.3702	0	9.6125	0.5	
I0517 09:31:32.033706  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:31:32.034536  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:31:32.034554  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:31:32.049686  4008 solver.cpp:260]     Total regularization terms: 2.27946 loss+regular. : 3.71471
I0517 09:32:55.836062  4008 solver.cpp:231] Iteration 8800, loss = 1.4571
I0517 09:32:55.836287  4008 solver.cpp:247]     Train net output #0: loss = 1.4571 (* 1 = 1.4571 loss)
I0517 09:32:55.836307  4008 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I0517 09:32:55.998584  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.64164	0	22.2881	0	26.1235	0.260417	22.1823	0	20.36	0	19.3214	0	16.5569	0	9.69592	0.5	
I0517 09:32:56.073102  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:32:56.074031  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:32:56.074053  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:32:56.088958  4008 solver.cpp:260]     Total regularization terms: 2.27134 loss+regular. : 3.72844
I0517 09:34:17.745784  4008 solver.cpp:348] Iteration 9000, Testing net (#0)
I0517 09:34:22.697407  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:35:35.550202  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5561
I0517 09:35:35.550457  4008 solver.cpp:415]     Test net output #1: loss = 1.90494 (* 1 = 1.90494 loss)
I0517 09:35:35.638247  4008 solver.cpp:231] Iteration 9000, loss = 1.50735
I0517 09:35:35.638325  4008 solver.cpp:247]     Train net output #0: loss = 1.50735 (* 1 = 1.50735 loss)
I0517 09:35:35.638345  4008 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0517 09:35:35.805636  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.68756	0	22.6637	0	26.5763	0.260417	22.5839	0	20.7052	0	19.5378	0	16.7403	0	9.77788	0.5	
I0517 09:35:35.879310  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:35:35.880094  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:35:35.880151  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:35:35.890095  4008 solver.cpp:260]     Total regularization terms: 2.26326 loss+regular. : 3.77061
I0517 09:36:05.837983  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:36:59.968252  4008 solver.cpp:231] Iteration 9200, loss = 1.40163
I0517 09:36:59.969259  4008 solver.cpp:247]     Train net output #0: loss = 1.40163 (* 1 = 1.40163 loss)
I0517 09:36:59.969282  4008 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I0517 09:37:00.128543  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.68182	0	23.0417	0	27.0268	0.260417	22.9739	0	21.07	0	19.7519	0	16.9207	0	9.86023	0.5	
I0517 09:37:00.202077  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.0434028	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:37:00.203003  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:37:00.203035  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:37:00.213022  4008 solver.cpp:260]     Total regularization terms: 2.25527 loss+regular. : 3.65691
I0517 09:38:30.958124  4008 solver.cpp:231] Iteration 9400, loss = 1.47393
I0517 09:38:30.958559  4008 solver.cpp:247]     Train net output #0: loss = 1.47393 (* 1 = 1.47393 loss)
I0517 09:38:30.958577  4008 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I0517 09:38:31.117990  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.84539	0	23.3919	0	27.4798	0.260417	23.3778	0	21.4335	0	19.9629	0	17.1024	0	9.9385	0.5	
I0517 09:38:31.191499  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.0434028	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:38:31.192376  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:38:31.192396  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:38:31.202201  4008 solver.cpp:260]     Total regularization terms: 2.2473 loss+regular. : 3.72124
I0517 09:39:58.809059  4008 solver.cpp:231] Iteration 9600, loss = 1.5777
I0517 09:39:58.809417  4008 solver.cpp:247]     Train net output #0: loss = 1.5777 (* 1 = 1.5777 loss)
I0517 09:39:58.809437  4008 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0517 09:39:58.967651  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.85399	0	23.7829	0	27.9341	0.260417	23.7648	0	21.7875	0	20.1695	0	17.2804	0	10.0163	0.5	
I0517 09:39:59.041097  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.0434028	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:39:59.042079  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:39:59.042100  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:39:59.051874  4008 solver.cpp:260]     Total regularization terms: 2.23941 loss+regular. : 3.81711
I0517 09:41:15.834682  4008 solver.cpp:231] Iteration 9800, loss = 1.60153
I0517 09:41:15.837667  4008 solver.cpp:247]     Train net output #0: loss = 1.60153 (* 1 = 1.60153 loss)
I0517 09:41:15.837704  4008 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I0517 09:41:15.996348  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.89417	0	24.1722	0	28.3797	0.260417	24.1556	0	22.1472	0	20.3778	0	17.456	0	10.0934	0.5	
I0517 09:41:16.070812  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.0434028	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:41:16.071667  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:41:16.071696  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:41:16.086669  4008 solver.cpp:260]     Total regularization terms: 2.23155 loss+regular. : 3.83308
I0517 09:42:39.789639  4008 solver.cpp:348] Iteration 10000, Testing net (#0)
I0517 09:42:46.988157  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:44:00.366920  4008 solver.cpp:415]     Test net output #0: accuracy = 0.552159
I0517 09:44:00.367302  4008 solver.cpp:415]     Test net output #1: loss = 1.9201 (* 1 = 1.9201 loss)
I0517 09:44:00.456974  4008 solver.cpp:231] Iteration 10000, loss = 1.60197
I0517 09:44:00.457070  4008 solver.cpp:247]     Train net output #0: loss = 1.60197 (* 1 = 1.60197 loss)
I0517 09:44:00.457088  4008 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0517 09:44:00.622758  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.80808	0	24.5514	0	28.8379	0.260417	24.5375	0	22.4876	0	20.5859	0	17.633	0	10.1717	0.5	
I0517 09:44:00.696843  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.0434028	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:44:00.697810  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:44:00.697844  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:44:00.707640  4008 solver.cpp:260]     Total regularization terms: 2.2238 loss+regular. : 3.82577
I0517 09:44:32.630009  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:45:20.430976  4008 solver.cpp:231] Iteration 10200, loss = 1.40257
I0517 09:45:20.431262  4008 solver.cpp:247]     Train net output #0: loss = 1.40257 (* 1 = 1.40257 loss)
I0517 09:45:20.431283  4008 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I0517 09:45:20.590837  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.77078	0	24.9001	0	29.2814	0.260417	24.902	0	22.8448	0	20.7904	0	17.8054	0	10.2499	0.5	
I0517 09:45:20.664532  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.0868056	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:45:20.665328  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:45:20.665359  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:45:20.675501  4008 solver.cpp:260]     Total regularization terms: 2.21639 loss+regular. : 3.61896
I0517 09:46:46.656882  4008 solver.cpp:231] Iteration 10400, loss = 1.44462
I0517 09:46:46.657143  4008 solver.cpp:247]     Train net output #0: loss = 1.44462 (* 1 = 1.44462 loss)
I0517 09:46:46.657162  4008 sgd_solver.cpp:106] Iteration 10400, lr = 0.001
I0517 09:46:46.818650  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.8626	0	25.2516	0	29.7141	0.520833	25.2872	0	23.1827	0	20.9963	0	17.9801	0	10.3255	0.5	
I0517 09:46:46.892202  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.0868056	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:46:46.893167  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:46:46.893189  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:46:46.902936  4008 solver.cpp:260]     Total regularization terms: 2.2089 loss+regular. : 3.65353
I0517 09:48:13.157511  4008 solver.cpp:231] Iteration 10600, loss = 1.6124
I0517 09:48:13.157790  4008 solver.cpp:247]     Train net output #0: loss = 1.6124 (* 1 = 1.6124 loss)
I0517 09:48:13.157809  4008 sgd_solver.cpp:106] Iteration 10600, lr = 0.001
I0517 09:48:13.318236  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.90565	0	25.6367	0	30.1613	0.520833	25.6721	0	23.5252	0	21.1973	0	18.1523	0	10.3995	0.5	
I0517 09:48:13.391571  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.0868056	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:48:13.392030  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:48:13.392041  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:48:13.407171  4008 solver.cpp:260]     Total regularization terms: 2.20154 loss+regular. : 3.81394
I0517 09:49:35.155004  4008 solver.cpp:231] Iteration 10800, loss = 1.59326
I0517 09:49:35.155514  4008 solver.cpp:247]     Train net output #0: loss = 1.59326 (* 1 = 1.59326 loss)
I0517 09:49:35.155536  4008 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I0517 09:49:35.317023  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.94869	0	25.9961	0	30.6	0.520833	26.0391	0	23.8627	0	21.3976	0	18.322	0	10.4728	0.5	
I0517 09:49:35.390525  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.0868056	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:49:35.391191  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:49:35.391208  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:49:35.400954  4008 solver.cpp:260]     Total regularization terms: 2.19422 loss+regular. : 3.78748
I0517 09:50:55.679483  4008 solver.cpp:348] Iteration 11000, Testing net (#0)
I0517 09:51:02.129998  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:52:10.268302  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55434
I0517 09:52:10.268609  4008 solver.cpp:415]     Test net output #1: loss = 1.90786 (* 1 = 1.90786 loss)
I0517 09:52:10.355918  4008 solver.cpp:231] Iteration 11000, loss = 1.48349
I0517 09:52:10.355969  4008 solver.cpp:247]     Train net output #0: loss = 1.48349 (* 1 = 1.48349 loss)
I0517 09:52:10.355981  4008 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0517 09:52:10.524560  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.85686	0	26.3389	0	31.0196	0.520833	26.4135	0	24.1934	0	21.5998	0	18.4945	0	10.5456	0.5	
I0517 09:52:10.598403  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.130208	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:52:10.599072  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:52:10.599090  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:52:10.608954  4008 solver.cpp:260]     Total regularization terms: 2.18695 loss+regular. : 3.67044
I0517 09:52:42.924803  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 09:53:25.895972  4008 solver.cpp:231] Iteration 11200, loss = 1.50615
I0517 09:53:25.896190  4008 solver.cpp:247]     Train net output #0: loss = 1.50615 (* 1 = 1.50615 loss)
I0517 09:53:25.896210  4008 sgd_solver.cpp:106] Iteration 11200, lr = 0.001
I0517 09:53:26.057698  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.89991	0	26.681	0	31.457	0.520833	26.7708	0	24.5262	0	21.799	0	18.6636	0	10.6169	0.5	
I0517 09:53:26.131074  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.173611	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:53:26.131769  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:53:26.131786  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:53:26.141605  4008 solver.cpp:260]     Total regularization terms: 2.17975 loss+regular. : 3.6859
I0517 09:54:49.179489  4008 solver.cpp:231] Iteration 11400, loss = 1.4652
I0517 09:54:49.180136  4008 solver.cpp:247]     Train net output #0: loss = 1.4652 (* 1 = 1.4652 loss)
I0517 09:54:49.180156  4008 sgd_solver.cpp:106] Iteration 11400, lr = 0.001
I0517 09:54:49.340301  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.80234	0	27.0107	0	31.8799	0.520833	27.1385	0	24.8619	0	21.999	0	18.8342	0	10.6867	0.5	
I0517 09:54:49.414746  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.173611	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:54:49.415467  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:54:49.415483  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:54:49.440611  4008 solver.cpp:260]     Total regularization terms: 2.17257 loss+regular. : 3.63777
I0517 09:56:15.363291  4008 solver.cpp:231] Iteration 11600, loss = 1.4657
I0517 09:56:15.363575  4008 solver.cpp:247]     Train net output #0: loss = 1.4657 (* 1 = 1.4657 loss)
I0517 09:56:15.363797  4008 sgd_solver.cpp:106] Iteration 11600, lr = 0.001
I0517 09:56:15.523360  4008 sgd_solver.cpp:120]     Element Sparsity %: 
5.94869	0	27.3743	0	32.2871	0.520833	27.4969	0	25.1976	0	22.1953	0	19.0019	0	10.7561	0.5	
I0517 09:56:15.596904  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.173611	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:56:15.597611  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:56:15.597631  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:56:15.607421  4008 solver.cpp:260]     Total regularization terms: 2.16534 loss+regular. : 3.63104
I0517 09:57:37.926025  4008 solver.cpp:231] Iteration 11800, loss = 1.28495
I0517 09:57:37.926272  4008 solver.cpp:247]     Train net output #0: loss = 1.28495 (* 1 = 1.28495 loss)
I0517 09:57:37.926301  4008 sgd_solver.cpp:106] Iteration 11800, lr = 0.001
I0517 09:57:38.087455  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.01469	0	27.6979	0	32.7112	0.520833	27.876	0	25.5373	0	22.3925	0	19.1687	0	10.8265	0.5	
I0517 09:57:38.161075  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.217014	0	0	0	0	0	0	0	0	0	0	0	
I0517 09:57:38.162016  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 09:57:38.162039  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 09:57:38.182093  4008 solver.cpp:260]     Total regularization terms: 2.15833 loss+regular. : 3.44328
I0517 09:59:01.092948  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_12000.caffemodel
I0517 10:00:14.482017  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_12000.solverstate
I0517 10:00:15.306300  4008 solver.cpp:348] Iteration 12000, Testing net (#0)
I0517 10:00:23.058970  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:01:34.189083  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55178
I0517 10:01:34.189442  4008 solver.cpp:415]     Test net output #1: loss = 1.93214 (* 1 = 1.93214 loss)
I0517 10:01:34.277797  4008 solver.cpp:231] Iteration 12000, loss = 1.40542
I0517 10:01:34.277890  4008 solver.cpp:247]     Train net output #0: loss = 1.40542 (* 1 = 1.40542 loss)
I0517 10:01:34.277911  4008 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0517 10:01:34.442739  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.02617	0	28.0452	0	33.1257	0.520833	28.227	0	25.8613	0	22.5851	0	19.3306	0	10.8944	0.5	
I0517 10:01:34.443104  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:01:34.443753  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:01:34.443773  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:01:34.453438  4008 solver.cpp:260]     Total regularization terms: 2.15129 loss+regular. : 3.55672
I0517 10:02:16.595116  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:03:05.693378  4008 solver.cpp:231] Iteration 12200, loss = 1.57095
I0517 10:03:05.693616  4008 solver.cpp:247]     Train net output #0: loss = 1.57095 (* 1 = 1.57095 loss)
I0517 10:03:05.693635  4008 sgd_solver.cpp:106] Iteration 12200, lr = 0.001
I0517 10:03:05.856081  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.12087	0	28.3997	0	33.5322	0.520833	28.594	0	26.2033	0	22.7795	0	19.4932	0	10.9633	0.5	
I0517 10:03:05.930515  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.260417	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:03:05.931239  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:03:05.931257  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:03:05.951593  4008 solver.cpp:260]     Total regularization terms: 2.14439 loss+regular. : 3.71534
I0517 10:04:28.486279  4008 solver.cpp:231] Iteration 12400, loss = 1.32509
I0517 10:04:28.487212  4008 solver.cpp:247]     Train net output #0: loss = 1.32509 (* 1 = 1.32509 loss)
I0517 10:04:28.487274  4008 sgd_solver.cpp:106] Iteration 12400, lr = 0.001
I0517 10:04:28.648946  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.12374	0	28.7161	0	33.942	0.520833	28.9519	0	26.5175	0	22.9703	0	19.6547	0	11.0314	0.5	
I0517 10:04:28.722627  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.347222	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:04:28.723196  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:04:28.723215  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:04:28.753336  4008 solver.cpp:260]     Total regularization terms: 2.13744 loss+regular. : 3.46254
I0517 10:06:01.444084  4008 solver.cpp:231] Iteration 12600, loss = 1.1779
I0517 10:06:01.444396  4008 solver.cpp:247]     Train net output #0: loss = 1.1779 (* 1 = 1.1779 loss)
I0517 10:06:01.444416  4008 sgd_solver.cpp:106] Iteration 12600, lr = 0.001
I0517 10:06:01.605062  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.30739	0	29.0661	0	34.3352	0.520833	29.3151	0	26.8338	0	23.1607	0	19.8144	0	11.0973	0.5	
I0517 10:06:01.679374  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.347222	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:06:01.680083  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:06:01.680101  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:06:01.690469  4008 solver.cpp:260]     Total regularization terms: 2.13058 loss+regular. : 3.30848
I0517 10:07:27.743232  4008 solver.cpp:231] Iteration 12800, loss = 1.32679
I0517 10:07:27.743537  4008 solver.cpp:247]     Train net output #0: loss = 1.32679 (* 1 = 1.32679 loss)
I0517 10:07:27.743564  4008 sgd_solver.cpp:106] Iteration 12800, lr = 0.001
I0517 10:07:27.904373  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.00608	0	29.3844	0	34.7343	0.520833	29.675	0	27.1435	0	23.3493	0	19.9747	0	11.1643	0.5	
I0517 10:07:27.977941  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.347222	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:07:27.978950  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:07:27.978977  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:07:27.988791  4008 solver.cpp:260]     Total regularization terms: 2.12375 loss+regular. : 3.45053
I0517 10:08:54.976680  4008 solver.cpp:348] Iteration 13000, Testing net (#0)
I0517 10:09:02.388226  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:10:18.459163  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55322
I0517 10:10:18.459452  4008 solver.cpp:415]     Test net output #1: loss = 1.9183 (* 1 = 1.9183 loss)
I0517 10:10:18.559895  4008 solver.cpp:231] Iteration 13000, loss = 1.31681
I0517 10:10:18.559978  4008 solver.cpp:247]     Train net output #0: loss = 1.31681 (* 1 = 1.31681 loss)
I0517 10:10:18.559998  4008 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0517 10:10:18.720494  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.20696	0	29.75	0	35.1374	0.520833	30.0329	0	27.4473	0	23.5382	0	20.1338	0	11.229	0.5	
I0517 10:10:18.794221  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.347222	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:10:18.795009  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:10:18.795027  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:10:18.806359  4008 solver.cpp:260]     Total regularization terms: 2.11699 loss+regular. : 3.4338
I0517 10:10:59.386432  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:11:41.421386  4008 solver.cpp:231] Iteration 13200, loss = 1.63118
I0517 10:11:41.421674  4008 solver.cpp:247]     Train net output #0: loss = 1.63118 (* 1 = 1.63118 loss)
I0517 10:11:41.421711  4008 sgd_solver.cpp:106] Iteration 13200, lr = 0.001
I0517 10:11:41.581012  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.316	0	30.0794	0	35.5275	0.520833	30.3827	0	27.757	0	23.7269	0	20.2918	0	11.2934	0.5	
I0517 10:11:41.654989  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.347222	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:11:41.656273  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:11:41.656308  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:11:41.666337  4008 solver.cpp:260]     Total regularization terms: 2.11023 loss+regular. : 3.74141
I0517 10:13:07.808944  4008 solver.cpp:231] Iteration 13400, loss = 1.3227
I0517 10:13:07.813660  4008 solver.cpp:247]     Train net output #0: loss = 1.3227 (* 1 = 1.3227 loss)
I0517 10:13:07.813724  4008 sgd_solver.cpp:106] Iteration 13400, lr = 0.001
I0517 10:13:07.971341  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.2787	0	30.3831	0	35.9023	0.520833	30.7186	0	28.0597	0	23.913	0	20.4477	0	11.3586	0.5	
I0517 10:13:08.045202  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.347222	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:13:08.046855  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:13:08.046910  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:13:08.056872  4008 solver.cpp:260]     Total regularization terms: 2.10358 loss+regular. : 3.42628
I0517 10:14:33.213155  4008 solver.cpp:231] Iteration 13600, loss = 1.4702
I0517 10:14:33.213408  4008 solver.cpp:247]     Train net output #0: loss = 1.4702 (* 1 = 1.4702 loss)
I0517 10:14:33.213430  4008 sgd_solver.cpp:106] Iteration 13600, lr = 0.001
I0517 10:14:33.373658  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.23852	0	30.6914	0	36.2892	0.520833	31.0601	0	28.3603	0	24.0995	0	20.6027	0	11.4208	0.5	
I0517 10:14:33.447346  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.390625	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:14:33.448483  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:14:33.448513  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:14:33.458407  4008 solver.cpp:260]     Total regularization terms: 2.09708 loss+regular. : 3.56728
I0517 10:16:05.176993  4008 solver.cpp:231] Iteration 13800, loss = 1.40942
I0517 10:16:05.178069  4008 solver.cpp:247]     Train net output #0: loss = 1.40942 (* 1 = 1.40942 loss)
I0517 10:16:05.178092  4008 sgd_solver.cpp:106] Iteration 13800, lr = 0.001
I0517 10:16:05.338448  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.29017	0	30.9759	0	36.672	0.520833	31.4078	0	28.6872	0	24.2821	0	20.757	0	11.4823	0.5	
I0517 10:16:05.412266  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.390625	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:16:05.413303  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:16:05.413341  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:16:05.423204  4008 solver.cpp:260]     Total regularization terms: 2.09056 loss+regular. : 3.49998
I0517 10:17:30.517480  4008 solver.cpp:348] Iteration 14000, Testing net (#0)
I0517 10:17:39.968214  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:19:04.468175  4008 solver.cpp:415]     Test net output #0: accuracy = 0.554159
I0517 10:19:04.468456  4008 solver.cpp:415]     Test net output #1: loss = 1.90765 (* 1 = 1.90765 loss)
I0517 10:19:04.556298  4008 solver.cpp:231] Iteration 14000, loss = 1.43969
I0517 10:19:04.556373  4008 solver.cpp:247]     Train net output #0: loss = 1.43969 (* 1 = 1.43969 loss)
I0517 10:19:04.556391  4008 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0517 10:19:04.719607  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.28444	0	31.3027	0	37.0416	0.520833	31.7595	0	28.984	0	24.464	0	20.9093	0	11.5465	0.5	
I0517 10:19:04.793856  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.390625	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:19:04.794900  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:19:04.794920  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:19:04.804698  4008 solver.cpp:260]     Total regularization terms: 2.08407 loss+regular. : 3.52376
I0517 10:19:48.453120  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:20:26.239012  4008 solver.cpp:231] Iteration 14200, loss = 1.74402
I0517 10:20:26.239375  4008 solver.cpp:247]     Train net output #0: loss = 1.74402 (* 1 = 1.74402 loss)
I0517 10:20:26.239405  4008 sgd_solver.cpp:106] Iteration 14200, lr = 0.001
I0517 10:20:26.398808  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.118	0	31.6139	0	37.4204	0.520833	32.0989	0	29.3023	0	24.6433	0	21.0617	0	11.609	0.5	
I0517 10:20:26.472322  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:20:26.472904  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:20:26.472921  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:20:26.482703  4008 solver.cpp:260]     Total regularization terms: 2.07775 loss+regular. : 3.82177
I0517 10:21:55.404427  4008 solver.cpp:231] Iteration 14400, loss = 1.58601
I0517 10:21:55.405211  4008 solver.cpp:247]     Train net output #0: loss = 1.58601 (* 1 = 1.58601 loss)
I0517 10:21:55.405233  4008 sgd_solver.cpp:106] Iteration 14400, lr = 0.001
I0517 10:21:55.565031  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.23565	0	31.9479	0	37.7981	0.520833	32.4344	0	29.5944	0	24.823	0	21.2098	0	11.6694	0.5	
I0517 10:21:55.641789  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:21:55.642410  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:21:55.642441  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:21:55.652174  4008 solver.cpp:260]     Total regularization terms: 2.07139 loss+regular. : 3.6574
I0517 10:23:19.108368  4008 solver.cpp:231] Iteration 14600, loss = 1.52358
I0517 10:23:19.108644  4008 solver.cpp:247]     Train net output #0: loss = 1.52358 (* 1 = 1.52358 loss)
I0517 10:23:19.108670  4008 sgd_solver.cpp:106] Iteration 14600, lr = 0.001
I0517 10:23:19.269381  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.40783	0	32.2637	0	38.1716	0.520833	32.7619	0	29.8887	0	25.0022	0	21.359	0	11.7302	0.5	
I0517 10:23:19.343727  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:23:19.344298  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:23:19.344315  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:23:19.359102  4008 solver.cpp:260]     Total regularization terms: 2.06503 loss+regular. : 3.58862
I0517 10:24:45.718045  4008 solver.cpp:231] Iteration 14800, loss = 1.52542
I0517 10:24:45.718355  4008 solver.cpp:247]     Train net output #0: loss = 1.52542 (* 1 = 1.52542 loss)
I0517 10:24:45.718379  4008 sgd_solver.cpp:106] Iteration 14800, lr = 0.001
I0517 10:24:45.878298  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.26435	0	32.5592	0	38.549	0.520833	33.0868	0	30.19	0	25.1804	0	21.5092	0	11.7925	0.5	
I0517 10:24:45.952091  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:24:45.953328  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:24:45.953374  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:24:45.963307  4008 solver.cpp:260]     Total regularization terms: 2.05872 loss+regular. : 3.58414
I0517 10:26:12.382803  4008 solver.cpp:348] Iteration 15000, Testing net (#0)
I0517 10:26:20.327987  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:27:30.451514  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55718
I0517 10:27:30.451737  4008 solver.cpp:415]     Test net output #1: loss = 1.90328 (* 1 = 1.90328 loss)
I0517 10:27:30.539149  4008 solver.cpp:231] Iteration 15000, loss = 1.72133
I0517 10:27:30.539229  4008 solver.cpp:247]     Train net output #0: loss = 1.72133 (* 1 = 1.72133 loss)
I0517 10:27:30.539249  4008 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I0517 10:27:30.699421  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.37913	0	32.873	0	38.9148	0.520833	33.4197	0	30.4846	0	25.3596	0	21.6575	0	11.8514	0.5	
I0517 10:27:30.788769  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:27:30.789600  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:27:30.789628  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:27:30.803225  4008 solver.cpp:260]     Total regularization terms: 2.05241 loss+regular. : 3.77374
I0517 10:28:16.544119  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:28:53.699359  4008 solver.cpp:231] Iteration 15200, loss = 1.41011
I0517 10:28:53.699772  4008 solver.cpp:247]     Train net output #0: loss = 1.41011 (* 1 = 1.41011 loss)
I0517 10:28:53.699790  4008 sgd_solver.cpp:106] Iteration 15200, lr = 0.001
I0517 10:28:53.859112  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.47096	0	33.1683	0	39.2708	0.520833	33.7396	0	30.7775	0	25.5356	0	21.8059	0	11.9094	0.5	
I0517 10:28:53.932776  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:28:53.933470  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:28:53.933491  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:28:53.943439  4008 solver.cpp:260]     Total regularization terms: 2.04637 loss+regular. : 3.45648
I0517 10:30:20.058955  4008 solver.cpp:231] Iteration 15400, loss = 1.36398
I0517 10:30:20.059171  4008 solver.cpp:247]     Train net output #0: loss = 1.36398 (* 1 = 1.36398 loss)
I0517 10:30:20.059190  4008 sgd_solver.cpp:106] Iteration 15400, lr = 0.001
I0517 10:30:20.220525  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.30739	0	33.4782	0	39.6324	0.520833	34.0502	0	31.0728	0	25.7127	0	21.9526	0	11.9672	0.5	
I0517 10:30:20.295605  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:30:20.296362  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:30:20.296378  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:30:20.316468  4008 solver.cpp:260]     Total regularization terms: 2.04043 loss+regular. : 3.40441
I0517 10:31:40.579308  4008 solver.cpp:231] Iteration 15600, loss = 1.36624
I0517 10:31:40.581640  4008 solver.cpp:247]     Train net output #0: loss = 1.36624 (* 1 = 1.36624 loss)
I0517 10:31:40.581666  4008 sgd_solver.cpp:106] Iteration 15600, lr = 0.001
I0517 10:31:40.740360  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.39922	0	33.7663	0	39.9909	0.520833	34.3862	0	31.3531	0	25.8883	0	22.0993	0	12.0243	0.5	
I0517 10:31:40.815752  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:31:40.816689  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:31:40.816709  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:31:40.836699  4008 solver.cpp:260]     Total regularization terms: 2.03449 loss+regular. : 3.40073
I0517 10:32:58.407533  4008 solver.cpp:231] Iteration 15800, loss = 1.55294
I0517 10:32:58.407765  4008 solver.cpp:247]     Train net output #0: loss = 1.55294 (* 1 = 1.55294 loss)
I0517 10:32:58.407784  4008 sgd_solver.cpp:106] Iteration 15800, lr = 0.001
I0517 10:32:58.569578  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.26148	0	34.0719	0	40.3269	0.520833	34.6888	0	31.6409	0	26.0631	0	22.2442	0	12.0798	0.5	
I0517 10:32:58.643028  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:32:58.643906  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:32:58.643925  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:32:58.653692  4008 solver.cpp:260]     Total regularization terms: 2.0286 loss+regular. : 3.58155
I0517 10:34:22.543745  4008 solver.cpp:348] Iteration 16000, Testing net (#0)
I0517 10:34:31.924340  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:35:40.784154  4008 solver.cpp:415]     Test net output #0: accuracy = 0.556539
I0517 10:35:40.784385  4008 solver.cpp:415]     Test net output #1: loss = 1.90883 (* 1 = 1.90883 loss)
I0517 10:35:40.872478  4008 solver.cpp:231] Iteration 16000, loss = 1.72195
I0517 10:35:40.872570  4008 solver.cpp:247]     Train net output #0: loss = 1.72195 (* 1 = 1.72195 loss)
I0517 10:35:40.872623  4008 sgd_solver.cpp:106] Iteration 16000, lr = 0.001
I0517 10:35:41.034337  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.45374	0	34.3698	0	40.673	0.520833	35.003	0	31.9216	0	26.2377	0	22.3889	0	12.1354	0.5	
I0517 10:35:41.112887  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:35:41.113860  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:35:41.113890  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:35:41.123687  4008 solver.cpp:260]     Total regularization terms: 2.0227 loss+regular. : 3.74465
I0517 10:36:33.688782  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:37:14.120611  4008 solver.cpp:231] Iteration 16200, loss = 1.2151
I0517 10:37:14.125712  4008 solver.cpp:247]     Train net output #0: loss = 1.2151 (* 1 = 1.2151 loss)
I0517 10:37:14.125757  4008 sgd_solver.cpp:106] Iteration 16200, lr = 0.001
I0517 10:37:14.282133  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.47096	0	34.6426	0	41.0092	0.520833	35.3145	0	32.204	0	26.4116	0	22.5321	0	12.1927	0.5	
I0517 10:37:14.356139  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:37:14.357707  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:37:14.357758  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:37:14.367871  4008 solver.cpp:260]     Total regularization terms: 2.01693 loss+regular. : 3.23203
I0517 10:38:34.076411  4008 solver.cpp:231] Iteration 16400, loss = 1.27391
I0517 10:38:34.076653  4008 solver.cpp:247]     Train net output #0: loss = 1.27391 (* 1 = 1.27391 loss)
I0517 10:38:34.076671  4008 sgd_solver.cpp:106] Iteration 16400, lr = 0.001
I0517 10:38:34.237782  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.43365	0	34.8753	0	41.3402	0.520833	35.6317	0	32.4786	0	26.5838	0	22.6779	0	12.248	0.5	
I0517 10:38:34.312290  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:38:34.313267  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:38:34.313294  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:38:34.343358  4008 solver.cpp:260]     Total regularization terms: 2.01113 loss+regular. : 3.28504
I0517 10:39:49.483809  4008 solver.cpp:231] Iteration 16600, loss = 1.47245
I0517 10:39:49.484019  4008 solver.cpp:247]     Train net output #0: loss = 1.47245 (* 1 = 1.47245 loss)
I0517 10:39:49.484038  4008 sgd_solver.cpp:106] Iteration 16600, lr = 0.001
I0517 10:39:49.646733  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.51113	0	35.1706	0	41.6833	0.520833	35.9407	0	32.7499	0	26.7539	0	22.8203	0	12.3035	0.5	
I0517 10:39:49.721220  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:39:49.721866  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:39:49.721880  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:39:49.742235  4008 solver.cpp:260]     Total regularization terms: 2.00541 loss+regular. : 3.47786
I0517 10:41:18.763901  4008 solver.cpp:231] Iteration 16800, loss = 1.41103
I0517 10:41:18.764475  4008 solver.cpp:247]     Train net output #0: loss = 1.41103 (* 1 = 1.41103 loss)
I0517 10:41:18.764499  4008 sgd_solver.cpp:106] Iteration 16800, lr = 0.001
I0517 10:41:18.931546  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.52261	0	35.4339	0	42.0276	0.520833	36.2467	0	33.0367	0	26.9257	0	22.964	0	12.3588	0.5	
I0517 10:41:19.006755  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:41:19.007674  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:41:19.007717  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:41:19.023092  4008 solver.cpp:260]     Total regularization terms: 1.99974 loss+regular. : 3.41077
I0517 10:42:46.642405  4008 solver.cpp:348] Iteration 17000, Testing net (#0)
I0517 10:43:00.832677  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:44:17.688597  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55316
I0517 10:44:17.688843  4008 solver.cpp:415]     Test net output #1: loss = 1.91502 (* 1 = 1.91502 loss)
I0517 10:44:17.779456  4008 solver.cpp:231] Iteration 17000, loss = 1.40087
I0517 10:44:17.779533  4008 solver.cpp:247]     Train net output #0: loss = 1.40087 (* 1 = 1.40087 loss)
I0517 10:44:17.779552  4008 sgd_solver.cpp:106] Iteration 17000, lr = 0.001
I0517 10:44:17.940928  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.72922	0	35.7168	0	42.3656	0.520833	36.5365	0	33.3039	0	27.0923	0	23.1038	0	12.4115	0.5	
I0517 10:44:18.014649  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:44:18.015717  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:44:18.015744  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:44:18.025588  4008 solver.cpp:260]     Total regularization terms: 1.99414 loss+regular. : 3.39502
I0517 10:45:08.841931  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:45:39.705238  4008 solver.cpp:231] Iteration 17200, loss = 1.47653
I0517 10:45:39.705498  4008 solver.cpp:247]     Train net output #0: loss = 1.47653 (* 1 = 1.47653 loss)
I0517 10:45:39.705528  4008 sgd_solver.cpp:106] Iteration 17200, lr = 0.001
I0517 10:45:39.866256  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.70053	0	35.9811	0	42.6991	0.520833	36.8325	0	33.57	0	27.2616	0	23.2426	0	12.4648	0.5	
I0517 10:45:39.939891  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:45:39.940800  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:45:39.940834  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:45:39.950951  4008 solver.cpp:260]     Total regularization terms: 1.98858 loss+regular. : 3.4651
I0517 10:47:14.317958  4008 solver.cpp:231] Iteration 17400, loss = 1.49104
I0517 10:47:14.318233  4008 solver.cpp:247]     Train net output #0: loss = 1.49104 (* 1 = 1.49104 loss)
I0517 10:47:14.318264  4008 sgd_solver.cpp:106] Iteration 17400, lr = 0.001
I0517 10:47:14.476615  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.79809	0	36.2275	0	43.0261	0.520833	37.122	0	33.8515	0	27.43	0	23.3815	0	12.5173	0.5	
I0517 10:47:14.550354  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:47:14.551199  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:47:14.551225  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:47:14.560987  4008 solver.cpp:260]     Total regularization terms: 1.98306 loss+regular. : 3.4741
I0517 10:48:38.864524  4008 solver.cpp:231] Iteration 17600, loss = 1.45805
I0517 10:48:38.864758  4008 solver.cpp:247]     Train net output #0: loss = 1.45805 (* 1 = 1.45805 loss)
I0517 10:48:38.864778  4008 sgd_solver.cpp:106] Iteration 17600, lr = 0.001
I0517 10:48:39.025179  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.78088	0	36.5055	0	43.3467	0.520833	37.4185	0	34.1263	0	27.5982	0	23.521	0	12.5702	0.5	
I0517 10:48:39.098610  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:48:39.099299  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:48:39.099315  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:48:39.114027  4008 solver.cpp:260]     Total regularization terms: 1.97748 loss+regular. : 3.43553
I0517 10:50:08.763031  4008 solver.cpp:231] Iteration 17800, loss = 1.47082
I0517 10:50:08.763504  4008 solver.cpp:247]     Train net output #0: loss = 1.47082 (* 1 = 1.47082 loss)
I0517 10:50:08.763520  4008 sgd_solver.cpp:106] Iteration 17800, lr = 0.001
I0517 10:50:08.926331  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.65748	0	36.7988	0	43.6737	0.520833	37.716	0	34.3816	0	27.7642	0	23.6583	0	12.6212	0.5	
I0517 10:50:08.999936  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:50:09.000746  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:50:09.000763  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:50:09.021003  4008 solver.cpp:260]     Total regularization terms: 1.97198 loss+regular. : 3.4428
I0517 10:51:34.482416  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_18000.caffemodel
I0517 10:53:54.843267  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_18000.solverstate
I0517 10:53:55.356161  4008 solver.cpp:348] Iteration 18000, Testing net (#0)
I0517 10:54:05.991962  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:55:17.626744  4008 solver.cpp:415]     Test net output #0: accuracy = 0.553659
I0517 10:55:17.629647  4008 solver.cpp:415]     Test net output #1: loss = 1.91335 (* 1 = 1.91335 loss)
I0517 10:55:17.721732  4008 solver.cpp:231] Iteration 18000, loss = 1.53435
I0517 10:55:17.721806  4008 solver.cpp:247]     Train net output #0: loss = 1.53435 (* 1 = 1.53435 loss)
I0517 10:55:17.721824  4008 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0517 10:55:17.888797  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.81818	0	37.0716	0	43.9931	0.520833	38.0002	0	34.6433	0	27.9321	0	23.7977	0	12.6727	0.5	
I0517 10:55:17.889214  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.477431	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:55:17.889961  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.520833	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:55:17.889981  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:55:17.899794  4008 solver.cpp:260]     Total regularization terms: 1.96664 loss+regular. : 3.50099
I0517 10:56:12.391587  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 10:56:37.235960  4008 solver.cpp:231] Iteration 18200, loss = 1.23676
I0517 10:56:37.236045  4008 solver.cpp:247]     Train net output #0: loss = 1.23676 (* 1 = 1.23676 loss)
I0517 10:56:37.236063  4008 sgd_solver.cpp:106] Iteration 18200, lr = 0.001
I0517 10:56:37.396600  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.87557	0	37.3447	0	44.3019	0.78125	38.2764	0	34.8918	0	28.0962	0	23.9347	0	12.7235	0.5	
I0517 10:56:37.470208  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:56:37.471107  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:56:37.471125  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:56:37.480864  4008 solver.cpp:260]     Total regularization terms: 1.96128 loss+regular. : 3.19804
I0517 10:57:58.872781  4008 solver.cpp:231] Iteration 18400, loss = 1.2972
I0517 10:57:58.877665  4008 solver.cpp:247]     Train net output #0: loss = 1.2972 (* 1 = 1.2972 loss)
I0517 10:57:58.877701  4008 sgd_solver.cpp:106] Iteration 18400, lr = 0.001
I0517 10:57:59.030933  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.92149	0	37.6058	0	44.6161	0.78125	38.5554	0	35.1515	0	28.2593	0	24.0712	0	12.7756	0.5	
I0517 10:57:59.104614  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:57:59.105444  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:57:59.105473  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:57:59.115394  4008 solver.cpp:260]     Total regularization terms: 1.956 loss+regular. : 3.2532
I0517 10:59:25.949465  4008 solver.cpp:231] Iteration 18600, loss = 1.46057
I0517 10:59:25.949959  4008 solver.cpp:247]     Train net output #0: loss = 1.46057 (* 1 = 1.46057 loss)
I0517 10:59:25.949983  4008 sgd_solver.cpp:106] Iteration 18600, lr = 0.001
I0517 10:59:26.110203  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.96166	0	37.8538	0	44.9149	0.78125	38.8572	0	35.4153	0	28.4246	0	24.2058	0	12.8265	0.5	
I0517 10:59:26.184108  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 10:59:26.185050  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 10:59:26.185071  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 10:59:26.194913  4008 solver.cpp:260]     Total regularization terms: 1.95069 loss+regular. : 3.41126
I0517 11:00:58.346104  4008 solver.cpp:231] Iteration 18800, loss = 1.51244
I0517 11:00:58.346415  4008 solver.cpp:247]     Train net output #0: loss = 1.51244 (* 1 = 1.51244 loss)
I0517 11:00:58.346437  4008 sgd_solver.cpp:106] Iteration 18800, lr = 0.001
I0517 11:00:58.506948  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.01332	0	38.0876	0	45.2369	0.78125	39.1392	0	35.666	0	28.587	0	24.3408	0	12.8758	0.5	
I0517 11:00:58.580633  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:00:58.581728  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:00:58.581784  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:00:58.592097  4008 solver.cpp:260]     Total regularization terms: 1.94549 loss+regular. : 3.45793
I0517 11:02:35.287782  4008 solver.cpp:348] Iteration 19000, Testing net (#0)
I0517 11:02:48.266643  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:04:08.332034  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5538
I0517 11:04:08.332310  4008 solver.cpp:415]     Test net output #1: loss = 1.91107 (* 1 = 1.91107 loss)
I0517 11:04:08.420334  4008 solver.cpp:231] Iteration 19000, loss = 1.46957
I0517 11:04:08.420433  4008 solver.cpp:247]     Train net output #0: loss = 1.46957 (* 1 = 1.46957 loss)
I0517 11:04:08.420455  4008 sgd_solver.cpp:106] Iteration 19000, lr = 0.001
I0517 11:04:08.588057  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.90714	0	38.3535	0	45.5438	0.78125	39.4268	0	35.909	0	28.7486	0	24.4766	0	12.9258	0.5	
I0517 11:04:08.662084  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:04:08.662925  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:04:08.662945  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:04:08.676416  4008 solver.cpp:260]     Total regularization terms: 1.94024 loss+regular. : 3.40981
I0517 11:05:01.967658  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:05:24.313160  4008 solver.cpp:231] Iteration 19200, loss = 1.58242
I0517 11:05:24.313247  4008 solver.cpp:247]     Train net output #0: loss = 1.58242 (* 1 = 1.58242 loss)
I0517 11:05:24.313271  4008 sgd_solver.cpp:106] Iteration 19200, lr = 0.001
I0517 11:05:24.475083  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.95879	0	38.6224	0	45.8582	0.78125	39.7069	0	36.1712	0	28.9076	0	24.6112	0	12.9753	0.5	
I0517 11:05:24.548653  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:05:24.549406  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:05:24.549423  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:05:24.559151  4008 solver.cpp:260]     Total regularization terms: 1.93512 loss+regular. : 3.51754
I0517 11:06:38.393354  4008 solver.cpp:231] Iteration 19400, loss = 1.55552
I0517 11:06:38.393602  4008 solver.cpp:247]     Train net output #0: loss = 1.55552 (* 1 = 1.55552 loss)
I0517 11:06:38.393622  4008 sgd_solver.cpp:106] Iteration 19400, lr = 0.001
I0517 11:06:38.556037  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.85836	0	38.8529	0	46.162	0.78125	39.9839	0	36.4161	0	29.0697	0	24.7437	0	13.0259	0.5	
I0517 11:06:38.630599  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:06:38.631214  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:06:38.631227  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:06:38.645900  4008 solver.cpp:260]     Total regularization terms: 1.92998 loss+regular. : 3.4855
I0517 11:08:02.627485  4008 solver.cpp:231] Iteration 19600, loss = 1.46085
I0517 11:08:02.628011  4008 solver.cpp:247]     Train net output #0: loss = 1.46085 (* 1 = 1.46085 loss)
I0517 11:08:02.628044  4008 sgd_solver.cpp:106] Iteration 19600, lr = 0.001
I0517 11:08:02.787811  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.97601	0	39.0951	0	46.4701	0.78125	40.2708	0	36.6602	0	29.2309	0	24.8769	0	13.075	0.5	
I0517 11:08:02.861482  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:08:02.862270  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:08:02.862293  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:08:02.872118  4008 solver.cpp:260]     Total regularization terms: 1.92483 loss+regular. : 3.38568
I0517 11:09:29.647012  4008 solver.cpp:231] Iteration 19800, loss = 1.50162
I0517 11:09:29.651491  4008 solver.cpp:247]     Train net output #0: loss = 1.50162 (* 1 = 1.50162 loss)
I0517 11:09:29.651516  4008 sgd_solver.cpp:106] Iteration 19800, lr = 0.001
I0517 11:09:29.808464  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.90714	0	39.376	0	46.7624	0.78125	40.5463	0	36.9134	0	29.3887	0	25.0075	0	13.1239	0.5	
I0517 11:09:29.882606  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:09:29.883225  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:09:29.883249  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:09:29.893132  4008 solver.cpp:260]     Total regularization terms: 1.9197 loss+regular. : 3.42132
I0517 11:11:07.036984  4008 solver.cpp:348] Iteration 20000, Testing net (#0)
I0517 11:11:20.199550  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:12:28.848939  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55322
I0517 11:12:28.849372  4008 solver.cpp:415]     Test net output #1: loss = 1.90918 (* 1 = 1.90918 loss)
I0517 11:12:28.956970  4008 solver.cpp:231] Iteration 20000, loss = 1.33295
I0517 11:12:28.957105  4008 solver.cpp:247]     Train net output #0: loss = 1.33295 (* 1 = 1.33295 loss)
I0517 11:12:28.957147  4008 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0517 11:12:29.117252  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.95305	0	39.5996	0	47.0454	0.78125	40.8113	0	37.1625	0	29.5486	0	25.1384	0	13.1727	0.5	
I0517 11:12:29.192548  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:12:29.193815  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:12:29.193861  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:12:29.203663  4008 solver.cpp:260]     Total regularization terms: 1.9147 loss+regular. : 3.24765
I0517 11:13:29.735054  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:13:51.977238  4008 solver.cpp:231] Iteration 20200, loss = 1.51472
I0517 11:13:51.977324  4008 solver.cpp:247]     Train net output #0: loss = 1.51472 (* 1 = 1.51472 loss)
I0517 11:13:51.977346  4008 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0517 11:13:52.137384  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.91001	0	39.848	0	47.3434	0.78125	41.0788	0	37.4003	0	29.7042	0	25.2653	0	13.2196	0.5	
I0517 11:13:52.211169  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:13:52.212079  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:13:52.212126  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:13:52.222017  4008 solver.cpp:260]     Total regularization terms: 1.90988 loss+regular. : 3.4246
I0517 11:15:27.030289  4008 solver.cpp:231] Iteration 20400, loss = 1.45162
I0517 11:15:27.030669  4008 solver.cpp:247]     Train net output #0: loss = 1.45162 (* 1 = 1.45162 loss)
I0517 11:15:27.030689  4008 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0517 11:15:27.189924  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.08219	0	40.0853	0	47.6202	0.78125	41.3402	0	37.646	0	29.8619	0	25.3962	0	13.2673	0.5	
I0517 11:15:27.264364  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:15:27.265347  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:15:27.265367  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:15:27.280252  4008 solver.cpp:260]     Total regularization terms: 1.90505 loss+regular. : 3.35667
I0517 11:16:56.832540  4008 solver.cpp:231] Iteration 20600, loss = 1.47218
I0517 11:16:56.832833  4008 solver.cpp:247]     Train net output #0: loss = 1.47218 (* 1 = 1.47218 loss)
I0517 11:16:56.832947  4008 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0517 11:16:56.993139  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.06784	0	40.3044	0	47.9107	0.78125	41.5982	0	37.8814	0	30.0186	0	25.5254	0	13.3146	0.5	
I0517 11:16:57.066701  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:16:57.067461  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:16:57.067479  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:16:57.077236  4008 solver.cpp:260]     Total regularization terms: 1.90026 loss+regular. : 3.37244
I0517 11:18:22.453558  4008 solver.cpp:231] Iteration 20800, loss = 1.35278
I0517 11:18:22.453830  4008 solver.cpp:247]     Train net output #0: loss = 1.35278 (* 1 = 1.35278 loss)
I0517 11:18:22.453845  4008 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0517 11:18:22.614506  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.10227	0	40.498	0	48.1984	0.78125	41.8505	0	38.1183	0	30.1746	0	25.6538	0	13.3616	0.5	
I0517 11:18:22.690784  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:18:22.691506  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:18:22.691524  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:18:22.706414  4008 solver.cpp:260]     Total regularization terms: 1.89552 loss+regular. : 3.24831
I0517 11:19:36.977035  4008 solver.cpp:348] Iteration 21000, Testing net (#0)
I0517 11:19:48.827337  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:20:59.826601  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55062
I0517 11:20:59.826922  4008 solver.cpp:415]     Test net output #1: loss = 1.9228 (* 1 = 1.9228 loss)
I0517 11:20:59.921771  4008 solver.cpp:231] Iteration 21000, loss = 1.53995
I0517 11:20:59.921845  4008 solver.cpp:247]     Train net output #0: loss = 1.53995 (* 1 = 1.53995 loss)
I0517 11:20:59.921866  4008 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0517 11:21:00.082304  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.91575	0	40.7913	0	48.4733	0.78125	42.1204	0	38.3608	0	30.3312	0	25.7822	0	13.4063	0.5	
I0517 11:21:00.156208  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:21:00.157061  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:21:00.157080  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:21:00.167034  4008 solver.cpp:260]     Total regularization terms: 1.89077 loss+regular. : 3.43071
I0517 11:22:10.877112  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:22:31.829437  4008 solver.cpp:231] Iteration 21200, loss = 1.41381
I0517 11:22:31.829530  4008 solver.cpp:247]     Train net output #0: loss = 1.41381 (* 1 = 1.41381 loss)
I0517 11:22:31.829550  4008 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0517 11:22:31.990267  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.9674	0	41.055	0	48.7447	0.78125	42.3798	0	38.6027	0	30.4877	0	25.91	0	13.4546	0.5	
I0517 11:22:32.064314  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:22:32.065415  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:22:32.065443  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:22:32.075523  4008 solver.cpp:260]     Total regularization terms: 1.88614 loss+regular. : 3.29995
I0517 11:23:52.083730  4008 solver.cpp:231] Iteration 21400, loss = 1.38878
I0517 11:23:52.083921  4008 solver.cpp:247]     Train net output #0: loss = 1.38878 (* 1 = 1.38878 loss)
I0517 11:23:52.083941  4008 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0517 11:23:52.246114  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.07071	0	41.2878	0	49.0151	0.78125	42.6374	0	38.8403	0	30.6411	0	26.0375	0	13.5	0.5	
I0517 11:23:52.321043  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:23:52.321888  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:23:52.321909  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:23:52.337110  4008 solver.cpp:260]     Total regularization terms: 1.88146 loss+regular. : 3.27024
I0517 11:25:12.766085  4008 solver.cpp:231] Iteration 21600, loss = 1.41133
I0517 11:25:12.766407  4008 solver.cpp:247]     Train net output #0: loss = 1.41133 (* 1 = 1.41133 loss)
I0517 11:25:12.766433  4008 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0517 11:25:12.928275  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.18262	0	41.5251	0	49.2846	0.78125	42.8804	0	39.0731	0	30.7942	0	26.1629	0	13.5452	0.5	
I0517 11:25:13.002935  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:25:13.003725  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:25:13.003746  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:25:13.018018  4008 solver.cpp:260]     Total regularization terms: 1.87682 loss+regular. : 3.28815
I0517 11:26:31.059449  4008 solver.cpp:231] Iteration 21800, loss = 1.45165
I0517 11:26:31.059730  4008 solver.cpp:247]     Train net output #0: loss = 1.45165 (* 1 = 1.45165 loss)
I0517 11:26:31.059751  4008 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0517 11:26:31.218905  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.18549	0	41.7386	0	49.5542	0.78125	43.1333	0	39.296	0	30.9487	0	26.2898	0	13.5894	0.5	
I0517 11:26:31.292593  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:26:31.293437  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:26:31.293457  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:26:31.303200  4008 solver.cpp:260]     Total regularization terms: 1.87223 loss+regular. : 3.32388
I0517 11:28:11.069133  4008 solver.cpp:348] Iteration 22000, Testing net (#0)
I0517 11:28:25.684577  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:29:30.117960  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55176
I0517 11:29:30.119971  4008 solver.cpp:415]     Test net output #1: loss = 1.91687 (* 1 = 1.91687 loss)
I0517 11:29:30.207511  4008 solver.cpp:231] Iteration 22000, loss = 1.37244
I0517 11:29:30.207607  4008 solver.cpp:247]     Train net output #0: loss = 1.37244 (* 1 = 1.37244 loss)
I0517 11:29:30.207624  4008 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0517 11:29:30.375495  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.1654	0	41.9876	0	49.8264	0.78125	43.3769	0	39.5169	0	31.102	0	26.4147	0	13.6326	0.5	
I0517 11:29:30.449445  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:29:30.450145  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:29:30.450160  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:29:30.459784  4008 solver.cpp:260]     Total regularization terms: 1.86769 loss+regular. : 3.24014
I0517 11:30:50.850698  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:31:06.063621  4008 solver.cpp:231] Iteration 22200, loss = 1.40028
I0517 11:31:06.063705  4008 solver.cpp:247]     Train net output #0: loss = 1.40028 (* 1 = 1.40028 loss)
I0517 11:31:06.063726  4008 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0517 11:31:06.223987  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.18262	0	42.1439	0	50.0927	0.78125	43.6189	0	39.7438	0	31.2529	0	26.5389	0	13.6775	0.5	
I0517 11:31:06.297430  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:31:06.302083  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:31:06.302127  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:31:06.317015  4008 solver.cpp:260]     Total regularization terms: 1.86311 loss+regular. : 3.26339
I0517 11:32:27.061044  4008 solver.cpp:231] Iteration 22400, loss = 1.48331
I0517 11:32:27.061297  4008 solver.cpp:247]     Train net output #0: loss = 1.48331 (* 1 = 1.48331 loss)
I0517 11:32:27.061329  4008 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0517 11:32:27.223347  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.1568	0	42.389	0	50.3522	0.78125	43.8671	0	39.9577	0	31.4042	0	26.6613	0	13.7225	0.5	
I0517 11:32:27.298013  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:32:27.299191  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:32:27.299231  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:32:27.309231  4008 solver.cpp:260]     Total regularization terms: 1.85864 loss+regular. : 3.34195
I0517 11:33:57.551501  4008 solver.cpp:231] Iteration 22600, loss = 1.57171
I0517 11:33:57.551755  4008 solver.cpp:247]     Train net output #0: loss = 1.57171 (* 1 = 1.57171 loss)
I0517 11:33:57.551777  4008 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0517 11:33:57.713541  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.26871	0	42.6553	0	50.6175	0.78125	44.1162	0	40.1695	0	31.5548	0	26.7861	0	13.766	0.5	
I0517 11:33:57.787251  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:33:57.788341  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:33:57.788370  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:33:57.798261  4008 solver.cpp:260]     Total regularization terms: 1.85418 loss+regular. : 3.42588
I0517 11:35:29.172796  4008 solver.cpp:231] Iteration 22800, loss = 1.45042
I0517 11:35:29.173076  4008 solver.cpp:247]     Train net output #0: loss = 1.45042 (* 1 = 1.45042 loss)
I0517 11:35:29.173099  4008 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0517 11:35:29.333127  4008 sgd_solver.cpp:120]     Element Sparsity %: 
6.9674	0	42.875	0	50.8766	0.78125	44.367	0	40.3985	0	31.7061	0	26.9131	0	13.8095	0.5	
I0517 11:35:29.406610  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:35:29.407398  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:35:29.407416  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:35:29.416970  4008 solver.cpp:260]     Total regularization terms: 1.84968 loss+regular. : 3.3001
I0517 11:36:58.720453  4008 solver.cpp:348] Iteration 23000, Testing net (#0)
I0517 11:37:13.154213  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:38:27.781054  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55388
I0517 11:38:27.782179  4008 solver.cpp:415]     Test net output #1: loss = 1.91421 (* 1 = 1.91421 loss)
I0517 11:38:27.873342  4008 solver.cpp:231] Iteration 23000, loss = 1.27658
I0517 11:38:27.873419  4008 solver.cpp:247]     Train net output #0: loss = 1.27658 (* 1 = 1.27658 loss)
I0517 11:38:27.873436  4008 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0517 11:38:28.034416  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.32897	0	43.1195	0	51.1428	0.78125	44.6084	0	40.6189	0	31.8548	0	27.0368	0	13.8528	0.5	
I0517 11:38:28.108525  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:38:28.109370  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:38:28.109393  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:38:28.119310  4008 solver.cpp:260]     Total regularization terms: 1.84529 loss+regular. : 3.12187
I0517 11:39:45.008090  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:39:57.431602  4008 solver.cpp:231] Iteration 23200, loss = 1.41081
I0517 11:39:57.431715  4008 solver.cpp:247]     Train net output #0: loss = 1.41081 (* 1 = 1.41081 loss)
I0517 11:39:57.431733  4008 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0517 11:39:57.592089  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.30314	0	43.3089	0	51.3876	0.78125	44.8462	0	40.8431	0	32.005	0	27.1595	0	13.8958	0.5	
I0517 11:39:57.665755  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:39:57.666683  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:39:57.666700  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:39:57.681815  4008 solver.cpp:260]     Total regularization terms: 1.8409 loss+regular. : 3.25171
I0517 11:41:13.950103  4008 solver.cpp:231] Iteration 23400, loss = 1.4994
I0517 11:41:13.961660  4008 solver.cpp:247]     Train net output #0: loss = 1.4994 (* 1 = 1.4994 loss)
I0517 11:41:13.961694  4008 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0517 11:41:14.125237  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.30314	0	43.5352	0	51.6424	0.78125	45.0926	0	41.0561	0	32.1543	0	27.2804	0	13.9397	0.5	
I0517 11:41:14.203727  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:41:14.204722  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:41:14.204748  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:41:14.231277  4008 solver.cpp:260]     Total regularization terms: 1.83666 loss+regular. : 3.33606
I0517 11:42:39.798622  4008 solver.cpp:231] Iteration 23600, loss = 1.36661
I0517 11:42:39.799048  4008 solver.cpp:247]     Train net output #0: loss = 1.36661 (* 1 = 1.36661 loss)
I0517 11:42:39.799080  4008 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0517 11:42:39.958772  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.05349	0	43.7363	0	51.8841	0.78125	45.3291	0	41.2704	0	32.3015	0	27.4011	0	13.9824	0.5	
I0517 11:42:40.032902  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:42:40.034111  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:42:40.034147  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:42:40.044291  4008 solver.cpp:260]     Total regularization terms: 1.83242 loss+regular. : 3.19902
I0517 11:44:03.673502  4008 solver.cpp:231] Iteration 23800, loss = 1.79203
I0517 11:44:03.673900  4008 solver.cpp:247]     Train net output #0: loss = 1.79203 (* 1 = 1.79203 loss)
I0517 11:44:03.673925  4008 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0517 11:44:03.836390  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.3921	0	43.9707	0	52.1341	0.78125	45.5511	0	41.4673	0	32.4477	0	27.5222	0	14.0242	0.5	
I0517 11:44:03.910167  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:44:03.910976  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:44:03.911017  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:44:03.925488  4008 solver.cpp:260]     Total regularization terms: 1.82817 loss+regular. : 3.6202
I0517 11:45:30.943779  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_24000.caffemodel
I0517 11:46:37.574079  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_24000.solverstate
I0517 11:46:38.364138  4008 solver.cpp:348] Iteration 24000, Testing net (#0)
I0517 11:46:55.161360  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:47:57.102649  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55178
I0517 11:47:57.106914  4008 solver.cpp:415]     Test net output #1: loss = 1.9213 (* 1 = 1.9213 loss)
I0517 11:47:57.194309  4008 solver.cpp:231] Iteration 24000, loss = 1.64898
I0517 11:47:57.194388  4008 solver.cpp:247]     Train net output #0: loss = 1.64898 (* 1 = 1.64898 loss)
I0517 11:47:57.194406  4008 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0517 11:47:57.361726  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.40358	0	44.1133	0	52.3849	0.78125	45.777	0	41.6796	0	32.5955	0	27.6426	0	14.0671	0.5	
I0517 11:47:57.362145  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:47:57.362685  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:47:57.362702  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:47:57.372432  4008 solver.cpp:260]     Total regularization terms: 1.82394 loss+regular. : 3.47292
I0517 11:49:17.945194  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:49:30.062943  4008 solver.cpp:231] Iteration 24200, loss = 1.4451
I0517 11:49:30.063017  4008 solver.cpp:247]     Train net output #0: loss = 1.4451 (* 1 = 1.4451 loss)
I0517 11:49:30.063033  4008 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0517 11:49:30.224390  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.24575	0	44.2939	0	52.6238	0.78125	46.0133	0	41.9076	0	32.7422	0	27.7623	0	14.1101	0.5	
I0517 11:49:30.297821  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:49:30.298336  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:49:30.298349  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:49:30.308012  4008 solver.cpp:260]     Total regularization terms: 1.81981 loss+regular. : 3.26491
I0517 11:51:07.556381  4008 solver.cpp:231] Iteration 24400, loss = 1.53904
I0517 11:51:07.557413  4008 solver.cpp:247]     Train net output #0: loss = 1.53904 (* 1 = 1.53904 loss)
I0517 11:51:07.557436  4008 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0517 11:51:07.718130  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.44949	0	44.5618	0	52.8723	0.78125	46.2318	0	42.1104	0	32.8884	0	27.8828	0	14.1504	0.5	
I0517 11:51:07.794054  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:51:07.794978  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:51:07.794996  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:51:07.816105  4008 solver.cpp:260]     Total regularization terms: 1.8156 loss+regular. : 3.35464
I0517 11:52:27.452891  4008 solver.cpp:231] Iteration 24600, loss = 1.59046
I0517 11:52:27.453264  4008 solver.cpp:247]     Train net output #0: loss = 1.59046 (* 1 = 1.59046 loss)
I0517 11:52:27.453285  4008 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0517 11:52:27.611703  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.25723	0	44.7923	0	53.1076	0.78125	46.453	0	42.303	0	33.0328	0	28.0014	0	14.1913	0.5	
I0517 11:52:27.685518  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:52:27.686300  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:52:27.686316  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:52:27.696053  4008 solver.cpp:260]     Total regularization terms: 1.81143 loss+regular. : 3.40189
I0517 11:53:50.728838  4008 solver.cpp:231] Iteration 24800, loss = 1.57875
I0517 11:53:50.729152  4008 solver.cpp:247]     Train net output #0: loss = 1.57875 (* 1 = 1.57875 loss)
I0517 11:53:50.729173  4008 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0517 11:53:50.888139  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.57002	0	45.0186	0	53.3431	0.78125	46.6664	0	42.509	0	33.1762	0	28.1196	0	14.2323	0.5	
I0517 11:53:50.962059  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:53:50.963492  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:53:50.963542  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:53:50.973670  4008 solver.cpp:260]     Total regularization terms: 1.80721 loss+regular. : 3.38596
I0517 11:55:11.915904  4008 solver.cpp:348] Iteration 25000, Testing net (#0)
I0517 11:55:26.315721  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:56:31.426448  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55262
I0517 11:56:31.426755  4008 solver.cpp:415]     Test net output #1: loss = 1.91832 (* 1 = 1.91832 loss)
I0517 11:56:31.514571  4008 solver.cpp:231] Iteration 25000, loss = 1.42298
I0517 11:56:31.514639  4008 solver.cpp:247]     Train net output #0: loss = 1.42298 (* 1 = 1.42298 loss)
I0517 11:56:31.514657  4008 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0517 11:56:31.680680  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.44949	0	45.2135	0	53.5781	0.78125	46.8908	0	42.7138	0	33.3227	0	28.2389	0	14.273	0.5	
I0517 11:56:31.760965  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:56:31.762075  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:56:31.762106  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:56:31.771999  4008 solver.cpp:260]     Total regularization terms: 1.80314 loss+regular. : 3.22612
I0517 11:57:58.181963  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 11:58:07.518396  4008 solver.cpp:231] Iteration 25200, loss = 1.28689
I0517 11:58:07.518499  4008 solver.cpp:247]     Train net output #0: loss = 1.28689 (* 1 = 1.28689 loss)
I0517 11:58:07.518524  4008 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0517 11:58:07.680012  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.38636	0	45.4199	0	53.8147	0.78125	47.1244	0	42.9231	0	33.4655	0	28.3571	0	14.3151	0.5	
I0517 11:58:07.753978  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:58:07.755149  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:58:07.755177  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:58:07.765184  4008 solver.cpp:260]     Total regularization terms: 1.7992 loss+regular. : 3.08609
I0517 11:59:38.329208  4008 solver.cpp:231] Iteration 25400, loss = 1.4001
I0517 11:59:38.329476  4008 solver.cpp:247]     Train net output #0: loss = 1.4001 (* 1 = 1.4001 loss)
I0517 11:59:38.329494  4008 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0517 11:59:38.490526  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.36628	0	45.61	0	54.0306	0.78125	47.3481	0	43.1261	0	33.6091	0	28.4731	0	14.3555	0.5	
I0517 11:59:38.564121  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 11:59:38.564803  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 11:59:38.564823  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 11:59:38.574548  4008 solver.cpp:260]     Total regularization terms: 1.7953 loss+regular. : 3.1954
I0517 12:00:58.812847  4008 solver.cpp:231] Iteration 25600, loss = 1.5777
I0517 12:00:58.813285  4008 solver.cpp:247]     Train net output #0: loss = 1.5777 (* 1 = 1.5777 loss)
I0517 12:00:58.813311  4008 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0517 12:00:58.973228  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.42654	0	45.7458	0	54.2619	0.78125	47.5633	0	43.3176	0	33.7513	0	28.5901	0	14.395	0.5	
I0517 12:00:59.047302  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:00:59.048210  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:00:59.048238  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:00:59.065242  4008 solver.cpp:260]     Total regularization terms: 1.79141 loss+regular. : 3.36911
I0517 12:02:22.128795  4008 solver.cpp:231] Iteration 25800, loss = 1.35661
I0517 12:02:22.129205  4008 solver.cpp:247]     Train net output #0: loss = 1.35661 (* 1 = 1.35661 loss)
I0517 12:02:22.129236  4008 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0517 12:02:22.290549  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.53558	0	45.9792	0	54.4873	0.78125	47.7804	0	43.516	0	33.8937	0	28.7067	0	14.4359	0.5	
I0517 12:02:22.364454  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:02:22.365463  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:02:22.365494  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:02:22.375504  4008 solver.cpp:260]     Total regularization terms: 1.7876 loss+regular. : 3.14421
I0517 12:03:54.925603  4008 solver.cpp:348] Iteration 26000, Testing net (#0)
I0517 12:04:09.036306  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:05:09.317287  4008 solver.cpp:415]     Test net output #0: accuracy = 0.554719
I0517 12:05:09.317625  4008 solver.cpp:415]     Test net output #1: loss = 1.91545 (* 1 = 1.91545 loss)
I0517 12:05:09.405405  4008 solver.cpp:231] Iteration 26000, loss = 1.60895
I0517 12:05:09.405484  4008 solver.cpp:247]     Train net output #0: loss = 1.60895 (* 1 = 1.60895 loss)
I0517 12:05:09.405505  4008 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0517 12:05:09.570444  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.50402	0	46.1634	0	54.7057	0.78125	48.0009	0	43.7052	0	34.0369	0	28.8229	0	14.4763	0.5	
I0517 12:05:09.644698  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:05:09.645756  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:05:09.645792  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:05:09.655714  4008 solver.cpp:260]     Total regularization terms: 1.78378 loss+regular. : 3.39273
I0517 12:06:40.728945  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:06:44.206990  4008 solver.cpp:231] Iteration 26200, loss = 1.40983
I0517 12:06:44.207095  4008 solver.cpp:247]     Train net output #0: loss = 1.40983 (* 1 = 1.40983 loss)
I0517 12:06:44.207118  4008 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0517 12:06:44.367336  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.47532	0	46.375	0	54.921	0.78125	48.2042	0	43.8926	0	34.1786	0	28.9409	0	14.5171	0.5	
I0517 12:06:44.442509  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:06:44.443675  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:06:44.443707  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:06:44.457917  4008 solver.cpp:260]     Total regularization terms: 1.77994 loss+regular. : 3.18977
I0517 12:08:10.912580  4008 solver.cpp:231] Iteration 26400, loss = 1.38979
I0517 12:08:10.913041  4008 solver.cpp:247]     Train net output #0: loss = 1.38979 (* 1 = 1.38979 loss)
I0517 12:08:10.913067  4008 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0517 12:08:11.073437  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.48967	0	46.5335	0	55.1361	0.78125	48.4254	0	44.0796	0	34.3197	0	29.0569	0	14.5565	0.5	
I0517 12:08:11.147455  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:08:11.148777  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:08:11.148813  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:08:11.158771  4008 solver.cpp:260]     Total regularization terms: 1.7761 loss+regular. : 3.16589
I0517 12:09:38.514874  4008 solver.cpp:231] Iteration 26600, loss = 1.51647
I0517 12:09:38.515262  4008 solver.cpp:247]     Train net output #0: loss = 1.51647 (* 1 = 1.51647 loss)
I0517 12:09:38.515296  4008 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0517 12:09:38.675087  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.61593	0	46.7653	0	55.3618	0.78125	48.6385	0	44.2595	0	34.4602	0	29.1707	0	14.5959	0.5	
I0517 12:09:38.748893  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:09:38.749711  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:09:38.749733  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:09:38.759372  4008 solver.cpp:260]     Total regularization terms: 1.77236 loss+regular. : 3.28883
I0517 12:11:04.250342  4008 solver.cpp:231] Iteration 26800, loss = 1.40267
I0517 12:11:04.250591  4008 solver.cpp:247]     Train net output #0: loss = 1.40267 (* 1 = 1.40267 loss)
I0517 12:11:04.250610  4008 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0517 12:11:04.408984  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.58437	0	46.8584	0	55.5804	0.78125	48.8433	0	44.4359	0	34.6007	0	29.2854	0	14.6348	0.5	
I0517 12:11:04.482786  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:11:04.483678  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:11:04.483697  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:11:04.493386  4008 solver.cpp:260]     Total regularization terms: 1.76864 loss+regular. : 3.17131
I0517 12:12:33.092563  4008 solver.cpp:348] Iteration 27000, Testing net (#0)
I0517 12:12:50.279467  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:13:59.502907  4008 solver.cpp:415]     Test net output #0: accuracy = 0.54814
I0517 12:13:59.503139  4008 solver.cpp:415]     Test net output #1: loss = 1.93369 (* 1 = 1.93369 loss)
I0517 12:13:59.595841  4008 solver.cpp:231] Iteration 27000, loss = 1.41472
I0517 12:13:59.595922  4008 solver.cpp:247]     Train net output #0: loss = 1.41472 (* 1 = 1.41472 loss)
I0517 12:13:59.595942  4008 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0517 12:13:59.755847  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.63889	0	47.0762	0	55.797	0.78125	49.0433	0	44.6352	0	34.7402	0	29.3995	0	14.6751	0.5	
I0517 12:13:59.831267  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:13:59.832357  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:13:59.832389  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:13:59.842136  4008 solver.cpp:260]     Total regularization terms: 1.76493 loss+regular. : 3.17965
I0517 12:15:22.200101  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:15:22.512020  4008 solver.cpp:231] Iteration 27200, loss = 1.27141
I0517 12:15:22.512147  4008 solver.cpp:247]     Train net output #0: loss = 1.27141 (* 1 = 1.27141 loss)
I0517 12:15:22.512208  4008 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0517 12:15:22.674232  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.46384	0	47.235	0	56.0218	0.78125	49.2447	0	44.8104	0	34.8778	0	29.512	0	14.7141	0.5	
I0517 12:15:22.748059  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:15:22.748787  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:15:22.748813  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:15:22.759062  4008 solver.cpp:260]     Total regularization terms: 1.76126 loss+regular. : 3.03268
I0517 12:16:48.069119  4008 solver.cpp:231] Iteration 27400, loss = 1.29204
I0517 12:16:48.073724  4008 solver.cpp:247]     Train net output #0: loss = 1.29204 (* 1 = 1.29204 loss)
I0517 12:16:48.073758  4008 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0517 12:16:48.230481  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.32036	0	47.4036	0	56.2254	0.78125	49.4439	0	45.0046	0	35.0138	0	29.6244	0	14.7516	0.5	
I0517 12:16:48.305188  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:16:48.305994  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:16:48.306021  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:16:48.317476  4008 solver.cpp:260]     Total regularization terms: 1.75766 loss+regular. : 3.0497
I0517 12:18:15.329079  4008 solver.cpp:231] Iteration 27600, loss = 1.4132
I0517 12:18:15.329365  4008 solver.cpp:247]     Train net output #0: loss = 1.4132 (* 1 = 1.4132 loss)
I0517 12:18:15.329383  4008 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0517 12:18:15.491744  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.60445	0	47.5482	0	56.4349	0.78125	49.6449	0	45.1888	0	35.1534	0	29.738	0	14.791	0.5	
I0517 12:18:15.565836  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:18:15.566825  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:18:15.566870  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:18:15.583480  4008 solver.cpp:260]     Total regularization terms: 1.75397 loss+regular. : 3.16716
I0517 12:19:41.319176  4008 solver.cpp:231] Iteration 27800, loss = 1.5831
I0517 12:19:41.319527  4008 solver.cpp:247]     Train net output #0: loss = 1.5831 (* 1 = 1.5831 loss)
I0517 12:19:41.319550  4008 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0517 12:19:41.480522  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.50402	0	47.8044	0	56.6357	0.78125	49.8507	0	45.3713	0	35.2906	0	29.8512	0	14.8284	0.5	
I0517 12:19:41.554255  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:19:41.555290  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:19:41.555321  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:19:41.565151  4008 solver.cpp:260]     Total regularization terms: 1.75035 loss+regular. : 3.33345
I0517 12:21:05.886793  4008 solver.cpp:348] Iteration 28000, Testing net (#0)
I0517 12:21:23.537722  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:22:29.472345  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55224
I0517 12:22:29.472693  4008 solver.cpp:415]     Test net output #1: loss = 1.92341 (* 1 = 1.92341 loss)
I0517 12:22:29.564333  4008 solver.cpp:231] Iteration 28000, loss = 1.49782
I0517 12:22:29.564414  4008 solver.cpp:247]     Train net output #0: loss = 1.49782 (* 1 = 1.49782 loss)
I0517 12:22:29.564435  4008 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0517 12:22:29.724683  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.64463	0	47.9762	0	56.8419	0.78125	50.0535	0	45.5591	0	35.4282	0	29.9622	0	14.8651	0.5	
I0517 12:22:29.804232  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:22:29.805337  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:22:29.805371  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:22:29.815428  4008 solver.cpp:260]     Total regularization terms: 1.74677 loss+regular. : 3.24459
I0517 12:24:02.045651  4008 solver.cpp:231] Iteration 28200, loss = 1.58937
I0517 12:24:02.046597  4008 solver.cpp:247]     Train net output #0: loss = 1.58937 (* 1 = 1.58937 loss)
I0517 12:24:02.046633  4008 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0517 12:24:02.206241  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.73646	0	48.1374	0	57.045	0.78125	50.2484	0	45.7307	0	35.563	0	30.0746	0	14.9026	0.5	
I0517 12:24:02.280508  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:24:02.281445  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:24:02.281468  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:24:02.291282  4008 solver.cpp:260]     Total regularization terms: 1.74319 loss+regular. : 3.33256
I0517 12:24:04.482641  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:25:23.164072  4008 solver.cpp:231] Iteration 28400, loss = 1.53707
I0517 12:25:23.164484  4008 solver.cpp:247]     Train net output #0: loss = 1.53707 (* 1 = 1.53707 loss)
I0517 12:25:23.164504  4008 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0517 12:25:23.325352  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.68767	0	48.3213	0	57.2456	0.78125	50.4461	0	45.9011	0	35.6999	0	30.1859	0	14.941	0.5	
I0517 12:25:23.400075  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:25:23.401013  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:25:23.401033  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:25:23.421928  4008 solver.cpp:260]     Total regularization terms: 1.73966 loss+regular. : 3.27672
I0517 12:26:37.202513  4008 solver.cpp:231] Iteration 28600, loss = 1.38141
I0517 12:26:37.202893  4008 solver.cpp:247]     Train net output #0: loss = 1.38141 (* 1 = 1.38141 loss)
I0517 12:26:37.202915  4008 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0517 12:26:37.365262  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.79959	0	48.5049	0	57.4404	0.78125	50.6382	0	46.0777	0	35.8367	0	30.2966	0	14.9782	0.5	
I0517 12:26:37.439822  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:26:37.440570  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:26:37.440593  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:26:37.464563  4008 solver.cpp:260]     Total regularization terms: 1.73613 loss+regular. : 3.11755
I0517 12:27:57.137446  4008 solver.cpp:231] Iteration 28800, loss = 1.5918
I0517 12:27:57.150534  4008 solver.cpp:247]     Train net output #0: loss = 1.5918 (* 1 = 1.5918 loss)
I0517 12:27:57.150565  4008 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0517 12:27:57.297948  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.7508	0	48.6608	0	57.6423	0.78125	50.8348	0	46.2533	0	35.9708	0	30.4072	0	15.0161	0.5	
I0517 12:27:57.371695  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:27:57.372486  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:27:57.372504  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:27:57.382364  4008 solver.cpp:260]     Total regularization terms: 1.73263 loss+regular. : 3.32443
I0517 12:29:14.411566  4008 solver.cpp:348] Iteration 29000, Testing net (#0)
I0517 12:29:30.212415  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:30:33.172122  4008 solver.cpp:415]     Test net output #0: accuracy = 0.552259
I0517 12:30:33.172818  4008 solver.cpp:415]     Test net output #1: loss = 1.92777 (* 1 = 1.92777 loss)
I0517 12:30:33.260668  4008 solver.cpp:231] Iteration 29000, loss = 1.51057
I0517 12:30:33.260737  4008 solver.cpp:247]     Train net output #0: loss = 1.51057 (* 1 = 1.51057 loss)
I0517 12:30:33.260754  4008 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0517 12:30:33.429561  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.81967	0	48.8691	0	57.8418	0.78125	51.0332	0	46.4197	0	36.1059	0	30.518	0	15.0525	0.5	
I0517 12:30:33.503659  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:30:33.504477  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:30:33.504498  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:30:33.514292  4008 solver.cpp:260]     Total regularization terms: 1.72918 loss+regular. : 3.23975
I0517 12:31:57.237514  4008 solver.cpp:231] Iteration 29200, loss = 1.26122
I0517 12:31:57.238004  4008 solver.cpp:247]     Train net output #0: loss = 1.26122 (* 1 = 1.26122 loss)
I0517 12:31:57.238025  4008 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0517 12:31:57.401098  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.76515	0	49.0296	0	58.0382	0.78125	51.2291	0	46.599	0	36.2383	0	30.6274	0	15.0878	0.5	
I0517 12:31:57.475787  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:31:57.476639  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:31:57.476656  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:31:57.497038  4008 solver.cpp:260]     Total regularization terms: 1.72577 loss+regular. : 2.987
I0517 12:32:02.197721  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:33:19.297359  4008 solver.cpp:231] Iteration 29400, loss = 1.41662
I0517 12:33:19.297704  4008 solver.cpp:247]     Train net output #0: loss = 1.41662 (* 1 = 1.41662 loss)
I0517 12:33:19.297724  4008 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0517 12:33:19.457988  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.59871	0	49.1602	0	58.2296	0.78125	51.4226	0	46.7604	0	36.3703	0	30.7376	0	15.1242	0.5	
I0517 12:33:19.531663  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:33:19.532609  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:33:19.532629  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:33:19.542405  4008 solver.cpp:260]     Total regularization terms: 1.72235 loss+regular. : 3.13897
I0517 12:34:39.861377  4008 solver.cpp:231] Iteration 29600, loss = 1.36341
I0517 12:34:39.861538  4008 solver.cpp:247]     Train net output #0: loss = 1.36341 (* 1 = 1.36341 loss)
I0517 12:34:39.861569  4008 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0517 12:34:40.023229  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.63028	0	49.3193	0	58.4127	0.78125	51.6059	0	46.934	0	36.5028	0	30.8458	0	15.1616	0.5	
I0517 12:34:40.097820  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:34:40.098542  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:34:40.098561  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:34:40.113646  4008 solver.cpp:260]     Total regularization terms: 1.71895 loss+regular. : 3.08236
I0517 12:35:59.013120  4008 solver.cpp:231] Iteration 29800, loss = 1.67314
I0517 12:35:59.013487  4008 solver.cpp:247]     Train net output #0: loss = 1.67314 (* 1 = 1.67314 loss)
I0517 12:35:59.013515  4008 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0517 12:35:59.175338  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.72211	0	49.4756	0	58.6032	0.78125	51.7925	0	47.1074	0	36.635	0	30.9537	0	15.1977	0.5	
I0517 12:35:59.250067  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:35:59.250754  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	0.78125	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:35:59.250776  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:35:59.265799  4008 solver.cpp:260]     Total regularization terms: 1.71546 loss+regular. : 3.3886
I0517 12:37:16.946723  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_30000.caffemodel
I0517 12:37:31.736727  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_30000.solverstate
I0517 12:37:32.223844  4008 solver.cpp:348] Iteration 30000, Testing net (#0)
I0517 12:37:47.904309  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:38:43.602424  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55412
I0517 12:38:43.602723  4008 solver.cpp:415]     Test net output #1: loss = 1.91657 (* 1 = 1.91657 loss)
I0517 12:38:43.742360  4008 solver.cpp:231] Iteration 30000, loss = 1.47354
I0517 12:38:43.742435  4008 solver.cpp:247]     Train net output #0: loss = 1.47354 (* 1 = 1.47354 loss)
I0517 12:38:43.742455  4008 sgd_solver.cpp:106] Iteration 30000, lr = 0.001
I0517 12:38:43.902809  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.63602	0	49.6475	0	58.7908	1.04167	51.9833	0	47.2814	0	36.7686	0	31.0616	0	15.2327	0.5	
I0517 12:38:43.903306  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:38:43.904052  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:38:43.904070  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:38:43.913791  4008 solver.cpp:260]     Total regularization terms: 1.71217 loss+regular. : 3.18571
I0517 12:40:04.562476  4008 solver.cpp:231] Iteration 30200, loss = 1.52116
I0517 12:40:04.562744  4008 solver.cpp:247]     Train net output #0: loss = 1.52116 (* 1 = 1.52116 loss)
I0517 12:40:04.562760  4008 sgd_solver.cpp:106] Iteration 30200, lr = 0.001
I0517 12:40:04.723533  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.73933	0	49.7939	0	58.9701	1.04167	52.1653	0	47.4474	0	36.902	0	31.1684	0	15.2696	0.5	
I0517 12:40:04.797894  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:40:04.798565  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:40:04.798579  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:40:04.812114  4008 solver.cpp:260]     Total regularization terms: 1.70895 loss+regular. : 3.2301
I0517 12:40:12.064893  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:41:22.334441  4008 solver.cpp:231] Iteration 30400, loss = 1.58218
I0517 12:41:22.334802  4008 solver.cpp:247]     Train net output #0: loss = 1.58218 (* 1 = 1.58218 loss)
I0517 12:41:22.334821  4008 sgd_solver.cpp:106] Iteration 30400, lr = 0.001
I0517 12:41:22.493302  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.83402	0	49.9502	0	59.1578	1.04167	52.3367	0	47.6083	0	37.035	0	31.274	0	15.3056	0.5	
I0517 12:41:22.566890  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:41:22.567680  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:41:22.567700  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:41:22.577370  4008 solver.cpp:260]     Total regularization terms: 1.70578 loss+regular. : 3.28795
I0517 12:42:44.551547  4008 solver.cpp:231] Iteration 30600, loss = 1.4573
I0517 12:42:44.551883  4008 solver.cpp:247]     Train net output #0: loss = 1.4573 (* 1 = 1.4573 loss)
I0517 12:42:44.551906  4008 sgd_solver.cpp:106] Iteration 30600, lr = 0.001
I0517 12:42:44.712317  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.6188	0	50.0885	0	59.3333	1.04167	52.521	0	47.7654	0	37.1667	0	31.3798	0	15.3403	0.5	
I0517 12:42:44.786981  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:42:44.787737  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:42:44.787755  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:42:44.808681  4008 solver.cpp:260]     Total regularization terms: 1.7026 loss+regular. : 3.1599
I0517 12:44:07.163851  4008 solver.cpp:231] Iteration 30800, loss = 1.52484
I0517 12:44:07.164264  4008 solver.cpp:247]     Train net output #0: loss = 1.52484 (* 1 = 1.52484 loss)
I0517 12:44:07.164283  4008 sgd_solver.cpp:106] Iteration 30800, lr = 0.001
I0517 12:44:07.324467  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.77663	0	50.2653	0	59.5111	1.04167	52.7101	0	47.9368	0	37.2988	0	31.4882	0	15.3733	0.5	
I0517 12:44:07.398061  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:44:07.398749  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:44:07.398771  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:44:07.408649  4008 solver.cpp:260]     Total regularization terms: 1.69943 loss+regular. : 3.22427
I0517 12:45:28.832003  4008 solver.cpp:348] Iteration 31000, Testing net (#0)
I0517 12:45:44.868896  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:46:46.048540  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55282
I0517 12:46:46.050667  4008 solver.cpp:415]     Test net output #1: loss = 1.91974 (* 1 = 1.91974 loss)
I0517 12:46:46.137732  4008 solver.cpp:231] Iteration 31000, loss = 1.43169
I0517 12:46:46.137820  4008 solver.cpp:247]     Train net output #0: loss = 1.43169 (* 1 = 1.43169 loss)
I0517 12:46:46.137832  4008 sgd_solver.cpp:106] Iteration 31000, lr = 0.001
I0517 12:46:46.313103  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.7795	0	50.4593	0	59.6948	1.04167	52.8881	0	48.0962	0	37.4292	0	31.5953	0	15.4078	0.5	
I0517 12:46:46.387130  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:46:46.387960  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:46:46.387979  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:46:46.397747  4008 solver.cpp:260]     Total regularization terms: 1.69627 loss+regular. : 3.12796
I0517 12:48:10.699740  4008 solver.cpp:231] Iteration 31200, loss = 1.67838
I0517 12:48:10.700042  4008 solver.cpp:247]     Train net output #0: loss = 1.67838 (* 1 = 1.67838 loss)
I0517 12:48:10.700062  4008 sgd_solver.cpp:106] Iteration 31200, lr = 0.001
I0517 12:48:10.862880  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.73646	0	50.5817	0	59.8776	1.04167	53.0525	0	48.2519	0	37.5589	0	31.7023	0	15.4419	0.5	
I0517 12:48:10.937361  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:48:10.938009  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:48:10.938022  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:48:10.949103  4008 solver.cpp:260]     Total regularization terms: 1.6932 loss+regular. : 3.37158
I0517 12:48:22.853276  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:49:32.904006  4008 solver.cpp:231] Iteration 31400, loss = 1.46079
I0517 12:49:32.904269  4008 solver.cpp:247]     Train net output #0: loss = 1.46079 (* 1 = 1.46079 loss)
I0517 12:49:32.904290  4008 sgd_solver.cpp:106] Iteration 31400, lr = 0.001
I0517 12:49:33.064012  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.91724	0	50.7396	0	60.0522	1.04167	53.226	0	48.4108	0	37.6878	0	31.8079	0	15.4748	0.5	
I0517 12:49:33.137768  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:49:33.138715  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:49:33.138751  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:49:33.148530  4008 solver.cpp:260]     Total regularization terms: 1.69005 loss+regular. : 3.15084
I0517 12:50:51.742413  4008 solver.cpp:231] Iteration 31600, loss = 1.35362
I0517 12:50:51.742756  4008 solver.cpp:247]     Train net output #0: loss = 1.35362 (* 1 = 1.35362 loss)
I0517 12:50:51.742926  4008 sgd_solver.cpp:106] Iteration 31600, lr = 0.001
I0517 12:50:51.904145  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.85698	0	50.8848	0	60.2293	1.04167	53.3994	0	48.5738	0	37.8165	0	31.9121	0	15.5076	0.5	
I0517 12:50:51.978705  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:50:51.979307  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:50:51.979324  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:50:51.994434  4008 solver.cpp:260]     Total regularization terms: 1.68688 loss+regular. : 3.0405
I0517 12:52:15.590172  4008 solver.cpp:231] Iteration 31800, loss = 1.60994
I0517 12:52:15.593641  4008 solver.cpp:247]     Train net output #0: loss = 1.60994 (* 1 = 1.60994 loss)
I0517 12:52:15.593667  4008 sgd_solver.cpp:106] Iteration 31800, lr = 0.001
I0517 12:52:15.750324  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.79098	0	51.0511	0	60.4047	1.04167	53.5684	0	48.7375	0	37.9483	0	32.0198	0	15.5416	0.5	
I0517 12:52:15.824405  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:52:15.825227  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:52:15.825247  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:52:15.835047  4008 solver.cpp:260]     Total regularization terms: 1.68376 loss+regular. : 3.2937
I0517 12:53:47.218158  4008 solver.cpp:348] Iteration 32000, Testing net (#0)
I0517 12:54:04.713482  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:55:03.586262  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5531
I0517 12:55:03.586628  4008 solver.cpp:415]     Test net output #1: loss = 1.92138 (* 1 = 1.92138 loss)
I0517 12:55:03.676952  4008 solver.cpp:231] Iteration 32000, loss = 1.45369
I0517 12:55:03.677031  4008 solver.cpp:247]     Train net output #0: loss = 1.45369 (* 1 = 1.45369 loss)
I0517 12:55:03.677047  4008 sgd_solver.cpp:106] Iteration 32000, lr = 0.001
I0517 12:55:03.845237  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.82254	0	51.2389	0	60.5732	1.04167	53.7341	0	48.9036	0	38.0757	0	32.1241	0	15.5742	0.5	
I0517 12:55:03.929237  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:55:03.930711  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:55:03.930732  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:55:03.940542  4008 solver.cpp:260]     Total regularization terms: 1.68071 loss+regular. : 3.1344
I0517 12:56:28.050199  4008 solver.cpp:231] Iteration 32200, loss = 1.54146
I0517 12:56:28.050530  4008 solver.cpp:247]     Train net output #0: loss = 1.54146 (* 1 = 1.54146 loss)
I0517 12:56:28.050550  4008 sgd_solver.cpp:106] Iteration 32200, lr = 0.001
I0517 12:56:28.209193  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.93159	0	51.3594	0	60.7402	1.04167	53.8983	0	49.0517	0	38.2046	0	32.228	0	15.6065	0.5	
I0517 12:56:28.283438  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:56:28.284553  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:56:28.284577  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:56:28.294394  4008 solver.cpp:260]     Total regularization terms: 1.67769 loss+regular. : 3.21915
I0517 12:56:47.335181  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 12:58:00.877341  4008 solver.cpp:231] Iteration 32400, loss = 1.50277
I0517 12:58:00.877784  4008 solver.cpp:247]     Train net output #0: loss = 1.50277 (* 1 = 1.50277 loss)
I0517 12:58:00.877815  4008 sgd_solver.cpp:106] Iteration 32400, lr = 0.001
I0517 12:58:01.038627  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.78524	0	51.4945	0	60.9083	1.04167	54.0642	0	49.2065	0	38.333	0	32.3319	0	15.6406	0.5	
I0517 12:58:01.112120  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:58:01.112908  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:58:01.112928  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:58:01.122660  4008 solver.cpp:260]     Total regularization terms: 1.67475 loss+regular. : 3.17751
I0517 12:59:24.334969  4008 solver.cpp:231] Iteration 32600, loss = 1.55558
I0517 12:59:24.335316  4008 solver.cpp:247]     Train net output #0: loss = 1.55558 (* 1 = 1.55558 loss)
I0517 12:59:24.335336  4008 sgd_solver.cpp:106] Iteration 32600, lr = 0.001
I0517 12:59:24.495746  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.77663	0	51.5811	0	61.0728	1.04167	54.2303	0	49.3519	0	38.4603	0	32.4366	0	15.6742	0.5	
I0517 12:59:24.569468  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 12:59:24.570384  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 12:59:24.570410  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 12:59:24.580241  4008 solver.cpp:260]     Total regularization terms: 1.67175 loss+regular. : 3.22732
I0517 13:00:43.577512  4008 solver.cpp:231] Iteration 32800, loss = 1.63129
I0517 13:00:43.577811  4008 solver.cpp:247]     Train net output #0: loss = 1.63129 (* 1 = 1.63129 loss)
I0517 13:00:43.577829  4008 sgd_solver.cpp:106] Iteration 32800, lr = 0.001
I0517 13:00:43.740394  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.82828	0	51.7962	0	61.2311	1.04167	54.3959	0	49.5113	0	38.5877	0	32.5392	0	15.7075	0.5	
I0517 13:00:43.815031  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:00:43.815999  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 13:00:43.816018  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:00:43.829671  4008 solver.cpp:260]     Total regularization terms: 1.66874 loss+regular. : 3.30003
I0517 13:02:06.767721  4008 solver.cpp:348] Iteration 33000, Testing net (#0)
I0517 13:02:25.609753  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:03:20.313849  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55338
I0517 13:03:20.314119  4008 solver.cpp:415]     Test net output #1: loss = 1.9179 (* 1 = 1.9179 loss)
I0517 13:03:20.401240  4008 solver.cpp:231] Iteration 33000, loss = 1.5465
I0517 13:03:20.401317  4008 solver.cpp:247]     Train net output #0: loss = 1.5465 (* 1 = 1.5465 loss)
I0517 13:03:20.401335  4008 sgd_solver.cpp:106] Iteration 33000, lr = 0.001
I0517 13:03:20.569986  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.69915	0	51.9245	0	61.3927	1.04167	54.568	0	49.6539	0	38.7134	0	32.6415	0	15.7397	0.5	
I0517 13:03:20.643673  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:03:20.644620  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 13:03:20.644642  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:03:20.654404  4008 solver.cpp:260]     Total regularization terms: 1.66572 loss+regular. : 3.21222
I0517 13:04:34.775120  4008 solver.cpp:231] Iteration 33200, loss = 1.37017
I0517 13:04:34.775413  4008 solver.cpp:247]     Train net output #0: loss = 1.37017 (* 1 = 1.37017 loss)
I0517 13:04:34.775432  4008 sgd_solver.cpp:106] Iteration 33200, lr = 0.001
I0517 13:04:34.938917  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.86846	0	52.0576	0	61.5537	1.04167	54.7366	0	49.8144	0	38.8401	0	32.7442	0	15.7712	0.5	
I0517 13:04:35.013450  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:04:35.015455  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 13:04:35.015481  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:04:35.035415  4008 solver.cpp:260]     Total regularization terms: 1.66279 loss+regular. : 3.03296
I0517 13:04:50.480845  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:05:52.921134  4008 solver.cpp:231] Iteration 33400, loss = 1.40276
I0517 13:05:52.921531  4008 solver.cpp:247]     Train net output #0: loss = 1.40276 (* 1 = 1.40276 loss)
I0517 13:05:52.921563  4008 sgd_solver.cpp:106] Iteration 33400, lr = 0.001
I0517 13:05:53.082947  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.03202	0	52.2031	0	61.7227	1.04167	54.894	0	49.9595	0	38.9641	0	32.8465	0	15.8028	0.5	
I0517 13:05:53.156662  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:05:53.157382  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 13:05:53.157403  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:05:53.167196  4008 solver.cpp:260]     Total regularization terms: 1.65985 loss+regular. : 3.06261
I0517 13:07:13.189163  4008 solver.cpp:231] Iteration 33600, loss = 1.54568
I0517 13:07:13.189431  4008 solver.cpp:247]     Train net output #0: loss = 1.54568 (* 1 = 1.54568 loss)
I0517 13:07:13.189452  4008 sgd_solver.cpp:106] Iteration 33600, lr = 0.001
I0517 13:07:13.351735  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.83115	0	52.2526	0	61.884	1.04167	55.0525	0	50.1049	0	39.0891	0	32.9491	0	15.8376	0.5	
I0517 13:07:13.425570  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:07:13.426424  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 13:07:13.426445  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:07:13.436178  4008 solver.cpp:260]     Total regularization terms: 1.65699 loss+regular. : 3.20267
I0517 13:08:38.969437  4008 solver.cpp:231] Iteration 33800, loss = 1.47636
I0517 13:08:38.969720  4008 solver.cpp:247]     Train net output #0: loss = 1.47636 (* 1 = 1.47636 loss)
I0517 13:08:38.969737  4008 sgd_solver.cpp:106] Iteration 33800, lr = 0.001
I0517 13:08:39.131408  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.87707	0	52.4287	0	62.0316	1.04167	55.2181	0	50.2516	0	39.2125	0	33.0513	0	15.8701	0.5	
I0517 13:08:39.205273  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:08:39.205971  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 13:08:39.205986  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:08:39.215606  4008 solver.cpp:260]     Total regularization terms: 1.65404 loss+regular. : 3.1304
I0517 13:10:00.452132  4008 solver.cpp:348] Iteration 34000, Testing net (#0)
I0517 13:10:20.424934  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:11:25.474912  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55106
I0517 13:11:25.477638  4008 solver.cpp:415]     Test net output #1: loss = 1.92388 (* 1 = 1.92388 loss)
I0517 13:11:25.566289  4008 solver.cpp:231] Iteration 34000, loss = 1.43718
I0517 13:11:25.566361  4008 solver.cpp:247]     Train net output #0: loss = 1.43718 (* 1 = 1.43718 loss)
I0517 13:11:25.566380  4008 sgd_solver.cpp:106] Iteration 34000, lr = 0.001
I0517 13:11:25.727962  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.08081	0	52.627	0	62.1905	1.04167	55.372	0	50.3913	0	39.3371	0	33.1517	0	15.9025	0.5	
I0517 13:11:25.804827  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:11:25.805989  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 13:11:25.806046  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:11:25.815810  4008 solver.cpp:260]     Total regularization terms: 1.65119 loss+regular. : 3.08836
I0517 13:12:40.048579  4008 solver.cpp:231] Iteration 34200, loss = 1.65823
I0517 13:12:40.048859  4008 solver.cpp:247]     Train net output #0: loss = 1.65823 (* 1 = 1.65823 loss)
I0517 13:12:40.048874  4008 sgd_solver.cpp:106] Iteration 34200, lr = 0.001
I0517 13:12:40.210214  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.95455	0	52.7002	0	62.3377	1.04167	55.5241	0	50.5421	0	39.4594	0	33.2529	0	15.9334	0.5	
I0517 13:12:40.284689  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:12:40.285338  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 13:12:40.285351  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:12:40.300179  4008 solver.cpp:260]     Total regularization terms: 1.64834 loss+regular. : 3.30656
I0517 13:12:59.410650  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:13:55.182473  4008 solver.cpp:231] Iteration 34400, loss = 1.41406
I0517 13:13:55.182741  4008 solver.cpp:247]     Train net output #0: loss = 1.41406 (* 1 = 1.41406 loss)
I0517 13:13:55.182859  4008 sgd_solver.cpp:106] Iteration 34400, lr = 0.001
I0517 13:13:55.343385  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.05211	0	52.901	0	62.4928	1.04167	55.6755	0	50.6953	0	39.5817	0	33.3551	0	15.9655	0.5	
I0517 13:13:55.418074  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:13:55.419045  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 13:13:55.419066  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:13:55.434602  4008 solver.cpp:260]     Total regularization terms: 1.64546 loss+regular. : 3.05951
I0517 13:15:14.405060  4008 solver.cpp:231] Iteration 34600, loss = 1.52139
I0517 13:15:14.406383  4008 solver.cpp:247]     Train net output #0: loss = 1.52139 (* 1 = 1.52139 loss)
I0517 13:15:14.406404  4008 sgd_solver.cpp:106] Iteration 34600, lr = 0.001
I0517 13:15:14.566040  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.0062	0	53.0065	0	62.63	1.04167	55.8297	0	50.8353	0	39.7039	0	33.4562	0	15.9959	0.5	
I0517 13:15:14.640743  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:15:14.641542  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 13:15:14.641571  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:15:14.671452  4008 solver.cpp:260]     Total regularization terms: 1.64269 loss+regular. : 3.16409
I0517 13:16:51.463282  4008 solver.cpp:231] Iteration 34800, loss = 1.46831
I0517 13:16:51.463785  4008 solver.cpp:247]     Train net output #0: loss = 1.46831 (* 1 = 1.46831 loss)
I0517 13:16:51.463809  4008 sgd_solver.cpp:106] Iteration 34800, lr = 0.001
I0517 13:16:51.625514  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.81107	0	53.1751	0	62.7858	1.04167	55.9887	0	50.9797	0	39.8257	0	33.5574	0	16.0288	0.5	
I0517 13:16:51.699473  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:16:51.700853  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.5	
I0517 13:16:51.700875  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:16:51.716069  4008 solver.cpp:260]     Total regularization terms: 1.63977 loss+regular. : 3.10807
I0517 13:18:19.588867  4008 solver.cpp:348] Iteration 35000, Testing net (#0)
I0517 13:18:37.863800  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:19:39.020865  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55398
I0517 13:19:39.021121  4008 solver.cpp:415]     Test net output #1: loss = 1.91359 (* 1 = 1.91359 loss)
I0517 13:19:39.111434  4008 solver.cpp:231] Iteration 35000, loss = 1.57524
I0517 13:19:39.111536  4008 solver.cpp:247]     Train net output #0: loss = 1.57524 (* 1 = 1.57524 loss)
I0517 13:19:39.111557  4008 sgd_solver.cpp:106] Iteration 35000, lr = 0.001
I0517 13:19:39.285259  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.01194	0	53.2855	0	62.9427	1.04167	56.1425	0	51.1185	0	39.9489	0	33.6579	0	16.0618	0.6	
I0517 13:19:39.369248  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:19:39.370136  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:19:39.370158  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:19:39.380010  4008 solver.cpp:260]     Total regularization terms: 1.63695 loss+regular. : 3.21219
I0517 13:20:53.782541  4008 solver.cpp:231] Iteration 35200, loss = 1.25991
I0517 13:20:53.782879  4008 solver.cpp:247]     Train net output #0: loss = 1.25991 (* 1 = 1.25991 loss)
I0517 13:20:53.782901  4008 sgd_solver.cpp:106] Iteration 35200, lr = 0.001
I0517 13:20:53.948906  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.15829	0	53.4183	0	63.0925	1.04167	56.2958	0	51.2648	0	40.0701	0	33.7571	0	16.0925	0.6	
I0517 13:20:54.022531  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:20:54.023149  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:20:54.023170  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:20:54.032871  4008 solver.cpp:260]     Total regularization terms: 1.63425 loss+regular. : 2.89416
I0517 13:21:15.923801  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:22:16.520874  4008 solver.cpp:231] Iteration 35400, loss = 1.27397
I0517 13:22:16.521239  4008 solver.cpp:247]     Train net output #0: loss = 1.27397 (* 1 = 1.27397 loss)
I0517 13:22:16.521260  4008 sgd_solver.cpp:106] Iteration 35400, lr = 0.001
I0517 13:22:16.681413  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.0062	0	53.4596	0	63.2374	1.04167	56.4412	0	51.3941	0	40.1923	0	33.8563	0	16.125	0.6	
I0517 13:22:16.755573  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:22:16.756216  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:22:16.756234  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:22:16.765950  4008 solver.cpp:260]     Total regularization terms: 1.63163 loss+regular. : 2.9056
I0517 13:23:42.242429  4008 solver.cpp:231] Iteration 35600, loss = 1.52144
I0517 13:23:42.242616  4008 solver.cpp:247]     Train net output #0: loss = 1.52144 (* 1 = 1.52144 loss)
I0517 13:23:42.242636  4008 sgd_solver.cpp:106] Iteration 35600, lr = 0.001
I0517 13:23:42.404595  4008 sgd_solver.cpp:120]     Element Sparsity %: 
7.93446	0	53.6195	0	63.3901	1.04167	56.5897	0	51.5229	0	40.3124	0	33.955	0	16.1556	0.6	
I0517 13:23:42.478423  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:23:42.479292  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:23:42.479311  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:23:42.488967  4008 solver.cpp:260]     Total regularization terms: 1.6289 loss+regular. : 3.15034
I0517 13:25:10.437777  4008 solver.cpp:231] Iteration 35800, loss = 1.44937
I0517 13:25:10.438144  4008 solver.cpp:247]     Train net output #0: loss = 1.44937 (* 1 = 1.44937 loss)
I0517 13:25:10.438164  4008 sgd_solver.cpp:106] Iteration 35800, lr = 0.001
I0517 13:25:10.598492  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.1382	0	53.8083	0	63.5274	1.04167	56.7329	0	51.6699	0	40.4342	0	34.0528	0	16.1871	0.6	
I0517 13:25:10.672242  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:25:10.673094  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:25:10.673117  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:25:10.682986  4008 solver.cpp:260]     Total regularization terms: 1.62621 loss+regular. : 3.07558
I0517 13:26:34.207329  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_36000.caffemodel
I0517 13:27:50.546967  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_36000.solverstate
I0517 13:27:51.045009  4008 solver.cpp:348] Iteration 36000, Testing net (#0)
I0517 13:28:11.596006  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:29:04.116828  4008 solver.cpp:415]     Test net output #0: accuracy = 0.54998
I0517 13:29:04.125679  4008 solver.cpp:415]     Test net output #1: loss = 1.92231 (* 1 = 1.92231 loss)
I0517 13:29:04.218183  4008 solver.cpp:231] Iteration 36000, loss = 1.5329
I0517 13:29:04.218284  4008 solver.cpp:247]     Train net output #0: loss = 1.5329 (* 1 = 1.5329 loss)
I0517 13:29:04.218302  4008 sgd_solver.cpp:106] Iteration 36000, lr = 0.001
I0517 13:29:04.378123  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.19559	0	53.9134	0	63.6678	1.04167	56.8881	0	51.8053	0	40.5549	0	34.1513	0	16.2176	0.6	
I0517 13:29:04.378648  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:29:04.379400  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:29:04.379415  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:29:04.389097  4008 solver.cpp:260]     Total regularization terms: 1.62358 loss+regular. : 3.15648
I0517 13:30:23.877563  4008 solver.cpp:231] Iteration 36200, loss = 1.4295
I0517 13:30:23.877835  4008 solver.cpp:247]     Train net output #0: loss = 1.4295 (* 1 = 1.4295 loss)
I0517 13:30:23.877856  4008 sgd_solver.cpp:106] Iteration 36200, lr = 0.001
I0517 13:30:24.039949  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.1669	0	54.0449	0	63.8182	1.04167	57.0328	0	51.9511	0	40.6766	0	34.2483	0	16.249	0.6	
I0517 13:30:24.114339  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:30:24.115031  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:30:24.115046  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:30:24.129993  4008 solver.cpp:260]     Total regularization terms: 1.62102 loss+regular. : 3.05052
I0517 13:30:47.882213  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:31:45.556514  4008 solver.cpp:231] Iteration 36400, loss = 1.69657
I0517 13:31:45.556826  4008 solver.cpp:247]     Train net output #0: loss = 1.69657 (* 1 = 1.69657 loss)
I0517 13:31:45.556854  4008 sgd_solver.cpp:106] Iteration 36400, lr = 0.001
I0517 13:31:45.717838  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.10376	0	54.1016	0	63.9605	1.04167	57.175	0	52.0804	0	40.7971	0	34.3465	0	16.2799	0.6	
I0517 13:31:45.792678  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:31:45.793375  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:31:45.793400  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:31:45.813760  4008 solver.cpp:260]     Total regularization terms: 1.61846 loss+regular. : 3.31503
I0517 13:33:02.360550  4008 solver.cpp:231] Iteration 36600, loss = 1.55337
I0517 13:33:02.360913  4008 solver.cpp:247]     Train net output #0: loss = 1.55337 (* 1 = 1.55337 loss)
I0517 13:33:02.360934  4008 sgd_solver.cpp:106] Iteration 36600, lr = 0.001
I0517 13:33:02.522127  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.30177	0	54.305	0	64.1023	1.04167	57.3209	0	52.2203	0	40.9166	0	34.4448	0	16.3101	0.6	
I0517 13:33:02.596863  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:33:02.597563  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:33:02.597585  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:33:02.618479  4008 solver.cpp:260]     Total regularization terms: 1.61577 loss+regular. : 3.16913
I0517 13:34:23.178948  4008 solver.cpp:231] Iteration 36800, loss = 1.44604
I0517 13:34:23.179266  4008 solver.cpp:247]     Train net output #0: loss = 1.44604 (* 1 = 1.44604 loss)
I0517 13:34:23.179286  4008 sgd_solver.cpp:106] Iteration 36800, lr = 0.001
I0517 13:34:23.339982  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.08368	0	54.3958	0	64.2452	1.04167	57.4561	0	52.3575	0	41.0379	0	34.5426	0	16.3406	0.6	
I0517 13:34:23.414494  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:34:23.415206  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:34:23.415220  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:34:23.428793  4008 solver.cpp:260]     Total regularization terms: 1.61316 loss+regular. : 3.0592
I0517 13:35:53.279063  4008 solver.cpp:348] Iteration 37000, Testing net (#0)
I0517 13:36:17.700273  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:37:21.563419  4008 solver.cpp:415]     Test net output #0: accuracy = 0.553879
I0517 13:37:21.563717  4008 solver.cpp:415]     Test net output #1: loss = 1.91265 (* 1 = 1.91265 loss)
I0517 13:37:21.653321  4008 solver.cpp:231] Iteration 37000, loss = 1.46755
I0517 13:37:21.653430  4008 solver.cpp:247]     Train net output #0: loss = 1.46755 (* 1 = 1.46755 loss)
I0517 13:37:21.653460  4008 sgd_solver.cpp:106] Iteration 37000, lr = 0.001
I0517 13:37:21.812852  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.38499	0	54.5173	0	64.3788	1.04167	57.5923	0	52.4857	0	41.1562	0	34.6405	0	16.3706	0.6	
I0517 13:37:21.887331  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:37:21.888650  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:37:21.888682  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:37:21.901641  4008 solver.cpp:260]     Total regularization terms: 1.61058 loss+regular. : 3.07814
I0517 13:38:40.762877  4008 solver.cpp:231] Iteration 37200, loss = 1.43874
I0517 13:38:40.763128  4008 solver.cpp:247]     Train net output #0: loss = 1.43874 (* 1 = 1.43874 loss)
I0517 13:38:40.763146  4008 sgd_solver.cpp:106] Iteration 37200, lr = 0.001
I0517 13:38:40.924410  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.34194	0	54.6348	0	64.5172	1.04167	57.7314	0	52.613	0	41.2748	0	34.7391	0	16.4005	0.6	
I0517 13:38:40.998237  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:38:40.999119  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:38:40.999137  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:38:41.014145  4008 solver.cpp:260]     Total regularization terms: 1.60803 loss+regular. : 3.04677
I0517 13:39:15.544466  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:40:18.318261  4008 solver.cpp:231] Iteration 37400, loss = 1.51561
I0517 13:40:18.318543  4008 solver.cpp:247]     Train net output #0: loss = 1.51561 (* 1 = 1.51561 loss)
I0517 13:40:18.318570  4008 sgd_solver.cpp:106] Iteration 37400, lr = 0.001
I0517 13:40:18.478229  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.17264	0	54.6136	0	64.6526	1.04167	57.8732	0	52.7364	0	41.3931	0	34.8357	0	16.4304	0.6	
I0517 13:40:18.552388  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:40:18.553582  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:40:18.553627  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:40:18.563745  4008 solver.cpp:260]     Total regularization terms: 1.60548 loss+regular. : 3.12109
I0517 13:41:44.235311  4008 solver.cpp:231] Iteration 37600, loss = 1.4666
I0517 13:41:44.235793  4008 solver.cpp:247]     Train net output #0: loss = 1.4666 (* 1 = 1.4666 loss)
I0517 13:41:44.235836  4008 sgd_solver.cpp:106] Iteration 37600, lr = 0.001
I0517 13:41:44.395385  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.08655	0	54.8516	0	64.7981	1.04167	58.0018	0	52.8492	0	41.5106	0	34.9315	0	16.4602	0.6	
I0517 13:41:44.469549  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:41:44.470620  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:41:44.470669  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:41:44.480726  4008 solver.cpp:260]     Total regularization terms: 1.60288 loss+regular. : 3.06948
I0517 13:43:14.857898  4008 solver.cpp:231] Iteration 37800, loss = 1.40336
I0517 13:43:14.858265  4008 solver.cpp:247]     Train net output #0: loss = 1.40336 (* 1 = 1.40336 loss)
I0517 13:43:14.858296  4008 sgd_solver.cpp:106] Iteration 37800, lr = 0.001
I0517 13:43:15.018498  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.13533	0	55.0505	0	64.9386	1.04167	58.132	0	52.9785	0	41.6268	0	35.028	0	16.4907	0.6	
I0517 13:43:15.092654  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:43:15.094485  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.04167	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:43:15.094530  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:43:15.104516  4008 solver.cpp:260]     Total regularization terms: 1.60034 loss+regular. : 3.0037
I0517 13:44:35.588582  4008 solver.cpp:348] Iteration 38000, Testing net (#0)
I0517 13:44:58.303524  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:46:14.772609  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55056
I0517 13:46:14.772948  4008 solver.cpp:415]     Test net output #1: loss = 1.93023 (* 1 = 1.93023 loss)
I0517 13:46:14.882742  4008 solver.cpp:231] Iteration 38000, loss = 1.44883
I0517 13:46:14.882891  4008 solver.cpp:247]     Train net output #0: loss = 1.44883 (* 1 = 1.44883 loss)
I0517 13:46:14.882931  4008 sgd_solver.cpp:106] Iteration 38000, lr = 0.001
I0517 13:46:15.052624  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.11524	0	55.1348	0	65.0705	1.30208	58.2779	0	53.109	0	41.7437	0	35.1238	0	16.5187	0.6	
I0517 13:46:15.127126  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:46:15.128240  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:46:15.128278  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:46:15.138880  4008 solver.cpp:260]     Total regularization terms: 1.59779 loss+regular. : 3.04662
I0517 13:47:45.429435  4008 solver.cpp:231] Iteration 38200, loss = 1.62196
I0517 13:47:45.429797  4008 solver.cpp:247]     Train net output #0: loss = 1.62196 (* 1 = 1.62196 loss)
I0517 13:47:45.429826  4008 sgd_solver.cpp:106] Iteration 38200, lr = 0.001
I0517 13:47:45.588680  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.27307	0	55.2282	0	65.2059	1.30208	58.4066	0	53.2353	0	41.8607	0	35.2189	0	16.5482	0.6	
I0517 13:47:45.662601  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:47:45.663686  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:47:45.663722  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:47:45.673624  4008 solver.cpp:260]     Total regularization terms: 1.5954 loss+regular. : 3.21736
I0517 13:48:15.797790  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:49:08.334280  4008 solver.cpp:231] Iteration 38400, loss = 1.549
I0517 13:49:08.334776  4008 solver.cpp:247]     Train net output #0: loss = 1.549 (* 1 = 1.549 loss)
I0517 13:49:08.334807  4008 sgd_solver.cpp:106] Iteration 38400, lr = 0.001
I0517 13:49:08.495194  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.45099	0	55.3477	0	65.3307	1.30208	58.5464	0	53.363	0	41.9766	0	35.3135	0	16.5784	0.6	
I0517 13:49:08.569355  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:49:08.570291  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:49:08.570338  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:49:08.580592  4008 solver.cpp:260]     Total regularization terms: 1.59293 loss+regular. : 3.14193
I0517 13:50:34.141948  4008 solver.cpp:231] Iteration 38600, loss = 1.52576
I0517 13:50:34.143940  4008 solver.cpp:247]     Train net output #0: loss = 1.52576 (* 1 = 1.52576 loss)
I0517 13:50:34.143968  4008 sgd_solver.cpp:106] Iteration 38600, lr = 0.001
I0517 13:50:34.304764  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.22142	0	55.4974	0	65.4608	1.30208	58.6732	0	53.4835	0	42.0928	0	35.4094	0	16.6087	0.6	
I0517 13:50:34.378872  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:50:34.379860  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:50:34.379904  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:50:34.389961  4008 solver.cpp:260]     Total regularization terms: 1.59047 loss+regular. : 3.11624
I0517 13:51:58.226611  4008 solver.cpp:231] Iteration 38800, loss = 1.5737
I0517 13:51:58.226917  4008 solver.cpp:247]     Train net output #0: loss = 1.5737 (* 1 = 1.5737 loss)
I0517 13:51:58.226953  4008 sgd_solver.cpp:106] Iteration 38800, lr = 0.001
I0517 13:51:58.388510  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.4682	0	55.6514	0	65.585	1.30208	58.8064	0	53.6142	0	42.2069	0	35.5043	0	16.6378	0.6	
I0517 13:51:58.462831  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:51:58.463500  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:51:58.463512  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:51:58.483618  4008 solver.cpp:260]     Total regularization terms: 1.58802 loss+regular. : 3.16172
I0517 13:53:09.337283  4008 solver.cpp:348] Iteration 39000, Testing net (#0)
I0517 13:53:29.950872  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:54:25.680227  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5508
I0517 13:54:25.680500  4008 solver.cpp:415]     Test net output #1: loss = 1.92774 (* 1 = 1.92774 loss)
I0517 13:54:25.772905  4008 solver.cpp:231] Iteration 39000, loss = 1.51931
I0517 13:54:25.772980  4008 solver.cpp:247]     Train net output #0: loss = 1.51931 (* 1 = 1.51931 loss)
I0517 13:54:25.772996  4008 sgd_solver.cpp:106] Iteration 39000, lr = 0.001
I0517 13:54:25.941705  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.35055	0	55.7689	0	65.7108	1.30208	58.9361	0	53.7383	0	42.3215	0	35.6003	0	16.6675	0.6	
I0517 13:54:26.015374  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:54:26.016242  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:54:26.016264  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:54:26.026015  4008 solver.cpp:260]     Total regularization terms: 1.58553 loss+regular. : 3.10484
I0517 13:55:43.299361  4008 solver.cpp:231] Iteration 39200, loss = 1.48836
I0517 13:55:43.301831  4008 solver.cpp:247]     Train net output #0: loss = 1.48836 (* 1 = 1.48836 loss)
I0517 13:55:43.301856  4008 sgd_solver.cpp:106] Iteration 39200, lr = 0.001
I0517 13:55:43.461783  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.31325	0	55.8197	0	65.8366	1.30208	59.062	0	53.8662	0	42.436	0	35.6932	0	16.6954	0.6	
I0517 13:55:43.536362  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:55:43.537251  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:55:43.537314  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:55:43.558576  4008 solver.cpp:260]     Total regularization terms: 1.58305 loss+regular. : 3.07141
I0517 13:56:14.547292  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 13:57:06.508590  4008 solver.cpp:231] Iteration 39400, loss = 1.42835
I0517 13:57:06.508960  4008 solver.cpp:247]     Train net output #0: loss = 1.42835 (* 1 = 1.42835 loss)
I0517 13:57:06.508981  4008 sgd_solver.cpp:106] Iteration 39400, lr = 0.001
I0517 13:57:06.669169  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.19272	0	55.9115	0	65.9578	1.30208	59.1917	0	53.9723	0	42.5499	0	35.7868	0	16.7243	0.6	
I0517 13:57:06.743793  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:57:06.744988  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:57:06.745024  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:57:06.765764  4008 solver.cpp:260]     Total regularization terms: 1.58061 loss+regular. : 3.00897
I0517 13:58:30.691488  4008 solver.cpp:231] Iteration 39600, loss = 1.53799
I0517 13:58:30.691776  4008 solver.cpp:247]     Train net output #0: loss = 1.53799 (* 1 = 1.53799 loss)
I0517 13:58:30.691790  4008 sgd_solver.cpp:106] Iteration 39600, lr = 0.001
I0517 13:58:30.851325  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.31038	0	56.071	0	66.0862	1.30208	59.3226	0	54.1054	0	42.6632	0	35.8806	0	16.752	0.6	
I0517 13:58:30.925076  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:58:30.925771  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:58:30.925792  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:58:30.935518  4008 solver.cpp:260]     Total regularization terms: 1.57813 loss+regular. : 3.11611
I0517 13:59:55.671847  4008 solver.cpp:231] Iteration 39800, loss = 1.54361
I0517 13:59:55.672140  4008 solver.cpp:247]     Train net output #0: loss = 1.54361 (* 1 = 1.54361 loss)
I0517 13:59:55.672158  4008 sgd_solver.cpp:106] Iteration 39800, lr = 0.001
I0517 13:59:55.834710  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.47681	0	56.1908	0	66.2179	1.30208	59.4496	0	54.2139	0	42.777	0	35.9733	0	16.7815	0.6	
I0517 13:59:55.911541  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 13:59:55.912303  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 13:59:55.912327  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 13:59:55.941900  4008 solver.cpp:260]     Total regularization terms: 1.57571 loss+regular. : 3.11932
I0517 14:01:17.154064  4008 solver.cpp:348] Iteration 40000, Testing net (#0)
I0517 14:01:38.140754  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:02:33.999749  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5532
I0517 14:02:34.000035  4008 solver.cpp:415]     Test net output #1: loss = 1.92651 (* 1 = 1.92651 loss)
I0517 14:02:34.087609  4008 solver.cpp:231] Iteration 40000, loss = 1.50441
I0517 14:02:34.087710  4008 solver.cpp:247]     Train net output #0: loss = 1.50441 (* 1 = 1.50441 loss)
I0517 14:02:34.087729  4008 sgd_solver.cpp:106] Iteration 40000, lr = 0.001
I0517 14:02:34.255264  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.34481	0	56.2904	0	66.3373	1.30208	59.5923	0	54.336	0	42.8914	0	36.0657	0	16.8098	0.6	
I0517 14:02:34.329473  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:02:34.330554  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:02:34.330579  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:02:34.342491  4008 solver.cpp:260]     Total regularization terms: 1.57334 loss+regular. : 3.07775
I0517 14:03:56.298851  4008 solver.cpp:231] Iteration 40200, loss = 1.38602
I0517 14:03:56.299736  4008 solver.cpp:247]     Train net output #0: loss = 1.38602 (* 1 = 1.38602 loss)
I0517 14:03:56.299758  4008 sgd_solver.cpp:106] Iteration 40200, lr = 0.001
I0517 14:03:56.459496  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.40507	0	56.4043	0	66.4523	1.30208	59.7201	0	54.454	0	43.0044	0	36.1587	0	16.8391	0.6	
I0517 14:03:56.533843  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:03:56.535001  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:03:56.535022  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:03:56.544929  4008 solver.cpp:260]     Total regularization terms: 1.57111 loss+regular. : 2.95714
I0517 14:04:44.175817  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:05:28.385679  4008 solver.cpp:231] Iteration 40400, loss = 1.50809
I0517 14:05:28.385946  4008 solver.cpp:247]     Train net output #0: loss = 1.50809 (* 1 = 1.50809 loss)
I0517 14:05:28.385967  4008 sgd_solver.cpp:106] Iteration 40400, lr = 0.001
I0517 14:05:28.547294  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.37064	0	56.5033	0	66.5632	1.30208	59.8447	0	54.5738	0	43.119	0	36.2526	0	16.8677	0.6	
I0517 14:05:28.621212  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:05:28.622305  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:05:28.622344  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:05:28.632411  4008 solver.cpp:260]     Total regularization terms: 1.56884 loss+regular. : 3.07693
I0517 14:06:51.375087  4008 solver.cpp:231] Iteration 40600, loss = 1.4509
I0517 14:06:51.377672  4008 solver.cpp:247]     Train net output #0: loss = 1.4509 (* 1 = 1.4509 loss)
I0517 14:06:51.377706  4008 sgd_solver.cpp:106] Iteration 40600, lr = 0.001
I0517 14:06:51.537237  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.20994	0	56.5931	0	66.6712	1.30208	59.968	0	54.6848	0	43.2305	0	36.3448	0	16.8955	0.6	
I0517 14:06:51.613664  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:06:51.614573  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:06:51.614598  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:06:51.635408  4008 solver.cpp:260]     Total regularization terms: 1.56651 loss+regular. : 3.01741
I0517 14:08:16.735734  4008 solver.cpp:231] Iteration 40800, loss = 1.42213
I0517 14:08:16.737704  4008 solver.cpp:247]     Train net output #0: loss = 1.42213 (* 1 = 1.42213 loss)
I0517 14:08:16.737737  4008 sgd_solver.cpp:106] Iteration 40800, lr = 0.001
I0517 14:08:16.896446  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.35342	0	56.7493	0	66.7873	1.30208	60.1006	0	54.8109	0	43.3433	0	36.4376	0	16.9235	0.6	
I0517 14:08:16.970419  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:08:16.971374  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:08:16.971405  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:08:16.981194  4008 solver.cpp:260]     Total regularization terms: 1.56423 loss+regular. : 2.98636
I0517 14:09:39.706686  4008 solver.cpp:348] Iteration 41000, Testing net (#0)
I0517 14:10:03.616117  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:10:58.584339  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55132
I0517 14:10:58.584601  4008 solver.cpp:415]     Test net output #1: loss = 1.92448 (* 1 = 1.92448 loss)
I0517 14:10:58.676247  4008 solver.cpp:231] Iteration 41000, loss = 1.62166
I0517 14:10:58.676321  4008 solver.cpp:247]     Train net output #0: loss = 1.62166 (* 1 = 1.62166 loss)
I0517 14:10:58.676336  4008 sgd_solver.cpp:106] Iteration 41000, lr = 0.001
I0517 14:10:58.842279  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.45673	0	56.8708	0	66.915	1.30208	60.2236	0	54.9294	0	43.4552	0	36.5302	0	16.9521	0.6	
I0517 14:10:58.915994  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:10:58.916904  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:10:58.916929  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:10:58.926710  4008 solver.cpp:260]     Total regularization terms: 1.56199 loss+regular. : 3.18365
I0517 14:12:23.555560  4008 solver.cpp:231] Iteration 41200, loss = 1.45016
I0517 14:12:23.557644  4008 solver.cpp:247]     Train net output #0: loss = 1.45016 (* 1 = 1.45016 loss)
I0517 14:12:23.557675  4008 sgd_solver.cpp:106] Iteration 41200, lr = 0.001
I0517 14:12:23.715852  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.50551	0	56.9661	0	67.0263	1.30208	60.3498	0	55.042	0	43.5666	0	36.6228	0	16.9806	0.6	
I0517 14:12:23.789820  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:12:23.791113  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:12:23.791159  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:12:23.800974  4008 solver.cpp:260]     Total regularization terms: 1.55983 loss+regular. : 3.00999
I0517 14:13:07.681902  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:13:48.962388  4008 solver.cpp:231] Iteration 41400, loss = 1.78796
I0517 14:13:48.962771  4008 solver.cpp:247]     Train net output #0: loss = 1.78796 (* 1 = 1.78796 loss)
I0517 14:13:48.962791  4008 sgd_solver.cpp:106] Iteration 41400, lr = 0.001
I0517 14:13:49.122695  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.37638	0	57.0586	0	67.1444	1.30208	60.4625	0	55.1523	0	43.6769	0	36.7136	0	17.0079	0.6	
I0517 14:13:49.196413  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:13:49.197290  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:13:49.197309  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:13:49.207306  4008 solver.cpp:260]     Total regularization terms: 1.5576 loss+regular. : 3.34556
I0517 14:15:18.761531  4008 solver.cpp:231] Iteration 41600, loss = 1.57385
I0517 14:15:18.764068  4008 solver.cpp:247]     Train net output #0: loss = 1.57385 (* 1 = 1.57385 loss)
I0517 14:15:18.764106  4008 sgd_solver.cpp:106] Iteration 41600, lr = 0.001
I0517 14:15:18.924863  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.51699	0	57.1585	0	67.2583	1.30208	60.5879	0	55.266	0	43.7876	0	36.8045	0	17.0336	0.6	
I0517 14:15:18.998492  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:15:18.999231  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:15:18.999265  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:15:19.008874  4008 solver.cpp:260]     Total regularization terms: 1.55536 loss+regular. : 3.12921
I0517 14:16:48.559522  4008 solver.cpp:231] Iteration 41800, loss = 1.43896
I0517 14:16:48.559839  4008 solver.cpp:247]     Train net output #0: loss = 1.43896 (* 1 = 1.43896 loss)
I0517 14:16:48.559860  4008 sgd_solver.cpp:106] Iteration 41800, lr = 0.001
I0517 14:16:48.720125  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.57725	0	57.2168	0	67.3738	1.30208	60.7054	0	55.3727	0	43.8993	0	36.8971	0	17.0619	0.6	
I0517 14:16:48.793862  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:16:48.795016  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:16:48.795037  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:16:48.804709  4008 solver.cpp:260]     Total regularization terms: 1.55316 loss+regular. : 2.99211
I0517 14:18:07.694677  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_42000.caffemodel
I0517 14:19:07.849217  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_42000.solverstate
I0517 14:19:08.340929  4008 solver.cpp:348] Iteration 42000, Testing net (#0)
I0517 14:19:31.398811  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:20:21.088105  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55164
I0517 14:20:21.088389  4008 solver.cpp:415]     Test net output #1: loss = 1.92377 (* 1 = 1.92377 loss)
I0517 14:20:21.179389  4008 solver.cpp:231] Iteration 42000, loss = 1.56537
I0517 14:20:21.179471  4008 solver.cpp:247]     Train net output #0: loss = 1.56537 (* 1 = 1.56537 loss)
I0517 14:20:21.179491  4008 sgd_solver.cpp:106] Iteration 42000, lr = 0.001
I0517 14:20:21.345981  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.55142	0	57.2949	0	67.4775	1.30208	60.8344	0	55.4871	0	44.0085	0	36.99	0	17.0879	0.6	
I0517 14:20:21.346663  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:20:21.347815  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:20:21.347831  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:20:21.357602  4008 solver.cpp:260]     Total regularization terms: 1.55104 loss+regular. : 3.11641
I0517 14:21:41.644763  4008 solver.cpp:231] Iteration 42200, loss = 1.50835
I0517 14:21:41.645027  4008 solver.cpp:247]     Train net output #0: loss = 1.50835 (* 1 = 1.50835 loss)
I0517 14:21:41.645171  4008 sgd_solver.cpp:106] Iteration 42200, lr = 0.001
I0517 14:21:41.805156  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.38212	0	57.4297	0	67.5965	1.30208	60.9544	0	55.5913	0	44.1182	0	37.0798	0	17.1143	0.6	
I0517 14:21:41.879827  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:21:41.880626  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:21:41.880643  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:21:41.895519  4008 solver.cpp:260]     Total regularization terms: 1.54885 loss+regular. : 3.0572
I0517 14:22:22.753880  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:22:58.100121  4008 solver.cpp:231] Iteration 42400, loss = 1.45467
I0517 14:22:58.100450  4008 solver.cpp:247]     Train net output #0: loss = 1.45467 (* 1 = 1.45467 loss)
I0517 14:22:58.100472  4008 sgd_solver.cpp:106] Iteration 42400, lr = 0.001
I0517 14:22:58.262095  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.53708	0	57.5159	0	67.7082	1.30208	61.0722	0	55.6928	0	44.2265	0	37.1693	0	17.14	0.6	
I0517 14:22:58.335840  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:22:58.336725  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:22:58.336747  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:22:58.346468  4008 solver.cpp:260]     Total regularization terms: 1.54676 loss+regular. : 3.00143
I0517 14:24:18.949441  4008 solver.cpp:231] Iteration 42600, loss = 1.41521
I0517 14:24:18.950402  4008 solver.cpp:247]     Train net output #0: loss = 1.41521 (* 1 = 1.41521 loss)
I0517 14:24:18.950423  4008 sgd_solver.cpp:106] Iteration 42600, lr = 0.001
I0517 14:24:19.109365  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.45673	0	57.6618	0	67.817	1.30208	61.188	0	55.8015	0	44.3358	0	37.2591	0	17.1681	0.6	
I0517 14:24:19.183496  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:24:19.184715  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:24:19.184736  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:24:19.194592  4008 solver.cpp:260]     Total regularization terms: 1.54459 loss+regular. : 2.95979
I0517 14:25:45.725016  4008 solver.cpp:231] Iteration 42800, loss = 1.3569
I0517 14:25:45.727743  4008 solver.cpp:247]     Train net output #0: loss = 1.3569 (* 1 = 1.3569 loss)
I0517 14:25:45.727772  4008 sgd_solver.cpp:106] Iteration 42800, lr = 0.001
I0517 14:25:45.885978  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.51986	0	57.7734	0	67.9239	1.30208	61.2992	0	55.9044	0	44.4444	0	37.3493	0	17.1933	0.6	
I0517 14:25:45.960608  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:25:45.961735  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:25:45.961756  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:25:45.976881  4008 solver.cpp:260]     Total regularization terms: 1.54248 loss+regular. : 2.89939
I0517 14:27:04.499941  4008 solver.cpp:348] Iteration 43000, Testing net (#0)
I0517 14:27:29.139292  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:28:26.480131  4008 solver.cpp:415]     Test net output #0: accuracy = 0.54816
I0517 14:28:26.480486  4008 solver.cpp:415]     Test net output #1: loss = 1.93961 (* 1 = 1.93961 loss)
I0517 14:28:26.568452  4008 solver.cpp:231] Iteration 43000, loss = 1.53502
I0517 14:28:26.568523  4008 solver.cpp:247]     Train net output #0: loss = 1.53502 (* 1 = 1.53502 loss)
I0517 14:28:26.568541  4008 sgd_solver.cpp:106] Iteration 43000, lr = 0.001
I0517 14:28:26.735831  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.59447	0	57.8809	0	68.0267	1.30208	61.4151	0	56.0187	0	44.553	0	37.4389	0	17.2211	0.6	
I0517 14:28:26.810011  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:28:26.811127  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:28:26.811147  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:28:26.820922  4008 solver.cpp:260]     Total regularization terms: 1.54032 loss+regular. : 3.07534
I0517 14:29:43.032368  4008 solver.cpp:231] Iteration 43200, loss = 1.60462
I0517 14:29:43.032702  4008 solver.cpp:247]     Train net output #0: loss = 1.60462 (* 1 = 1.60462 loss)
I0517 14:29:43.032848  4008 sgd_solver.cpp:106] Iteration 43200, lr = 0.001
I0517 14:29:43.193305  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.47394	0	57.9495	0	68.1366	1.30208	61.5332	0	56.132	0	44.6604	0	37.5283	0	17.249	0.6	
I0517 14:29:43.267182  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:29:43.268299  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:29:43.268321  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:29:43.278374  4008 solver.cpp:260]     Total regularization terms: 1.53827 loss+regular. : 3.14288
I0517 14:30:26.703191  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:31:00.284350  4008 solver.cpp:231] Iteration 43400, loss = 1.61571
I0517 14:31:00.284535  4008 solver.cpp:247]     Train net output #0: loss = 1.61571 (* 1 = 1.61571 loss)
I0517 14:31:00.284554  4008 sgd_solver.cpp:106] Iteration 43400, lr = 0.001
I0517 14:31:00.446977  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.49403	0	58.071	0	68.238	1.30208	61.6512	0	56.2258	0	44.7673	0	37.6176	0	17.274	0.6	
I0517 14:31:00.520603  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:31:00.521492  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:31:00.521510  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:31:00.531283  4008 solver.cpp:260]     Total regularization terms: 1.5361 loss+regular. : 3.15181
I0517 14:32:45.975247  4008 solver.cpp:231] Iteration 43600, loss = 1.51726
I0517 14:32:45.975512  4008 solver.cpp:247]     Train net output #0: loss = 1.51726 (* 1 = 1.51726 loss)
I0517 14:32:45.975541  4008 sgd_solver.cpp:106] Iteration 43600, lr = 0.001
I0517 14:32:46.149440  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.33907	0	58.0798	0	68.3381	1.30208	61.7628	0	56.3434	0	44.8757	0	37.7074	0	17.3024	0.6	
I0517 14:32:46.223243  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:32:46.224138  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:32:46.224159  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:32:46.233994  4008 solver.cpp:260]     Total regularization terms: 1.53404 loss+regular. : 3.05129
I0517 14:34:13.920195  4008 solver.cpp:231] Iteration 43800, loss = 1.35492
I0517 14:34:13.920575  4008 solver.cpp:247]     Train net output #0: loss = 1.35492 (* 1 = 1.35492 loss)
I0517 14:34:13.920594  4008 sgd_solver.cpp:106] Iteration 43800, lr = 0.001
I0517 14:34:14.082159  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.61455	0	58.2188	0	68.4457	1.30208	61.8835	0	56.46	0	44.9837	0	37.7976	0	17.3291	0.6	
I0517 14:34:14.156512  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:34:14.157052  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:34:14.157063  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:34:14.171747  4008 solver.cpp:260]     Total regularization terms: 1.53199 loss+regular. : 2.8869
I0517 14:35:31.633630  4008 solver.cpp:348] Iteration 44000, Testing net (#0)
I0517 14:35:56.828274  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:36:50.603412  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55316
I0517 14:36:50.603741  4008 solver.cpp:415]     Test net output #1: loss = 1.92024 (* 1 = 1.92024 loss)
I0517 14:36:50.692314  4008 solver.cpp:231] Iteration 44000, loss = 1.40587
I0517 14:36:50.692394  4008 solver.cpp:247]     Train net output #0: loss = 1.40587 (* 1 = 1.40587 loss)
I0517 14:36:50.692410  4008 sgd_solver.cpp:106] Iteration 44000, lr = 0.001
I0517 14:36:50.853564  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.64612	0	58.307	0	68.544	1.30208	61.9888	0	56.5538	0	45.0915	0	37.8881	0	17.3554	0.6	
I0517 14:36:50.929311  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:36:50.930070  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:36:50.930096  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:36:50.939937  4008 solver.cpp:260]     Total regularization terms: 1.52987 loss+regular. : 2.93575
I0517 14:38:09.275131  4008 solver.cpp:231] Iteration 44200, loss = 1.49138
I0517 14:38:09.275372  4008 solver.cpp:247]     Train net output #0: loss = 1.49138 (* 1 = 1.49138 loss)
I0517 14:38:09.275393  4008 sgd_solver.cpp:106] Iteration 44200, lr = 0.001
I0517 14:38:09.437954  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.61742	0	58.4248	0	68.6467	1.30208	62.0985	0	56.656	0	45.1985	0	37.9757	0	17.382	0.6	
I0517 14:38:09.512835  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:38:09.514021  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:38:09.514048  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:38:09.527920  4008 solver.cpp:260]     Total regularization terms: 1.52778 loss+regular. : 3.01916
I0517 14:39:00.675541  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:39:37.636471  4008 solver.cpp:231] Iteration 44400, loss = 1.7725
I0517 14:39:37.636700  4008 solver.cpp:247]     Train net output #0: loss = 1.7725 (* 1 = 1.7725 loss)
I0517 14:39:37.636720  4008 sgd_solver.cpp:106] Iteration 44400, lr = 0.001
I0517 14:39:37.797653  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.60308	0	58.4795	0	68.7466	1.30208	62.2052	0	56.7498	0	45.3053	0	38.0631	0	17.4088	0.6	
I0517 14:39:37.871863  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:39:37.872738  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:39:37.872761  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:39:37.882552  4008 solver.cpp:260]     Total regularization terms: 1.52575 loss+regular. : 3.29826
I0517 14:41:06.721112  4008 solver.cpp:231] Iteration 44600, loss = 1.55663
I0517 14:41:06.721460  4008 solver.cpp:247]     Train net output #0: loss = 1.55663 (* 1 = 1.55663 loss)
I0517 14:41:06.721482  4008 sgd_solver.cpp:106] Iteration 44600, lr = 0.001
I0517 14:41:06.883086  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.62603	0	58.6527	0	68.8489	1.30208	62.3085	0	56.8687	0	45.4112	0	38.1505	0	17.4346	0.6	
I0517 14:41:06.956805  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:41:06.957490  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:41:06.957509  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:41:06.967391  4008 solver.cpp:260]     Total regularization terms: 1.52371 loss+regular. : 3.08034
I0517 14:42:33.161356  4008 solver.cpp:231] Iteration 44800, loss = 1.53808
I0517 14:42:33.161617  4008 solver.cpp:247]     Train net output #0: loss = 1.53808 (* 1 = 1.53808 loss)
I0517 14:42:33.161638  4008 sgd_solver.cpp:106] Iteration 44800, lr = 0.001
I0517 14:42:33.322168  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.60021	0	58.7272	0	68.9476	1.30208	62.417	0	56.9707	0	45.5156	0	38.2383	0	17.4601	0.6	
I0517 14:42:33.396139  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:42:33.397266  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:42:33.397287  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:42:33.407099  4008 solver.cpp:260]     Total regularization terms: 1.5216 loss+regular. : 3.05968
I0517 14:43:55.211453  4008 solver.cpp:348] Iteration 45000, Testing net (#0)
I0517 14:44:28.462818  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:45:24.724989  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5515
I0517 14:45:24.725282  4008 solver.cpp:415]     Test net output #1: loss = 1.92297 (* 1 = 1.92297 loss)
I0517 14:45:24.813619  4008 solver.cpp:231] Iteration 45000, loss = 1.62866
I0517 14:45:24.813725  4008 solver.cpp:247]     Train net output #0: loss = 1.62866 (* 1 = 1.62866 loss)
I0517 14:45:24.813746  4008 sgd_solver.cpp:106] Iteration 45000, lr = 0.001
I0517 14:45:24.980361  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.53994	0	58.8311	0	69.0461	1.30208	62.5268	0	57.0697	0	45.6211	0	38.3255	0	17.4857	0.6	
I0517 14:45:25.054538  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:45:25.055590  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:45:25.055615  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:45:25.065357  4008 solver.cpp:260]     Total regularization terms: 1.51957 loss+regular. : 3.14823
I0517 14:46:57.157933  4008 solver.cpp:231] Iteration 45200, loss = 1.43257
I0517 14:46:57.158351  4008 solver.cpp:247]     Train net output #0: loss = 1.43257 (* 1 = 1.43257 loss)
I0517 14:46:57.158382  4008 sgd_solver.cpp:106] Iteration 45200, lr = 0.001
I0517 14:46:57.319162  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.57438	0	58.8145	0	69.1363	1.30208	62.6338	0	57.1619	0	45.7261	0	38.4133	0	17.5095	0.6	
I0517 14:46:57.393008  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:46:57.393829  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:46:57.393852  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:46:57.403805  4008 solver.cpp:260]     Total regularization terms: 1.51764 loss+regular. : 2.95021
I0517 14:47:48.162480  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:48:19.004099  4008 solver.cpp:231] Iteration 45400, loss = 1.43237
I0517 14:48:19.004436  4008 solver.cpp:247]     Train net output #0: loss = 1.43237 (* 1 = 1.43237 loss)
I0517 14:48:19.004456  4008 sgd_solver.cpp:106] Iteration 45400, lr = 0.001
I0517 14:48:19.164438  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.68916	0	58.9753	0	69.2414	1.30208	62.7426	0	57.2695	0	45.8307	0	38.4997	0	17.535	0.6	
I0517 14:48:19.240607  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:48:19.241304  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:48:19.241315  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:48:19.254719  4008 solver.cpp:260]     Total regularization terms: 1.51576 loss+regular. : 2.94813
I0517 14:49:40.001538  4008 solver.cpp:231] Iteration 45600, loss = 1.46041
I0517 14:49:40.002529  4008 solver.cpp:247]     Train net output #0: loss = 1.46041 (* 1 = 1.46041 loss)
I0517 14:49:40.002569  4008 sgd_solver.cpp:106] Iteration 45600, lr = 0.001
I0517 14:49:40.162578  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.63464	0	59.0426	0	69.3391	1.30208	62.8537	0	57.3581	0	45.9364	0	38.587	0	17.5602	0.6	
I0517 14:49:40.237993  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:49:40.238744  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:49:40.238756  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:49:40.253695  4008 solver.cpp:260]     Total regularization terms: 1.51376 loss+regular. : 2.97418
I0517 14:51:08.939129  4008 solver.cpp:231] Iteration 45800, loss = 1.37831
I0517 14:51:08.941644  4008 solver.cpp:247]     Train net output #0: loss = 1.37831 (* 1 = 1.37831 loss)
I0517 14:51:08.941675  4008 sgd_solver.cpp:106] Iteration 45800, lr = 0.001
I0517 14:51:09.100167  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.74943	0	59.1934	0	69.4342	1.30208	62.9628	0	57.4549	0	46.0405	0	38.6727	0	17.5847	0.6	
I0517 14:51:09.174156  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:51:09.175631  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:51:09.175673  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:51:09.190819  4008 solver.cpp:260]     Total regularization terms: 1.51183 loss+regular. : 2.89014
I0517 14:52:32.347162  4008 solver.cpp:348] Iteration 46000, Testing net (#0)
I0517 14:53:03.540793  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:54:02.563019  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55338
I0517 14:54:02.563513  4008 solver.cpp:415]     Test net output #1: loss = 1.91625 (* 1 = 1.91625 loss)
I0517 14:54:02.651024  4008 solver.cpp:231] Iteration 46000, loss = 1.44292
I0517 14:54:02.651108  4008 solver.cpp:247]     Train net output #0: loss = 1.44292 (* 1 = 1.44292 loss)
I0517 14:54:02.651126  4008 sgd_solver.cpp:106] Iteration 46000, lr = 0.001
I0517 14:54:02.816233  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.64899	0	59.2611	0	69.5195	1.30208	63.0644	0	57.5523	0	46.1454	0	38.7613	0	17.6101	0.6	
I0517 14:54:02.890144  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:54:02.890926  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.6	
I0517 14:54:02.890947  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:54:02.900852  4008 solver.cpp:260]     Total regularization terms: 1.50989 loss+regular. : 2.95281
I0517 14:55:20.557775  4008 solver.cpp:231] Iteration 46200, loss = 1.53008
I0517 14:55:20.558085  4008 solver.cpp:247]     Train net output #0: loss = 1.53008 (* 1 = 1.53008 loss)
I0517 14:55:20.558115  4008 sgd_solver.cpp:106] Iteration 46200, lr = 0.001
I0517 14:55:20.719980  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.72647	0	59.4131	0	69.6135	1.30208	63.1654	0	57.6382	0	46.2495	0	38.8471	0	17.636	0.7	
I0517 14:55:20.793825  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:55:20.794819  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 14:55:20.794836  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:55:20.804685  4008 solver.cpp:260]     Total regularization terms: 1.50805 loss+regular. : 3.03813
I0517 14:56:18.014255  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 14:56:43.177829  4008 solver.cpp:231] Iteration 46400, loss = 1.68033
I0517 14:56:43.177918  4008 solver.cpp:247]     Train net output #0: loss = 1.68033 (* 1 = 1.68033 loss)
I0517 14:56:43.177937  4008 sgd_solver.cpp:106] Iteration 46400, lr = 0.001
I0517 14:56:43.340407  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.63177	0	59.4801	0	69.7115	1.30208	63.2621	0	57.7521	0	46.351	0	38.9324	0	17.6596	0.7	
I0517 14:56:43.414142  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:56:43.415107  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 14:56:43.415127  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:56:43.424908  4008 solver.cpp:260]     Total regularization terms: 1.50614 loss+regular. : 3.18647
I0517 14:58:05.438884  4008 solver.cpp:231] Iteration 46600, loss = 1.45088
I0517 14:58:05.439265  4008 solver.cpp:247]     Train net output #0: loss = 1.45088 (* 1 = 1.45088 loss)
I0517 14:58:05.439290  4008 sgd_solver.cpp:106] Iteration 46600, lr = 0.001
I0517 14:58:05.600853  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.71786	0	59.5977	0	69.8061	1.30208	63.3661	0	57.8493	0	46.4536	0	39.0168	0	17.6842	0.7	
I0517 14:58:05.674973  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:58:05.675685  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 14:58:05.675704  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:58:05.686992  4008 solver.cpp:260]     Total regularization terms: 1.50421 loss+regular. : 2.95509
I0517 14:59:23.142307  4008 solver.cpp:231] Iteration 46800, loss = 1.45249
I0517 14:59:23.142614  4008 solver.cpp:247]     Train net output #0: loss = 1.45249 (* 1 = 1.45249 loss)
I0517 14:59:23.142635  4008 sgd_solver.cpp:106] Iteration 46800, lr = 0.001
I0517 14:59:23.302525  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.53708	0	59.6263	0	69.8946	1.30208	63.4639	0	57.945	0	46.558	0	39.1028	0	17.7077	0.7	
I0517 14:59:23.375974  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 14:59:23.376605  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 14:59:23.376618  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 14:59:23.386365  4008 solver.cpp:260]     Total regularization terms: 1.50231 loss+regular. : 2.9548
I0517 15:00:43.220935  4008 solver.cpp:348] Iteration 47000, Testing net (#0)
I0517 15:01:13.065038  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:02:06.108491  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55078
I0517 15:02:06.108765  4008 solver.cpp:415]     Test net output #1: loss = 1.92789 (* 1 = 1.92789 loss)
I0517 15:02:06.196295  4008 solver.cpp:231] Iteration 47000, loss = 1.54798
I0517 15:02:06.196382  4008 solver.cpp:247]     Train net output #0: loss = 1.54798 (* 1 = 1.54798 loss)
I0517 15:02:06.196399  4008 sgd_solver.cpp:106] Iteration 47000, lr = 0.001
I0517 15:02:06.363407  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.76377	0	59.627	0	69.9632	1.30208	63.5659	0	58.0419	0	46.6583	0	39.1869	0	17.7324	0.7	
I0517 15:02:06.437120  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:02:06.438042  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:02:06.438071  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:02:06.447815  4008 solver.cpp:260]     Total regularization terms: 1.50053 loss+regular. : 3.04851
I0517 15:03:29.839804  4008 solver.cpp:231] Iteration 47200, loss = 1.38952
I0517 15:03:29.840229  4008 solver.cpp:247]     Train net output #0: loss = 1.38952 (* 1 = 1.38952 loss)
I0517 15:03:29.840248  4008 sgd_solver.cpp:106] Iteration 47200, lr = 0.001
I0517 15:03:30.001029  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.68342	0	59.7725	0	70.0724	1.30208	63.6708	0	58.1369	0	46.7599	0	39.271	0	17.7557	0.7	
I0517 15:03:30.074766  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:03:30.075673  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:03:30.075695  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:03:30.085471  4008 solver.cpp:260]     Total regularization terms: 1.49865 loss+regular. : 2.88816
I0517 15:04:27.813827  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:04:52.235853  4008 solver.cpp:231] Iteration 47400, loss = 1.59803
I0517 15:04:52.235962  4008 solver.cpp:247]     Train net output #0: loss = 1.59803 (* 1 = 1.59803 loss)
I0517 15:04:52.235981  4008 sgd_solver.cpp:106] Iteration 47400, lr = 0.001
I0517 15:04:52.396685  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.70638	0	59.8675	0	70.1539	1.30208	63.7627	0	58.233	0	46.8605	0	39.3539	0	17.7791	0.7	
I0517 15:04:52.470451  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:04:52.471387  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:04:52.471423  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:04:52.481210  4008 solver.cpp:260]     Total regularization terms: 1.49675 loss+regular. : 3.09478
I0517 15:06:16.831892  4008 solver.cpp:231] Iteration 47600, loss = 1.4781
I0517 15:06:16.833638  4008 solver.cpp:247]     Train net output #0: loss = 1.4781 (* 1 = 1.4781 loss)
I0517 15:06:16.833668  4008 sgd_solver.cpp:106] Iteration 47600, lr = 0.001
I0517 15:06:16.993470  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.69777	0	59.9466	0	70.258	1.30208	63.8554	0	58.3268	0	46.9617	0	39.4381	0	17.8031	0.7	
I0517 15:06:17.068840  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:06:17.070019  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:06:17.070044  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:06:17.091092  4008 solver.cpp:260]     Total regularization terms: 1.49489 loss+regular. : 2.97298
I0517 15:07:40.075237  4008 solver.cpp:231] Iteration 47800, loss = 1.26448
I0517 15:07:40.089718  4008 solver.cpp:247]     Train net output #0: loss = 1.26448 (* 1 = 1.26448 loss)
I0517 15:07:40.089752  4008 sgd_solver.cpp:106] Iteration 47800, lr = 0.001
I0517 15:07:40.234922  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.49403	0	60.0566	0	70.3464	1.30208	63.9654	0	58.4242	0	47.0628	0	39.5217	0	17.8271	0.7	
I0517 15:07:40.310191  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:07:40.311096  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:07:40.311120  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:07:40.320837  4008 solver.cpp:260]     Total regularization terms: 1.49299 loss+regular. : 2.75747
I0517 15:09:04.996670  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_48000.caffemodel
I0517 15:10:23.631378  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_48000.solverstate
I0517 15:10:24.113600  4008 solver.cpp:348] Iteration 48000, Testing net (#0)
I0517 15:10:50.097087  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:11:39.808363  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55492
I0517 15:11:39.808897  4008 solver.cpp:415]     Test net output #1: loss = 1.91279 (* 1 = 1.91279 loss)
I0517 15:11:39.897543  4008 solver.cpp:231] Iteration 48000, loss = 1.15011
I0517 15:11:39.897631  4008 solver.cpp:247]     Train net output #0: loss = 1.15011 (* 1 = 1.15011 loss)
I0517 15:11:39.897651  4008 sgd_solver.cpp:106] Iteration 48000, lr = 0.001
I0517 15:11:40.057934  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.42803	0	60.1676	0	70.4277	1.30208	64.0569	0	58.5189	0	47.1636	0	39.6064	0	17.8499	0.7	
I0517 15:11:40.058672  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:11:40.059682  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:11:40.059700  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:11:40.083191  4008 solver.cpp:260]     Total regularization terms: 1.49113 loss+regular. : 2.64124
I0517 15:13:02.152110  4008 solver.cpp:231] Iteration 48200, loss = 1.33125
I0517 15:13:02.152426  4008 solver.cpp:247]     Train net output #0: loss = 1.33125 (* 1 = 1.33125 loss)
I0517 15:13:02.152447  4008 sgd_solver.cpp:106] Iteration 48200, lr = 0.001
I0517 15:13:02.311419  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.61455	0	60.2705	0	70.525	1.30208	64.1549	0	58.622	0	47.2649	0	39.6894	0	17.8745	0.7	
I0517 15:13:02.385272  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:13:02.386400  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:13:02.386436  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:13:02.396263  4008 solver.cpp:260]     Total regularization terms: 1.48932 loss+regular. : 2.82057
I0517 15:14:02.382423  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:14:23.336977  4008 solver.cpp:231] Iteration 48400, loss = 1.45364
I0517 15:14:23.337067  4008 solver.cpp:247]     Train net output #0: loss = 1.45364 (* 1 = 1.45364 loss)
I0517 15:14:23.337086  4008 sgd_solver.cpp:106] Iteration 48400, lr = 0.001
I0517 15:14:23.497589  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.67769	0	60.3314	0	70.6115	1.30208	64.2494	0	58.7068	0	47.3645	0	39.7722	0	17.8986	0.7	
I0517 15:14:23.572240  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:14:23.573345  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:14:23.573372  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:14:23.588358  4008 solver.cpp:260]     Total regularization terms: 1.48752 loss+regular. : 2.94116
I0517 15:15:43.624591  4008 solver.cpp:231] Iteration 48600, loss = 1.43031
I0517 15:15:43.624848  4008 solver.cpp:247]     Train net output #0: loss = 1.43031 (* 1 = 1.43031 loss)
I0517 15:15:43.624879  4008 sgd_solver.cpp:106] Iteration 48600, lr = 0.001
I0517 15:15:43.785815  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.6576	0	60.4072	0	70.6959	1.30208	64.3467	0	58.7947	0	47.4651	0	39.8552	0	17.9237	0.7	
I0517 15:15:43.860442  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:15:43.861202  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:15:43.861215  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:15:43.874820  4008 solver.cpp:260]     Total regularization terms: 1.48574 loss+regular. : 2.91605
I0517 15:17:04.075114  4008 solver.cpp:231] Iteration 48800, loss = 1.39561
I0517 15:17:04.075500  4008 solver.cpp:247]     Train net output #0: loss = 1.39561 (* 1 = 1.39561 loss)
I0517 15:17:04.075656  4008 sgd_solver.cpp:106] Iteration 48800, lr = 0.001
I0517 15:17:04.236788  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.64899	0	60.4492	0	70.779	1.30208	64.4473	0	58.8854	0	47.565	0	39.9388	0	17.9464	0.7	
I0517 15:17:04.311224  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:17:04.312396  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:17:04.312430  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:17:04.322484  4008 solver.cpp:260]     Total regularization terms: 1.4839 loss+regular. : 2.87951
I0517 15:18:26.234354  4008 solver.cpp:348] Iteration 49000, Testing net (#0)
I0517 15:18:58.726187  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:19:50.309206  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55132
I0517 15:19:50.309520  4008 solver.cpp:415]     Test net output #1: loss = 1.9236 (* 1 = 1.9236 loss)
I0517 15:19:50.400250  4008 solver.cpp:231] Iteration 49000, loss = 1.59647
I0517 15:19:50.400372  4008 solver.cpp:247]     Train net output #0: loss = 1.59647 (* 1 = 1.59647 loss)
I0517 15:19:50.400390  4008 sgd_solver.cpp:106] Iteration 49000, lr = 0.001
I0517 15:19:50.566794  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.6576	0	60.5072	0	70.874	1.30208	64.5444	0	58.9654	0	47.6668	0	40.0225	0	17.9709	0.7	
I0517 15:19:50.641121  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:19:50.641835  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:19:50.641856  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:19:50.651677  4008 solver.cpp:260]     Total regularization terms: 1.48211 loss+regular. : 3.07859
I0517 15:21:13.157073  4008 solver.cpp:231] Iteration 49200, loss = 1.48989
I0517 15:21:13.157425  4008 solver.cpp:247]     Train net output #0: loss = 1.48989 (* 1 = 1.48989 loss)
I0517 15:21:13.157446  4008 sgd_solver.cpp:106] Iteration 49200, lr = 0.001
I0517 15:21:13.321351  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.80969	0	60.6123	0	70.9486	1.30208	64.6328	0	59.0676	0	47.7657	0	40.1051	0	17.994	0.7	
I0517 15:21:13.396356  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:21:13.397171  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:21:13.397195  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:21:13.418550  4008 solver.cpp:260]     Total regularization terms: 1.4804 loss+regular. : 2.97029
I0517 15:22:15.613173  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:22:33.136853  4008 solver.cpp:231] Iteration 49400, loss = 1.41389
I0517 15:22:33.136965  4008 solver.cpp:247]     Train net output #0: loss = 1.41389 (* 1 = 1.41389 loss)
I0517 15:22:33.136983  4008 sgd_solver.cpp:106] Iteration 49400, lr = 0.001
I0517 15:22:33.297333  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.63464	0	60.6934	0	71.0324	1.30208	64.7295	0	59.1623	0	47.8634	0	40.1874	0	18.0174	0.7	
I0517 15:22:33.371237  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:22:33.372323  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:22:33.372347  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:22:33.382097  4008 solver.cpp:260]     Total regularization terms: 1.47862 loss+regular. : 2.89251
I0517 15:23:55.102831  4008 solver.cpp:231] Iteration 49600, loss = 1.36409
I0517 15:23:55.105667  4008 solver.cpp:247]     Train net output #0: loss = 1.36409 (* 1 = 1.36409 loss)
I0517 15:23:55.105696  4008 sgd_solver.cpp:106] Iteration 49600, lr = 0.001
I0517 15:23:55.262904  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.70351	0	60.8118	0	71.1131	1.30208	64.8216	0	59.2568	0	47.9616	0	40.2698	0	18.0408	0.7	
I0517 15:23:55.336575  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:23:55.337285  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:23:55.337303  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:23:55.347056  4008 solver.cpp:260]     Total regularization terms: 1.4768 loss+regular. : 2.84089
I0517 15:25:21.090950  4008 solver.cpp:231] Iteration 49800, loss = 1.37922
I0517 15:25:21.093673  4008 solver.cpp:247]     Train net output #0: loss = 1.37922 (* 1 = 1.37922 loss)
I0517 15:25:21.093703  4008 sgd_solver.cpp:106] Iteration 49800, lr = 0.001
I0517 15:25:21.249205  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.71786	0	60.8721	0	71.1931	1.30208	64.9171	0	59.3497	0	48.0594	0	40.3516	0	18.0646	0.7	
I0517 15:25:21.322985  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:25:21.323979  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:25:21.324007  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:25:21.333742  4008 solver.cpp:260]     Total regularization terms: 1.475 loss+regular. : 2.85422
I0517 15:26:39.270066  4008 solver.cpp:348] Iteration 50000, Testing net (#0)
I0517 15:27:09.472057  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:28:00.753197  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55328
I0517 15:28:00.753428  4008 solver.cpp:415]     Test net output #1: loss = 1.915 (* 1 = 1.915 loss)
I0517 15:28:00.841609  4008 solver.cpp:231] Iteration 50000, loss = 1.46587
I0517 15:28:00.841701  4008 solver.cpp:247]     Train net output #0: loss = 1.46587 (* 1 = 1.46587 loss)
I0517 15:28:00.841727  4008 sgd_solver.cpp:106] Iteration 50000, lr = 0.001
I0517 15:28:01.010505  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.82691	0	60.9635	0	71.2605	1.30208	65.0122	0	59.4376	0	48.1572	0	40.434	0	18.0881	0.7	
I0517 15:28:01.084214  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:28:01.085108  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:28:01.085139  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:28:01.095044  4008 solver.cpp:260]     Total regularization terms: 1.47327 loss+regular. : 2.93914
I0517 15:29:19.280226  4008 solver.cpp:231] Iteration 50200, loss = 1.54617
I0517 15:29:19.280635  4008 solver.cpp:247]     Train net output #0: loss = 1.54617 (* 1 = 1.54617 loss)
I0517 15:29:19.280673  4008 sgd_solver.cpp:106] Iteration 50200, lr = 0.001
I0517 15:29:19.442878  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.60595	0	61.0378	0	71.3526	1.30208	65.1001	0	59.5278	0	48.2548	0	40.5159	0	18.111	0.7	
I0517 15:29:19.517704  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:29:19.518630  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:29:19.518651  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:29:19.533701  4008 solver.cpp:260]     Total regularization terms: 1.47152 loss+regular. : 3.01768
I0517 15:30:25.824419  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:30:40.306843  4008 solver.cpp:231] Iteration 50400, loss = 1.41456
I0517 15:30:40.306928  4008 solver.cpp:247]     Train net output #0: loss = 1.41456 (* 1 = 1.41456 loss)
I0517 15:30:40.306946  4008 sgd_solver.cpp:106] Iteration 50400, lr = 0.001
I0517 15:30:40.466816  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.63177	0	61.1403	0	71.4431	1.30208	65.1892	0	59.6221	0	48.3528	0	40.5976	0	18.1356	0.7	
I0517 15:30:40.540560  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:30:40.541754  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:30:40.541779  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:30:40.551542  4008 solver.cpp:260]     Total regularization terms: 1.46987 loss+regular. : 2.88444
I0517 15:31:58.034571  4008 solver.cpp:231] Iteration 50600, loss = 1.70557
I0517 15:31:58.039698  4008 solver.cpp:247]     Train net output #0: loss = 1.70557 (* 1 = 1.70557 loss)
I0517 15:31:58.039736  4008 sgd_solver.cpp:106] Iteration 50600, lr = 0.001
I0517 15:31:58.199165  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.62029	0	61.0804	0	71.5382	1.30208	65.2818	0	59.7055	0	48.4513	0	40.6807	0	18.1598	0.7	
I0517 15:31:58.273754  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:31:58.274526  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:31:58.274540  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:31:58.294937  4008 solver.cpp:260]     Total regularization terms: 1.46817 loss+regular. : 3.17374
I0517 15:33:12.478456  4008 solver.cpp:231] Iteration 50800, loss = 1.32069
I0517 15:33:12.478709  4008 solver.cpp:247]     Train net output #0: loss = 1.32069 (* 1 = 1.32069 loss)
I0517 15:33:12.478731  4008 sgd_solver.cpp:106] Iteration 50800, lr = 0.001
I0517 15:33:12.640229  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.82404	0	61.2318	0	71.6129	1.30208	65.3786	0	59.7982	0	48.5495	0	40.7623	0	18.1839	0.7	
I0517 15:33:12.714602  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:33:12.715829  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:33:12.715854  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:33:12.727108  4008 solver.cpp:260]     Total regularization terms: 1.4665 loss+regular. : 2.7872
I0517 15:34:28.898226  4008 solver.cpp:348] Iteration 51000, Testing net (#0)
I0517 15:34:57.589367  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:35:46.934916  4008 solver.cpp:415]     Test net output #0: accuracy = 0.54954
I0517 15:35:46.936255  4008 solver.cpp:415]     Test net output #1: loss = 1.93494 (* 1 = 1.93494 loss)
I0517 15:35:47.027456  4008 solver.cpp:231] Iteration 51000, loss = 1.56157
I0517 15:35:47.027530  4008 solver.cpp:247]     Train net output #0: loss = 1.56157 (* 1 = 1.56157 loss)
I0517 15:35:47.027549  4008 sgd_solver.cpp:106] Iteration 51000, lr = 0.001
I0517 15:35:47.195852  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.73795	0	61.2878	0	71.6972	1.30208	65.4616	0	59.8741	0	48.6468	0	40.8445	0	18.2078	0.7	
I0517 15:35:47.269825  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:35:47.270959  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:35:47.270977  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:35:47.280818  4008 solver.cpp:260]     Total regularization terms: 1.46486 loss+regular. : 3.02643
I0517 15:37:06.601336  4008 solver.cpp:231] Iteration 51200, loss = 1.70424
I0517 15:37:06.605621  4008 solver.cpp:247]     Train net output #0: loss = 1.70424 (* 1 = 1.70424 loss)
I0517 15:37:06.605641  4008 sgd_solver.cpp:106] Iteration 51200, lr = 0.001
I0517 15:37:06.761992  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.83551	0	61.4421	0	71.7844	1.30208	65.5527	0	59.9594	0	48.744	0	40.9255	0	18.2306	0.7	
I0517 15:37:06.835736  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:37:06.836905  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:37:06.836927  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:37:06.846652  4008 solver.cpp:260]     Total regularization terms: 1.46318 loss+regular. : 3.16743
I0517 15:38:18.028506  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:38:29.476261  4008 solver.cpp:231] Iteration 51400, loss = 1.37278
I0517 15:38:29.476356  4008 solver.cpp:247]     Train net output #0: loss = 1.37278 (* 1 = 1.37278 loss)
I0517 15:38:29.476373  4008 sgd_solver.cpp:106] Iteration 51400, lr = 0.001
I0517 15:38:29.639853  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.7896	0	61.5007	0	71.8749	1.30208	65.6384	0	60.0434	0	48.8395	0	41.0061	0	18.253	0.7	
I0517 15:38:29.714437  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:38:29.715215  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:38:29.715241  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:38:29.734941  4008 solver.cpp:260]     Total regularization terms: 1.4615 loss+regular. : 2.83428
I0517 15:39:52.340368  4008 solver.cpp:231] Iteration 51600, loss = 1.4692
I0517 15:39:52.340659  4008 solver.cpp:247]     Train net output #0: loss = 1.4692 (* 1 = 1.4692 loss)
I0517 15:39:52.340680  4008 sgd_solver.cpp:106] Iteration 51600, lr = 0.001
I0517 15:39:52.500610  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.75517	0	61.5205	0	71.9465	1.30208	65.7261	0	60.1345	0	48.9351	0	41.0857	0	18.2761	0.7	
I0517 15:39:52.574823  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:39:52.575667  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:39:52.575685  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:39:52.585574  4008 solver.cpp:260]     Total regularization terms: 1.45986 loss+regular. : 2.92905
I0517 15:41:16.429733  4008 solver.cpp:231] Iteration 51800, loss = 1.62304
I0517 15:41:16.434900  4008 solver.cpp:247]     Train net output #0: loss = 1.62304 (* 1 = 1.62304 loss)
I0517 15:41:16.434937  4008 sgd_solver.cpp:106] Iteration 51800, lr = 0.001
I0517 15:41:16.592002  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.74082	0	61.5488	0	72.03	1.30208	65.8158	0	60.2143	0	49.0317	0	41.1656	0	18.2996	0.7	
I0517 15:41:16.666673  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:41:16.667662  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:41:16.667685  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:41:16.697712  4008 solver.cpp:260]     Total regularization terms: 1.45826 loss+regular. : 3.0813
I0517 15:42:36.998317  4008 solver.cpp:348] Iteration 52000, Testing net (#0)
I0517 15:43:06.848095  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:44:00.093436  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55286
I0517 15:44:00.093807  4008 solver.cpp:415]     Test net output #1: loss = 1.92474 (* 1 = 1.92474 loss)
I0517 15:44:00.181677  4008 solver.cpp:231] Iteration 52000, loss = 1.4619
I0517 15:44:00.181758  4008 solver.cpp:247]     Train net output #0: loss = 1.4619 (* 1 = 1.4619 loss)
I0517 15:44:00.181777  4008 sgd_solver.cpp:106] Iteration 52000, lr = 0.001
I0517 15:44:00.347414  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.71212	0	61.7204	0	72.1064	1.30208	65.9027	0	60.2919	0	49.1251	0	41.2444	0	18.3213	0.7	
I0517 15:44:00.421751  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:44:00.422422  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:44:00.422437  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:44:00.432819  4008 solver.cpp:260]     Total regularization terms: 1.45663 loss+regular. : 2.91853
I0517 15:45:24.111975  4008 solver.cpp:231] Iteration 52200, loss = 1.61907
I0517 15:45:24.112298  4008 solver.cpp:247]     Train net output #0: loss = 1.61907 (* 1 = 1.61907 loss)
I0517 15:45:24.112319  4008 sgd_solver.cpp:106] Iteration 52200, lr = 0.001
I0517 15:45:24.272738  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.89865	0	61.7913	0	72.183	1.30208	65.9902	0	60.3814	0	49.22	0	41.3247	0	18.3434	0.7	
I0517 15:45:24.346429  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:45:24.347383  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:45:24.347404  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:45:24.359570  4008 solver.cpp:260]     Total regularization terms: 1.45499 loss+regular. : 3.07405
I0517 15:46:42.913489  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:46:52.145988  4008 solver.cpp:231] Iteration 52400, loss = 1.38542
I0517 15:46:52.146077  4008 solver.cpp:247]     Train net output #0: loss = 1.38542 (* 1 = 1.38542 loss)
I0517 15:46:52.146095  4008 sgd_solver.cpp:106] Iteration 52400, lr = 0.001
I0517 15:46:52.306845  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.93021	0	61.8008	0	72.2573	1.30208	66.0807	0	60.4592	0	49.3137	0	41.4037	0	18.3666	0.7	
I0517 15:46:52.380545  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:46:52.381350  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:46:52.381369  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:46:52.391090  4008 solver.cpp:260]     Total regularization terms: 1.45341 loss+regular. : 2.83883
I0517 15:48:24.980602  4008 solver.cpp:231] Iteration 52600, loss = 1.40137
I0517 15:48:24.980859  4008 solver.cpp:247]     Train net output #0: loss = 1.40137 (* 1 = 1.40137 loss)
I0517 15:48:24.980880  4008 sgd_solver.cpp:106] Iteration 52600, lr = 0.001
I0517 15:48:25.140202  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.60595	0	61.932	0	72.335	1.30208	66.1705	0	60.5559	0	49.4081	0	41.4825	0	18.3887	0.7	
I0517 15:48:25.213672  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:48:25.214314  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:48:25.214329  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:48:25.223934  4008 solver.cpp:260]     Total regularization terms: 1.45172 loss+regular. : 2.85309
I0517 15:49:45.724885  4008 solver.cpp:231] Iteration 52800, loss = 1.31725
I0517 15:49:45.726729  4008 solver.cpp:247]     Train net output #0: loss = 1.31725 (* 1 = 1.31725 loss)
I0517 15:49:45.726758  4008 sgd_solver.cpp:106] Iteration 52800, lr = 0.001
I0517 15:49:45.885664  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.90725	0	62.071	0	72.4111	1.30208	66.2569	0	60.6441	0	49.5019	0	41.5607	0	18.4121	0.7	
I0517 15:49:45.961864  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:49:45.962785  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:49:45.962805  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:49:45.988051  4008 solver.cpp:260]     Total regularization terms: 1.45005 loss+regular. : 2.76731
I0517 15:51:09.141858  4008 solver.cpp:348] Iteration 53000, Testing net (#0)
I0517 15:51:41.173338  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:52:32.198899  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5489
I0517 15:52:32.201690  4008 solver.cpp:415]     Test net output #1: loss = 1.93967 (* 1 = 1.93967 loss)
I0517 15:52:32.294759  4008 solver.cpp:231] Iteration 53000, loss = 1.67617
I0517 15:52:32.294831  4008 solver.cpp:247]     Train net output #0: loss = 1.67617 (* 1 = 1.67617 loss)
I0517 15:52:32.294847  4008 sgd_solver.cpp:106] Iteration 53000, lr = 0.001
I0517 15:52:32.453934  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.7896	0	62.1934	0	72.4813	1.30208	66.3356	0	60.727	0	49.5971	0	41.6387	0	18.4347	0.7	
I0517 15:52:32.528015  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:52:32.529145  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:52:32.529170  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:52:32.541957  4008 solver.cpp:260]     Total regularization terms: 1.4484 loss+regular. : 3.12457
I0517 15:53:54.577042  4008 solver.cpp:231] Iteration 53200, loss = 1.63495
I0517 15:53:54.577394  4008 solver.cpp:247]     Train net output #0: loss = 1.63495 (* 1 = 1.63495 loss)
I0517 15:53:54.577411  4008 sgd_solver.cpp:106] Iteration 53200, lr = 0.001
I0517 15:53:54.738279  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.89578	0	62.1745	0	72.5699	1.30208	66.4201	0	60.8134	0	49.6919	0	41.718	0	18.4576	0.7	
I0517 15:53:54.817118  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:53:54.818029  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:53:54.818055  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:53:54.833042  4008 solver.cpp:260]     Total regularization terms: 1.44679 loss+regular. : 3.08174
I0517 15:55:07.489506  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 15:55:14.911340  4008 solver.cpp:231] Iteration 53400, loss = 1.54528
I0517 15:55:14.911424  4008 solver.cpp:247]     Train net output #0: loss = 1.54528 (* 1 = 1.54528 loss)
I0517 15:55:14.911443  4008 sgd_solver.cpp:106] Iteration 53400, lr = 0.001
I0517 15:55:15.072660  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.79534	0	62.2357	0	72.6434	1.30208	66.5063	0	60.8939	0	49.7848	0	41.7956	0	18.4808	0.7	
I0517 15:55:15.146491  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:55:15.147441  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:55:15.147472  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:55:15.157248  4008 solver.cpp:260]     Total regularization terms: 1.44518 loss+regular. : 2.99045
I0517 15:56:40.098765  4008 solver.cpp:231] Iteration 53600, loss = 1.40327
I0517 15:56:40.099082  4008 solver.cpp:247]     Train net output #0: loss = 1.40327 (* 1 = 1.40327 loss)
I0517 15:56:40.099117  4008 sgd_solver.cpp:106] Iteration 53600, lr = 0.001
I0517 15:56:40.260408  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.01917	0	62.221	0	72.7015	1.30208	66.586	0	60.9644	0	49.8787	0	41.8741	0	18.502	0.7	
I0517 15:56:40.334288  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:56:40.335209  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:56:40.335242  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:56:40.345060  4008 solver.cpp:260]     Total regularization terms: 1.44359 loss+regular. : 2.84686
I0517 15:58:12.312321  4008 solver.cpp:231] Iteration 53800, loss = 1.6079
I0517 15:58:12.312652  4008 solver.cpp:247]     Train net output #0: loss = 1.6079 (* 1 = 1.6079 loss)
I0517 15:58:12.312675  4008 sgd_solver.cpp:106] Iteration 53800, lr = 0.001
I0517 15:58:12.471148  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.9503	0	62.3431	0	72.7817	1.30208	66.6733	0	61.0508	0	49.9706	0	41.9529	0	18.524	0.7	
I0517 15:58:12.544896  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 15:58:12.545686  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 15:58:12.545708  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 15:58:12.555367  4008 solver.cpp:260]     Total regularization terms: 1.44207 loss+regular. : 3.04997
I0517 15:59:41.628768  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_54000.caffemodel
I0517 16:01:16.717476  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_54000.solverstate
I0517 16:01:17.323825  4008 solver.cpp:348] Iteration 54000, Testing net (#0)
I0517 16:01:48.904319  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:02:39.246547  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5528
I0517 16:02:39.247306  4008 solver.cpp:415]     Test net output #1: loss = 1.91808 (* 1 = 1.91808 loss)
I0517 16:02:39.337414  4008 solver.cpp:231] Iteration 54000, loss = 1.56186
I0517 16:02:39.337489  4008 solver.cpp:247]     Train net output #0: loss = 1.56186 (* 1 = 1.56186 loss)
I0517 16:02:39.337507  4008 sgd_solver.cpp:106] Iteration 54000, lr = 0.001
I0517 16:02:39.504608  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.01917	0	62.4596	0	72.8344	1.30208	66.747	0	61.1204	0	50.0634	0	42.0304	0	18.5458	0.7	
I0517 16:02:39.505441  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:02:39.506575  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 16:02:39.506600  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:02:39.516506  4008 solver.cpp:260]     Total regularization terms: 1.44045 loss+regular. : 3.0023
I0517 16:04:02.834663  4008 solver.cpp:231] Iteration 54200, loss = 1.48503
I0517 16:04:02.836577  4008 solver.cpp:247]     Train net output #0: loss = 1.48503 (* 1 = 1.48503 loss)
I0517 16:04:02.836683  4008 sgd_solver.cpp:106] Iteration 54200, lr = 0.001
I0517 16:04:02.994005  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.97899	0	62.5055	0	72.9268	1.30208	66.8361	0	61.2013	0	50.1542	0	42.1089	0	18.5685	0.7	
I0517 16:04:03.068130  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:04:03.069206  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 16:04:03.069231  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:04:03.079144  4008 solver.cpp:260]     Total regularization terms: 1.43882 loss+regular. : 2.92385
I0517 16:05:25.906167  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:05:30.112972  4008 solver.cpp:231] Iteration 54400, loss = 1.54423
I0517 16:05:30.113081  4008 solver.cpp:247]     Train net output #0: loss = 1.54423 (* 1 = 1.54423 loss)
I0517 16:05:30.113100  4008 sgd_solver.cpp:106] Iteration 54400, lr = 0.001
I0517 16:05:30.273931  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.07369	0	62.459	0	72.9893	1.30208	66.9058	0	61.2759	0	50.2465	0	42.1869	0	18.5894	0.7	
I0517 16:05:30.347692  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:05:30.348587  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 16:05:30.348624  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:05:30.358476  4008 solver.cpp:260]     Total regularization terms: 1.43725 loss+regular. : 2.98148
I0517 16:07:02.095558  4008 solver.cpp:231] Iteration 54600, loss = 1.35926
I0517 16:07:02.095780  4008 solver.cpp:247]     Train net output #0: loss = 1.35926 (* 1 = 1.35926 loss)
I0517 16:07:02.095800  4008 sgd_solver.cpp:106] Iteration 54600, lr = 0.001
I0517 16:07:02.256083  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.00482	0	62.6491	0	73.0627	1.30208	66.9937	0	61.3512	0	50.3379	0	42.2633	0	18.6116	0.7	
I0517 16:07:02.329968  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:07:02.330863  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 16:07:02.330883  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:07:02.340657  4008 solver.cpp:260]     Total regularization terms: 1.4357 loss+regular. : 2.79496
I0517 16:08:18.269256  4008 solver.cpp:231] Iteration 54800, loss = 1.69802
I0517 16:08:18.269703  4008 solver.cpp:247]     Train net output #0: loss = 1.69802 (* 1 = 1.69802 loss)
I0517 16:08:18.269769  4008 sgd_solver.cpp:106] Iteration 54800, lr = 0.001
I0517 16:08:18.433367  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.92447	0	62.6471	0	73.1394	1.30208	67.0582	0	61.4217	0	50.4274	0	42.34	0	18.6331	0.7	
I0517 16:08:18.510352  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:08:18.511067  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.7	
I0517 16:08:18.511091  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:08:18.532220  4008 solver.cpp:260]     Total regularization terms: 1.43407 loss+regular. : 3.13209
I0517 16:09:43.811892  4008 solver.cpp:348] Iteration 55000, Testing net (#0)
I0517 16:10:17.771385  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:11:06.211616  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55322
I0517 16:11:06.211992  4008 solver.cpp:415]     Test net output #1: loss = 1.92036 (* 1 = 1.92036 loss)
I0517 16:11:06.299079  4008 solver.cpp:231] Iteration 55000, loss = 1.38051
I0517 16:11:06.299165  4008 solver.cpp:247]     Train net output #0: loss = 1.38051 (* 1 = 1.38051 loss)
I0517 16:11:06.299185  4008 sgd_solver.cpp:106] Iteration 55000, lr = 0.001
I0517 16:11:06.464329  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.97612	0	62.7279	0	73.2105	1.30208	67.1355	0	61.5049	0	50.519	0	42.417	0	18.6557	0.8	
I0517 16:11:06.538743  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:11:06.539583  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:11:06.539607  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:11:06.549629  4008 solver.cpp:260]     Total regularization terms: 1.43246 loss+regular. : 2.81297
I0517 16:12:27.469108  4008 solver.cpp:231] Iteration 55200, loss = 1.40747
I0517 16:12:27.469482  4008 solver.cpp:247]     Train net output #0: loss = 1.40747 (* 1 = 1.40747 loss)
I0517 16:12:27.469511  4008 sgd_solver.cpp:106] Iteration 55200, lr = 0.001
I0517 16:12:27.630028  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.07943	0	62.8411	0	73.2782	1.30208	67.2176	0	61.5829	0	50.6099	0	42.4939	0	18.6777	0.8	
I0517 16:12:27.704174  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:12:27.705389  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:12:27.705430  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:12:27.715447  4008 solver.cpp:260]     Total regularization terms: 1.43091 loss+regular. : 2.83837
I0517 16:13:58.109802  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:13:59.100049  4008 solver.cpp:231] Iteration 55400, loss = 1.37961
I0517 16:13:59.100131  4008 solver.cpp:247]     Train net output #0: loss = 1.37961 (* 1 = 1.37961 loss)
I0517 16:13:59.100148  4008 sgd_solver.cpp:106] Iteration 55400, lr = 0.001
I0517 16:13:59.259024  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.9503	0	62.9046	0	73.3509	1.30208	67.298	0	61.6498	0	50.7008	0	42.5701	0	18.6981	0.8	
I0517 16:13:59.332726  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:13:59.333945  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:13:59.333983  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:13:59.343788  4008 solver.cpp:260]     Total regularization terms: 1.42954 loss+regular. : 2.80914
I0517 16:15:32.141191  4008 solver.cpp:231] Iteration 55600, loss = 1.25902
I0517 16:15:32.141594  4008 solver.cpp:247]     Train net output #0: loss = 1.25902 (* 1 = 1.25902 loss)
I0517 16:15:32.141626  4008 sgd_solver.cpp:106] Iteration 55600, lr = 0.001
I0517 16:15:32.301426  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.8843	0	62.9772	0	73.3993	1.30208	67.3679	0	61.7206	0	50.7917	0	42.6472	0	18.7209	0.8	
I0517 16:15:32.375864  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:15:32.377616  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:15:32.377688  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:15:32.387918  4008 solver.cpp:260]     Total regularization terms: 1.42806 loss+regular. : 2.68708
I0517 16:17:00.235726  4008 solver.cpp:231] Iteration 55800, loss = 1.37031
I0517 16:17:00.236205  4008 solver.cpp:247]     Train net output #0: loss = 1.37031 (* 1 = 1.37031 loss)
I0517 16:17:00.236227  4008 sgd_solver.cpp:106] Iteration 55800, lr = 0.001
I0517 16:17:00.398366  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.309	0	63.0286	0	73.4712	1.30208	67.4548	0	61.7936	0	50.8822	0	42.7236	0	18.7427	0.8	
I0517 16:17:00.473631  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:17:00.474865  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:17:00.474884  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:17:00.489914  4008 solver.cpp:260]     Total regularization terms: 1.42659 loss+regular. : 2.7969
I0517 16:18:32.646368  4008 solver.cpp:348] Iteration 56000, Testing net (#0)
I0517 16:19:05.193526  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:20:00.610242  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5533
I0517 16:20:00.611409  4008 solver.cpp:415]     Test net output #1: loss = 1.91989 (* 1 = 1.91989 loss)
I0517 16:20:00.710539  4008 solver.cpp:231] Iteration 56000, loss = 1.4092
I0517 16:20:00.710635  4008 solver.cpp:247]     Train net output #0: loss = 1.4092 (* 1 = 1.4092 loss)
I0517 16:20:00.710656  4008 sgd_solver.cpp:106] Iteration 56000, lr = 0.001
I0517 16:20:00.887688  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.13108	0	63.0921	0	73.5413	1.30208	67.5329	0	61.875	0	50.9728	0	42.8002	0	18.764	0.8	
I0517 16:20:00.962270  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:20:00.963438  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:20:00.963475  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:20:00.973450  4008 solver.cpp:260]     Total regularization terms: 1.42509 loss+regular. : 2.83429
I0517 16:21:35.388051  4008 solver.cpp:231] Iteration 56200, loss = 1.39473
I0517 16:21:35.388363  4008 solver.cpp:247]     Train net output #0: loss = 1.39473 (* 1 = 1.39473 loss)
I0517 16:21:35.388386  4008 sgd_solver.cpp:106] Iteration 56200, lr = 0.001
I0517 16:21:35.547960  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.17126	0	63.1478	0	73.6049	1.30208	67.6153	0	61.9568	0	51.063	0	42.8772	0	18.7854	0.8	
I0517 16:21:35.622041  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:21:35.623149  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:21:35.623178  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:21:35.633019  4008 solver.cpp:260]     Total regularization terms: 1.42367 loss+regular. : 2.81839
I0517 16:23:09.241998  4008 solver.cpp:231] Iteration 56400, loss = 1.50287
I0517 16:23:09.246757  4008 solver.cpp:247]     Train net output #0: loss = 1.50287 (* 1 = 1.50287 loss)
I0517 16:23:09.246794  4008 sgd_solver.cpp:106] Iteration 56400, lr = 0.001
I0517 16:23:09.403028  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.10239	0	63.0426	0	73.6637	1.30208	67.6862	0	62.0203	0	51.1507	0	42.9532	0	18.8068	0.8	
I0517 16:23:09.477651  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:23:09.479266  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:23:09.479316  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:23:09.489593  4008 solver.cpp:260]     Total regularization terms: 1.42225 loss+regular. : 2.92512
I0517 16:23:12.416929  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:24:38.529980  4008 solver.cpp:231] Iteration 56600, loss = 1.51028
I0517 16:24:38.530293  4008 solver.cpp:247]     Train net output #0: loss = 1.51028 (* 1 = 1.51028 loss)
I0517 16:24:38.530314  4008 sgd_solver.cpp:106] Iteration 56600, lr = 0.001
I0517 16:24:38.688665  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.93882	0	63.2624	0	73.7344	1.30208	67.7623	0	62.1008	0	51.2401	0	43.0278	0	18.8279	0.8	
I0517 16:24:38.762882  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:24:38.764443  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.30208	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:24:38.764487  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:24:38.774646  4008 solver.cpp:260]     Total regularization terms: 1.42078 loss+regular. : 2.93105
I0517 16:26:07.197193  4008 solver.cpp:231] Iteration 56800, loss = 1.5781
I0517 16:26:07.197492  4008 solver.cpp:247]     Train net output #0: loss = 1.5781 (* 1 = 1.5781 loss)
I0517 16:26:07.197512  4008 sgd_solver.cpp:106] Iteration 56800, lr = 0.001
I0517 16:26:07.358134  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.09091	0	63.3337	0	73.8144	1.5625	67.8399	0	62.1831	0	51.3287	0	43.1038	0	18.849	0.8	
I0517 16:26:07.432056  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:26:07.433428  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.5625	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:26:07.433449  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:26:07.443161  4008 solver.cpp:260]     Total regularization terms: 1.41928 loss+regular. : 2.99738
I0517 16:27:27.697348  4008 solver.cpp:348] Iteration 57000, Testing net (#0)
I0517 16:27:57.484225  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:28:41.931989  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55446
I0517 16:28:41.933609  4008 solver.cpp:415]     Test net output #1: loss = 1.91914 (* 1 = 1.91914 loss)
I0517 16:28:42.024157  4008 solver.cpp:231] Iteration 57000, loss = 1.44074
I0517 16:28:42.024267  4008 solver.cpp:247]     Train net output #0: loss = 1.44074 (* 1 = 1.44074 loss)
I0517 16:28:42.024287  4008 sgd_solver.cpp:106] Iteration 57000, lr = 0.001
I0517 16:28:42.193250  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.111	0	63.3389	0	73.8735	1.5625	67.9244	0	62.2525	0	51.4174	0	43.1794	0	18.8701	0.8	
I0517 16:28:42.266949  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:28:42.267765  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.5625	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:28:42.267783  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:28:42.278965  4008 solver.cpp:260]     Total regularization terms: 1.41793 loss+regular. : 2.85867
I0517 16:30:01.106374  4008 solver.cpp:231] Iteration 57200, loss = 1.36185
I0517 16:30:01.107991  4008 solver.cpp:247]     Train net output #0: loss = 1.36185 (* 1 = 1.36185 loss)
I0517 16:30:01.108013  4008 sgd_solver.cpp:106] Iteration 57200, lr = 0.001
I0517 16:30:01.265799  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.045	0	63.4922	0	73.9392	1.5625	67.9989	0	62.3146	0	51.5057	0	43.2544	0	18.8906	0.8	
I0517 16:30:01.339890  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:30:01.340955  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.5625	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:30:01.340975  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:30:01.350764  4008 solver.cpp:260]     Total regularization terms: 1.41647 loss+regular. : 2.77833
I0517 16:31:21.308362  4008 solver.cpp:231] Iteration 57400, loss = 1.39375
I0517 16:31:21.308960  4008 solver.cpp:247]     Train net output #0: loss = 1.39375 (* 1 = 1.39375 loss)
I0517 16:31:21.308990  4008 sgd_solver.cpp:106] Iteration 57400, lr = 0.001
I0517 16:31:21.467926  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.25448	0	63.4424	0	74.0034	1.5625	68.0715	0	62.3895	0	51.5927	0	43.3294	0	18.911	0.8	
I0517 16:31:21.542317  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:31:21.543438  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.5625	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:31:21.543463  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:31:21.558548  4008 solver.cpp:260]     Total regularization terms: 1.41504 loss+regular. : 2.80879
I0517 16:31:26.238049  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:32:38.537860  4008 solver.cpp:231] Iteration 57600, loss = 1.57943
I0517 16:32:38.538173  4008 solver.cpp:247]     Train net output #0: loss = 1.57943 (* 1 = 1.57943 loss)
I0517 16:32:38.538192  4008 sgd_solver.cpp:106] Iteration 57600, lr = 0.001
I0517 16:32:38.700464  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.31761	0	63.6768	0	74.0815	1.5625	68.144	0	62.446	0	51.6799	0	43.405	0	18.9319	0.8	
I0517 16:32:38.777087  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:32:38.777997  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.5625	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:32:38.778018  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:32:38.787749  4008 solver.cpp:260]     Total regularization terms: 1.41356 loss+regular. : 2.99298
I0517 16:33:53.847751  4008 solver.cpp:231] Iteration 57800, loss = 1.53054
I0517 16:33:53.848063  4008 solver.cpp:247]     Train net output #0: loss = 1.53054 (* 1 = 1.53054 loss)
I0517 16:33:53.848083  4008 sgd_solver.cpp:106] Iteration 57800, lr = 0.001
I0517 16:33:54.010314  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.97612	0	63.651	0	74.1382	1.5625	68.2118	0	62.5355	0	51.7678	0	43.4788	0	18.9529	0.8	
I0517 16:33:54.084899  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:33:54.085605  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.5625	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:33:54.085623  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:33:54.107144  4008 solver.cpp:260]     Total regularization terms: 1.41215 loss+regular. : 2.9427
I0517 16:35:08.495059  4008 solver.cpp:348] Iteration 58000, Testing net (#0)
I0517 16:35:40.200023  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:36:37.360009  4008 solver.cpp:415]     Test net output #0: accuracy = 0.54986
I0517 16:36:37.360234  4008 solver.cpp:415]     Test net output #1: loss = 1.93167 (* 1 = 1.93167 loss)
I0517 16:36:37.451068  4008 solver.cpp:231] Iteration 58000, loss = 1.53444
I0517 16:36:37.451150  4008 solver.cpp:247]     Train net output #0: loss = 1.53444 (* 1 = 1.53444 loss)
I0517 16:36:37.451167  4008 sgd_solver.cpp:106] Iteration 58000, lr = 0.001
I0517 16:36:37.618170  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.15978	0	63.8083	0	74.1966	1.5625	68.2863	0	62.6157	0	51.8557	0	43.5527	0	18.9733	0.8	
I0517 16:36:37.691871  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:36:37.692867  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.5625	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:36:37.692891  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:36:37.702582  4008 solver.cpp:260]     Total regularization terms: 1.41073 loss+regular. : 2.94518
I0517 16:37:56.350970  4008 solver.cpp:231] Iteration 58200, loss = 1.59062
I0517 16:37:56.351336  4008 solver.cpp:247]     Train net output #0: loss = 1.59062 (* 1 = 1.59062 loss)
I0517 16:37:56.351356  4008 sgd_solver.cpp:106] Iteration 58200, lr = 0.001
I0517 16:37:56.511750  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.05073	0	63.8206	0	74.2723	1.5625	68.3695	0	62.6971	0	51.9439	0	43.6271	0	18.9946	0.8	
I0517 16:37:56.586771  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:37:56.587810  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.5625	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:37:56.587832  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:37:56.617382  4008 solver.cpp:260]     Total regularization terms: 1.40935 loss+regular. : 2.99997
I0517 16:39:13.929107  4008 solver.cpp:231] Iteration 58400, loss = 1.48285
I0517 16:39:13.929467  4008 solver.cpp:247]     Train net output #0: loss = 1.48285 (* 1 = 1.48285 loss)
I0517 16:39:13.929489  4008 sgd_solver.cpp:106] Iteration 58400, lr = 0.001
I0517 16:39:14.089794  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.28317	0	63.8047	0	74.3299	1.5625	68.4453	0	62.7692	0	52.0312	0	43.7022	0	19.015	0.8	
I0517 16:39:14.163529  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:39:14.164304  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.5625	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:39:14.164324  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:39:14.174136  4008 solver.cpp:260]     Total regularization terms: 1.40797 loss+regular. : 2.89082
I0517 16:39:23.246134  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:40:33.381705  4008 solver.cpp:231] Iteration 58600, loss = 1.5325
I0517 16:40:33.382009  4008 solver.cpp:247]     Train net output #0: loss = 1.5325 (* 1 = 1.5325 loss)
I0517 16:40:33.382027  4008 sgd_solver.cpp:106] Iteration 58600, lr = 0.001
I0517 16:40:33.545372  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.07369	0	63.9271	0	74.3882	1.82292	68.5141	0	62.8373	0	52.1185	0	43.7773	0	19.0356	0.8	
I0517 16:40:33.619457  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:40:33.620641  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:40:33.620663  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:40:33.630359  4008 solver.cpp:260]     Total regularization terms: 1.40657 loss+regular. : 2.93908
I0517 16:41:52.077018  4008 solver.cpp:231] Iteration 58800, loss = 1.52959
I0517 16:41:52.077235  4008 solver.cpp:247]     Train net output #0: loss = 1.52959 (* 1 = 1.52959 loss)
I0517 16:41:52.077258  4008 sgd_solver.cpp:106] Iteration 58800, lr = 0.001
I0517 16:41:52.239578  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.08517	0	64.0143	0	74.4523	1.82292	68.5815	0	62.913	0	52.2034	0	43.8517	0	19.0563	0.8	
I0517 16:41:52.314755  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:41:52.315728  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:41:52.315747  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:41:52.329743  4008 solver.cpp:260]     Total regularization terms: 1.40519 loss+regular. : 2.93477
I0517 16:43:11.467453  4008 solver.cpp:348] Iteration 59000, Testing net (#0)
I0517 16:43:45.224215  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:44:29.192405  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55226
I0517 16:44:29.192981  4008 solver.cpp:415]     Test net output #1: loss = 1.92562 (* 1 = 1.92562 loss)
I0517 16:44:29.289873  4008 solver.cpp:231] Iteration 59000, loss = 1.48022
I0517 16:44:29.289985  4008 solver.cpp:247]     Train net output #0: loss = 1.48022 (* 1 = 1.48022 loss)
I0517 16:44:29.290007  4008 sgd_solver.cpp:106] Iteration 59000, lr = 0.001
I0517 16:44:29.447887  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.13108	0	64.0846	0	74.5174	1.82292	68.6546	0	62.9763	0	52.2907	0	43.9252	0	19.0765	0.8	
I0517 16:44:29.523897  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:44:29.524966  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:44:29.524989  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:44:29.534812  4008 solver.cpp:260]     Total regularization terms: 1.40373 loss+regular. : 2.88395
I0517 16:45:59.865936  4008 solver.cpp:231] Iteration 59200, loss = 1.43299
I0517 16:45:59.866439  4008 solver.cpp:247]     Train net output #0: loss = 1.43299 (* 1 = 1.43299 loss)
I0517 16:45:59.866463  4008 sgd_solver.cpp:106] Iteration 59200, lr = 0.001
I0517 16:46:00.027438  4008 sgd_solver.cpp:120]     Element Sparsity %: 
8.93595	0	64.1497	0	74.585	1.82292	68.7275	0	63.0482	0	52.3758	0	43.9986	0	19.0949	0.8	
I0517 16:46:00.101477  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:46:00.102515  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:46:00.102543  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:46:00.112331  4008 solver.cpp:260]     Total regularization terms: 1.40237 loss+regular. : 2.83536
I0517 16:47:25.074861  4008 solver.cpp:231] Iteration 59400, loss = 1.57068
I0517 16:47:25.075213  4008 solver.cpp:247]     Train net output #0: loss = 1.57068 (* 1 = 1.57068 loss)
I0517 16:47:25.075232  4008 sgd_solver.cpp:106] Iteration 59400, lr = 0.001
I0517 16:47:25.234460  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.15404	0	64.124	0	74.638	1.82292	68.791	0	63.1205	0	52.4611	0	44.0727	0	19.1155	0.8	
I0517 16:47:25.308526  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:47:25.309514  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:47:25.309541  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:47:25.319340  4008 solver.cpp:260]     Total regularization terms: 1.40097 loss+regular. : 2.97165
I0517 16:47:34.690089  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:48:43.162335  4008 solver.cpp:231] Iteration 59600, loss = 1.52231
I0517 16:48:43.162636  4008 solver.cpp:247]     Train net output #0: loss = 1.52231 (* 1 = 1.52231 loss)
I0517 16:48:43.162667  4008 sgd_solver.cpp:106] Iteration 59600, lr = 0.001
I0517 16:48:43.325904  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.24013	0	64.278	0	74.7035	1.82292	68.8665	0	63.1938	0	52.5473	0	44.1458	0	19.136	0.8	
I0517 16:48:43.399832  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:48:43.400563  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:48:43.400580  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:48:43.410429  4008 solver.cpp:260]     Total regularization terms: 1.39958 loss+regular. : 2.92189
I0517 16:50:10.335628  4008 solver.cpp:231] Iteration 59800, loss = 1.61948
I0517 16:50:10.336021  4008 solver.cpp:247]     Train net output #0: loss = 1.61948 (* 1 = 1.61948 loss)
I0517 16:50:10.336042  4008 sgd_solver.cpp:106] Iteration 59800, lr = 0.001
I0517 16:50:10.495218  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.28604	0	64.2184	0	74.7617	1.82292	68.9271	0	63.2727	0	52.6325	0	44.2194	0	19.1569	0.8	
I0517 16:50:10.569049  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:50:10.570047  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:50:10.570071  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:50:10.579815  4008 solver.cpp:260]     Total regularization terms: 1.39814 loss+regular. : 3.01762
I0517 16:51:32.061434  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_60000.caffemodel
I0517 16:52:41.114354  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_60000.solverstate
I0517 16:52:41.933048  4008 solver.cpp:348] Iteration 60000, Testing net (#0)
I0517 16:53:15.938832  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:54:06.680126  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55442
I0517 16:54:06.680421  4008 solver.cpp:415]     Test net output #1: loss = 1.91634 (* 1 = 1.91634 loss)
I0517 16:54:06.769042  4008 solver.cpp:231] Iteration 60000, loss = 1.50078
I0517 16:54:06.769127  4008 solver.cpp:247]     Train net output #0: loss = 1.50078 (* 1 = 1.50078 loss)
I0517 16:54:06.769148  4008 sgd_solver.cpp:106] Iteration 60000, lr = 0.001
I0517 16:54:06.929801  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.21717	0	64.3398	0	74.8319	1.82292	69.0063	0	63.3366	0	52.7185	0	44.2919	0	19.1773	0.8	
I0517 16:54:06.930438  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:54:06.931378  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:54:06.931394  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:54:06.941123  4008 solver.cpp:260]     Total regularization terms: 1.39676 loss+regular. : 2.89754
I0517 16:55:26.184475  4008 solver.cpp:231] Iteration 60200, loss = 1.30836
I0517 16:55:26.184666  4008 solver.cpp:247]     Train net output #0: loss = 1.30836 (* 1 = 1.30836 loss)
I0517 16:55:26.184681  4008 sgd_solver.cpp:106] Iteration 60200, lr = 0.001
I0517 16:55:26.345434  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.16265	0	64.4417	0	74.8664	1.82292	69.0764	0	63.4054	0	52.8025	0	44.363	0	19.1973	0.8	
I0517 16:55:26.419952  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:55:26.420631  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:55:26.420650  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:55:26.440491  4008 solver.cpp:260]     Total regularization terms: 1.39542 loss+regular. : 2.70379
I0517 16:56:54.206060  4008 solver.cpp:231] Iteration 60400, loss = 1.40824
I0517 16:56:54.206410  4008 solver.cpp:247]     Train net output #0: loss = 1.40824 (* 1 = 1.40824 loss)
I0517 16:56:54.206506  4008 sgd_solver.cpp:106] Iteration 60400, lr = 0.001
I0517 16:56:54.365751  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.20856	0	64.4772	0	74.9376	1.82292	69.1384	0	63.4684	0	52.8863	0	44.4365	0	19.2167	0.8	
I0517 16:56:54.439539  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:56:54.440327  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:56:54.440353  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:56:54.450136  4008 solver.cpp:260]     Total regularization terms: 1.3942 loss+regular. : 2.80244
I0517 16:57:09.642784  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 16:58:17.712455  4008 solver.cpp:231] Iteration 60600, loss = 1.5687
I0517 16:58:17.712735  4008 solver.cpp:247]     Train net output #0: loss = 1.5687 (* 1 = 1.5687 loss)
I0517 16:58:17.712756  4008 sgd_solver.cpp:106] Iteration 60600, lr = 0.001
I0517 16:58:17.874485  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.12821	0	64.4411	0	75.0099	1.82292	69.205	0	63.5304	0	52.9702	0	44.5104	0	19.2377	0.8	
I0517 16:58:17.948164  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:58:17.949019  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:58:17.949041  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:58:17.958758  4008 solver.cpp:260]     Total regularization terms: 1.39295 loss+regular. : 2.96165
I0517 16:59:40.026922  4008 solver.cpp:231] Iteration 60800, loss = 1.51502
I0517 16:59:40.028133  4008 solver.cpp:247]     Train net output #0: loss = 1.51502 (* 1 = 1.51502 loss)
I0517 16:59:40.028153  4008 sgd_solver.cpp:106] Iteration 60800, lr = 0.001
I0517 16:59:40.188767  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.12534	0	64.513	0	75.0679	1.82292	69.276	0	63.6018	0	53.056	0	44.5837	0	19.2576	0.8	
I0517 16:59:40.262806  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 16:59:40.263828  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 16:59:40.263859  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 16:59:40.273792  4008 solver.cpp:260]     Total regularization terms: 1.3917 loss+regular. : 2.90672
I0517 17:00:56.823689  4008 solver.cpp:348] Iteration 61000, Testing net (#0)
I0517 17:01:30.738435  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:02:11.923655  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55396
I0517 17:02:11.924005  4008 solver.cpp:415]     Test net output #1: loss = 1.91861 (* 1 = 1.91861 loss)
I0517 17:02:12.012054  4008 solver.cpp:231] Iteration 61000, loss = 1.3408
I0517 17:02:12.012127  4008 solver.cpp:247]     Train net output #0: loss = 1.3408 (* 1 = 1.3408 loss)
I0517 17:02:12.012146  4008 sgd_solver.cpp:106] Iteration 61000, lr = 0.001
I0517 17:02:12.177592  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.29752	0	64.6829	0	75.1325	1.82292	69.345	0	63.6773	0	53.1406	0	44.6562	0	19.2786	0.8	
I0517 17:02:12.251791  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:02:12.252804  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:02:12.252828  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:02:12.262773  4008 solver.cpp:260]     Total regularization terms: 1.39038 loss+regular. : 2.73118
I0517 17:03:31.037993  4008 solver.cpp:231] Iteration 61200, loss = 1.44001
I0517 17:03:31.041681  4008 solver.cpp:247]     Train net output #0: loss = 1.44001 (* 1 = 1.44001 loss)
I0517 17:03:31.041713  4008 sgd_solver.cpp:106] Iteration 61200, lr = 0.001
I0517 17:03:31.200711  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.48978	0	64.7611	0	75.1902	1.82292	69.4075	0	63.7447	0	53.2248	0	44.7282	0	19.2982	0.8	
I0517 17:03:31.275913  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:03:31.277135  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:03:31.277159  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:03:31.292161  4008 solver.cpp:260]     Total regularization terms: 1.38911 loss+regular. : 2.82913
I0517 17:04:49.480779  4008 solver.cpp:231] Iteration 61400, loss = 1.61677
I0517 17:04:49.481073  4008 solver.cpp:247]     Train net output #0: loss = 1.61677 (* 1 = 1.61677 loss)
I0517 17:04:49.481094  4008 sgd_solver.cpp:106] Iteration 61400, lr = 0.001
I0517 17:04:49.640497  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.21717	0	64.7269	0	75.2372	1.82292	69.4664	0	63.793	0	53.3079	0	44.7992	0	19.3181	0.8	
I0517 17:04:49.714279  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:04:49.715560  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:04:49.715582  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:04:49.732441  4008 solver.cpp:260]     Total regularization terms: 1.38787 loss+regular. : 3.00464
I0517 17:05:06.634045  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:06:11.176452  4008 solver.cpp:231] Iteration 61600, loss = 1.4728
I0517 17:06:11.176748  4008 solver.cpp:247]     Train net output #0: loss = 1.4728 (* 1 = 1.4728 loss)
I0517 17:06:11.176767  4008 sgd_solver.cpp:106] Iteration 61600, lr = 0.001
I0517 17:06:11.337087  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.29178	0	64.8604	0	75.3008	1.82292	69.5332	0	63.8636	0	53.3909	0	44.8695	0	19.3375	0.8	
I0517 17:06:11.410758  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:06:11.411766  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:06:11.411813  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:06:11.421582  4008 solver.cpp:260]     Total regularization terms: 1.38646 loss+regular. : 2.85927
I0517 17:07:32.738005  4008 solver.cpp:231] Iteration 61800, loss = 1.5528
I0517 17:07:32.738370  4008 solver.cpp:247]     Train net output #0: loss = 1.5528 (* 1 = 1.5528 loss)
I0517 17:07:32.738400  4008 sgd_solver.cpp:106] Iteration 61800, lr = 0.001
I0517 17:07:32.884969  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.3463	0	64.8636	0	75.3636	1.82292	69.5915	0	63.9314	0	53.4749	0	44.9411	0	19.3583	0.8	
I0517 17:07:32.970774  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:07:32.971835  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:07:32.971859  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:07:32.995239  4008 solver.cpp:260]     Total regularization terms: 1.38521 loss+regular. : 2.93801
I0517 17:08:49.044071  4008 solver.cpp:348] Iteration 62000, Testing net (#0)
I0517 17:09:23.957195  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:10:08.850857  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5555
I0517 17:10:08.851161  4008 solver.cpp:415]     Test net output #1: loss = 1.90928 (* 1 = 1.90928 loss)
I0517 17:10:08.940485  4008 solver.cpp:231] Iteration 62000, loss = 1.68413
I0517 17:10:08.940578  4008 solver.cpp:247]     Train net output #0: loss = 1.68413 (* 1 = 1.68413 loss)
I0517 17:10:08.940596  4008 sgd_solver.cpp:106] Iteration 62000, lr = 0.001
I0517 17:10:09.105222  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.309	0	64.9648	0	75.4	1.82292	69.6575	0	63.9879	0	53.5567	0	45.0124	0	19.3777	0.8	
I0517 17:10:09.179455  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:10:09.180465  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:10:09.180495  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:10:09.190246  4008 solver.cpp:260]     Total regularization terms: 1.38406 loss+regular. : 3.06819
I0517 17:11:31.127830  4008 solver.cpp:231] Iteration 62200, loss = 1.29943
I0517 17:11:31.128155  4008 solver.cpp:247]     Train net output #0: loss = 1.29943 (* 1 = 1.29943 loss)
I0517 17:11:31.128178  4008 sgd_solver.cpp:106] Iteration 62200, lr = 0.001
I0517 17:11:31.288697  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.18274	0	64.9577	0	75.4658	1.82292	69.7157	0	64.0584	0	53.6394	0	45.0842	0	19.3972	0.8	
I0517 17:11:31.362332  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:11:31.363076  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:11:31.363093  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:11:31.372805  4008 solver.cpp:260]     Total regularization terms: 1.38281 loss+regular. : 2.68224
I0517 17:12:48.677814  4008 solver.cpp:231] Iteration 62400, loss = 1.56746
I0517 17:12:48.678093  4008 solver.cpp:247]     Train net output #0: loss = 1.56746 (* 1 = 1.56746 loss)
I0517 17:12:48.678115  4008 sgd_solver.cpp:106] Iteration 62400, lr = 0.001
I0517 17:12:48.840132  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.39509	0	64.9365	0	75.5177	1.82292	69.7829	0	64.1201	0	53.721	0	45.1546	0	19.4167	0.8	
I0517 17:12:48.913867  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:12:48.914963  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:12:48.914988  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:12:48.924734  4008 solver.cpp:260]     Total regularization terms: 1.3815 loss+regular. : 2.94896
I0517 17:13:06.845672  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:14:18.555469  4008 solver.cpp:231] Iteration 62600, loss = 1.49069
I0517 17:14:18.555832  4008 solver.cpp:247]     Train net output #0: loss = 1.49069 (* 1 = 1.49069 loss)
I0517 17:14:18.555853  4008 sgd_solver.cpp:106] Iteration 62600, lr = 0.001
I0517 17:14:18.715874  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.42091	0	65.1107	0	75.5846	1.82292	69.8379	0	64.1823	0	53.8033	0	45.2253	0	19.4362	0.8	
I0517 17:14:18.789669  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:14:18.790563  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	1.82292	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:14:18.790596  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:14:18.800719  4008 solver.cpp:260]     Total regularization terms: 1.38017 loss+regular. : 2.87085
I0517 17:15:39.422534  4008 solver.cpp:231] Iteration 62800, loss = 1.62629
I0517 17:15:39.422862  4008 solver.cpp:247]     Train net output #0: loss = 1.62629 (* 1 = 1.62629 loss)
I0517 17:15:39.422883  4008 sgd_solver.cpp:106] Iteration 62800, lr = 0.001
I0517 17:15:39.584652  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.18848	0	65.0055	0	75.6478	2.08333	69.9097	0	64.2422	0	53.885	0	45.2955	0	19.4568	0.8	
I0517 17:15:39.659373  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:15:39.660428  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:15:39.660460  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:15:39.675518  4008 solver.cpp:260]     Total regularization terms: 1.37889 loss+regular. : 3.00518
I0517 17:16:55.869072  4008 solver.cpp:348] Iteration 63000, Testing net (#0)
I0517 17:17:30.589501  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:18:10.939051  4008 solver.cpp:415]     Test net output #0: accuracy = 0.54972
I0517 17:18:10.939339  4008 solver.cpp:415]     Test net output #1: loss = 1.92675 (* 1 = 1.92675 loss)
I0517 17:18:11.029083  4008 solver.cpp:231] Iteration 63000, loss = 1.30115
I0517 17:18:11.029153  4008 solver.cpp:247]     Train net output #0: loss = 1.30115 (* 1 = 1.30115 loss)
I0517 17:18:11.029170  4008 sgd_solver.cpp:106] Iteration 63000, lr = 0.001
I0517 17:18:11.189225  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.19995	0	65.2839	0	75.6959	2.08333	69.9645	0	64.2996	0	53.9663	0	45.3652	0	19.4762	0.8	
I0517 17:18:11.266983  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:18:11.268028  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:18:11.268064  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:18:11.277951  4008 solver.cpp:260]     Total regularization terms: 1.37764 loss+regular. : 2.67879
I0517 17:19:33.177628  4008 solver.cpp:231] Iteration 63200, loss = 1.35218
I0517 17:19:33.178757  4008 solver.cpp:247]     Train net output #0: loss = 1.35218 (* 1 = 1.35218 loss)
I0517 17:19:33.178779  4008 sgd_solver.cpp:106] Iteration 63200, lr = 0.001
I0517 17:19:33.338716  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.243	0	65.2979	0	75.7542	2.08333	70.0272	0	64.3654	0	54.0485	0	45.4355	0	19.4956	0.8	
I0517 17:19:33.412612  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:19:33.413707  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:19:33.413748  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:19:33.423609  4008 solver.cpp:260]     Total regularization terms: 1.37636 loss+regular. : 2.72854
I0517 17:21:01.489605  4008 solver.cpp:231] Iteration 63400, loss = 1.66737
I0517 17:21:01.492202  4008 solver.cpp:247]     Train net output #0: loss = 1.66737 (* 1 = 1.66737 loss)
I0517 17:21:01.492238  4008 sgd_solver.cpp:106] Iteration 63400, lr = 0.001
I0517 17:21:01.651439  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.27456	0	65.3581	0	75.8077	2.08333	70.0931	0	64.4246	0	54.1288	0	45.5045	0	19.5148	0.8	
I0517 17:21:01.725690  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:21:01.726877  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:21:01.726923  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:21:01.736881  4008 solver.cpp:260]     Total regularization terms: 1.37513 loss+regular. : 3.0425
I0517 17:21:25.849934  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:22:25.848842  4008 solver.cpp:231] Iteration 63600, loss = 1.60829
I0517 17:22:25.849298  4008 solver.cpp:247]     Train net output #0: loss = 1.60829 (* 1 = 1.60829 loss)
I0517 17:22:25.849320  4008 sgd_solver.cpp:106] Iteration 63600, lr = 0.001
I0517 17:22:26.023111  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.38935	0	65.402	0	75.87	2.08333	70.1516	0	64.4977	0	54.21	0	45.5752	0	19.5337	0.8	
I0517 17:22:26.097429  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:22:26.098510  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.8	
I0517 17:22:26.098549  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:22:26.108492  4008 solver.cpp:260]     Total regularization terms: 1.37385 loss+regular. : 2.98214
I0517 17:24:10.689205  4008 solver.cpp:231] Iteration 63800, loss = 1.53166
I0517 17:24:10.689576  4008 solver.cpp:247]     Train net output #0: loss = 1.53166 (* 1 = 1.53166 loss)
I0517 17:24:10.689616  4008 sgd_solver.cpp:106] Iteration 63800, lr = 0.001
I0517 17:24:10.847893  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.309	0	65.2523	0	75.9186	2.08333	70.2031	0	64.5562	0	54.2898	0	45.6452	0	19.5527	0.9	
I0517 17:24:10.922310  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:24:10.924084  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:24:10.924144  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:24:10.934468  4008 solver.cpp:260]     Total regularization terms: 1.37261 loss+regular. : 2.90427
I0517 17:25:48.793861  4008 solver.cpp:348] Iteration 64000, Testing net (#0)
I0517 17:26:28.968533  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:27:14.128389  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5544
I0517 17:27:14.128739  4008 solver.cpp:415]     Test net output #1: loss = 1.91189 (* 1 = 1.91189 loss)
I0517 17:27:14.216898  4008 solver.cpp:231] Iteration 64000, loss = 1.61917
I0517 17:27:14.217023  4008 solver.cpp:247]     Train net output #0: loss = 1.61917 (* 1 = 1.61917 loss)
I0517 17:27:14.217043  4008 sgd_solver.cpp:106] Iteration 64000, lr = 0.001
I0517 17:27:14.385419  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.36926	0	65.4274	0	75.9776	2.08333	70.2784	0	64.6057	0	54.3701	0	45.716	0	19.5716	0.9	
I0517 17:27:14.459401  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:27:14.460572  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:27:14.460598  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:27:14.470345  4008 solver.cpp:260]     Total regularization terms: 1.37132 loss+regular. : 2.99049
I0517 17:28:42.457237  4008 solver.cpp:231] Iteration 64200, loss = 1.44078
I0517 17:28:42.457706  4008 solver.cpp:247]     Train net output #0: loss = 1.44078 (* 1 = 1.44078 loss)
I0517 17:28:42.457734  4008 sgd_solver.cpp:106] Iteration 64200, lr = 0.001
I0517 17:28:42.617318  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.36065	0	65.5312	0	76.0297	2.08333	70.3437	0	64.6771	0	54.4482	0	45.7843	0	19.5907	0.9	
I0517 17:28:42.691937  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:28:42.693094  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:28:42.693186  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:28:42.703377  4008 solver.cpp:260]     Total regularization terms: 1.37006 loss+regular. : 2.81083
I0517 17:30:07.584959  4008 solver.cpp:231] Iteration 64400, loss = 1.45295
I0517 17:30:07.585363  4008 solver.cpp:247]     Train net output #0: loss = 1.45295 (* 1 = 1.45295 loss)
I0517 17:30:07.585392  4008 sgd_solver.cpp:106] Iteration 64400, lr = 0.001
I0517 17:30:07.746122  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.07082	0	65.5863	0	76.0773	2.08333	70.3939	0	64.7368	0	54.5273	0	45.8531	0	19.6086	0.9	
I0517 17:30:07.820320  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:30:07.821493  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:30:07.821527  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:30:07.841837  4008 solver.cpp:260]     Total regularization terms: 1.3689 loss+regular. : 2.82184
I0517 17:30:33.128846  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:31:27.921988  4008 solver.cpp:231] Iteration 64600, loss = 1.65466
I0517 17:31:27.922255  4008 solver.cpp:247]     Train net output #0: loss = 1.65466 (* 1 = 1.65466 loss)
I0517 17:31:27.922277  4008 sgd_solver.cpp:106] Iteration 64600, lr = 0.001
I0517 17:31:28.083740  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.32909	0	65.5407	0	76.1213	2.08333	70.4597	0	64.7924	0	54.606	0	45.9214	0	19.6285	0.9	
I0517 17:31:28.158017  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:31:28.159180  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:31:28.159221  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:31:28.169016  4008 solver.cpp:260]     Total regularization terms: 1.36767 loss+regular. : 3.02233
I0517 17:32:55.997396  4008 solver.cpp:231] Iteration 64800, loss = 1.55044
I0517 17:32:55.997612  4008 solver.cpp:247]     Train net output #0: loss = 1.55044 (* 1 = 1.55044 loss)
I0517 17:32:55.997637  4008 sgd_solver.cpp:106] Iteration 64800, lr = 0.001
I0517 17:32:56.158336  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.27456	0	65.5641	0	76.1744	2.08333	70.5188	0	64.8548	0	54.6852	0	45.9907	0	19.647	0.9	
I0517 17:32:56.232378  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:32:56.233677  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:32:56.233711  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:32:56.243563  4008 solver.cpp:260]     Total regularization terms: 1.36638 loss+regular. : 2.91682
I0517 17:34:14.170830  4008 solver.cpp:348] Iteration 65000, Testing net (#0)
I0517 17:34:48.048058  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:35:27.493054  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55286
I0517 17:35:27.493371  4008 solver.cpp:415]     Test net output #1: loss = 1.91961 (* 1 = 1.91961 loss)
I0517 17:35:27.582273  4008 solver.cpp:231] Iteration 65000, loss = 1.42279
I0517 17:35:27.582360  4008 solver.cpp:247]     Train net output #0: loss = 1.42279 (* 1 = 1.42279 loss)
I0517 17:35:27.582373  4008 sgd_solver.cpp:106] Iteration 65000, lr = 0.001
I0517 17:35:27.747467  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.17987	0	65.637	0	76.2318	2.08333	70.5967	0	64.924	0	54.7645	0	46.0606	0	19.6659	0.9	
I0517 17:35:27.821480  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:35:27.822360  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:35:27.822394  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:35:27.832226  4008 solver.cpp:260]     Total regularization terms: 1.36521 loss+regular. : 2.788
I0517 17:36:46.318200  4008 solver.cpp:231] Iteration 65200, loss = 1.71856
I0517 17:36:46.318548  4008 solver.cpp:247]     Train net output #0: loss = 1.71856 (* 1 = 1.71856 loss)
I0517 17:36:46.318567  4008 sgd_solver.cpp:106] Iteration 65200, lr = 0.001
I0517 17:36:46.478430  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.32048	0	65.6953	0	76.2551	2.08333	70.6513	0	64.9826	0	54.8432	0	46.1303	0	19.6866	0.9	
I0517 17:36:46.552409  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:36:46.553505  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:36:46.553539  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:36:46.563655  4008 solver.cpp:260]     Total regularization terms: 1.36404 loss+regular. : 3.08261
I0517 17:38:19.727883  4008 solver.cpp:231] Iteration 65400, loss = 1.47751
I0517 17:38:19.728191  4008 solver.cpp:247]     Train net output #0: loss = 1.47751 (* 1 = 1.47751 loss)
I0517 17:38:19.728212  4008 sgd_solver.cpp:106] Iteration 65400, lr = 0.001
I0517 17:38:19.887514  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.61031	0	65.7982	0	76.3119	2.08333	70.7174	0	65.0515	0	54.9226	0	46.1974	0	19.7067	0.9	
I0517 17:38:19.962757  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:38:19.963769  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:38:19.963796  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:38:19.984002  4008 solver.cpp:260]     Total regularization terms: 1.36289 loss+regular. : 2.8404
I0517 17:38:48.763550  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:39:42.988032  4008 solver.cpp:231] Iteration 65600, loss = 1.45402
I0517 17:39:42.988389  4008 solver.cpp:247]     Train net output #0: loss = 1.45402 (* 1 = 1.45402 loss)
I0517 17:39:42.988409  4008 sgd_solver.cpp:106] Iteration 65600, lr = 0.001
I0517 17:39:43.148728  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.58448	0	65.8763	0	76.3711	2.08333	70.7788	0	65.1067	0	54.9998	0	46.2657	0	19.725	0.9	
I0517 17:39:43.222776  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:39:43.223701  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:39:43.223726  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:39:43.233424  4008 solver.cpp:260]     Total regularization terms: 1.36175 loss+regular. : 2.81577
I0517 17:41:10.149293  4008 solver.cpp:231] Iteration 65800, loss = 1.44323
I0517 17:41:10.149606  4008 solver.cpp:247]     Train net output #0: loss = 1.44323 (* 1 = 1.44323 loss)
I0517 17:41:10.149627  4008 sgd_solver.cpp:106] Iteration 65800, lr = 0.001
I0517 17:41:10.309523  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.44961	0	65.9023	0	76.4173	2.08333	70.8356	0	65.1609	0	55.0802	0	46.3347	0	19.7434	0.9	
I0517 17:41:10.383360  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:41:10.384212  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:41:10.384232  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:41:10.394022  4008 solver.cpp:260]     Total regularization terms: 1.36061 loss+regular. : 2.80384
I0517 17:42:44.960443  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_66000.caffemodel
I0517 17:44:57.883491  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_66000.solverstate
I0517 17:44:58.403656  4008 solver.cpp:348] Iteration 66000, Testing net (#0)
I0517 17:45:37.852094  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:46:21.087985  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55286
I0517 17:46:21.088315  4008 solver.cpp:415]     Test net output #1: loss = 1.92178 (* 1 = 1.92178 loss)
I0517 17:46:21.178817  4008 solver.cpp:231] Iteration 66000, loss = 1.64544
I0517 17:46:21.178916  4008 solver.cpp:247]     Train net output #0: loss = 1.64544 (* 1 = 1.64544 loss)
I0517 17:46:21.178933  4008 sgd_solver.cpp:106] Iteration 66000, lr = 0.001
I0517 17:46:21.337625  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.18561	0	66.0104	0	76.4636	2.08333	70.8951	0	65.2224	0	55.1581	0	46.4025	0	19.7621	0.9	
I0517 17:46:21.338343  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:46:21.339375  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:46:21.339399  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:46:21.354796  4008 solver.cpp:260]     Total regularization terms: 1.35935 loss+regular. : 3.00478
I0517 17:47:38.112251  4008 solver.cpp:231] Iteration 66200, loss = 1.63602
I0517 17:47:38.112493  4008 solver.cpp:247]     Train net output #0: loss = 1.63602 (* 1 = 1.63602 loss)
I0517 17:47:38.112514  4008 sgd_solver.cpp:106] Iteration 66200, lr = 0.001
I0517 17:47:38.272984  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.58735	0	66.1331	0	76.5201	2.08333	70.9542	0	65.2803	0	55.237	0	46.4702	0	19.7802	0.9	
I0517 17:47:38.347813  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:47:38.348966  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:47:38.348999  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:47:38.363981  4008 solver.cpp:260]     Total regularization terms: 1.35823 loss+regular. : 2.99425
I0517 17:49:01.197397  4008 solver.cpp:231] Iteration 66400, loss = 1.44798
I0517 17:49:01.201694  4008 solver.cpp:247]     Train net output #0: loss = 1.44798 (* 1 = 1.44798 loss)
I0517 17:49:01.201726  4008 sgd_solver.cpp:106] Iteration 66400, lr = 0.001
I0517 17:49:01.357116  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.47544	0	66.151	0	76.5793	2.08333	71.0199	0	65.3347	0	55.314	0	46.5382	0	19.7992	0.9	
I0517 17:49:01.431044  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:49:01.431820  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:49:01.431848  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:49:01.447105  4008 solver.cpp:260]     Total regularization terms: 1.35713 loss+regular. : 2.8051
I0517 17:49:31.779110  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:50:18.474046  4008 solver.cpp:231] Iteration 66600, loss = 1.41415
I0517 17:50:18.476243  4008 solver.cpp:247]     Train net output #0: loss = 1.41415 (* 1 = 1.41415 loss)
I0517 17:50:18.476267  4008 sgd_solver.cpp:106] Iteration 66600, lr = 0.001
I0517 17:50:18.636754  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.44961	0	66.1787	0	76.6147	2.08333	71.0781	0	65.387	0	55.3921	0	46.6069	0	19.8183	0.9	
I0517 17:50:18.710526  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:50:18.711393  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:50:18.711416  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:50:18.721318  4008 solver.cpp:260]     Total regularization terms: 1.35601 loss+regular. : 2.77016
I0517 17:51:35.406316  4008 solver.cpp:231] Iteration 66800, loss = 1.45029
I0517 17:51:35.406584  4008 solver.cpp:247]     Train net output #0: loss = 1.45029 (* 1 = 1.45029 loss)
I0517 17:51:35.406605  4008 sgd_solver.cpp:106] Iteration 66800, lr = 0.001
I0517 17:51:35.567667  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.53857	0	66.2467	0	76.6764	2.08333	71.1271	0	65.4396	0	55.4695	0	46.6748	0	19.8369	0.9	
I0517 17:51:35.641613  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:51:35.642895  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:51:35.642922  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:51:35.652709  4008 solver.cpp:260]     Total regularization terms: 1.35483 loss+regular. : 2.80511
I0517 17:52:57.311879  4008 solver.cpp:348] Iteration 67000, Testing net (#0)
I0517 17:53:32.360980  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:54:19.522375  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55034
I0517 17:54:19.522713  4008 solver.cpp:415]     Test net output #1: loss = 1.93394 (* 1 = 1.93394 loss)
I0517 17:54:19.612422  4008 solver.cpp:231] Iteration 67000, loss = 1.58251
I0517 17:54:19.612496  4008 solver.cpp:247]     Train net output #0: loss = 1.58251 (* 1 = 1.58251 loss)
I0517 17:54:19.612514  4008 sgd_solver.cpp:106] Iteration 67000, lr = 0.001
I0517 17:54:19.781322  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.53857	0	66.0505	0	76.698	2.08333	71.1843	0	65.4934	0	55.5467	0	46.7424	0	19.855	0.9	
I0517 17:54:19.855478  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:54:19.856719  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:54:19.856741  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:54:19.866505  4008 solver.cpp:260]     Total regularization terms: 1.35368 loss+regular. : 2.93619
I0517 17:55:38.521692  4008 solver.cpp:231] Iteration 67200, loss = 1.43999
I0517 17:55:38.521980  4008 solver.cpp:247]     Train net output #0: loss = 1.43999 (* 1 = 1.43999 loss)
I0517 17:55:38.522002  4008 sgd_solver.cpp:106] Iteration 67200, lr = 0.001
I0517 17:55:38.680855  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.51274	0	66.2604	0	76.7563	2.08333	71.242	0	65.5603	0	55.6237	0	46.8086	0	19.874	0.9	
I0517 17:55:38.754808  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:55:38.755656  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:55:38.755681  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:55:38.765925  4008 solver.cpp:260]     Total regularization terms: 1.3525 loss+regular. : 2.79249
I0517 17:57:03.200744  4008 solver.cpp:231] Iteration 67400, loss = 1.5302
I0517 17:57:03.201057  4008 solver.cpp:247]     Train net output #0: loss = 1.5302 (* 1 = 1.5302 loss)
I0517 17:57:03.201076  4008 sgd_solver.cpp:106] Iteration 67400, lr = 0.001
I0517 17:57:03.363571  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.44961	0	66.278	0	76.7921	2.08333	71.2995	0	65.6214	0	55.6999	0	46.8753	0	19.8938	0.9	
I0517 17:57:03.438362  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:57:03.439599  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:57:03.439620  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:57:03.459863  4008 solver.cpp:260]     Total regularization terms: 1.35133 loss+regular. : 2.88154
I0517 17:57:39.876351  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 17:58:23.260468  4008 solver.cpp:231] Iteration 67600, loss = 1.60304
I0517 17:58:23.260704  4008 solver.cpp:247]     Train net output #0: loss = 1.60304 (* 1 = 1.60304 loss)
I0517 17:58:23.260823  4008 sgd_solver.cpp:106] Iteration 67600, lr = 0.001
I0517 17:58:23.424116  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.46109	0	66.4124	0	76.8624	2.08333	71.3549	0	65.684	0	55.7771	0	46.9412	0	19.9121	0.9	
I0517 17:58:23.498633  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:58:23.499909  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:58:23.499932  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:58:23.515192  4008 solver.cpp:260]     Total regularization terms: 1.35016 loss+regular. : 2.9532
I0517 17:59:40.126014  4008 solver.cpp:231] Iteration 67800, loss = 1.60431
I0517 17:59:40.126410  4008 solver.cpp:247]     Train net output #0: loss = 1.60431 (* 1 = 1.60431 loss)
I0517 17:59:40.126436  4008 sgd_solver.cpp:106] Iteration 67800, lr = 0.001
I0517 17:59:40.289758  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.59596	0	66.3867	0	76.9134	2.08333	71.4078	0	65.7507	0	55.8545	0	47.0074	0	19.9297	0.9	
I0517 17:59:40.363620  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 17:59:40.364691  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 17:59:40.364708  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 17:59:40.374337  4008 solver.cpp:260]     Total regularization terms: 1.34901 loss+regular. : 2.95332
I0517 18:01:03.798665  4008 solver.cpp:348] Iteration 68000, Testing net (#0)
I0517 18:01:41.720716  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:02:20.326315  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55326
I0517 18:02:20.329617  4008 solver.cpp:415]     Test net output #1: loss = 1.91653 (* 1 = 1.91653 loss)
I0517 18:02:20.417419  4008 solver.cpp:231] Iteration 68000, loss = 1.76813
I0517 18:02:20.417507  4008 solver.cpp:247]     Train net output #0: loss = 1.76813 (* 1 = 1.76813 loss)
I0517 18:02:20.417526  4008 sgd_solver.cpp:106] Iteration 68000, lr = 0.001
I0517 18:02:20.578841  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.39222	0	66.4938	0	76.9511	2.08333	71.4536	0	65.809	0	55.9314	0	47.0746	0	19.9471	0.9	
I0517 18:02:20.652876  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:02:20.653954  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	0.9	
I0517 18:02:20.653980  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:02:20.665184  4008 solver.cpp:260]     Total regularization terms: 1.3479 loss+regular. : 3.11603
I0517 18:03:35.941515  4008 solver.cpp:231] Iteration 68200, loss = 1.43354
I0517 18:03:35.942638  4008 solver.cpp:247]     Train net output #0: loss = 1.43354 (* 1 = 1.43354 loss)
I0517 18:03:35.942658  4008 sgd_solver.cpp:106] Iteration 68200, lr = 0.001
I0517 18:03:36.101835  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.58735	0	66.5446	0	76.9956	2.08333	71.5135	0	65.866	0	56.0074	0	47.1404	0	19.9646	1	
I0517 18:03:36.175734  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:03:36.176805  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:03:36.176822  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:03:36.186507  4008 solver.cpp:260]     Total regularization terms: 1.34674 loss+regular. : 2.78029
I0517 18:05:00.737712  4008 solver.cpp:231] Iteration 68400, loss = 1.54128
I0517 18:05:00.740128  4008 solver.cpp:247]     Train net output #0: loss = 1.54128 (* 1 = 1.54128 loss)
I0517 18:05:00.740269  4008 sgd_solver.cpp:106] Iteration 68400, lr = 0.001
I0517 18:05:00.901022  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.64187	0	66.5667	0	77.0426	2.08333	71.5727	0	65.9121	0	56.082	0	47.2072	0	19.9827	1	
I0517 18:05:00.977318  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:05:00.978428  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:05:00.978452  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:05:00.988260  4008 solver.cpp:260]     Total regularization terms: 1.34564 loss+regular. : 2.88692
I0517 18:05:35.386435  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:06:22.992723  4008 solver.cpp:231] Iteration 68600, loss = 1.56252
I0517 18:06:22.993118  4008 solver.cpp:247]     Train net output #0: loss = 1.56252 (* 1 = 1.56252 loss)
I0517 18:06:22.993146  4008 sgd_solver.cpp:106] Iteration 68600, lr = 0.001
I0517 18:06:23.153229  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.46109	0	66.5091	0	77.0796	2.08333	71.6313	0	65.9571	0	56.1574	0	47.2738	0	20.0011	1	
I0517 18:06:23.226969  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:06:23.228066  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:06:23.228091  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:06:23.237836  4008 solver.cpp:260]     Total regularization terms: 1.34445 loss+regular. : 2.90698
I0517 18:07:37.884390  4008 solver.cpp:231] Iteration 68800, loss = 1.47652
I0517 18:07:37.884693  4008 solver.cpp:247]     Train net output #0: loss = 1.47652 (* 1 = 1.47652 loss)
I0517 18:07:37.884714  4008 sgd_solver.cpp:106] Iteration 68800, lr = 0.001
I0517 18:07:38.047404  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.67631	0	66.6393	0	77.1372	2.08333	71.6893	0	66.0276	0	56.2322	0	47.3397	0	20.0188	1	
I0517 18:07:38.122045  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:07:38.122989  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:07:38.123009  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:07:38.138031  4008 solver.cpp:260]     Total regularization terms: 1.34338 loss+regular. : 2.8199
I0517 18:08:55.960019  4008 solver.cpp:348] Iteration 69000, Testing net (#0)
I0517 18:09:36.629602  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:10:12.838758  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55282
I0517 18:10:12.839061  4008 solver.cpp:415]     Test net output #1: loss = 1.91281 (* 1 = 1.91281 loss)
I0517 18:10:12.926496  4008 solver.cpp:231] Iteration 69000, loss = 1.45712
I0517 18:10:12.926594  4008 solver.cpp:247]     Train net output #0: loss = 1.45712 (* 1 = 1.45712 loss)
I0517 18:10:12.926612  4008 sgd_solver.cpp:106] Iteration 69000, lr = 0.001
I0517 18:10:13.091941  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.61605	0	66.7773	0	77.1917	2.08333	71.7364	0	66.0778	0	56.3076	0	47.4052	0	20.0372	1	
I0517 18:10:13.166118  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:10:13.167166  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:10:13.167187  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:10:13.178118  4008 solver.cpp:260]     Total regularization terms: 1.34219 loss+regular. : 2.79931
I0517 18:11:28.769187  4008 solver.cpp:231] Iteration 69200, loss = 1.32905
I0517 18:11:28.769404  4008 solver.cpp:247]     Train net output #0: loss = 1.32905 (* 1 = 1.32905 loss)
I0517 18:11:28.769423  4008 sgd_solver.cpp:106] Iteration 69200, lr = 0.001
I0517 18:11:28.930760  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.59883	0	66.7998	0	77.2302	2.08333	71.7891	0	66.144	0	56.382	0	47.4705	0	20.0547	1	
I0517 18:11:29.005177  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:11:29.005862  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:11:29.005878  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:11:29.019076  4008 solver.cpp:260]     Total regularization terms: 1.34111 loss+regular. : 2.67016
I0517 18:12:47.075650  4008 solver.cpp:231] Iteration 69400, loss = 1.39359
I0517 18:12:47.075896  4008 solver.cpp:247]     Train net output #0: loss = 1.39359 (* 1 = 1.39359 loss)
I0517 18:12:47.076030  4008 sgd_solver.cpp:106] Iteration 69400, lr = 0.001
I0517 18:12:47.236935  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.49552	0	66.7477	0	77.289	2.08333	71.8461	0	66.2057	0	56.4563	0	47.5361	0	20.0733	1	
I0517 18:12:47.311072  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:12:47.312538  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:12:47.312568  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:12:47.322623  4008 solver.cpp:260]     Total regularization terms: 1.34 loss+regular. : 2.73359
I0517 18:13:33.644397  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:14:19.336642  4008 solver.cpp:231] Iteration 69600, loss = 1.50618
I0517 18:14:19.336947  4008 solver.cpp:247]     Train net output #0: loss = 1.50618 (* 1 = 1.50618 loss)
I0517 18:14:19.336966  4008 sgd_solver.cpp:106] Iteration 69600, lr = 0.001
I0517 18:14:19.497112  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.45535	0	66.9066	0	77.3417	2.08333	71.8886	0	66.267	0	56.5296	0	47.6016	0	20.0914	1	
I0517 18:14:19.573642  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:14:19.574720  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:14:19.574741  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:14:19.589743  4008 solver.cpp:260]     Total regularization terms: 1.3389 loss+regular. : 2.84508
I0517 18:15:36.135865  4008 solver.cpp:231] Iteration 69800, loss = 1.68498
I0517 18:15:36.136196  4008 solver.cpp:247]     Train net output #0: loss = 1.68498 (* 1 = 1.68498 loss)
I0517 18:15:36.136219  4008 sgd_solver.cpp:106] Iteration 69800, lr = 0.001
I0517 18:15:36.296906  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.42665	0	66.9411	0	77.3841	2.08333	71.954	0	66.3246	0	56.604	0	47.6673	0	20.1101	1	
I0517 18:15:36.371883  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:15:36.372931  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:15:36.372952  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:15:36.395464  4008 solver.cpp:260]     Total regularization terms: 1.33776 loss+regular. : 3.02274
I0517 18:16:51.785688  4008 solver.cpp:348] Iteration 70000, Testing net (#0)
I0517 18:17:31.402189  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:18:07.978587  4008 solver.cpp:415]     Test net output #0: accuracy = 0.553719
I0517 18:18:07.978906  4008 solver.cpp:415]     Test net output #1: loss = 1.91785 (* 1 = 1.91785 loss)
I0517 18:18:08.069120  4008 solver.cpp:231] Iteration 70000, loss = 1.62086
I0517 18:18:08.069222  4008 solver.cpp:247]     Train net output #0: loss = 1.62086 (* 1 = 1.62086 loss)
I0517 18:18:08.073633  4008 sgd_solver.cpp:106] Iteration 70000, lr = 0.001
I0517 18:18:08.234241  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.55865	0	67.0872	0	77.4299	2.08333	72.0007	0	66.3775	0	56.6778	0	47.7319	0	20.1269	1	
I0517 18:18:08.308513  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:18:08.309461  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:18:08.309484  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:18:08.319377  4008 solver.cpp:260]     Total regularization terms: 1.33665 loss+regular. : 2.95752
I0517 18:19:26.724381  4008 solver.cpp:231] Iteration 70200, loss = 1.41148
I0517 18:19:26.724716  4008 solver.cpp:247]     Train net output #0: loss = 1.41148 (* 1 = 1.41148 loss)
I0517 18:19:26.724732  4008 sgd_solver.cpp:106] Iteration 70200, lr = 0.001
I0517 18:19:26.885426  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.40083	0	66.9173	0	77.4733	2.08333	72.0509	0	66.4318	0	56.7512	0	47.7976	0	20.144	1	
I0517 18:19:26.959004  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:19:26.959810  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:19:26.959830  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:19:26.969475  4008 solver.cpp:260]     Total regularization terms: 1.33557 loss+regular. : 2.74705
I0517 18:20:54.137087  4008 solver.cpp:231] Iteration 70400, loss = 1.52824
I0517 18:20:54.141634  4008 solver.cpp:247]     Train net output #0: loss = 1.52824 (* 1 = 1.52824 loss)
I0517 18:20:54.141660  4008 sgd_solver.cpp:106] Iteration 70400, lr = 0.001
I0517 18:20:54.297335  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.46683	0	66.9134	0	77.5255	2.08333	72.0985	0	66.4933	0	56.8251	0	47.8626	0	20.1616	1	
I0517 18:20:54.371073  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:20:54.371978  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:20:54.372000  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:20:54.381739  4008 solver.cpp:260]     Total regularization terms: 1.33453 loss+regular. : 2.86277
I0517 18:21:40.802623  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:22:21.669070  4008 solver.cpp:231] Iteration 70600, loss = 1.51869
I0517 18:22:21.669333  4008 solver.cpp:247]     Train net output #0: loss = 1.51869 (* 1 = 1.51869 loss)
I0517 18:22:21.669354  4008 sgd_solver.cpp:106] Iteration 70600, lr = 0.001
I0517 18:22:21.829505  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.15978	0	67.1396	0	77.5771	2.08333	72.1708	0	66.5448	0	56.8985	0	47.9266	0	20.1791	1	
I0517 18:22:21.903506  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:22:21.904803  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:22:21.904820  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:22:21.914681  4008 solver.cpp:260]     Total regularization terms: 1.33348 loss+regular. : 2.85217
I0517 18:23:50.043823  4008 solver.cpp:231] Iteration 70800, loss = 1.62416
I0517 18:23:50.044140  4008 solver.cpp:247]     Train net output #0: loss = 1.62416 (* 1 = 1.62416 loss)
I0517 18:23:50.044167  4008 sgd_solver.cpp:106] Iteration 70800, lr = 0.001
I0517 18:23:50.205592  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.54718	0	67.1624	0	77.6196	2.08333	72.2224	0	66.6027	0	56.9719	0	47.9911	0	20.1964	1	
I0517 18:23:50.280139  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:23:50.281337  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:23:50.281373  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:23:50.291118  4008 solver.cpp:260]     Total regularization terms: 1.33242 loss+regular. : 2.95658
I0517 18:25:11.889477  4008 solver.cpp:348] Iteration 71000, Testing net (#0)
I0517 18:25:51.089212  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:26:29.920166  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55298
I0517 18:26:29.920452  4008 solver.cpp:415]     Test net output #1: loss = 1.92505 (* 1 = 1.92505 loss)
I0517 18:26:30.012004  4008 solver.cpp:231] Iteration 71000, loss = 1.36554
I0517 18:26:30.012133  4008 solver.cpp:247]     Train net output #0: loss = 1.36554 (* 1 = 1.36554 loss)
I0517 18:26:30.012156  4008 sgd_solver.cpp:106] Iteration 71000, lr = 0.001
I0517 18:26:30.180800  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.51848	0	67.1139	0	77.6597	2.08333	72.2723	0	66.647	0	57.0446	0	48.0556	0	20.2138	1	
I0517 18:26:30.254585  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:26:30.255560  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:26:30.255581  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:26:30.270983  4008 solver.cpp:260]     Total regularization terms: 1.33143 loss+regular. : 2.69697
I0517 18:27:50.562908  4008 solver.cpp:231] Iteration 71200, loss = 1.45557
I0517 18:27:50.563174  4008 solver.cpp:247]     Train net output #0: loss = 1.45557 (* 1 = 1.45557 loss)
I0517 18:27:50.563191  4008 sgd_solver.cpp:106] Iteration 71200, lr = 0.001
I0517 18:27:50.724251  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.59596	0	67.2253	0	77.6681	2.08333	72.3167	0	66.7053	0	57.1176	0	48.1199	0	20.2318	1	
I0517 18:27:50.798336  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:27:50.799201  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:27:50.799217  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:27:50.809015  4008 solver.cpp:260]     Total regularization terms: 1.33046 loss+regular. : 2.78603
I0517 18:29:09.122958  4008 solver.cpp:231] Iteration 71400, loss = 1.54941
I0517 18:29:09.125651  4008 solver.cpp:247]     Train net output #0: loss = 1.54941 (* 1 = 1.54941 loss)
I0517 18:29:09.125677  4008 sgd_solver.cpp:106] Iteration 71400, lr = 0.001
I0517 18:29:09.285581  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.4697	0	67.3623	0	77.7364	2.08333	72.3702	0	66.7564	0	57.1898	0	48.1836	0	20.2499	1	
I0517 18:29:09.360323  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:29:09.361407  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:29:09.361434  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:29:09.382705  4008 solver.cpp:260]     Total regularization terms: 1.32938 loss+regular. : 2.87879
I0517 18:29:51.139081  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:30:26.900355  4008 solver.cpp:231] Iteration 71600, loss = 1.75163
I0517 18:30:26.900594  4008 solver.cpp:247]     Train net output #0: loss = 1.75163 (* 1 = 1.75163 loss)
I0517 18:30:26.900612  4008 sgd_solver.cpp:106] Iteration 71600, lr = 0.001
I0517 18:30:27.060403  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.52709	0	67.334	0	77.7745	2.08333	72.4192	0	66.8147	0	57.2623	0	48.2467	0	20.2664	1	
I0517 18:30:27.135182  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:30:27.136225  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:30:27.136255  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:30:27.151242  4008 solver.cpp:260]     Total regularization terms: 1.32829 loss+regular. : 3.07993
I0517 18:31:45.535287  4008 solver.cpp:231] Iteration 71800, loss = 1.46878
I0517 18:31:45.535580  4008 solver.cpp:247]     Train net output #0: loss = 1.46878 (* 1 = 1.46878 loss)
I0517 18:31:45.535601  4008 sgd_solver.cpp:106] Iteration 71800, lr = 0.001
I0517 18:31:45.695294  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.64761	0	67.3503	0	77.8232	2.08333	72.4736	0	66.8683	0	57.3351	0	48.3111	0	20.2838	1	
I0517 18:31:45.769029  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:31:45.770042  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:31:45.770072  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:31:45.779950  4008 solver.cpp:260]     Total regularization terms: 1.32727 loss+regular. : 2.79605
I0517 18:33:02.688751  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_72000.caffemodel
I0517 18:34:43.788035  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_72000.solverstate
I0517 18:34:44.553181  4008 solver.cpp:348] Iteration 72000, Testing net (#0)
I0517 18:35:27.254942  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:36:06.712060  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5535
I0517 18:36:06.712416  4008 solver.cpp:415]     Test net output #1: loss = 1.92294 (* 1 = 1.92294 loss)
I0517 18:36:06.800722  4008 solver.cpp:231] Iteration 72000, loss = 1.44734
I0517 18:36:06.800798  4008 solver.cpp:247]     Train net output #0: loss = 1.44734 (* 1 = 1.44734 loss)
I0517 18:36:06.800837  4008 sgd_solver.cpp:106] Iteration 72000, lr = 0.001
I0517 18:36:06.965880  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.62753	0	67.3512	0	77.874	2.08333	72.519	0	66.9165	0	57.4074	0	48.3745	0	20.3002	1	
I0517 18:36:06.966625  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:36:06.967490  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:36:06.967507  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:36:06.977219  4008 solver.cpp:260]     Total regularization terms: 1.32629 loss+regular. : 2.77364
I0517 18:37:27.402662  4008 solver.cpp:231] Iteration 72200, loss = 1.38839
I0517 18:37:27.403152  4008 solver.cpp:247]     Train net output #0: loss = 1.38839 (* 1 = 1.38839 loss)
I0517 18:37:27.403177  4008 sgd_solver.cpp:106] Iteration 72200, lr = 0.001
I0517 18:37:27.565788  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.44961	0	67.4788	0	77.9235	2.08333	72.5779	0	66.9825	0	57.4789	0	48.4374	0	20.3179	1	
I0517 18:37:27.641613  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:37:27.642654  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:37:27.642689  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:37:27.657446  4008 solver.cpp:260]     Total regularization terms: 1.32517 loss+regular. : 2.71356
I0517 18:38:48.509960  4008 solver.cpp:231] Iteration 72400, loss = 1.40399
I0517 18:38:48.510181  4008 solver.cpp:247]     Train net output #0: loss = 1.40399 (* 1 = 1.40399 loss)
I0517 18:38:48.510196  4008 sgd_solver.cpp:106] Iteration 72400, lr = 0.001
I0517 18:38:48.670657  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.74805	0	67.4128	0	77.9499	2.08333	72.6044	0	67.0241	0	57.5498	0	48.5008	0	20.335	1	
I0517 18:38:48.745357  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:38:48.746245  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:38:48.746273  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:38:48.760093  4008 solver.cpp:260]     Total regularization terms: 1.32422 loss+regular. : 2.72822
I0517 18:39:34.808421  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:40:09.334278  4008 solver.cpp:231] Iteration 72600, loss = 1.52213
I0517 18:40:09.334539  4008 solver.cpp:247]     Train net output #0: loss = 1.52213 (* 1 = 1.52213 loss)
I0517 18:40:09.334683  4008 sgd_solver.cpp:106] Iteration 72600, lr = 0.001
I0517 18:40:09.495292  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.71935	0	67.4342	0	78.003	2.08333	72.6617	0	67.0817	0	57.6209	0	48.564	0	20.3514	1	
I0517 18:40:09.569264  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:40:09.570493  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:40:09.570538  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:40:09.580534  4008 solver.cpp:260]     Total regularization terms: 1.32309 loss+regular. : 2.84522
I0517 18:41:27.962508  4008 solver.cpp:231] Iteration 72800, loss = 1.42931
I0517 18:41:27.962801  4008 solver.cpp:247]     Train net output #0: loss = 1.42931 (* 1 = 1.42931 loss)
I0517 18:41:27.962821  4008 sgd_solver.cpp:106] Iteration 72800, lr = 0.001
I0517 18:41:28.124729  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.59883	0	67.4896	0	78.0616	2.08333	72.7191	0	67.1387	0	57.6916	0	48.6265	0	20.3675	1	
I0517 18:41:28.199386  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:41:28.200376  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:41:28.200402  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:41:28.215540  4008 solver.cpp:260]     Total regularization terms: 1.32203 loss+regular. : 2.75135
I0517 18:42:49.371013  4008 solver.cpp:348] Iteration 73000, Testing net (#0)
I0517 18:43:28.258543  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:44:03.595980  4008 solver.cpp:415]     Test net output #0: accuracy = 0.554479
I0517 18:44:03.596318  4008 solver.cpp:415]     Test net output #1: loss = 1.91977 (* 1 = 1.91977 loss)
I0517 18:44:03.685027  4008 solver.cpp:231] Iteration 73000, loss = 1.41982
I0517 18:44:03.685111  4008 solver.cpp:247]     Train net output #0: loss = 1.41982 (* 1 = 1.41982 loss)
I0517 18:44:03.685129  4008 sgd_solver.cpp:106] Iteration 73000, lr = 0.001
I0517 18:44:03.850827  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.74231	0	67.6019	0	78.0875	2.08333	72.7672	0	67.1647	0	57.7636	0	48.6895	0	20.3856	1	
I0517 18:44:03.924872  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:44:03.926048  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:44:03.926086  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:44:03.936187  4008 solver.cpp:260]     Total regularization terms: 1.321 loss+regular. : 2.74082
I0517 18:45:19.761713  4008 solver.cpp:231] Iteration 73200, loss = 1.35198
I0517 18:45:19.762079  4008 solver.cpp:247]     Train net output #0: loss = 1.35198 (* 1 = 1.35198 loss)
I0517 18:45:19.762102  4008 sgd_solver.cpp:106] Iteration 73200, lr = 0.001
I0517 18:45:19.922619  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.77961	0	67.6846	0	78.143	2.08333	72.825	0	67.2273	0	57.8347	0	48.7519	0	20.4019	1	
I0517 18:45:19.996497  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:45:19.997701  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:45:19.997750  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:45:20.007824  4008 solver.cpp:260]     Total regularization terms: 1.32003 loss+regular. : 2.67201
I0517 18:46:37.692350  4008 solver.cpp:231] Iteration 73400, loss = 1.42937
I0517 18:46:37.692615  4008 solver.cpp:247]     Train net output #0: loss = 1.42937 (* 1 = 1.42937 loss)
I0517 18:46:37.692634  4008 sgd_solver.cpp:106] Iteration 73400, lr = 0.001
I0517 18:46:37.852680  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.6677	0	67.7871	0	78.1741	2.08333	72.8739	0	67.27	0	57.9052	0	48.8149	0	20.4202	1	
I0517 18:46:37.927566  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:46:37.928644  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:46:37.928665  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:46:37.958490  4008 solver.cpp:260]     Total regularization terms: 1.31898 loss+regular. : 2.74836
I0517 18:47:31.635804  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:48:02.646481  4008 solver.cpp:231] Iteration 73600, loss = 1.4852
I0517 18:48:02.646816  4008 solver.cpp:247]     Train net output #0: loss = 1.4852 (* 1 = 1.4852 loss)
I0517 18:48:02.646847  4008 sgd_solver.cpp:106] Iteration 73600, lr = 0.001
I0517 18:48:02.806691  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.65335	0	67.7949	0	78.2198	2.08333	72.9245	0	67.339	0	57.9762	0	48.8766	0	20.4364	1	
I0517 18:48:02.880719  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:48:02.882122  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:48:02.882156  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:48:02.892024  4008 solver.cpp:260]     Total regularization terms: 1.31795 loss+regular. : 2.80315
I0517 18:49:23.156090  4008 solver.cpp:231] Iteration 73800, loss = 1.63778
I0517 18:49:23.157649  4008 solver.cpp:247]     Train net output #0: loss = 1.63778 (* 1 = 1.63778 loss)
I0517 18:49:23.157691  4008 sgd_solver.cpp:106] Iteration 73800, lr = 0.001
I0517 18:49:23.317191  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.74231	0	67.6852	0	78.2528	2.08333	72.9638	0	67.3844	0	58.0466	0	48.9394	0	20.4542	1	
I0517 18:49:23.395134  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:49:23.395969  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:49:23.395992  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:49:23.410641  4008 solver.cpp:260]     Total regularization terms: 1.31696 loss+regular. : 2.95474
I0517 18:50:46.222833  4008 solver.cpp:348] Iteration 74000, Testing net (#0)
I0517 18:51:29.935894  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:52:10.034257  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55168
I0517 18:52:10.034576  4008 solver.cpp:415]     Test net output #1: loss = 1.91872 (* 1 = 1.91872 loss)
I0517 18:52:10.124584  4008 solver.cpp:231] Iteration 74000, loss = 1.54192
I0517 18:52:10.124678  4008 solver.cpp:247]     Train net output #0: loss = 1.54192 (* 1 = 1.54192 loss)
I0517 18:52:10.124697  4008 sgd_solver.cpp:106] Iteration 74000, lr = 0.001
I0517 18:52:10.294757  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.67631	0	67.9427	0	78.3003	2.08333	73.017	0	67.4348	0	58.1164	0	49.0023	0	20.4705	1	
I0517 18:52:10.368558  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:52:10.369710  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:52:10.369734  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:52:10.379513  4008 solver.cpp:260]     Total regularization terms: 1.31588 loss+regular. : 2.85779
I0517 18:53:32.309463  4008 solver.cpp:231] Iteration 74200, loss = 1.32711
I0517 18:53:32.309907  4008 solver.cpp:247]     Train net output #0: loss = 1.32711 (* 1 = 1.32711 loss)
I0517 18:53:32.309937  4008 sgd_solver.cpp:106] Iteration 74200, lr = 0.001
I0517 18:53:32.470337  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.71074	0	67.818	0	78.329	2.08333	73.0577	0	67.4705	0	58.1858	0	49.0643	0	20.4873	1	
I0517 18:53:32.545265  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:53:32.546272  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:53:32.546309  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:53:32.561529  4008 solver.cpp:260]     Total regularization terms: 1.31493 loss+regular. : 2.64204
I0517 18:54:58.928189  4008 solver.cpp:231] Iteration 74400, loss = 1.35843
I0517 18:54:58.929806  4008 solver.cpp:247]     Train net output #0: loss = 1.35843 (* 1 = 1.35843 loss)
I0517 18:54:58.929831  4008 sgd_solver.cpp:106] Iteration 74400, lr = 0.001
I0517 18:54:59.091603  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.59596	0	67.8073	0	78.3868	2.08333	73.1088	0	67.5268	0	58.2558	0	49.1264	0	20.5049	1	
I0517 18:54:59.165437  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:54:59.166538  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.08333	0	0	0	0	0	0	0	0	0	1	
I0517 18:54:59.166579  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:54:59.176389  4008 solver.cpp:260]     Total regularization terms: 1.31391 loss+regular. : 2.67234
I0517 18:55:57.351364  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 18:56:28.838933  4008 solver.cpp:231] Iteration 74600, loss = 1.57552
I0517 18:56:28.839571  4008 solver.cpp:247]     Train net output #0: loss = 1.57552 (* 1 = 1.57552 loss)
I0517 18:56:28.839592  4008 sgd_solver.cpp:106] Iteration 74600, lr = 0.001
I0517 18:56:28.999482  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.46683	0	67.8044	0	78.402	2.34375	73.1561	0	67.5734	0	58.3242	0	49.1881	0	20.5219	1	
I0517 18:56:29.073328  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:56:29.074440  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 18:56:29.074465  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:56:29.084142  4008 solver.cpp:260]     Total regularization terms: 1.31297 loss+regular. : 2.88849
I0517 18:57:58.479617  4008 solver.cpp:231] Iteration 74800, loss = 1.33172
I0517 18:57:58.480200  4008 solver.cpp:247]     Train net output #0: loss = 1.33172 (* 1 = 1.33172 loss)
I0517 18:57:58.480217  4008 sgd_solver.cpp:106] Iteration 74800, lr = 0.001
I0517 18:57:58.640842  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.67631	0	67.9531	0	78.4619	2.34375	73.2095	0	67.6335	0	58.3922	0	49.2509	0	20.5383	1	
I0517 18:57:58.714694  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 18:57:58.715735  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 18:57:58.715764  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 18:57:58.725570  4008 solver.cpp:260]     Total regularization terms: 1.31193 loss+regular. : 2.64365
I0517 18:59:27.266832  4008 solver.cpp:348] Iteration 75000, Testing net (#0)
I0517 19:00:10.417170  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:00:47.329023  4008 solver.cpp:415]     Test net output #0: accuracy = 0.552859
I0517 19:00:47.329322  4008 solver.cpp:415]     Test net output #1: loss = 1.91726 (* 1 = 1.91726 loss)
I0517 19:00:47.416934  4008 solver.cpp:231] Iteration 75000, loss = 1.49083
I0517 19:00:47.417029  4008 solver.cpp:247]     Train net output #0: loss = 1.49083 (* 1 = 1.49083 loss)
I0517 19:00:47.417049  4008 sgd_solver.cpp:106] Iteration 75000, lr = 0.001
I0517 19:00:47.583454  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.54718	0	68.0218	0	78.5034	2.34375	73.2526	0	67.6787	0	58.462	0	49.3127	0	20.5555	1	
I0517 19:00:47.657171  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:00:47.657974  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:00:47.657994  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:00:47.667600  4008 solver.cpp:260]     Total regularization terms: 1.31093 loss+regular. : 2.80176
I0517 19:02:04.574779  4008 solver.cpp:231] Iteration 75200, loss = 1.41114
I0517 19:02:04.575011  4008 solver.cpp:247]     Train net output #0: loss = 1.41114 (* 1 = 1.41114 loss)
I0517 19:02:04.575039  4008 sgd_solver.cpp:106] Iteration 75200, lr = 0.001
I0517 19:02:04.735772  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.80544	0	67.7806	0	78.5314	2.34375	73.3017	0	67.7212	0	58.5314	0	49.374	0	20.5725	1	
I0517 19:02:04.810387  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:02:04.811202  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:02:04.811219  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:02:04.826197  4008 solver.cpp:260]     Total regularization terms: 1.31004 loss+regular. : 2.72117
I0517 19:03:28.462116  4008 solver.cpp:231] Iteration 75400, loss = 1.3941
I0517 19:03:28.462330  4008 solver.cpp:247]     Train net output #0: loss = 1.3941 (* 1 = 1.3941 loss)
I0517 19:03:28.462349  4008 sgd_solver.cpp:106] Iteration 75400, lr = 0.001
I0517 19:03:28.621990  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.74231	0	68.0508	0	78.5707	2.34375	73.3539	0	67.7723	0	58.5993	0	49.4355	0	20.5883	1	
I0517 19:03:28.696652  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:03:28.697803  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:03:28.697837  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:03:28.716475  4008 solver.cpp:260]     Total regularization terms: 1.30915 loss+regular. : 2.70325
I0517 19:04:28.907742  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:04:54.156437  4008 solver.cpp:231] Iteration 75600, loss = 1.7348
I0517 19:04:54.156528  4008 solver.cpp:247]     Train net output #0: loss = 1.7348 (* 1 = 1.7348 loss)
I0517 19:04:54.156544  4008 sgd_solver.cpp:106] Iteration 75600, lr = 0.001
I0517 19:04:54.317133  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.79109	0	67.9863	0	78.6177	2.34375	73.3945	0	67.8175	0	58.6678	0	49.4974	0	20.6062	1	
I0517 19:04:54.391013  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:04:54.391964  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:04:54.391984  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:04:54.402376  4008 solver.cpp:260]     Total regularization terms: 1.30825 loss+regular. : 3.04305
I0517 19:06:27.098366  4008 solver.cpp:231] Iteration 75800, loss = 1.46136
I0517 19:06:27.098592  4008 solver.cpp:247]     Train net output #0: loss = 1.46136 (* 1 = 1.46136 loss)
I0517 19:06:27.098611  4008 sgd_solver.cpp:106] Iteration 75800, lr = 0.001
I0517 19:06:27.258358  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.95466	0	68.1735	0	78.6669	2.34375	73.4396	0	67.8817	0	58.7361	0	49.5576	0	20.6237	1	
I0517 19:06:27.333194  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:06:27.334453  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:06:27.334489  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:06:27.349647  4008 solver.cpp:260]     Total regularization terms: 1.30722 loss+regular. : 2.76858
I0517 19:07:51.115398  4008 solver.cpp:348] Iteration 76000, Testing net (#0)
I0517 19:08:37.380198  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:09:14.011168  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5515
I0517 19:09:14.011427  4008 solver.cpp:415]     Test net output #1: loss = 1.9253 (* 1 = 1.9253 loss)
I0517 19:09:14.100365  4008 solver.cpp:231] Iteration 76000, loss = 1.52136
I0517 19:09:14.100455  4008 solver.cpp:247]     Train net output #0: loss = 1.52136 (* 1 = 1.52136 loss)
I0517 19:09:14.100472  4008 sgd_solver.cpp:106] Iteration 76000, lr = 0.001
I0517 19:09:14.260881  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.69927	0	68.2415	0	78.6863	2.34375	73.4749	0	67.9292	0	58.804	0	49.6184	0	20.6399	1	
I0517 19:09:14.336473  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:09:14.337364  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:09:14.337396  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:09:14.347307  4008 solver.cpp:260]     Total regularization terms: 1.30623 loss+regular. : 2.82759
I0517 19:10:38.062237  4008 solver.cpp:231] Iteration 76200, loss = 1.48905
I0517 19:10:38.062605  4008 solver.cpp:247]     Train net output #0: loss = 1.48905 (* 1 = 1.48905 loss)
I0517 19:10:38.062628  4008 sgd_solver.cpp:106] Iteration 76200, lr = 0.001
I0517 19:10:38.222975  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.65622	0	68.2783	0	78.7376	2.34375	73.5184	0	67.9586	0	58.8723	0	49.6796	0	20.6575	1	
I0517 19:10:38.297371  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:10:38.298532  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:10:38.298569  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:10:38.319214  4008 solver.cpp:260]     Total regularization terms: 1.30536 loss+regular. : 2.7944
I0517 19:12:06.296265  4008 solver.cpp:231] Iteration 76400, loss = 1.41603
I0517 19:12:06.297642  4008 solver.cpp:247]     Train net output #0: loss = 1.41603 (* 1 = 1.41603 loss)
I0517 19:12:06.297674  4008 sgd_solver.cpp:106] Iteration 76400, lr = 0.001
I0517 19:12:06.457273  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.81979	0	68.3076	0	78.776	2.34375	73.5683	0	68.0133	0	58.94	0	49.7416	0	20.6733	1	
I0517 19:12:06.531417  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:12:06.532594  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:12:06.532637  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:12:06.545020  4008 solver.cpp:260]     Total regularization terms: 1.30442 loss+regular. : 2.72045
I0517 19:13:03.316260  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:13:24.961937  4008 solver.cpp:231] Iteration 76600, loss = 1.35104
I0517 19:13:24.962038  4008 solver.cpp:247]     Train net output #0: loss = 1.35104 (* 1 = 1.35104 loss)
I0517 19:13:24.962060  4008 sgd_solver.cpp:106] Iteration 76600, lr = 0.001
I0517 19:13:25.121975  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.81405	0	68.152	0	78.8235	2.34375	73.6218	0	68.0653	0	59.0075	0	49.803	0	20.6897	1	
I0517 19:13:25.196562  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:13:25.198017  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:13:25.198050  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:13:25.207840  4008 solver.cpp:260]     Total regularization terms: 1.30348 loss+regular. : 2.65451
I0517 19:14:46.722410  4008 solver.cpp:231] Iteration 76800, loss = 1.47755
I0517 19:14:46.722623  4008 solver.cpp:247]     Train net output #0: loss = 1.47755 (* 1 = 1.47755 loss)
I0517 19:14:46.722650  4008 sgd_solver.cpp:106] Iteration 76800, lr = 0.001
I0517 19:14:46.883270  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.8284	0	68.4219	0	78.8466	2.34375	73.6642	0	68.1166	0	59.0748	0	49.8633	0	20.7049	1	
I0517 19:14:46.957397  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:14:46.958739  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:14:46.958784  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:14:46.968860  4008 solver.cpp:260]     Total regularization terms: 1.30257 loss+regular. : 2.78012
I0517 19:16:14.489850  4008 solver.cpp:348] Iteration 77000, Testing net (#0)
I0517 19:17:10.546914  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:17:49.902546  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55194
I0517 19:17:49.902773  4008 solver.cpp:415]     Test net output #1: loss = 1.92919 (* 1 = 1.92919 loss)
I0517 19:17:49.991605  4008 solver.cpp:231] Iteration 77000, loss = 1.30101
I0517 19:17:49.991690  4008 solver.cpp:247]     Train net output #0: loss = 1.30101 (* 1 = 1.30101 loss)
I0517 19:17:49.991708  4008 sgd_solver.cpp:106] Iteration 77000, lr = 0.001
I0517 19:17:50.157971  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.81118	0	68.2952	0	78.8726	2.34375	73.7059	0	68.1582	0	59.1414	0	49.9237	0	20.721	1	
I0517 19:17:50.232266  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:17:50.233269  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:17:50.233304  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:17:50.243266  4008 solver.cpp:260]     Total regularization terms: 1.3017 loss+regular. : 2.60271
I0517 19:19:03.097466  4008 solver.cpp:231] Iteration 77200, loss = 1.46252
I0517 19:19:03.097781  4008 solver.cpp:247]     Train net output #0: loss = 1.46252 (* 1 = 1.46252 loss)
I0517 19:19:03.097856  4008 sgd_solver.cpp:106] Iteration 77200, lr = 0.001
I0517 19:19:03.259873  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.71361	0	68.3691	0	78.9346	2.34375	73.7571	0	68.2115	0	59.2078	0	49.9834	0	20.7378	1	
I0517 19:19:03.334794  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:19:03.335829  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:19:03.335861  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:19:03.356974  4008 solver.cpp:260]     Total regularization terms: 1.30075 loss+regular. : 2.76328
I0517 19:20:20.771235  4008 solver.cpp:231] Iteration 77400, loss = 1.51987
I0517 19:20:20.771630  4008 solver.cpp:247]     Train net output #0: loss = 1.51987 (* 1 = 1.51987 loss)
I0517 19:20:20.771649  4008 sgd_solver.cpp:106] Iteration 77400, lr = 0.001
I0517 19:20:20.933619  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.90588	0	68.5462	0	78.9689	2.34375	73.7999	0	68.2567	0	59.2738	0	50.0426	0	20.7529	1	
I0517 19:20:21.008435  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:20:21.009655  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:20:21.009685  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:20:21.030448  4008 solver.cpp:260]     Total regularization terms: 1.29978 loss+regular. : 2.81965
I0517 19:21:18.057633  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:21:35.794114  4008 solver.cpp:231] Iteration 77600, loss = 1.41533
I0517 19:21:35.794232  4008 solver.cpp:247]     Train net output #0: loss = 1.41533 (* 1 = 1.41533 loss)
I0517 19:21:35.794252  4008 sgd_solver.cpp:106] Iteration 77600, lr = 0.001
I0517 19:21:35.956817  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.85135	0	68.6003	0	78.9811	2.34375	73.8408	0	68.2938	0	59.3399	0	50.1026	0	20.7698	1	
I0517 19:21:36.030923  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:21:36.032480  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:21:36.032526  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:21:36.048939  4008 solver.cpp:260]     Total regularization terms: 1.29887 loss+regular. : 2.71421
I0517 19:22:57.483520  4008 solver.cpp:231] Iteration 77800, loss = 1.40849
I0517 19:22:57.483891  4008 solver.cpp:247]     Train net output #0: loss = 1.40849 (* 1 = 1.40849 loss)
I0517 19:22:57.483911  4008 sgd_solver.cpp:106] Iteration 77800, lr = 0.001
I0517 19:22:57.643942  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.92023	0	68.4121	0	79.0142	2.34375	73.8821	0	68.3519	0	59.4057	0	50.1618	0	20.7861	1	
I0517 19:22:57.717790  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:22:57.719012  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:22:57.719045  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:22:57.728837  4008 solver.cpp:260]     Total regularization terms: 1.29796 loss+regular. : 2.70645
I0517 19:24:19.220295  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_78000.caffemodel
I0517 19:26:06.264655  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_78000.solverstate
I0517 19:26:06.996630  4008 solver.cpp:348] Iteration 78000, Testing net (#0)
I0517 19:26:51.426939  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:27:24.825364  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55422
I0517 19:27:24.829665  4008 solver.cpp:415]     Test net output #1: loss = 1.91857 (* 1 = 1.91857 loss)
I0517 19:27:24.919155  4008 solver.cpp:231] Iteration 78000, loss = 1.59136
I0517 19:27:24.919281  4008 solver.cpp:247]     Train net output #0: loss = 1.59136 (* 1 = 1.59136 loss)
I0517 19:27:24.919299  4008 sgd_solver.cpp:106] Iteration 78000, lr = 0.001
I0517 19:27:25.086657  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.8944	0	68.6146	0	79.0469	2.34375	73.9118	0	68.3992	0	59.4718	0	50.2207	0	20.8033	1	
I0517 19:27:25.087442  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:27:25.088557  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1	
I0517 19:27:25.088572  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:27:25.098294  4008 solver.cpp:260]     Total regularization terms: 1.29705 loss+regular. : 2.88841
I0517 19:28:41.746948  4008 solver.cpp:231] Iteration 78200, loss = 1.37545
I0517 19:28:41.747449  4008 solver.cpp:247]     Train net output #0: loss = 1.37545 (* 1 = 1.37545 loss)
I0517 19:28:41.747478  4008 sgd_solver.cpp:106] Iteration 78200, lr = 0.001
I0517 19:28:41.906719  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.88292	0	68.6419	0	79.0998	2.34375	73.9775	0	68.4496	0	59.5389	0	50.2808	0	20.82	1.1	
I0517 19:28:41.980439  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:28:41.981473  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:28:41.981500  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:28:41.991528  4008 solver.cpp:260]     Total regularization terms: 1.29614 loss+regular. : 2.67159
I0517 19:30:02.360419  4008 solver.cpp:231] Iteration 78400, loss = 1.49106
I0517 19:30:02.360761  4008 solver.cpp:247]     Train net output #0: loss = 1.49106 (* 1 = 1.49106 loss)
I0517 19:30:02.360780  4008 sgd_solver.cpp:106] Iteration 78400, lr = 0.001
I0517 19:30:02.522426  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.91162	0	68.6351	0	79.1358	2.34375	74.0275	0	68.4975	0	59.6045	0	50.3402	0	20.8357	1.1	
I0517 19:30:02.597090  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:30:02.598290  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:30:02.598312  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:30:02.618481  4008 solver.cpp:260]     Total regularization terms: 1.29525 loss+regular. : 2.78631
I0517 19:31:11.017216  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:31:25.746783  4008 solver.cpp:231] Iteration 78600, loss = 1.59734
I0517 19:31:25.746896  4008 solver.cpp:247]     Train net output #0: loss = 1.59734 (* 1 = 1.59734 loss)
I0517 19:31:25.746914  4008 sgd_solver.cpp:106] Iteration 78600, lr = 0.001
I0517 19:31:25.908885  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.80257	0	68.724	0	79.1671	2.34375	74.0686	0	68.5484	0	59.6709	0	50.4001	0	20.8517	1.1	
I0517 19:31:25.982748  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:31:25.984041  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.34375	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:31:25.984064  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:31:25.993804  4008 solver.cpp:260]     Total regularization terms: 1.29435 loss+regular. : 2.8917
I0517 19:32:47.069833  4008 solver.cpp:231] Iteration 78800, loss = 1.69045
I0517 19:32:47.070137  4008 solver.cpp:247]     Train net output #0: loss = 1.69045 (* 1 = 1.69045 loss)
I0517 19:32:47.070161  4008 sgd_solver.cpp:106] Iteration 78800, lr = 0.001
I0517 19:32:47.233309  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.84848	0	68.6263	0	79.2156	2.60417	74.1151	0	68.5897	0	59.7377	0	50.4602	0	20.8685	1.1	
I0517 19:32:47.308055  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:32:47.308842  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:32:47.308856  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:32:47.322124  4008 solver.cpp:260]     Total regularization terms: 1.29348 loss+regular. : 2.98393
I0517 19:34:06.910272  4008 solver.cpp:348] Iteration 79000, Testing net (#0)
I0517 19:34:51.100965  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:35:22.288059  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55272
I0517 19:35:22.288302  4008 solver.cpp:415]     Test net output #1: loss = 1.91671 (* 1 = 1.91671 loss)
I0517 19:35:22.375419  4008 solver.cpp:231] Iteration 79000, loss = 1.32842
I0517 19:35:22.375512  4008 solver.cpp:247]     Train net output #0: loss = 1.32842 (* 1 = 1.32842 loss)
I0517 19:35:22.375530  4008 sgd_solver.cpp:106] Iteration 79000, lr = 0.001
I0517 19:35:22.543262  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0379	0	68.8076	0	79.2536	2.60417	74.1583	0	68.6338	0	59.8028	0	50.5181	0	20.8841	1.1	
I0517 19:35:22.618093  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:35:22.619343  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:35:22.619374  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:35:22.630381  4008 solver.cpp:260]     Total regularization terms: 1.29248 loss+regular. : 2.6209
I0517 19:36:46.362170  4008 solver.cpp:231] Iteration 79200, loss = 1.38694
I0517 19:36:46.365676  4008 solver.cpp:247]     Train net output #0: loss = 1.38694 (* 1 = 1.38694 loss)
I0517 19:36:46.365710  4008 sgd_solver.cpp:106] Iteration 79200, lr = 0.001
I0517 19:36:46.523893  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.81405	0	68.6045	0	79.2866	2.60417	74.1984	0	68.6584	0	59.8677	0	50.5767	0	20.8995	1.1	
I0517 19:36:46.602438  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:36:46.604043  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:36:46.604079  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:36:46.625352  4008 solver.cpp:260]     Total regularization terms: 1.29162 loss+regular. : 2.67856
I0517 19:38:13.352896  4008 solver.cpp:231] Iteration 79400, loss = 1.58699
I0517 19:38:13.353160  4008 solver.cpp:247]     Train net output #0: loss = 1.58699 (* 1 = 1.58699 loss)
I0517 19:38:13.353196  4008 sgd_solver.cpp:106] Iteration 79400, lr = 0.001
I0517 19:38:13.516237  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.7624	0	68.8337	0	79.3343	2.60417	74.2478	0	68.7233	0	59.9319	0	50.6348	0	20.9149	1.1	
I0517 19:38:13.590790  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:38:13.592361  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:38:13.592407  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:38:13.602226  4008 solver.cpp:260]     Total regularization terms: 1.29068 loss+regular. : 2.87767
I0517 19:39:23.357374  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:39:35.963853  4008 solver.cpp:231] Iteration 79600, loss = 1.50287
I0517 19:39:35.963930  4008 solver.cpp:247]     Train net output #0: loss = 1.50287 (* 1 = 1.50287 loss)
I0517 19:39:35.963944  4008 sgd_solver.cpp:106] Iteration 79600, lr = 0.001
I0517 19:39:36.125447  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.88005	0	68.7832	0	79.3389	2.60417	74.2873	0	68.7751	0	59.9963	0	50.693	0	20.9311	1.1	
I0517 19:39:36.200163  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:39:36.201128  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:39:36.201165  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:39:36.216017  4008 solver.cpp:260]     Total regularization terms: 1.2898 loss+regular. : 2.79267
I0517 19:40:53.983842  4008 solver.cpp:231] Iteration 79800, loss = 1.46087
I0517 19:40:53.984140  4008 solver.cpp:247]     Train net output #0: loss = 1.46087 (* 1 = 1.46087 loss)
I0517 19:40:53.984282  4008 sgd_solver.cpp:106] Iteration 79800, lr = 0.001
I0517 19:40:54.146046  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.90588	0	68.9352	0	79.3895	2.60417	74.3349	0	68.8169	0	60.0601	0	50.7516	0	20.9468	1.1	
I0517 19:40:54.220216  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:40:54.221221  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	0	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:40:54.221247  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:40:54.231586  4008 solver.cpp:260]     Total regularization terms: 1.28885 loss+regular. : 2.74972
I0517 19:42:11.228559  4008 solver.cpp:348] Iteration 80000, Testing net (#0)
I0517 19:42:58.029186  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:43:34.152039  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55014
I0517 19:43:34.152256  4008 solver.cpp:415]     Test net output #1: loss = 1.92514 (* 1 = 1.92514 loss)
I0517 19:43:34.243029  4008 solver.cpp:231] Iteration 80000, loss = 1.51888
I0517 19:43:34.243120  4008 solver.cpp:247]     Train net output #0: loss = 1.51888 (* 1 = 1.51888 loss)
I0517 19:43:34.243137  4008 sgd_solver.cpp:106] Iteration 80000, lr = 0.001
I0517 19:43:34.409200  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.76814	1.04167	68.7894	0	79.4168	2.60417	74.3749	0	68.8535	0	60.1238	0	50.8101	0	20.9628	1.1	
I0517 19:43:34.483166  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:43:34.484402  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:43:34.484427  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:43:34.494094  4008 solver.cpp:260]     Total regularization terms: 1.2879 loss+regular. : 2.80679
I0517 19:44:58.628089  4008 solver.cpp:231] Iteration 80200, loss = 1.43792
I0517 19:44:58.628324  4008 solver.cpp:247]     Train net output #0: loss = 1.43792 (* 1 = 1.43792 loss)
I0517 19:44:58.628342  4008 sgd_solver.cpp:106] Iteration 80200, lr = 0.001
I0517 19:44:58.789914  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.91736	1.04167	68.9678	0	79.4444	2.60417	74.4211	0	68.8999	0	60.1874	0	50.8675	0	20.9783	1.1	
I0517 19:44:58.865345  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:44:58.866335  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:44:58.866358  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:44:58.881639  4008 solver.cpp:260]     Total regularization terms: 1.28698 loss+regular. : 2.7249
I0517 19:46:15.491857  4008 solver.cpp:231] Iteration 80400, loss = 1.3685
I0517 19:46:15.492162  4008 solver.cpp:247]     Train net output #0: loss = 1.3685 (* 1 = 1.3685 loss)
I0517 19:46:15.492182  4008 sgd_solver.cpp:106] Iteration 80400, lr = 0.001
I0517 19:46:15.651728  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.85135	1.04167	68.9886	0	79.489	2.60417	74.4636	0	68.9336	0	60.2513	0	50.926	0	20.9947	1.1	
I0517 19:46:15.727205  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:46:15.728544  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:46:15.728579  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:46:15.743391  4008 solver.cpp:260]     Total regularization terms: 1.28615 loss+regular. : 2.65464
I0517 19:47:23.514469  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:47:34.055830  4008 solver.cpp:231] Iteration 80600, loss = 1.58794
I0517 19:47:34.055918  4008 solver.cpp:247]     Train net output #0: loss = 1.58794 (* 1 = 1.58794 loss)
I0517 19:47:34.055938  4008 sgd_solver.cpp:106] Iteration 80600, lr = 0.001
I0517 19:47:34.217360  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.69927	1.04167	68.9274	0	79.5195	2.60417	74.5019	0	68.9695	0	60.3156	0	50.9833	0	21.0102	1.1	
I0517 19:47:34.291761  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:47:34.293334  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:47:34.293414  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:47:34.303388  4008 solver.cpp:260]     Total regularization terms: 1.28534 loss+regular. : 2.87328
I0517 19:48:53.242086  4008 solver.cpp:231] Iteration 80800, loss = 1.49242
I0517 19:48:53.244194  4008 solver.cpp:247]     Train net output #0: loss = 1.49242 (* 1 = 1.49242 loss)
I0517 19:48:53.244221  4008 sgd_solver.cpp:106] Iteration 80800, lr = 0.001
I0517 19:48:53.402554  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.89153	1.04167	69.1663	0	79.5696	2.60417	74.5548	0	69.0176	0	60.3795	0	51.0413	0	21.0263	1.1	
I0517 19:48:53.477365  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:48:53.478329  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:48:53.478363  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:48:53.508136  4008 solver.cpp:260]     Total regularization terms: 1.28445 loss+regular. : 2.77687
I0517 19:50:15.542606  4008 solver.cpp:348] Iteration 81000, Testing net (#0)
I0517 19:50:56.778872  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:51:26.275033  4008 solver.cpp:415]     Test net output #0: accuracy = 0.54994
I0517 19:51:26.275158  4008 solver.cpp:415]     Test net output #1: loss = 1.93882 (* 1 = 1.93882 loss)
I0517 19:51:26.362740  4008 solver.cpp:231] Iteration 81000, loss = 1.25343
I0517 19:51:26.362843  4008 solver.cpp:247]     Train net output #0: loss = 1.25343 (* 1 = 1.25343 loss)
I0517 19:51:26.362861  4008 sgd_solver.cpp:106] Iteration 81000, lr = 0.001
I0517 19:51:26.528731  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.94318	1.04167	69.1263	0	79.5946	2.60417	74.5883	0	69.0602	0	60.4441	0	51.0983	0	21.0424	1.1	
I0517 19:51:26.603380  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:51:26.604395  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:51:26.604411  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:51:26.615473  4008 solver.cpp:260]     Total regularization terms: 1.28359 loss+regular. : 2.53702
I0517 19:52:43.332074  4008 solver.cpp:231] Iteration 81200, loss = 1.42404
I0517 19:52:43.332404  4008 solver.cpp:247]     Train net output #0: loss = 1.42404 (* 1 = 1.42404 loss)
I0517 19:52:43.332520  4008 sgd_solver.cpp:106] Iteration 81200, lr = 0.001
I0517 19:52:43.493973  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.80831	1.04167	69.2441	0	79.6414	2.60417	74.6386	0	69.1178	0	60.5079	0	51.1559	0	21.0584	1.1	
I0517 19:52:43.567885  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:52:43.568804  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:52:43.568825  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:52:43.578552  4008 solver.cpp:260]     Total regularization terms: 1.28276 loss+regular. : 2.70681
I0517 19:53:59.588310  4008 solver.cpp:231] Iteration 81400, loss = 1.44047
I0517 19:53:59.588593  4008 solver.cpp:247]     Train net output #0: loss = 1.44047 (* 1 = 1.44047 loss)
I0517 19:53:59.588714  4008 sgd_solver.cpp:106] Iteration 81400, lr = 0.001
I0517 19:53:59.750185  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.84562	1.04167	69.3311	0	79.6696	2.60417	74.6775	0	69.1531	0	60.5706	0	51.2133	0	21.0738	1.1	
I0517 19:53:59.823940  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:53:59.824901  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:53:59.824919  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:53:59.844524  4008 solver.cpp:260]     Total regularization terms: 1.28192 loss+regular. : 2.72239
I0517 19:55:13.066697  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:55:19.604200  4008 solver.cpp:231] Iteration 81600, loss = 1.34508
I0517 19:55:19.604308  4008 solver.cpp:247]     Train net output #0: loss = 1.34508 (* 1 = 1.34508 loss)
I0517 19:55:19.604328  4008 sgd_solver.cpp:106] Iteration 81600, lr = 0.001
I0517 19:55:19.765213  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.9604	1.04167	69.3929	0	79.7211	2.60417	74.7162	0	69.1949	0	60.6337	0	51.2705	0	21.089	1.1	
I0517 19:55:19.839187  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:55:19.840478  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:55:19.840502  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:55:19.850208  4008 solver.cpp:260]     Total regularization terms: 1.281 loss+regular. : 2.62607
I0517 19:56:35.372066  4008 solver.cpp:231] Iteration 81800, loss = 1.50053
I0517 19:56:35.372330  4008 solver.cpp:247]     Train net output #0: loss = 1.50053 (* 1 = 1.50053 loss)
I0517 19:56:35.372352  4008 sgd_solver.cpp:106] Iteration 81800, lr = 0.001
I0517 19:56:35.533296  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0666	1.04167	69.3115	0	79.7371	2.60417	74.764	0	69.2412	0	60.6972	0	51.3284	0	21.1045	1.1	
I0517 19:56:35.608355  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:56:35.609535  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:56:35.609578  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:56:35.629791  4008 solver.cpp:260]     Total regularization terms: 1.28015 loss+regular. : 2.78069
I0517 19:57:54.159318  4008 solver.cpp:348] Iteration 82000, Testing net (#0)
I0517 19:58:39.906960  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 19:59:10.178892  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55404
I0517 19:59:10.179184  4008 solver.cpp:415]     Test net output #1: loss = 1.91983 (* 1 = 1.91983 loss)
I0517 19:59:10.268978  4008 solver.cpp:231] Iteration 82000, loss = 1.34838
I0517 19:59:10.269057  4008 solver.cpp:247]     Train net output #0: loss = 1.34838 (* 1 = 1.34838 loss)
I0517 19:59:10.269074  4008 sgd_solver.cpp:106] Iteration 82000, lr = 0.001
I0517 19:59:10.434680  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.94892	1.04167	69.3587	0	79.7509	2.60417	74.7993	0	69.288	0	60.7596	0	51.3855	0	21.1204	1.1	
I0517 19:59:10.509690  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 19:59:10.511247  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 19:59:10.511292  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 19:59:10.522064  4008 solver.cpp:260]     Total regularization terms: 1.27932 loss+regular. : 2.62771
I0517 20:00:23.379518  4008 solver.cpp:231] Iteration 82200, loss = 1.49724
I0517 20:00:23.379783  4008 solver.cpp:247]     Train net output #0: loss = 1.49724 (* 1 = 1.49724 loss)
I0517 20:00:23.379806  4008 sgd_solver.cpp:106] Iteration 82200, lr = 0.001
I0517 20:00:23.540390  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.56726	1.04167	69.4375	0	79.8183	2.60417	74.857	0	69.34	0	60.8219	0	51.4414	0	21.1356	1.1	
I0517 20:00:23.614509  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:00:23.615892  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:00:23.615926  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:00:23.626072  4008 solver.cpp:260]     Total regularization terms: 1.27848 loss+regular. : 2.77572
I0517 20:01:44.976658  4008 solver.cpp:231] Iteration 82400, loss = 1.24447
I0517 20:01:44.976981  4008 solver.cpp:247]     Train net output #0: loss = 1.24447 (* 1 = 1.24447 loss)
I0517 20:01:44.977005  4008 sgd_solver.cpp:106] Iteration 82400, lr = 0.001
I0517 20:01:45.137337  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.92309	1.04167	69.3503	0	79.8369	2.60417	74.8924	0	69.3769	0	60.8837	0	51.4976	0	21.1532	1.1	
I0517 20:01:45.211374  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:01:45.212610  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:01:45.212646  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:01:45.222522  4008 solver.cpp:260]     Total regularization terms: 1.27761 loss+regular. : 2.52208
I0517 20:03:01.786305  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:03:06.377666  4008 solver.cpp:231] Iteration 82600, loss = 1.62729
I0517 20:03:06.377748  4008 solver.cpp:247]     Train net output #0: loss = 1.62729 (* 1 = 1.62729 loss)
I0517 20:03:06.377768  4008 sgd_solver.cpp:106] Iteration 82600, lr = 0.001
I0517 20:03:06.537981  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.96327	1.04167	69.568	0	79.8772	2.60417	74.9319	0	69.4198	0	60.9464	0	51.5542	0	21.1687	1.1	
I0517 20:03:06.611865  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:03:06.613320  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:03:06.613343  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:03:06.623101  4008 solver.cpp:260]     Total regularization terms: 1.27669 loss+regular. : 2.90398
I0517 20:04:31.689689  4008 solver.cpp:231] Iteration 82800, loss = 1.57869
I0517 20:04:31.691395  4008 solver.cpp:247]     Train net output #0: loss = 1.57869 (* 1 = 1.57869 loss)
I0517 20:04:31.691465  4008 sgd_solver.cpp:106] Iteration 82800, lr = 0.001
I0517 20:04:31.850973  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0235	1.04167	69.6064	0	79.896	2.60417	74.9718	0	69.47	0	61.0084	0	51.6103	0	21.1842	1.1	
I0517 20:04:31.925089  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:04:31.926548  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:04:31.926589  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:04:31.936401  4008 solver.cpp:260]     Total regularization terms: 1.27583 loss+regular. : 2.85452
I0517 20:05:50.894215  4008 solver.cpp:348] Iteration 83000, Testing net (#0)
I0517 20:06:38.152338  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:07:08.696641  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5537
I0517 20:07:08.696889  4008 solver.cpp:415]     Test net output #1: loss = 1.91821 (* 1 = 1.91821 loss)
I0517 20:07:08.787948  4008 solver.cpp:231] Iteration 83000, loss = 1.32942
I0517 20:07:08.788023  4008 solver.cpp:247]     Train net output #0: loss = 1.32942 (* 1 = 1.32942 loss)
I0517 20:07:08.788043  4008 sgd_solver.cpp:106] Iteration 83000, lr = 0.001
I0517 20:07:08.955885  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.89727	1.04167	69.4469	0	79.9269	2.60417	75.0033	0	69.5127	0	61.0707	0	51.6683	0	21.1999	1.1	
I0517 20:07:09.029881  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:07:09.031169  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:07:09.031213  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:07:09.041196  4008 solver.cpp:260]     Total regularization terms: 1.27501 loss+regular. : 2.60443
I0517 20:08:34.718850  4008 solver.cpp:231] Iteration 83200, loss = 1.46682
I0517 20:08:34.719111  4008 solver.cpp:247]     Train net output #0: loss = 1.46682 (* 1 = 1.46682 loss)
I0517 20:08:34.719130  4008 sgd_solver.cpp:106] Iteration 83200, lr = 0.001
I0517 20:08:34.879819  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.9977	1.04167	69.5225	0	79.9606	2.60417	75.0425	0	69.5545	0	61.1328	0	51.7245	0	21.215	1.1	
I0517 20:08:34.954710  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:08:34.956028  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:08:34.956066  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:08:34.976455  4008 solver.cpp:260]     Total regularization terms: 1.27416 loss+regular. : 2.74098
I0517 20:10:08.600642  4008 solver.cpp:231] Iteration 83400, loss = 1.35863
I0517 20:10:08.600955  4008 solver.cpp:247]     Train net output #0: loss = 1.35863 (* 1 = 1.35863 loss)
I0517 20:10:08.600980  4008 sgd_solver.cpp:106] Iteration 83400, lr = 0.001
I0517 20:10:08.760426  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0034	1.04167	69.584	0	79.9874	2.60417	75.0851	0	69.5873	0	61.1943	0	51.78	0	21.2305	1.1	
I0517 20:10:08.835230  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:10:08.836519  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:10:08.836554  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:10:08.851452  4008 solver.cpp:260]     Total regularization terms: 1.27329 loss+regular. : 2.63192
I0517 20:11:25.965229  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:11:26.881942  4008 solver.cpp:231] Iteration 83600, loss = 1.37239
I0517 20:11:26.882128  4008 solver.cpp:247]     Train net output #0: loss = 1.37239 (* 1 = 1.37239 loss)
I0517 20:11:26.882148  4008 sgd_solver.cpp:106] Iteration 83600, lr = 0.001
I0517 20:11:27.042351  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0752	1.04167	69.5046	0	80.0224	2.60417	75.1275	0	69.6386	0	61.2556	0	51.836	0	21.2461	1.1	
I0517 20:11:27.116219  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:11:27.117271  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:11:27.117286  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:11:27.126922  4008 solver.cpp:260]     Total regularization terms: 1.27249 loss+regular. : 2.64489
I0517 20:12:51.691651  4008 solver.cpp:231] Iteration 83800, loss = 1.46984
I0517 20:12:51.691879  4008 solver.cpp:247]     Train net output #0: loss = 1.46984 (* 1 = 1.46984 loss)
I0517 20:12:51.691897  4008 sgd_solver.cpp:106] Iteration 83800, lr = 0.001
I0517 20:12:51.852159  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.86283	1.04167	69.5667	0	80.0537	2.60417	75.1709	0	69.668	0	61.3169	0	51.8929	0	21.2611	1.1	
I0517 20:12:51.927209  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:12:51.928701  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.60417	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:12:51.928730  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:12:51.942513  4008 solver.cpp:260]     Total regularization terms: 1.27166 loss+regular. : 2.74149
I0517 20:14:29.185464  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_84000.caffemodel
I0517 20:16:43.610961  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_84000.solverstate
I0517 20:16:44.410109  4008 solver.cpp:348] Iteration 84000, Testing net (#0)
I0517 20:17:29.404182  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:18:00.601320  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55338
I0517 20:18:00.601568  4008 solver.cpp:415]     Test net output #1: loss = 1.91262 (* 1 = 1.91262 loss)
I0517 20:18:00.688957  4008 solver.cpp:231] Iteration 84000, loss = 1.19156
I0517 20:18:00.689033  4008 solver.cpp:247]     Train net output #0: loss = 1.19156 (* 1 = 1.19156 loss)
I0517 20:18:00.689051  4008 sgd_solver.cpp:106] Iteration 84000, lr = 0.001
I0517 20:18:00.857045  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.9891	1.04167	69.7148	0	80.1063	2.86458	75.1973	0	69.7225	0	61.3776	0	51.9506	0	21.2759	1.1	
I0517 20:18:00.857945  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:18:00.859218  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:18:00.859249  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:18:00.869174  4008 solver.cpp:260]     Total regularization terms: 1.27075 loss+regular. : 2.46231
I0517 20:19:23.231012  4008 solver.cpp:231] Iteration 84200, loss = 1.33495
I0517 20:19:23.231338  4008 solver.cpp:247]     Train net output #0: loss = 1.33495 (* 1 = 1.33495 loss)
I0517 20:19:23.231361  4008 sgd_solver.cpp:106] Iteration 84200, lr = 0.001
I0517 20:19:23.391374  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.85135	1.04167	69.8102	0	80.1406	2.86458	75.2432	0	69.7541	0	61.4383	0	52.0061	0	21.2907	1.1	
I0517 20:19:23.466272  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:19:23.467718  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:19:23.467752  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:19:23.482790  4008 solver.cpp:260]     Total regularization terms: 1.26995 loss+regular. : 2.6049
I0517 20:20:40.406368  4008 solver.cpp:231] Iteration 84400, loss = 1.41279
I0517 20:20:40.406594  4008 solver.cpp:247]     Train net output #0: loss = 1.41279 (* 1 = 1.41279 loss)
I0517 20:20:40.406615  4008 sgd_solver.cpp:106] Iteration 84400, lr = 0.001
I0517 20:20:40.567401  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.71935	1.04167	69.793	0	80.1549	2.86458	75.2768	0	69.798	0	61.499	0	52.0635	0	21.3057	1.1	
I0517 20:20:40.641465  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:20:40.642614  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:20:40.642645  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:20:40.652427  4008 solver.cpp:260]     Total regularization terms: 1.26912 loss+regular. : 2.68191
I0517 20:22:00.903430  4008 solver.cpp:231] Iteration 84600, loss = 1.44129
I0517 20:22:00.903697  4008 solver.cpp:247]     Train net output #0: loss = 1.44129 (* 1 = 1.44129 loss)
I0517 20:22:00.903722  4008 sgd_solver.cpp:106] Iteration 84600, lr = 0.001
I0517 20:22:01.062338  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.94318	1.04167	69.8356	0	80.1887	2.86458	75.3088	0	69.8389	0	61.5589	0	52.1204	0	21.3212	1.1	
I0517 20:22:01.136435  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:22:01.137812  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:22:01.137852  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:22:01.148001  4008 solver.cpp:260]     Total regularization terms: 1.26825 loss+regular. : 2.70954
I0517 20:22:02.786736  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:23:24.279361  4008 solver.cpp:231] Iteration 84800, loss = 1.5665
I0517 20:23:24.279614  4008 solver.cpp:247]     Train net output #0: loss = 1.5665 (* 1 = 1.5665 loss)
I0517 20:23:24.279634  4008 sgd_solver.cpp:106] Iteration 84800, lr = 0.001
I0517 20:23:24.439932  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.95753	1.04167	69.6663	0	80.2042	2.86458	75.3605	0	69.8742	0	61.6188	0	52.1752	0	21.3364	1.1	
I0517 20:23:24.513893  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:23:24.515434  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:23:24.515470  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:23:24.528666  4008 solver.cpp:260]     Total regularization terms: 1.26743 loss+regular. : 2.83393
I0517 20:24:48.729293  4008 solver.cpp:348] Iteration 85000, Testing net (#0)
I0517 20:25:39.084318  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:26:12.336076  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55308
I0517 20:26:12.336294  4008 solver.cpp:415]     Test net output #1: loss = 1.91666 (* 1 = 1.91666 loss)
I0517 20:26:12.427002  4008 solver.cpp:231] Iteration 85000, loss = 1.3872
I0517 20:26:12.427072  4008 solver.cpp:247]     Train net output #0: loss = 1.3872 (* 1 = 1.3872 loss)
I0517 20:26:12.427090  4008 sgd_solver.cpp:106] Iteration 85000, lr = 0.001
I0517 20:26:12.591950  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0407	1.04167	69.7897	0	80.2558	2.86458	75.4031	0	69.9305	0	61.6794	0	52.2309	0	21.3511	1.1	
I0517 20:26:12.666380  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:26:12.667963  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:26:12.667996  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:26:12.677824  4008 solver.cpp:260]     Total regularization terms: 1.26667 loss+regular. : 2.65386
I0517 20:27:40.739480  4008 solver.cpp:231] Iteration 85200, loss = 1.42847
I0517 20:27:40.739768  4008 solver.cpp:247]     Train net output #0: loss = 1.42847 (* 1 = 1.42847 loss)
I0517 20:27:40.739791  4008 sgd_solver.cpp:106] Iteration 85200, lr = 0.001
I0517 20:27:40.900770  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1268	1.04167	69.8551	0	80.2768	2.86458	75.4276	0	69.9698	0	61.7404	0	52.2863	0	21.3667	1.1	
I0517 20:27:40.974956  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:27:40.976572  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:27:40.976611  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:27:40.986966  4008 solver.cpp:260]     Total regularization terms: 1.26587 loss+regular. : 2.69434
I0517 20:29:06.475368  4008 solver.cpp:231] Iteration 85400, loss = 1.47067
I0517 20:29:06.481705  4008 solver.cpp:247]     Train net output #0: loss = 1.47067 (* 1 = 1.47067 loss)
I0517 20:29:06.481740  4008 sgd_solver.cpp:106] Iteration 85400, lr = 0.001
I0517 20:29:06.636587  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1613	1.04167	69.8952	0	80.309	2.86458	75.4795	0	70.0182	0	61.8004	0	52.3417	0	21.382	1.1	
I0517 20:29:06.710558  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:29:06.711499  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:29:06.711522  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:29:06.721351  4008 solver.cpp:260]     Total regularization terms: 1.26513 loss+regular. : 2.7358
I0517 20:30:24.739320  4008 solver.cpp:231] Iteration 85600, loss = 1.41655
I0517 20:30:24.740131  4008 solver.cpp:247]     Train net output #0: loss = 1.41655 (* 1 = 1.41655 loss)
I0517 20:30:24.740154  4008 sgd_solver.cpp:106] Iteration 85600, lr = 0.001
I0517 20:30:24.900051  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2014	1.04167	69.958	0	80.3601	2.86458	75.5208	0	70.0378	0	61.8596	0	52.397	0	21.397	1.1	
I0517 20:30:24.975816  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:30:24.977115  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.1	
I0517 20:30:24.977161  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:30:24.992243  4008 solver.cpp:260]     Total regularization terms: 1.26438 loss+regular. : 2.68092
I0517 20:30:29.101795  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:31:46.732780  4008 solver.cpp:231] Iteration 85800, loss = 1.53998
I0517 20:31:46.733222  4008 solver.cpp:247]     Train net output #0: loss = 1.53998 (* 1 = 1.53998 loss)
I0517 20:31:46.733244  4008 sgd_solver.cpp:106] Iteration 85800, lr = 0.001
I0517 20:31:46.892858  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.93457	1.04167	69.8841	0	80.3825	2.86458	75.5638	0	70.0941	0	61.9203	0	52.4519	0	21.4125	1.2	
I0517 20:31:46.966749  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:31:46.967965  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.2	
I0517 20:31:46.967986  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:31:46.977849  4008 solver.cpp:260]     Total regularization terms: 1.2636 loss+regular. : 2.80357
I0517 20:33:12.084612  4008 solver.cpp:348] Iteration 86000, Testing net (#0)
I0517 20:34:01.276659  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:34:33.727000  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55206
I0517 20:34:33.727212  4008 solver.cpp:415]     Test net output #1: loss = 1.92365 (* 1 = 1.92365 loss)
I0517 20:34:33.817849  4008 solver.cpp:231] Iteration 86000, loss = 1.67782
I0517 20:34:33.817922  4008 solver.cpp:247]     Train net output #0: loss = 1.67782 (* 1 = 1.67782 loss)
I0517 20:34:33.817940  4008 sgd_solver.cpp:106] Iteration 86000, lr = 0.001
I0517 20:34:33.983294  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0781	1.04167	69.8714	0	80.4062	2.86458	75.598	0	70.1289	0	61.9808	0	52.5077	0	21.4276	1.2	
I0517 20:34:34.057596  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:34:34.058691  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.2	
I0517 20:34:34.058724  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:34:34.068732  4008 solver.cpp:260]     Total regularization terms: 1.26281 loss+regular. : 2.94063
I0517 20:35:55.446598  4008 solver.cpp:231] Iteration 86200, loss = 1.40333
I0517 20:35:55.446897  4008 solver.cpp:247]     Train net output #0: loss = 1.40333 (* 1 = 1.40333 loss)
I0517 20:35:55.446924  4008 sgd_solver.cpp:106] Iteration 86200, lr = 0.001
I0517 20:35:55.609546  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.96901	1.04167	70.0189	0	80.4357	2.86458	75.6409	0	70.1771	0	62.0391	0	52.5636	0	21.4425	1.2	
I0517 20:35:55.683943  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:35:55.685480  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.2	
I0517 20:35:55.685514  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:35:55.695405  4008 solver.cpp:260]     Total regularization terms: 1.26201 loss+regular. : 2.66534
I0517 20:37:16.060531  4008 solver.cpp:231] Iteration 86400, loss = 1.47607
I0517 20:37:16.060732  4008 solver.cpp:247]     Train net output #0: loss = 1.47607 (* 1 = 1.47607 loss)
I0517 20:37:16.060750  4008 sgd_solver.cpp:106] Iteration 86400, lr = 0.001
I0517 20:37:16.221011  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.79683	1.04167	69.9717	0	80.4537	2.86458	75.6825	0	70.1997	0	62.0975	0	52.6199	0	21.4577	1.2	
I0517 20:37:16.298359  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:37:16.300112  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.2	
I0517 20:37:16.300151  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:37:16.309978  4008 solver.cpp:260]     Total regularization terms: 1.26124 loss+regular. : 2.73731
I0517 20:38:40.578095  4008 solver.cpp:231] Iteration 86600, loss = 1.66855
I0517 20:38:40.581694  4008 solver.cpp:247]     Train net output #0: loss = 1.66855 (* 1 = 1.66855 loss)
I0517 20:38:40.581732  4008 sgd_solver.cpp:106] Iteration 86600, lr = 0.001
I0517 20:38:40.740339  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.95753	1.04167	69.9349	0	80.4914	2.86458	75.7255	0	70.2445	0	62.1566	0	52.6734	0	21.4718	1.2	
I0517 20:38:40.815054  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:38:40.817426  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.2	
I0517 20:38:40.817482  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:38:40.827312  4008 solver.cpp:260]     Total regularization terms: 1.26048 loss+regular. : 2.92902
I0517 20:38:48.636395  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:40:12.270277  4008 solver.cpp:231] Iteration 86800, loss = 1.35585
I0517 20:40:12.270617  4008 solver.cpp:247]     Train net output #0: loss = 1.35585 (* 1 = 1.35585 loss)
I0517 20:40:12.270653  4008 sgd_solver.cpp:106] Iteration 86800, lr = 0.001
I0517 20:40:12.432231  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0608	1.04167	70.0833	0	80.5339	2.86458	75.754	0	70.2768	0	62.2154	0	52.7281	0	21.4868	1.2	
I0517 20:40:12.506237  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:40:12.507508  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.2	
I0517 20:40:12.507541  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:40:12.518789  4008 solver.cpp:260]     Total regularization terms: 1.25973 loss+regular. : 2.61558
I0517 20:41:45.967494  4008 solver.cpp:348] Iteration 87000, Testing net (#0)
I0517 20:42:40.496536  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:43:12.756222  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55002
I0517 20:43:12.756577  4008 solver.cpp:415]     Test net output #1: loss = 1.93325 (* 1 = 1.93325 loss)
I0517 20:43:12.847858  4008 solver.cpp:231] Iteration 87000, loss = 1.42106
I0517 20:43:12.847976  4008 solver.cpp:247]     Train net output #0: loss = 1.42106 (* 1 = 1.42106 loss)
I0517 20:43:12.847998  4008 sgd_solver.cpp:106] Iteration 87000, lr = 0.001
I0517 20:43:13.007937  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0953	1.04167	69.9961	0	80.5528	2.86458	75.7843	0	70.313	0	62.2733	0	52.782	0	21.5008	1.2	
I0517 20:43:13.084452  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:43:13.085748  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.2	
I0517 20:43:13.085803  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:43:13.095767  4008 solver.cpp:260]     Total regularization terms: 1.25905 loss+regular. : 2.68011
I0517 20:44:52.378890  4008 solver.cpp:231] Iteration 87200, loss = 1.57709
I0517 20:44:52.379421  4008 solver.cpp:247]     Train net output #0: loss = 1.57709 (* 1 = 1.57709 loss)
I0517 20:44:52.379459  4008 sgd_solver.cpp:106] Iteration 87200, lr = 0.001
I0517 20:44:52.538993  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.86283	1.04167	70.0651	0	80.5804	2.86458	75.8268	0	70.3536	0	62.3313	0	52.8362	0	21.5146	1.2	
I0517 20:44:52.614037  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:44:52.616751  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.2	
I0517 20:44:52.616822  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:44:52.627221  4008 solver.cpp:260]     Total regularization terms: 1.25827 loss+regular. : 2.83537
I0517 20:46:19.660810  4008 solver.cpp:231] Iteration 87400, loss = 1.40234
I0517 20:46:19.661118  4008 solver.cpp:247]     Train net output #0: loss = 1.40234 (* 1 = 1.40234 loss)
I0517 20:46:19.661144  4008 sgd_solver.cpp:106] Iteration 87400, lr = 0.001
I0517 20:46:19.822028  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.91162	1.04167	70.123	0	80.6158	2.86458	75.8583	0	70.3961	0	62.3891	0	52.89	0	21.5295	1.3	
I0517 20:46:19.896590  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.520833	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:46:19.898329  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	2.86458	0	0	0	0	0	0	0	0	0	1.3	
I0517 20:46:19.898413  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:46:19.908398  4008 solver.cpp:260]     Total regularization terms: 1.25748 loss+regular. : 2.65982
I0517 20:47:50.240586  4008 solver.cpp:231] Iteration 87600, loss = 1.67491
I0517 20:47:50.240941  4008 solver.cpp:247]     Train net output #0: loss = 1.67491 (* 1 = 1.67491 loss)
I0517 20:47:50.240963  4008 sgd_solver.cpp:106] Iteration 87600, lr = 0.001
I0517 20:47:50.401357  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0781	1.04167	70.1888	0	80.6189	3.125	75.8893	0	70.4314	0	62.4474	0	52.9453	0	21.5438	1.3	
I0517 20:47:50.475399  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:47:50.476780  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.125	0	0	0	0	0	0	0	0	0	1.3	
I0517 20:47:50.476822  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:47:50.486707  4008 solver.cpp:260]     Total regularization terms: 1.25673 loss+regular. : 2.93165
I0517 20:48:01.880908  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:49:18.838812  4008 solver.cpp:231] Iteration 87800, loss = 1.49242
I0517 20:49:18.843246  4008 solver.cpp:247]     Train net output #0: loss = 1.49242 (* 1 = 1.49242 loss)
I0517 20:49:18.843289  4008 sgd_solver.cpp:106] Iteration 87800, lr = 0.001
I0517 20:49:18.999199  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.88866	1.04167	70.2103	0	80.6615	3.125	75.9312	0	70.4829	0	62.5047	0	52.9996	0	21.5588	1.3	
I0517 20:49:19.073577  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:49:19.075127  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.125	0	0	0	0	0	0	0	0	0	1.3	
I0517 20:49:19.075177  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:49:19.085705  4008 solver.cpp:260]     Total regularization terms: 1.25592 loss+regular. : 2.74834
I0517 20:50:50.103889  4008 solver.cpp:348] Iteration 88000, Testing net (#0)
I0517 20:51:46.368146  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:52:24.739917  4008 solver.cpp:415]     Test net output #0: accuracy = 0.552979
I0517 20:52:24.740324  4008 solver.cpp:415]     Test net output #1: loss = 1.92914 (* 1 = 1.92914 loss)
I0517 20:52:24.839435  4008 solver.cpp:231] Iteration 88000, loss = 1.40186
I0517 20:52:24.839545  4008 solver.cpp:247]     Train net output #0: loss = 1.40186 (* 1 = 1.40186 loss)
I0517 20:52:24.839570  4008 sgd_solver.cpp:106] Iteration 88000, lr = 0.001
I0517 20:52:25.019244  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.8657	1.04167	70.2832	0	80.6727	3.125	75.9576	0	70.5288	0	62.5639	0	53.0538	0	21.5733	1.3	
I0517 20:52:25.094257  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:52:25.095458  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.125	0	0	0	0	0	0	0	0	0	1.3	
I0517 20:52:25.095494  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:52:25.105855  4008 solver.cpp:260]     Total regularization terms: 1.25512 loss+regular. : 2.65698
I0517 20:53:46.358541  4008 solver.cpp:231] Iteration 88200, loss = 1.40627
I0517 20:53:46.358831  4008 solver.cpp:247]     Train net output #0: loss = 1.40627 (* 1 = 1.40627 loss)
I0517 20:53:46.358855  4008 sgd_solver.cpp:106] Iteration 88200, lr = 0.001
I0517 20:53:46.518854  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0608	1.04167	70.3434	0	80.7228	3.125	76.0052	0	70.5661	0	62.6213	0	53.1076	0	21.588	1.3	
I0517 20:53:46.593089  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:53:46.594359  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.125	0	0	0	0	0	0	0	0	0	1.3	
I0517 20:53:46.594383  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:53:46.604238  4008 solver.cpp:260]     Total regularization terms: 1.25437 loss+regular. : 2.66064
I0517 20:55:04.838775  4008 solver.cpp:231] Iteration 88400, loss = 1.53782
I0517 20:55:04.839337  4008 solver.cpp:247]     Train net output #0: loss = 1.53782 (* 1 = 1.53782 loss)
I0517 20:55:04.839372  4008 sgd_solver.cpp:106] Iteration 88400, lr = 0.001
I0517 20:55:04.998004  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0407	1.04167	70.3441	0	80.758	3.38542	76.0451	0	70.6104	0	62.6781	0	53.1596	0	21.6029	1.4	
I0517 20:55:05.071910  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:55:05.073103  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.38542	0	0	0	0	0	0	0	0	0	1.4	
I0517 20:55:05.073138  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:55:05.082928  4008 solver.cpp:260]     Total regularization terms: 1.25366 loss+regular. : 2.79148
I0517 20:56:33.067833  4008 solver.cpp:231] Iteration 88600, loss = 1.37014
I0517 20:56:33.068140  4008 solver.cpp:247]     Train net output #0: loss = 1.37014 (* 1 = 1.37014 loss)
I0517 20:56:33.068156  4008 sgd_solver.cpp:106] Iteration 88600, lr = 0.001
I0517 20:56:33.227005  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1067	1.04167	70.3122	0	80.7798	3.38542	76.0827	0	70.6419	0	62.7365	0	53.2131	0	21.617	1.4	
I0517 20:56:33.300724  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:56:33.301962  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.38542	0	0	0	0	0	0	0	0	0	1.4	
I0517 20:56:33.301998  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:56:33.311816  4008 solver.cpp:260]     Total regularization terms: 1.25287 loss+regular. : 2.62301
I0517 20:56:48.580544  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 20:58:11.093711  4008 solver.cpp:231] Iteration 88800, loss = 1.4636
I0517 20:58:11.094007  4008 solver.cpp:247]     Train net output #0: loss = 1.4636 (* 1 = 1.4636 loss)
I0517 20:58:11.094228  4008 sgd_solver.cpp:106] Iteration 88800, lr = 0.001
I0517 20:58:11.255964  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1527	1.04167	70.3073	0	80.806	3.38542	76.1148	0	70.6844	0	62.7941	0	53.2672	0	21.6319	1.4	
I0517 20:58:11.330010  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 20:58:11.331267  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.38542	0	0	0	0	0	0	0	0	0	1.4	
I0517 20:58:11.331297  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 20:58:11.341158  4008 solver.cpp:260]     Total regularization terms: 1.25213 loss+regular. : 2.71574
I0517 21:00:06.375231  4008 solver.cpp:348] Iteration 89000, Testing net (#0)
I0517 21:00:58.385287  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:01:31.776458  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55304
I0517 21:01:31.776798  4008 solver.cpp:415]     Test net output #1: loss = 1.92147 (* 1 = 1.92147 loss)
I0517 21:01:31.870287  4008 solver.cpp:231] Iteration 89000, loss = 1.29322
I0517 21:01:31.870378  4008 solver.cpp:247]     Train net output #0: loss = 1.29322 (* 1 = 1.29322 loss)
I0517 21:01:31.870401  4008 sgd_solver.cpp:106] Iteration 89000, lr = 0.001
I0517 21:01:32.036106  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1125	1.04167	70.3955	0	80.8448	3.38542	76.1592	0	70.7237	0	62.8512	0	53.3216	0	21.6458	1.4	
I0517 21:01:32.114594  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:01:32.115967  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.38542	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:01:32.116008  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:01:32.125970  4008 solver.cpp:260]     Total regularization terms: 1.25127 loss+regular. : 2.54449
I0517 21:03:00.215909  4008 solver.cpp:231] Iteration 89200, loss = 1.61136
I0517 21:03:00.216295  4008 solver.cpp:247]     Train net output #0: loss = 1.61136 (* 1 = 1.61136 loss)
I0517 21:03:00.216330  4008 sgd_solver.cpp:106] Iteration 89200, lr = 0.001
I0517 21:03:00.376682  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0436	1.04167	70.3376	0	80.8659	3.38542	76.1847	0	70.7386	0	62.9072	0	53.3736	0	21.6603	1.4	
I0517 21:03:00.451040  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:03:00.452241  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.38542	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:03:00.452261  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:03:00.461894  4008 solver.cpp:260]     Total regularization terms: 1.25058 loss+regular. : 2.86193
I0517 21:04:33.317790  4008 solver.cpp:231] Iteration 89400, loss = 1.32694
I0517 21:04:33.318166  4008 solver.cpp:247]     Train net output #0: loss = 1.32694 (* 1 = 1.32694 loss)
I0517 21:04:33.318188  4008 sgd_solver.cpp:106] Iteration 89400, lr = 0.001
I0517 21:04:33.477427  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1469	1.04167	70.4404	0	80.8947	3.64583	76.2264	0	70.7879	0	62.9633	0	53.4261	0	21.6742	1.4	
I0517 21:04:33.551687  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:04:33.553649  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:04:33.553699  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:04:33.563776  4008 solver.cpp:260]     Total regularization terms: 1.24976 loss+regular. : 2.57671
I0517 21:06:05.641012  4008 solver.cpp:231] Iteration 89600, loss = 1.62892
I0517 21:06:05.641322  4008 solver.cpp:247]     Train net output #0: loss = 1.62892 (* 1 = 1.62892 loss)
I0517 21:06:05.641342  4008 sgd_solver.cpp:106] Iteration 89600, lr = 0.001
I0517 21:06:05.800757  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.96614	1.04167	70.5472	0	80.9117	3.64583	76.2413	0	70.8218	0	63.0192	0	53.4787	0	21.689	1.4	
I0517 21:06:05.874801  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:06:05.876332  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:06:05.876373  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:06:05.886297  4008 solver.cpp:260]     Total regularization terms: 1.24892 loss+regular. : 2.87784
I0517 21:06:22.026026  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:07:30.603077  4008 solver.cpp:231] Iteration 89800, loss = 1.45996
I0517 21:07:30.603425  4008 solver.cpp:247]     Train net output #0: loss = 1.45996 (* 1 = 1.45996 loss)
I0517 21:07:30.603446  4008 sgd_solver.cpp:106] Iteration 89800, lr = 0.001
I0517 21:07:30.761952  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.167	1.04167	70.5915	0	80.9437	3.64583	76.2848	0	70.8693	0	63.0757	0	53.532	0	21.704	1.4	
I0517 21:07:30.836268  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:07:30.837848  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:07:30.837910  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:07:30.847961  4008 solver.cpp:260]     Total regularization terms: 1.24817 loss+regular. : 2.70813
I0517 21:09:04.967026  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_90000.caffemodel
I0517 21:13:08.944355  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_90000.solverstate
I0517 21:13:09.508460  4008 solver.cpp:348] Iteration 90000, Testing net (#0)
I0517 21:14:04.983474  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:14:34.109200  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55142
I0517 21:14:34.109313  4008 solver.cpp:415]     Test net output #1: loss = 1.92336 (* 1 = 1.92336 loss)
I0517 21:14:34.203660  4008 solver.cpp:231] Iteration 90000, loss = 1.31174
I0517 21:14:34.203778  4008 solver.cpp:247]     Train net output #0: loss = 1.31174 (* 1 = 1.31174 loss)
I0517 21:14:34.203804  4008 sgd_solver.cpp:106] Iteration 90000, lr = 0.001
I0517 21:14:34.369416  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2904	1.04167	70.5889	0	80.9915	3.64583	76.3128	0	70.9086	0	63.1319	0	53.5848	0	21.7183	1.4	
I0517 21:14:34.370476  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:14:34.372126  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:14:34.372164  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:14:34.384982  4008 solver.cpp:260]     Total regularization terms: 1.24739 loss+regular. : 2.55913
I0517 21:16:04.245395  4008 solver.cpp:231] Iteration 90200, loss = 1.33254
I0517 21:16:04.246006  4008 solver.cpp:247]     Train net output #0: loss = 1.33254 (* 1 = 1.33254 loss)
I0517 21:16:04.246031  4008 sgd_solver.cpp:106] Iteration 90200, lr = 0.001
I0517 21:16:04.405694  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1641	1.04167	70.5531	0	81.0039	3.64583	76.3584	0	70.9357	0	63.1884	0	53.6378	0	21.7318	1.4	
I0517 21:16:04.480289  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:16:04.481935  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:16:04.481986  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:16:04.491830  4008 solver.cpp:260]     Total regularization terms: 1.24663 loss+regular. : 2.57916
I0517 21:17:32.159353  4008 solver.cpp:231] Iteration 90400, loss = 1.41542
I0517 21:17:32.159669  4008 solver.cpp:247]     Train net output #0: loss = 1.41542 (* 1 = 1.41542 loss)
I0517 21:17:32.159694  4008 sgd_solver.cpp:106] Iteration 90400, lr = 0.001
I0517 21:17:32.320338  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.94892	1.04167	70.6341	0	81.0423	3.64583	76.4018	0	70.9742	0	63.2446	0	53.6898	0	21.7462	1.4	
I0517 21:17:32.394912  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:17:32.396747  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:17:32.396795  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:17:32.411808  4008 solver.cpp:260]     Total regularization terms: 1.24597 loss+regular. : 2.66139
I0517 21:18:55.289077  4008 solver.cpp:231] Iteration 90600, loss = 1.4967
I0517 21:18:55.289321  4008 solver.cpp:247]     Train net output #0: loss = 1.4967 (* 1 = 1.4967 loss)
I0517 21:18:55.289342  4008 sgd_solver.cpp:106] Iteration 90600, lr = 0.001
I0517 21:18:55.448779  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0522	1.04167	70.5384	0	81.0801	3.64583	76.4275	0	71.0214	0	63.3004	0	53.7426	0	21.7601	1.4	
I0517 21:18:55.523072  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:18:55.524943  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:18:55.524987  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:18:55.534910  4008 solver.cpp:260]     Total regularization terms: 1.24532 loss+regular. : 2.74203
I0517 21:19:18.695533  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:20:27.205445  4008 solver.cpp:231] Iteration 90800, loss = 1.34541
I0517 21:20:27.205762  4008 solver.cpp:247]     Train net output #0: loss = 1.34541 (* 1 = 1.34541 loss)
I0517 21:20:27.205790  4008 sgd_solver.cpp:106] Iteration 90800, lr = 0.001
I0517 21:20:27.366534  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1297	1.04167	70.554	0	81.0913	3.64583	76.4731	0	71.0546	0	63.3567	0	53.7959	0	21.7754	1.4	
I0517 21:20:27.441072  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:20:27.442996  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:20:27.443071  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:20:27.452940  4008 solver.cpp:260]     Total regularization terms: 1.24452 loss+regular. : 2.58992
I0517 21:21:57.371865  4008 solver.cpp:348] Iteration 91000, Testing net (#0)
I0517 21:22:53.191051  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:23:24.786655  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55336
I0517 21:23:24.789665  4008 solver.cpp:415]     Test net output #1: loss = 1.91867 (* 1 = 1.91867 loss)
I0517 21:23:24.954588  4008 solver.cpp:231] Iteration 91000, loss = 1.572
I0517 21:23:24.954679  4008 solver.cpp:247]     Train net output #0: loss = 1.572 (* 1 = 1.572 loss)
I0517 21:23:24.954717  4008 sgd_solver.cpp:106] Iteration 91000, lr = 0.001
I0517 21:23:25.118963  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0321	1.04167	70.6787	0	81.1303	3.64583	76.506	0	71.0985	0	63.4121	0	53.8478	0	21.7889	1.4	
I0517 21:23:25.193919  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:23:25.196153  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:23:25.196239  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:23:25.206624  4008 solver.cpp:260]     Total regularization terms: 1.24375 loss+regular. : 2.81575
I0517 21:25:05.351776  4008 solver.cpp:231] Iteration 91200, loss = 1.41571
I0517 21:25:05.352104  4008 solver.cpp:247]     Train net output #0: loss = 1.41571 (* 1 = 1.41571 loss)
I0517 21:25:05.352126  4008 sgd_solver.cpp:106] Iteration 91200, lr = 0.001
I0517 21:25:05.512367  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3048	1.04167	70.7331	0	81.1483	3.64583	76.5363	0	71.1326	0	63.4674	0	53.8998	0	21.8033	1.4	
I0517 21:25:05.586474  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:25:05.588138  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:25:05.588172  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:25:05.597970  4008 solver.cpp:260]     Total regularization terms: 1.24305 loss+regular. : 2.65876
I0517 21:26:34.063323  4008 solver.cpp:231] Iteration 91400, loss = 1.50747
I0517 21:26:34.064163  4008 solver.cpp:247]     Train net output #0: loss = 1.50747 (* 1 = 1.50747 loss)
I0517 21:26:34.064240  4008 sgd_solver.cpp:106] Iteration 91400, lr = 0.001
I0517 21:26:34.225353  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2703	1.04167	70.8571	0	81.1836	3.64583	76.569	0	71.1555	0	63.5223	0	53.9505	0	21.819	1.4	
I0517 21:26:34.300127  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:26:34.302389  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:26:34.302435  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:26:34.312432  4008 solver.cpp:260]     Total regularization terms: 1.24233 loss+regular. : 2.7498
I0517 21:27:57.977442  4008 solver.cpp:231] Iteration 91600, loss = 1.56527
I0517 21:27:57.978060  4008 solver.cpp:247]     Train net output #0: loss = 1.56527 (* 1 = 1.56527 loss)
I0517 21:27:57.978260  4008 sgd_solver.cpp:106] Iteration 91600, lr = 0.001
I0517 21:27:58.137393  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.9977	1.04167	70.7757	0	81.2164	3.64583	76.6118	0	71.2054	0	63.5774	0	54.002	0	21.8342	1.4	
I0517 21:27:58.211417  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:27:58.212688  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.4	
I0517 21:27:58.212726  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:27:58.222539  4008 solver.cpp:260]     Total regularization terms: 1.2416 loss+regular. : 2.80687
I0517 21:28:26.131387  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:29:32.250133  4008 solver.cpp:231] Iteration 91800, loss = 1.40818
I0517 21:29:32.250514  4008 solver.cpp:247]     Train net output #0: loss = 1.40818 (* 1 = 1.40818 loss)
I0517 21:29:32.250535  4008 sgd_solver.cpp:106] Iteration 91800, lr = 0.001
I0517 21:29:32.411372  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1383	1.04167	70.8887	0	81.2355	3.64583	76.6436	0	71.2466	0	63.6316	0	54.0543	0	21.8491	1.5	
I0517 21:29:32.487462  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:29:32.488807  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.5	
I0517 21:29:32.488849  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:29:32.498787  4008 solver.cpp:260]     Total regularization terms: 1.2409 loss+regular. : 2.64907
I0517 21:31:08.448247  4008 solver.cpp:348] Iteration 92000, Testing net (#0)
I0517 21:32:03.481297  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:32:33.020213  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55292
I0517 21:32:33.020298  4008 solver.cpp:415]     Test net output #1: loss = 1.92286 (* 1 = 1.92286 loss)
I0517 21:32:33.109282  4008 solver.cpp:231] Iteration 92000, loss = 1.40621
I0517 21:32:33.109377  4008 solver.cpp:247]     Train net output #0: loss = 1.40621 (* 1 = 1.40621 loss)
I0517 21:32:33.109401  4008 sgd_solver.cpp:106] Iteration 92000, lr = 0.001
I0517 21:32:33.275547  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2904	1.04167	70.681	0	81.2463	3.64583	76.6805	0	71.285	0	63.686	0	54.1056	0	21.8631	1.5	
I0517 21:32:33.354097  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:32:33.355271  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.5	
I0517 21:32:33.355304  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:32:33.365295  4008 solver.cpp:260]     Total regularization terms: 1.24023 loss+regular. : 2.64644
I0517 21:33:59.748605  4008 solver.cpp:231] Iteration 92200, loss = 1.48069
I0517 21:33:59.748914  4008 solver.cpp:247]     Train net output #0: loss = 1.48069 (* 1 = 1.48069 loss)
I0517 21:33:59.748953  4008 sgd_solver.cpp:106] Iteration 92200, lr = 0.001
I0517 21:33:59.909947  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1096	1.04167	70.8558	0	81.2934	3.64583	76.7278	0	71.3218	0	63.7403	0	54.1574	0	21.8762	1.5	
I0517 21:33:59.984349  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:33:59.986383  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.5	
I0517 21:33:59.986431  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:33:59.996354  4008 solver.cpp:260]     Total regularization terms: 1.23947 loss+regular. : 2.72016
I0517 21:35:25.577322  4008 solver.cpp:231] Iteration 92400, loss = 1.54574
I0517 21:35:25.578392  4008 solver.cpp:247]     Train net output #0: loss = 1.54574 (* 1 = 1.54574 loss)
I0517 21:35:25.578420  4008 sgd_solver.cpp:106] Iteration 92400, lr = 0.001
I0517 21:35:25.740643  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1928	1.04167	70.9977	0	81.3284	3.64583	76.7539	0	71.3463	0	63.7947	0	54.2093	0	21.8905	1.6	
I0517 21:35:25.815055  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:35:25.817164  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:35:25.817211  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:35:25.827301  4008 solver.cpp:260]     Total regularization terms: 1.23874 loss+regular. : 2.78448
I0517 21:37:07.349828  4008 solver.cpp:231] Iteration 92600, loss = 1.48001
I0517 21:37:07.350070  4008 solver.cpp:247]     Train net output #0: loss = 1.48001 (* 1 = 1.48001 loss)
I0517 21:37:07.350088  4008 sgd_solver.cpp:106] Iteration 92600, lr = 0.001
I0517 21:37:07.510182  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1814	1.04167	70.8949	0	81.3353	3.64583	76.7848	0	71.363	0	63.8488	0	54.2612	0	21.9052	1.6	
I0517 21:37:07.584414  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:37:07.585945  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:37:07.585986  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:37:07.596122  4008 solver.cpp:260]     Total regularization terms: 1.23803 loss+regular. : 2.71803
I0517 21:37:34.516767  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:38:34.148530  4008 solver.cpp:231] Iteration 92800, loss = 1.41092
I0517 21:38:34.151165  4008 solver.cpp:247]     Train net output #0: loss = 1.41092 (* 1 = 1.41092 loss)
I0517 21:38:34.151202  4008 sgd_solver.cpp:106] Iteration 92800, lr = 0.001
I0517 21:38:34.309890  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.19	1.04167	70.9163	0	81.3775	3.64583	76.814	0	71.408	0	63.9031	0	54.3122	0	21.919	1.6	
I0517 21:38:34.384153  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:38:34.385623  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:38:34.385661  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:38:34.395700  4008 solver.cpp:260]     Total regularization terms: 1.23731 loss+regular. : 2.64823
I0517 21:40:03.236156  4008 solver.cpp:348] Iteration 93000, Testing net (#0)
I0517 21:40:59.290920  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:41:31.829484  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55364
I0517 21:41:31.833703  4008 solver.cpp:415]     Test net output #1: loss = 1.91657 (* 1 = 1.91657 loss)
I0517 21:41:31.923758  4008 solver.cpp:231] Iteration 93000, loss = 1.40045
I0517 21:41:31.923842  4008 solver.cpp:247]     Train net output #0: loss = 1.40045 (* 1 = 1.40045 loss)
I0517 21:41:31.923862  4008 sgd_solver.cpp:106] Iteration 93000, lr = 0.001
I0517 21:41:32.091188  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0379	1.04167	70.8154	0	81.3835	3.64583	76.8297	0	71.4457	0	63.9575	0	54.3635	0	21.9326	1.6	
I0517 21:41:32.165446  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:41:32.166766  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:41:32.166810  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:41:32.176837  4008 solver.cpp:260]     Total regularization terms: 1.23662 loss+regular. : 2.63706
I0517 21:43:01.899116  4008 solver.cpp:231] Iteration 93200, loss = 1.42978
I0517 21:43:01.899399  4008 solver.cpp:247]     Train net output #0: loss = 1.42978 (* 1 = 1.42978 loss)
I0517 21:43:01.899420  4008 sgd_solver.cpp:106] Iteration 93200, lr = 0.001
I0517 21:43:02.059455  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1383	1.04167	70.8464	0	81.4206	3.64583	76.8754	0	71.476	0	64.0114	0	54.4158	0	21.9471	1.6	
I0517 21:43:02.133711  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:43:02.135615  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:43:02.135664  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:43:02.145596  4008 solver.cpp:260]     Total regularization terms: 1.23596 loss+regular. : 2.66574
I0517 21:44:35.921078  4008 solver.cpp:231] Iteration 93400, loss = 1.45852
I0517 21:44:35.921468  4008 solver.cpp:247]     Train net output #0: loss = 1.45852 (* 1 = 1.45852 loss)
I0517 21:44:35.921502  4008 sgd_solver.cpp:106] Iteration 93400, lr = 0.001
I0517 21:44:36.081643  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2502	1.04167	70.8447	0	81.4336	3.64583	76.882	0	71.5108	0	64.0654	0	54.466	0	21.9615	1.6	
I0517 21:44:36.155624  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:44:36.156934  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:44:36.156965  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:44:36.166759  4008 solver.cpp:260]     Total regularization terms: 1.23532 loss+regular. : 2.69384
I0517 21:46:04.799572  4008 solver.cpp:231] Iteration 93600, loss = 1.55309
I0517 21:46:04.799986  4008 solver.cpp:247]     Train net output #0: loss = 1.55309 (* 1 = 1.55309 loss)
I0517 21:46:04.800019  4008 sgd_solver.cpp:106] Iteration 93600, lr = 0.001
I0517 21:46:04.959802  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2502	1.04167	70.944	0	81.4724	3.64583	76.9283	0	71.5506	0	64.12	0	54.5169	0	21.9779	1.6	
I0517 21:46:05.034148  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:46:05.035776  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:46:05.035827  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:46:05.051075  4008 solver.cpp:260]     Total regularization terms: 1.23467 loss+regular. : 2.78777
I0517 21:46:32.837819  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:47:31.959831  4008 solver.cpp:231] Iteration 93800, loss = 1.76645
I0517 21:47:31.961669  4008 solver.cpp:247]     Train net output #0: loss = 1.76645 (* 1 = 1.76645 loss)
I0517 21:47:31.961707  4008 sgd_solver.cpp:106] Iteration 93800, lr = 0.001
I0517 21:47:32.121997  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2703	1.04167	71.0492	0	81.4858	3.64583	76.9708	0	71.5755	0	64.1732	0	54.5674	0	21.9921	1.6	
I0517 21:47:32.196092  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.564236	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:47:32.197104  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:47:32.197141  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:47:32.207128  4008 solver.cpp:260]     Total regularization terms: 1.23397 loss+regular. : 3.00041
I0517 21:48:56.528141  4008 solver.cpp:348] Iteration 94000, Testing net (#0)
I0517 21:49:55.622386  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:50:27.352171  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55272
I0517 21:50:27.352452  4008 solver.cpp:415]     Test net output #1: loss = 1.91842 (* 1 = 1.91842 loss)
I0517 21:50:27.440268  4008 solver.cpp:231] Iteration 94000, loss = 1.30993
I0517 21:50:27.440351  4008 solver.cpp:247]     Train net output #0: loss = 1.30993 (* 1 = 1.30993 loss)
I0517 21:50:27.440369  4008 sgd_solver.cpp:106] Iteration 94000, lr = 0.001
I0517 21:50:27.608420  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3162	1.04167	71.085	0	81.5239	3.64583	77.0113	0	71.6214	0	64.2273	0	54.6173	0	22.0058	1.6	
I0517 21:50:27.682677  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:50:27.684561  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:50:27.684607  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:50:27.694512  4008 solver.cpp:260]     Total regularization terms: 1.2332 loss+regular. : 2.54313
I0517 21:52:01.182248  4008 solver.cpp:231] Iteration 94200, loss = 1.54953
I0517 21:52:01.182708  4008 solver.cpp:247]     Train net output #0: loss = 1.54953 (* 1 = 1.54953 loss)
I0517 21:52:01.182759  4008 sgd_solver.cpp:106] Iteration 94200, lr = 0.001
I0517 21:52:01.343226  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3334	1.04167	71.2158	0	81.5575	3.64583	77.0307	0	71.6471	0	64.28	0	54.6675	0	22.0199	1.6	
I0517 21:52:01.417346  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:52:01.418726  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:52:01.418781  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:52:01.431550  4008 solver.cpp:260]     Total regularization terms: 1.23253 loss+regular. : 2.78206
I0517 21:53:36.820370  4008 solver.cpp:231] Iteration 94400, loss = 1.53341
I0517 21:53:36.820847  4008 solver.cpp:247]     Train net output #0: loss = 1.53341 (* 1 = 1.53341 loss)
I0517 21:53:36.820869  4008 sgd_solver.cpp:106] Iteration 94400, lr = 0.001
I0517 21:53:36.980283  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3019	1.04167	71.1494	0	81.5876	3.64583	77.0741	0	71.6853	0	64.3334	0	54.7168	0	22.0348	1.6	
I0517 21:53:37.054554  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:53:37.056318  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:53:37.056352  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:53:37.066134  4008 solver.cpp:260]     Total regularization terms: 1.23181 loss+regular. : 2.76522
I0517 21:55:12.663810  4008 solver.cpp:231] Iteration 94600, loss = 1.49596
I0517 21:55:12.665381  4008 solver.cpp:247]     Train net output #0: loss = 1.49596 (* 1 = 1.49596 loss)
I0517 21:55:12.665419  4008 sgd_solver.cpp:106] Iteration 94600, lr = 0.001
I0517 21:55:12.825759  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4568	1.04167	71.1748	0	81.6173	3.64583	77.121	0	71.724	0	64.3859	0	54.767	0	22.0484	1.6	
I0517 21:55:12.899832  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:55:12.900990  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:55:12.901022  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:55:12.910878  4008 solver.cpp:260]     Total regularization terms: 1.23109 loss+regular. : 2.72705
I0517 21:55:46.312247  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:56:40.563868  4008 solver.cpp:231] Iteration 94800, loss = 1.50185
I0517 21:56:40.565795  4008 solver.cpp:247]     Train net output #0: loss = 1.50185 (* 1 = 1.50185 loss)
I0517 21:56:40.565842  4008 sgd_solver.cpp:106] Iteration 94800, lr = 0.001
I0517 21:56:40.723917  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2531	1.04167	71.1097	0	81.6351	3.64583	77.1474	0	71.7606	0	64.4377	0	54.8176	0	22.0623	1.6	
I0517 21:56:40.798415  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:56:40.800551  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:56:40.800601  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:56:40.810645  4008 solver.cpp:260]     Total regularization terms: 1.23041 loss+regular. : 2.73226
I0517 21:58:09.566373  4008 solver.cpp:348] Iteration 95000, Testing net (#0)
I0517 21:59:10.561712  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 21:59:39.816434  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55392
I0517 21:59:39.816529  4008 solver.cpp:415]     Test net output #1: loss = 1.92007 (* 1 = 1.92007 loss)
I0517 21:59:39.904053  4008 solver.cpp:231] Iteration 95000, loss = 1.33829
I0517 21:59:39.904139  4008 solver.cpp:247]     Train net output #0: loss = 1.33829 (* 1 = 1.33829 loss)
I0517 21:59:39.904156  4008 sgd_solver.cpp:106] Iteration 95000, lr = 0.001
I0517 21:59:40.064616  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3794	1.04167	71.1051	0	81.6482	3.64583	77.1774	0	71.7864	0	64.4901	0	54.8673	0	22.076	1.6	
I0517 21:59:40.140949  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 21:59:40.142614  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 21:59:40.142659  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 21:59:40.156350  4008 solver.cpp:260]     Total regularization terms: 1.22974 loss+regular. : 2.56803
I0517 22:01:08.368234  4008 solver.cpp:231] Iteration 95200, loss = 1.32979
I0517 22:01:08.368574  4008 solver.cpp:247]     Train net output #0: loss = 1.32979 (* 1 = 1.32979 loss)
I0517 22:01:08.368593  4008 sgd_solver.cpp:106] Iteration 95200, lr = 0.001
I0517 22:01:08.529727  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2014	1.04167	71.2214	0	81.6857	3.64583	77.2074	0	71.8185	0	64.5422	0	54.9163	0	22.0898	1.6	
I0517 22:01:08.605664  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:01:08.607573  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:01:08.607617  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:01:08.621240  4008 solver.cpp:260]     Total regularization terms: 1.22898 loss+regular. : 2.55877
I0517 22:02:36.865934  4008 solver.cpp:231] Iteration 95400, loss = 1.53678
I0517 22:02:36.866178  4008 solver.cpp:247]     Train net output #0: loss = 1.53678 (* 1 = 1.53678 loss)
I0517 22:02:36.866199  4008 sgd_solver.cpp:106] Iteration 95400, lr = 0.001
I0517 22:02:37.027575  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3363	1.04167	71.2012	0	81.6933	3.64583	77.2449	0	71.8569	0	64.595	0	54.9655	0	22.1043	1.6	
I0517 22:02:37.101797  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:02:37.103653  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:02:37.103699  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:02:37.120594  4008 solver.cpp:260]     Total regularization terms: 1.22838 loss+regular. : 2.76516
I0517 22:04:10.155920  4008 solver.cpp:231] Iteration 95600, loss = 1.43762
I0517 22:04:10.156303  4008 solver.cpp:247]     Train net output #0: loss = 1.43762 (* 1 = 1.43762 loss)
I0517 22:04:10.156330  4008 sgd_solver.cpp:106] Iteration 95600, lr = 0.001
I0517 22:04:10.316534  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3908	1.04167	71.4743	0	81.7391	3.64583	77.2841	0	71.8965	0	64.647	0	55.0151	0	22.118	1.6	
I0517 22:04:10.390749  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:04:10.391963  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:04:10.391994  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:04:10.401806  4008 solver.cpp:260]     Total regularization terms: 1.22771 loss+regular. : 2.66534
I0517 22:04:46.615365  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:05:46.442558  4008 solver.cpp:231] Iteration 95800, loss = 1.37352
I0517 22:05:46.442916  4008 solver.cpp:247]     Train net output #0: loss = 1.37352 (* 1 = 1.37352 loss)
I0517 22:05:46.443027  4008 sgd_solver.cpp:106] Iteration 95800, lr = 0.001
I0517 22:05:46.601183  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3679	1.04167	71.3779	0	81.7714	3.64583	77.3198	0	71.9453	0	64.6984	0	55.0644	0	22.1309	1.6	
I0517 22:05:46.675851  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:05:46.677832  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:05:46.677893  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:05:46.688017  4008 solver.cpp:260]     Total regularization terms: 1.22704 loss+regular. : 2.60056
I0517 22:07:13.514808  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_96000.caffemodel
I0517 22:10:47.892010  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_96000.solverstate
I0517 22:10:48.423269  4008 solver.cpp:348] Iteration 96000, Testing net (#0)
I0517 22:11:41.436241  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:12:05.247164  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55468
I0517 22:12:05.247303  4008 solver.cpp:415]     Test net output #1: loss = 1.91388 (* 1 = 1.91388 loss)
I0517 22:12:05.334920  4008 solver.cpp:231] Iteration 96000, loss = 1.55498
I0517 22:12:05.334992  4008 solver.cpp:247]     Train net output #0: loss = 1.55498 (* 1 = 1.55498 loss)
I0517 22:12:05.335010  4008 sgd_solver.cpp:106] Iteration 96000, lr = 0.001
I0517 22:12:05.503120  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4482	1.04167	71.5156	0	81.7968	3.64583	77.3543	0	71.9763	0	64.7495	0	55.1143	0	22.146	1.6	
I0517 22:12:05.504235  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:12:05.505915  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:12:05.505955  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:12:05.515864  4008 solver.cpp:260]     Total regularization terms: 1.22621 loss+regular. : 2.78119
I0517 22:13:42.142154  4008 solver.cpp:231] Iteration 96200, loss = 1.3793
I0517 22:13:42.142501  4008 solver.cpp:247]     Train net output #0: loss = 1.3793 (* 1 = 1.3793 loss)
I0517 22:13:42.142534  4008 sgd_solver.cpp:106] Iteration 96200, lr = 0.001
I0517 22:13:42.300242  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2789	1.04167	71.5397	0	81.8012	3.64583	77.385	0	72.0149	0	64.8009	0	55.1632	0	22.1597	1.6	
I0517 22:13:42.375156  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:13:42.377460  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:13:42.377511  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:13:42.387656  4008 solver.cpp:260]     Total regularization terms: 1.22561 loss+regular. : 2.6049
I0517 22:15:11.579916  4008 solver.cpp:231] Iteration 96400, loss = 1.36816
I0517 22:15:11.581449  4008 solver.cpp:247]     Train net output #0: loss = 1.36816 (* 1 = 1.36816 loss)
I0517 22:15:11.581485  4008 sgd_solver.cpp:106] Iteration 96400, lr = 0.001
I0517 22:15:11.741173  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.94892	1.04167	71.5153	0	81.8498	3.64583	77.4149	0	72.0391	0	64.8524	0	55.2121	0	22.1738	1.6	
I0517 22:15:11.815850  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:15:11.816926  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:15:11.816969  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:15:11.829162  4008 solver.cpp:260]     Total regularization terms: 1.22489 loss+regular. : 2.59305
I0517 22:16:42.683218  4008 solver.cpp:231] Iteration 96600, loss = 1.51009
I0517 22:16:42.683928  4008 solver.cpp:247]     Train net output #0: loss = 1.51009 (* 1 = 1.51009 loss)
I0517 22:16:42.683966  4008 sgd_solver.cpp:106] Iteration 96600, lr = 0.001
I0517 22:16:42.843140  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1354	1.04167	71.5619	0	81.8622	3.64583	77.4375	0	72.0552	0	64.9037	0	55.2614	0	22.1877	1.6	
I0517 22:16:42.917439  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:16:42.919172  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:16:42.919226  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:16:42.929435  4008 solver.cpp:260]     Total regularization terms: 1.22422 loss+regular. : 2.73432
I0517 22:17:22.252284  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:18:09.654506  4008 solver.cpp:231] Iteration 96800, loss = 1.55554
I0517 22:18:09.654870  4008 solver.cpp:247]     Train net output #0: loss = 1.55554 (* 1 = 1.55554 loss)
I0517 22:18:09.654891  4008 sgd_solver.cpp:106] Iteration 96800, lr = 0.001
I0517 22:18:09.813849  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2158	1.04167	71.5599	0	81.8758	3.64583	77.463	0	72.1058	0	64.9552	0	55.3113	0	22.2012	1.6	
I0517 22:18:09.888124  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:18:09.889986  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:18:09.890029  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:18:09.900017  4008 solver.cpp:260]     Total regularization terms: 1.22349 loss+regular. : 2.77903
I0517 22:19:40.180341  4008 solver.cpp:348] Iteration 97000, Testing net (#0)
I0517 22:20:36.305230  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:21:04.380522  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55278
I0517 22:21:04.380609  4008 solver.cpp:415]     Test net output #1: loss = 1.92526 (* 1 = 1.92526 loss)
I0517 22:21:04.480202  4008 solver.cpp:231] Iteration 97000, loss = 1.55761
I0517 22:21:04.480331  4008 solver.cpp:247]     Train net output #0: loss = 1.55761 (* 1 = 1.55761 loss)
I0517 22:21:04.480367  4008 sgd_solver.cpp:106] Iteration 97000, lr = 0.001
I0517 22:21:04.651283  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.0981	1.04167	71.4147	0	81.9106	3.64583	77.4996	0	72.1381	0	65.0064	0	55.361	0	22.2148	1.6	
I0517 22:21:04.725658  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:21:04.727195  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:21:04.727244  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:21:04.740787  4008 solver.cpp:260]     Total regularization terms: 1.22291 loss+regular. : 2.78052
I0517 22:22:40.711513  4008 solver.cpp:231] Iteration 97200, loss = 1.46199
I0517 22:22:40.711838  4008 solver.cpp:247]     Train net output #0: loss = 1.46199 (* 1 = 1.46199 loss)
I0517 22:22:40.711869  4008 sgd_solver.cpp:106] Iteration 97200, lr = 0.001
I0517 22:22:40.870302  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.233	1.04167	71.6224	0	81.9342	3.64583	77.5389	0	72.1781	0	65.0566	0	55.4094	0	22.2285	1.6	
I0517 22:22:40.944732  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:22:40.946576  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:22:40.946617  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:22:40.956512  4008 solver.cpp:260]     Total regularization terms: 1.22222 loss+regular. : 2.68421
I0517 22:24:16.913089  4008 solver.cpp:231] Iteration 97400, loss = 1.48833
I0517 22:24:16.913595  4008 solver.cpp:247]     Train net output #0: loss = 1.48833 (* 1 = 1.48833 loss)
I0517 22:24:16.913636  4008 sgd_solver.cpp:106] Iteration 97400, lr = 0.001
I0517 22:24:17.073284  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4195	1.04167	71.5186	0	81.9629	3.64583	77.5754	0	72.2059	0	65.107	0	55.4589	0	22.241	1.6	
I0517 22:24:17.147822  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:24:17.149489  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:24:17.149547  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:24:17.159694  4008 solver.cpp:260]     Total regularization terms: 1.22159 loss+regular. : 2.70992
I0517 22:25:48.990741  4008 solver.cpp:231] Iteration 97600, loss = 1.40391
I0517 22:25:48.991103  4008 solver.cpp:247]     Train net output #0: loss = 1.40391 (* 1 = 1.40391 loss)
I0517 22:25:48.991127  4008 sgd_solver.cpp:106] Iteration 97600, lr = 0.001
I0517 22:25:49.149415  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.454	1.04167	71.6784	0	82.0036	3.64583	77.6003	0	72.2466	0	65.1583	0	55.5084	0	22.2549	1.6	
I0517 22:25:49.228631  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:25:49.230687  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:25:49.230743  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:25:49.241096  4008 solver.cpp:260]     Total regularization terms: 1.22091 loss+regular. : 2.62482
I0517 22:26:35.435667  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:27:22.862718  4008 solver.cpp:231] Iteration 97800, loss = 1.63464
I0517 22:27:22.863214  4008 solver.cpp:247]     Train net output #0: loss = 1.63464 (* 1 = 1.63464 loss)
I0517 22:27:22.863245  4008 sgd_solver.cpp:106] Iteration 97800, lr = 0.001
I0517 22:27:23.021973  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2273	1.04167	71.6777	0	82.0062	3.64583	77.6201	0	72.2753	0	65.2095	0	55.5561	0	22.2678	1.6	
I0517 22:27:23.096777  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:27:23.098836  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:27:23.098887  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:27:23.108958  4008 solver.cpp:260]     Total regularization terms: 1.22026 loss+regular. : 2.8549
I0517 22:28:52.609611  4008 solver.cpp:348] Iteration 98000, Testing net (#0)
I0517 22:29:51.611032  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:30:18.048198  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55294
I0517 22:30:18.048285  4008 solver.cpp:415]     Test net output #1: loss = 1.92438 (* 1 = 1.92438 loss)
I0517 22:30:18.136505  4008 solver.cpp:231] Iteration 98000, loss = 1.42732
I0517 22:30:18.136590  4008 solver.cpp:247]     Train net output #0: loss = 1.42732 (* 1 = 1.42732 loss)
I0517 22:30:18.136610  4008 sgd_solver.cpp:106] Iteration 98000, lr = 0.001
I0517 22:30:18.303932  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2789	1.04167	71.627	0	81.9997	3.64583	77.6369	0	72.3147	0	65.2602	0	55.6052	0	22.2816	1.6	
I0517 22:30:18.378329  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:30:18.380198  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:30:18.380240  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:30:18.390190  4008 solver.cpp:260]     Total regularization terms: 1.21966 loss+regular. : 2.64699
I0517 22:31:48.981626  4008 solver.cpp:231] Iteration 98200, loss = 1.59319
I0517 22:31:48.981940  4008 solver.cpp:247]     Train net output #0: loss = 1.59319 (* 1 = 1.59319 loss)
I0517 22:31:48.981961  4008 sgd_solver.cpp:106] Iteration 98200, lr = 0.001
I0517 22:31:49.142240  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2818	1.04167	71.8444	0	82.0702	3.64583	77.6747	0	72.3612	0	65.3117	0	55.6532	0	22.295	1.6	
I0517 22:31:49.216502  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:31:49.218330  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:31:49.218379  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:31:49.232492  4008 solver.cpp:260]     Total regularization terms: 1.21894 loss+regular. : 2.81213
I0517 22:33:18.276695  4008 solver.cpp:231] Iteration 98400, loss = 1.48623
I0517 22:33:18.277046  4008 solver.cpp:247]     Train net output #0: loss = 1.48623 (* 1 = 1.48623 loss)
I0517 22:33:18.277070  4008 sgd_solver.cpp:106] Iteration 98400, lr = 0.001
I0517 22:33:18.435858  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1928	1.04167	71.6338	0	82.0679	3.64583	77.7125	0	72.3737	0	65.3624	0	55.7015	0	22.3091	1.6	
I0517 22:33:18.510130  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:33:18.512089  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:33:18.512136  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:33:18.522181  4008 solver.cpp:260]     Total regularization terms: 1.21835 loss+regular. : 2.70458
I0517 22:34:47.051013  4008 solver.cpp:231] Iteration 98600, loss = 1.33659
I0517 22:34:47.051441  4008 solver.cpp:247]     Train net output #0: loss = 1.33659 (* 1 = 1.33659 loss)
I0517 22:34:47.051476  4008 sgd_solver.cpp:106] Iteration 98600, lr = 0.001
I0517 22:34:47.211125  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3019	1.04167	71.6224	0	82.0958	3.64583	77.7419	0	72.4189	0	65.4133	0	55.7495	0	22.3227	1.6	
I0517 22:34:47.285461  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:34:47.287348  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:34:47.287398  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:34:47.297435  4008 solver.cpp:260]     Total regularization terms: 1.21771 loss+regular. : 2.55429
I0517 22:35:35.062105  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:36:17.609172  4008 solver.cpp:231] Iteration 98800, loss = 1.40656
I0517 22:36:17.609581  4008 solver.cpp:247]     Train net output #0: loss = 1.40656 (* 1 = 1.40656 loss)
I0517 22:36:17.609613  4008 sgd_solver.cpp:106] Iteration 98800, lr = 0.001
I0517 22:36:17.768792  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4224	1.04167	71.6344	0	82.1286	3.64583	77.7725	0	72.4469	0	65.463	0	55.7975	0	22.3366	1.6	
I0517 22:36:17.842802  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:36:17.844060  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:36:17.844100  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:36:17.853890  4008 solver.cpp:260]     Total regularization terms: 1.21702 loss+regular. : 2.62358
I0517 22:37:48.627188  4008 solver.cpp:348] Iteration 99000, Testing net (#0)
I0517 22:38:45.227218  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:39:08.401618  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55224
I0517 22:39:08.401734  4008 solver.cpp:415]     Test net output #1: loss = 1.91469 (* 1 = 1.91469 loss)
I0517 22:39:08.491881  4008 solver.cpp:231] Iteration 99000, loss = 1.34897
I0517 22:39:08.492015  4008 solver.cpp:247]     Train net output #0: loss = 1.34897 (* 1 = 1.34897 loss)
I0517 22:39:08.492058  4008 sgd_solver.cpp:106] Iteration 99000, lr = 0.001
I0517 22:39:08.652024  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.1067	1.04167	71.7412	0	82.157	3.64583	77.7993	0	72.4802	0	65.5127	0	55.8456	0	22.3495	1.6	
I0517 22:39:08.728986  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:39:08.731575  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:39:08.731642  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:39:08.741833  4008 solver.cpp:260]     Total regularization terms: 1.21634 loss+regular. : 2.56531
I0517 22:40:37.089304  4008 solver.cpp:231] Iteration 99200, loss = 1.40748
I0517 22:40:37.089637  4008 solver.cpp:247]     Train net output #0: loss = 1.40748 (* 1 = 1.40748 loss)
I0517 22:40:37.089660  4008 sgd_solver.cpp:106] Iteration 99200, lr = 0.001
I0517 22:40:37.249529  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3851	1.04167	71.8877	0	82.1703	3.64583	77.8212	0	72.4953	0	65.5617	0	55.8937	0	22.3628	1.6	
I0517 22:40:37.323914  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:40:37.325507  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:40:37.325573  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:40:37.336000  4008 solver.cpp:260]     Total regularization terms: 1.21577 loss+regular. : 2.62324
I0517 22:42:09.150060  4008 solver.cpp:231] Iteration 99400, loss = 1.44808
I0517 22:42:09.152488  4008 solver.cpp:247]     Train net output #0: loss = 1.44808 (* 1 = 1.44808 loss)
I0517 22:42:09.152519  4008 sgd_solver.cpp:106] Iteration 99400, lr = 0.001
I0517 22:42:09.310057  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4339	1.04167	71.9303	0	82.2035	3.64583	77.8584	0	72.5376	0	65.6105	0	55.9417	0	22.376	1.6	
I0517 22:42:09.384392  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:42:09.386293  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:42:09.386342  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:42:09.396348  4008 solver.cpp:260]     Total regularization terms: 1.21509 loss+regular. : 2.66317
I0517 22:43:39.900820  4008 solver.cpp:231] Iteration 99600, loss = 1.4469
I0517 22:43:39.901240  4008 solver.cpp:247]     Train net output #0: loss = 1.4469 (* 1 = 1.4469 loss)
I0517 22:43:39.901273  4008 sgd_solver.cpp:106] Iteration 99600, lr = 0.001
I0517 22:43:40.061007  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3076	1.04167	71.8141	0	82.2326	3.64583	77.894	0	72.569	0	65.6603	0	55.9887	0	22.3908	1.6	
I0517 22:43:40.135130  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:43:40.136328  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:43:40.136368  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:43:40.146441  4008 solver.cpp:260]     Total regularization terms: 1.21441 loss+regular. : 2.66131
I0517 22:44:28.705847  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:45:09.860827  4008 solver.cpp:231] Iteration 99800, loss = 1.41928
I0517 22:45:09.861172  4008 solver.cpp:247]     Train net output #0: loss = 1.41928 (* 1 = 1.41928 loss)
I0517 22:45:09.861198  4008 sgd_solver.cpp:106] Iteration 99800, lr = 0.001
I0517 22:45:10.023293  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2732	1.04167	71.6214	0	82.2434	3.64583	77.9211	0	72.6072	0	65.7093	0	56.0364	0	22.4039	1.6	
I0517 22:45:10.097618  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:45:10.099560  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:45:10.099607  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:45:10.111601  4008 solver.cpp:260]     Total regularization terms: 1.21375 loss+regular. : 2.63303
I0517 22:46:40.541923  4008 solver.cpp:348] Iteration 100000, Testing net (#0)
I0517 22:47:36.240315  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:48:00.620573  4008 solver.cpp:415]     Test net output #0: accuracy = 0.550959
I0517 22:48:00.620715  4008 solver.cpp:415]     Test net output #1: loss = 1.9233 (* 1 = 1.9233 loss)
I0517 22:48:00.715651  4008 solver.cpp:231] Iteration 100000, loss = 1.41207
I0517 22:48:00.715764  4008 solver.cpp:247]     Train net output #0: loss = 1.41207 (* 1 = 1.41207 loss)
I0517 22:48:00.715783  4008 sgd_solver.cpp:106] Iteration 100000, lr = 0.001
I0517 22:48:00.875746  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5888	1.04167	71.8184	0	82.2639	3.64583	77.9443	0	72.6323	0	65.7588	0	56.0842	0	22.4172	1.6	
I0517 22:48:00.950527  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:48:00.951716  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:48:00.951745  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:48:00.961969  4008 solver.cpp:260]     Total regularization terms: 1.21305 loss+regular. : 2.62513
I0517 22:49:25.474323  4008 solver.cpp:231] Iteration 100200, loss = 1.41567
I0517 22:49:25.474827  4008 solver.cpp:247]     Train net output #0: loss = 1.41567 (* 1 = 1.41567 loss)
I0517 22:49:25.474853  4008 sgd_solver.cpp:106] Iteration 100200, lr = 0.001
I0517 22:49:25.633836  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2474	1.04167	71.5964	0	82.2677	3.64583	77.95	0	72.656	0	65.8082	0	56.1317	0	22.4304	1.6	
I0517 22:49:25.708340  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:49:25.709805  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:49:25.709857  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:49:25.719795  4008 solver.cpp:260]     Total regularization terms: 1.21239 loss+regular. : 2.62806
I0517 22:51:02.210752  4008 solver.cpp:231] Iteration 100400, loss = 1.51765
I0517 22:51:02.211064  4008 solver.cpp:247]     Train net output #0: loss = 1.51765 (* 1 = 1.51765 loss)
I0517 22:51:02.211082  4008 sgd_solver.cpp:106] Iteration 100400, lr = 0.001
I0517 22:51:02.370789  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4913	1.04167	71.8867	0	82.3115	3.64583	77.9925	0	72.6877	0	65.8575	0	56.1798	0	22.4443	1.6	
I0517 22:51:02.444960  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:51:02.446439  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:51:02.446503  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:51:02.459625  4008 solver.cpp:260]     Total regularization terms: 1.21179 loss+regular. : 2.72944
I0517 22:52:23.430894  4008 solver.cpp:231] Iteration 100600, loss = 1.28987
I0517 22:52:23.431363  4008 solver.cpp:247]     Train net output #0: loss = 1.28987 (* 1 = 1.28987 loss)
I0517 22:52:23.431393  4008 sgd_solver.cpp:106] Iteration 100600, lr = 0.001
I0517 22:52:23.591341  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3966	1.04167	71.9541	0	82.3395	3.64583	78.0126	0	72.7166	0	65.906	0	56.2273	0	22.4573	1.6	
I0517 22:52:23.666077  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:52:23.667765  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:52:23.667806  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:52:23.677872  4008 solver.cpp:260]     Total regularization terms: 1.2112 loss+regular. : 2.50107
I0517 22:53:11.267423  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:53:50.179494  4008 solver.cpp:231] Iteration 100800, loss = 1.23765
I0517 22:53:50.182031  4008 solver.cpp:247]     Train net output #0: loss = 1.23765 (* 1 = 1.23765 loss)
I0517 22:53:50.182075  4008 sgd_solver.cpp:106] Iteration 100800, lr = 0.001
I0517 22:53:50.341300  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3392	1.04167	72.0462	0	82.3718	3.64583	78.0475	0	72.751	0	65.9553	0	56.275	0	22.471	1.6	
I0517 22:53:50.415645  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:53:50.417848  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:53:50.417911  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:53:50.427738  4008 solver.cpp:260]     Total regularization terms: 1.21057 loss+regular. : 2.44822
I0517 22:55:21.661298  4008 solver.cpp:348] Iteration 101000, Testing net (#0)
I0517 22:56:24.078439  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 22:56:45.177131  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55226
I0517 22:56:45.177237  4008 solver.cpp:415]     Test net output #1: loss = 1.91713 (* 1 = 1.91713 loss)
I0517 22:56:45.267943  4008 solver.cpp:231] Iteration 101000, loss = 1.29439
I0517 22:56:45.268052  4008 solver.cpp:247]     Train net output #0: loss = 1.29439 (* 1 = 1.29439 loss)
I0517 22:56:45.268081  4008 sgd_solver.cpp:106] Iteration 101000, lr = 0.001
I0517 22:56:45.434221  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4999	1.04167	72.18	0	82.3972	3.64583	78.0564	0	72.7833	0	66.0039	0	56.3228	0	22.4847	1.6	
I0517 22:56:45.508934  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:56:45.510843  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:56:45.510900  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:56:45.521438  4008 solver.cpp:260]     Total regularization terms: 1.20987 loss+regular. : 2.50427
I0517 22:58:08.442960  4008 solver.cpp:231] Iteration 101200, loss = 1.48912
I0517 22:58:08.443364  4008 solver.cpp:247]     Train net output #0: loss = 1.48912 (* 1 = 1.48912 loss)
I0517 22:58:08.443402  4008 sgd_solver.cpp:106] Iteration 101200, lr = 0.001
I0517 22:58:08.604076  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4425	1.04167	72.1751	0	82.4126	3.64583	78.0971	0	72.7926	0	66.0521	0	56.3697	0	22.498	1.6	
I0517 22:58:08.678419  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:58:08.679551  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:58:08.679585  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:58:08.689591  4008 solver.cpp:260]     Total regularization terms: 1.20929 loss+regular. : 2.69841
I0517 22:59:34.924350  4008 solver.cpp:231] Iteration 101400, loss = 1.4858
I0517 22:59:34.927903  4008 solver.cpp:247]     Train net output #0: loss = 1.4858 (* 1 = 1.4858 loss)
I0517 22:59:34.927945  4008 sgd_solver.cpp:106] Iteration 101400, lr = 0.001
I0517 22:59:35.083107  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5171	1.04167	72.1182	0	82.4355	3.64583	78.109	0	72.8235	0	66.1005	0	56.4162	0	22.5111	1.6	
I0517 22:59:35.157419  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 22:59:35.158632  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 22:59:35.158680  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 22:59:35.168534  4008 solver.cpp:260]     Total regularization terms: 1.20875 loss+regular. : 2.69454
I0517 23:00:58.078073  4008 solver.cpp:231] Iteration 101600, loss = 1.67713
I0517 23:00:58.078572  4008 solver.cpp:247]     Train net output #0: loss = 1.67713 (* 1 = 1.67713 loss)
I0517 23:00:58.078593  4008 sgd_solver.cpp:106] Iteration 101600, lr = 0.001
I0517 23:00:58.238441  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5573	1.04167	72.1908	0	82.4566	3.64583	78.1518	0	72.8602	0	66.1485	0	56.4627	0	22.5238	1.6	
I0517 23:00:58.312891  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:00:58.314286  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:00:58.314330  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:00:58.329524  4008 solver.cpp:260]     Total regularization terms: 1.2081 loss+regular. : 2.88523
I0517 23:01:54.078593  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:02:26.973762  4008 solver.cpp:231] Iteration 101800, loss = 1.38391
I0517 23:02:26.974128  4008 solver.cpp:247]     Train net output #0: loss = 1.38391 (* 1 = 1.38391 loss)
I0517 23:02:26.974154  4008 sgd_solver.cpp:106] Iteration 101800, lr = 0.001
I0517 23:02:27.133733  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5688	1.04167	72.1595	0	82.4849	3.64583	78.1862	0	72.9036	0	66.1969	0	56.5098	0	22.5365	1.6	
I0517 23:02:27.207875  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:02:27.209326  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:02:27.209388  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:02:27.219509  4008 solver.cpp:260]     Total regularization terms: 1.20744 loss+regular. : 2.59135
I0517 23:03:53.621646  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_102000.caffemodel
I0517 23:07:19.076865  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_102000.solverstate
I0517 23:07:19.624197  4008 solver.cpp:348] Iteration 102000, Testing net (#0)
I0517 23:08:17.132171  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:08:40.307989  4008 solver.cpp:415]     Test net output #0: accuracy = 0.555839
I0517 23:08:40.308100  4008 solver.cpp:415]     Test net output #1: loss = 1.90807 (* 1 = 1.90807 loss)
I0517 23:08:40.398314  4008 solver.cpp:231] Iteration 102000, loss = 1.62145
I0517 23:08:40.398429  4008 solver.cpp:247]     Train net output #0: loss = 1.62145 (* 1 = 1.62145 loss)
I0517 23:08:40.398454  4008 sgd_solver.cpp:106] Iteration 102000, lr = 0.001
I0517 23:08:40.563036  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6175	1.04167	71.959	0	82.5004	3.64583	78.2172	0	72.9291	0	66.2447	0	56.556	0	22.5489	1.6	
I0517 23:08:40.564224  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:08:40.566045  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:08:40.566077  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:08:40.575973  4008 solver.cpp:260]     Total regularization terms: 1.2068 loss+regular. : 2.82825
I0517 23:10:11.377391  4008 solver.cpp:231] Iteration 102200, loss = 1.21042
I0517 23:10:11.377774  4008 solver.cpp:247]     Train net output #0: loss = 1.21042 (* 1 = 1.21042 loss)
I0517 23:10:11.377801  4008 sgd_solver.cpp:106] Iteration 102200, lr = 0.001
I0517 23:10:11.542911  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6204	1.04167	71.9395	0	82.5239	3.64583	78.2424	0	72.9641	0	66.2925	0	56.6029	0	22.5622	1.6	
I0517 23:10:11.617257  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:10:11.618949  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:10:11.618995  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:10:11.628962  4008 solver.cpp:260]     Total regularization terms: 1.20615 loss+regular. : 2.41657
I0517 23:11:38.676255  4008 solver.cpp:231] Iteration 102400, loss = 1.46333
I0517 23:11:38.676585  4008 solver.cpp:247]     Train net output #0: loss = 1.46333 (* 1 = 1.46333 loss)
I0517 23:11:38.676607  4008 sgd_solver.cpp:106] Iteration 102400, lr = 0.001
I0517 23:11:38.836174  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4999	1.04167	72.1771	0	82.55	3.64583	78.2655	0	72.9899	0	66.3399	0	56.649	0	22.5752	1.6	
I0517 23:11:38.910398  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:11:38.911780  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:11:38.911828  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:11:38.931787  4008 solver.cpp:260]     Total regularization terms: 1.20553 loss+regular. : 2.66886
I0517 23:13:02.387337  4008 solver.cpp:231] Iteration 102600, loss = 1.41957
I0517 23:13:02.389936  4008 solver.cpp:247]     Train net output #0: loss = 1.41957 (* 1 = 1.41957 loss)
I0517 23:13:02.389967  4008 sgd_solver.cpp:106] Iteration 102600, lr = 0.001
I0517 23:13:02.547677  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7208	1.04167	72.0924	0	82.5728	3.64583	78.2989	0	73.0195	0	66.3874	0	56.6952	0	22.5884	1.6	
I0517 23:13:02.621727  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:13:02.623178  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:13:02.623220  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:13:02.633044  4008 solver.cpp:260]     Total regularization terms: 1.20494 loss+regular. : 2.62451
I0517 23:13:58.163521  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:14:30.218114  4008 solver.cpp:231] Iteration 102800, loss = 1.52744
I0517 23:14:30.218538  4008 solver.cpp:247]     Train net output #0: loss = 1.52744 (* 1 = 1.52744 loss)
I0517 23:14:30.218561  4008 sgd_solver.cpp:106] Iteration 102800, lr = 0.001
I0517 23:14:30.380717  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3048	1.04167	72.3109	0	82.6013	3.64583	78.3256	0	73.0489	0	66.4349	0	56.7405	0	22.6007	1.6	
I0517 23:14:30.454807  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:14:30.456269  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:14:30.456315  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:14:30.466183  4008 solver.cpp:260]     Total regularization terms: 1.20432 loss+regular. : 2.73175
I0517 23:15:52.676774  4008 solver.cpp:348] Iteration 103000, Testing net (#0)
I0517 23:16:50.538869  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:17:11.682751  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55348
I0517 23:17:11.682859  4008 solver.cpp:415]     Test net output #1: loss = 1.91848 (* 1 = 1.91848 loss)
I0517 23:17:11.770381  4008 solver.cpp:231] Iteration 103000, loss = 1.6016
I0517 23:17:11.770469  4008 solver.cpp:247]     Train net output #0: loss = 1.6016 (* 1 = 1.6016 loss)
I0517 23:17:11.770489  4008 sgd_solver.cpp:106] Iteration 103000, lr = 0.001
I0517 23:17:11.937894  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.563	1.04167	72.1657	0	82.5971	3.64583	78.3309	0	73.0602	0	66.482	0	56.7875	0	22.6137	1.6	
I0517 23:17:12.012085  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:17:12.014168  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:17:12.014253  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:17:12.024307  4008 solver.cpp:260]     Total regularization terms: 1.20371 loss+regular. : 2.80531
I0517 23:18:35.929231  4008 solver.cpp:231] Iteration 103200, loss = 1.50913
I0517 23:18:35.929520  4008 solver.cpp:247]     Train net output #0: loss = 1.50913 (* 1 = 1.50913 loss)
I0517 23:18:35.929543  4008 sgd_solver.cpp:106] Iteration 103200, lr = 0.001
I0517 23:18:36.089090  4008 sgd_solver.cpp:120]     Element Sparsity %: 
9.94318	1.04167	71.832	0	82.6269	3.64583	78.3593	0	73.1118	0	66.5296	0	56.8349	0	22.6259	1.6	
I0517 23:18:36.163139  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:18:36.164563  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:18:36.164618  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:18:36.174688  4008 solver.cpp:260]     Total regularization terms: 1.20312 loss+regular. : 2.71226
I0517 23:20:04.040604  4008 solver.cpp:231] Iteration 103400, loss = 1.47676
I0517 23:20:04.040930  4008 solver.cpp:247]     Train net output #0: loss = 1.47676 (* 1 = 1.47676 loss)
I0517 23:20:04.040953  4008 sgd_solver.cpp:106] Iteration 103400, lr = 0.001
I0517 23:20:04.198398  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4597	1.04167	72.3558	0	82.6658	3.64583	78.4027	0	73.1436	0	66.5763	0	56.8812	0	22.6385	1.6	
I0517 23:20:04.272661  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:20:04.274152  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:20:04.274196  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:20:04.284261  4008 solver.cpp:260]     Total regularization terms: 1.20247 loss+regular. : 2.67922
I0517 23:21:34.869637  4008 solver.cpp:231] Iteration 103600, loss = 1.42513
I0517 23:21:34.869973  4008 solver.cpp:247]     Train net output #0: loss = 1.42513 (* 1 = 1.42513 loss)
I0517 23:21:34.869997  4008 sgd_solver.cpp:106] Iteration 103600, lr = 0.001
I0517 23:21:35.035668  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6089	1.04167	72.2809	0	82.6865	3.64583	78.4376	0	73.1823	0	66.6233	0	56.9267	0	22.6505	1.6	
I0517 23:21:35.111042  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:21:35.112869  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:21:35.112908  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:21:35.122843  4008 solver.cpp:260]     Total regularization terms: 1.20186 loss+regular. : 2.62699
I0517 23:22:36.738978  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:23:05.519924  4008 solver.cpp:231] Iteration 103800, loss = 1.25244
I0517 23:23:05.520048  4008 solver.cpp:247]     Train net output #0: loss = 1.25244 (* 1 = 1.25244 loss)
I0517 23:23:05.520076  4008 sgd_solver.cpp:106] Iteration 103800, lr = 0.001
I0517 23:23:05.679986  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5286	1.04167	72.1406	0	82.6847	3.64583	78.4526	0	73.2029	0	66.6699	0	56.9726	0	22.663	1.6	
I0517 23:23:05.754465  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:23:05.756175  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:23:05.756212  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:23:05.766499  4008 solver.cpp:260]     Total regularization terms: 1.20131 loss+regular. : 2.45375
I0517 23:24:36.693547  4008 solver.cpp:348] Iteration 104000, Testing net (#0)
I0517 23:25:35.026521  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:25:56.290191  4008 solver.cpp:415]     Test net output #0: accuracy = 0.551419
I0517 23:25:56.290303  4008 solver.cpp:415]     Test net output #1: loss = 1.92972 (* 1 = 1.92972 loss)
I0517 23:25:56.378514  4008 solver.cpp:231] Iteration 104000, loss = 1.28916
I0517 23:25:56.378675  4008 solver.cpp:247]     Train net output #0: loss = 1.28916 (* 1 = 1.28916 loss)
I0517 23:25:56.378710  4008 sgd_solver.cpp:106] Iteration 104000, lr = 0.001
I0517 23:25:56.546444  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6032	1.04167	72.2409	0	82.7131	3.64583	78.4888	0	73.225	0	66.7167	0	57.0187	0	22.6759	1.6	
I0517 23:25:56.620874  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:25:56.622829  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:25:56.622891  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:25:56.633055  4008 solver.cpp:260]     Total regularization terms: 1.20066 loss+regular. : 2.48982
I0517 23:27:20.164216  4008 solver.cpp:231] Iteration 104200, loss = 1.45566
I0517 23:27:20.164568  4008 solver.cpp:247]     Train net output #0: loss = 1.45566 (* 1 = 1.45566 loss)
I0517 23:27:20.164587  4008 sgd_solver.cpp:106] Iteration 104200, lr = 0.001
I0517 23:27:20.324504  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7008	1.04167	72.3577	0	82.7573	3.64583	78.5107	0	73.2496	0	66.763	0	57.0634	0	22.6893	1.6	
I0517 23:27:20.398877  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:27:20.400169  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:27:20.400208  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:27:20.415531  4008 solver.cpp:260]     Total regularization terms: 1.20005 loss+regular. : 2.65571
I0517 23:28:47.139178  4008 solver.cpp:231] Iteration 104400, loss = 1.55804
I0517 23:28:47.139521  4008 solver.cpp:247]     Train net output #0: loss = 1.55804 (* 1 = 1.55804 loss)
I0517 23:28:47.139544  4008 sgd_solver.cpp:106] Iteration 104400, lr = 0.001
I0517 23:28:47.298790  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3392	1.04167	72.4144	0	82.7766	3.64583	78.5459	0	73.2849	0	66.8086	0	57.1093	0	22.7015	1.6	
I0517 23:28:47.372956  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:28:47.374518  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:28:47.374567  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:28:47.386057  4008 solver.cpp:260]     Total regularization terms: 1.19945 loss+regular. : 2.75749
I0517 23:30:12.980121  4008 solver.cpp:231] Iteration 104600, loss = 1.45118
I0517 23:30:12.980702  4008 solver.cpp:247]     Train net output #0: loss = 1.45118 (* 1 = 1.45118 loss)
I0517 23:30:12.980732  4008 sgd_solver.cpp:106] Iteration 104600, lr = 0.001
I0517 23:30:13.140260  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5286	1.04167	72.5003	0	82.792	3.64583	78.5718	0	73.3129	0	66.8554	0	57.1535	0	22.7152	1.6	
I0517 23:30:13.214680  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:30:13.216292  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:30:13.216343  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:30:13.231715  4008 solver.cpp:260]     Total regularization terms: 1.19879 loss+regular. : 2.64997
I0517 23:31:15.913946  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:31:37.739919  4008 solver.cpp:231] Iteration 104800, loss = 1.31204
I0517 23:31:37.740041  4008 solver.cpp:247]     Train net output #0: loss = 1.31204 (* 1 = 1.31204 loss)
I0517 23:31:37.740070  4008 sgd_solver.cpp:106] Iteration 104800, lr = 0.001
I0517 23:31:37.899304  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5515	1.04167	72.4974	0	82.8184	3.64583	78.6092	0	73.3475	0	66.9018	0	57.1992	0	22.7288	1.6	
I0517 23:31:37.973948  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:31:37.975309  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:31:37.975364  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:31:37.990402  4008 solver.cpp:260]     Total regularization terms: 1.19818 loss+regular. : 2.51022
I0517 23:33:03.074349  4008 solver.cpp:348] Iteration 105000, Testing net (#0)
I0517 23:34:02.531532  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:34:24.227486  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5539
I0517 23:34:24.227625  4008 solver.cpp:415]     Test net output #1: loss = 1.9107 (* 1 = 1.9107 loss)
I0517 23:34:24.319947  4008 solver.cpp:231] Iteration 105000, loss = 1.43689
I0517 23:34:24.320071  4008 solver.cpp:247]     Train net output #0: loss = 1.43689 (* 1 = 1.43689 loss)
I0517 23:34:24.320096  4008 sgd_solver.cpp:106] Iteration 105000, lr = 0.001
I0517 23:34:24.480490  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4511	1.04167	72.4938	0	82.8323	3.64583	78.6199	0	73.3591	0	66.9479	0	57.2445	0	22.7421	1.6	
I0517 23:34:24.558835  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:34:24.560636  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:34:24.560683  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:34:24.583605  4008 solver.cpp:260]     Total regularization terms: 1.19756 loss+regular. : 2.63445
I0517 23:35:58.566705  4008 solver.cpp:231] Iteration 105200, loss = 1.31007
I0517 23:35:58.567018  4008 solver.cpp:247]     Train net output #0: loss = 1.31007 (* 1 = 1.31007 loss)
I0517 23:35:58.567039  4008 sgd_solver.cpp:106] Iteration 105200, lr = 0.001
I0517 23:35:58.727351  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3478	1.04167	72.4085	0	82.8551	3.64583	78.6654	0	73.407	0	66.9938	0	57.2899	0	22.7553	1.6	
I0517 23:35:58.805675  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:35:58.807093  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:35:58.807137  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:35:58.822505  4008 solver.cpp:260]     Total regularization terms: 1.19693 loss+regular. : 2.50701
I0517 23:37:30.612007  4008 solver.cpp:231] Iteration 105400, loss = 1.34342
I0517 23:37:30.612432  4008 solver.cpp:247]     Train net output #0: loss = 1.34342 (* 1 = 1.34342 loss)
I0517 23:37:30.612459  4008 sgd_solver.cpp:106] Iteration 105400, lr = 0.001
I0517 23:37:30.771092  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2674	1.04167	72.2822	0	82.8522	3.64583	78.6751	0	73.4339	0	67.0403	0	57.3359	0	22.7684	1.6	
I0517 23:37:30.845391  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:37:30.846534  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:37:30.846582  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:37:30.860904  4008 solver.cpp:260]     Total regularization terms: 1.19645 loss+regular. : 2.53987
I0517 23:38:52.275473  4008 solver.cpp:231] Iteration 105600, loss = 1.39048
I0517 23:38:52.275810  4008 solver.cpp:247]     Train net output #0: loss = 1.39048 (* 1 = 1.39048 loss)
I0517 23:38:52.275837  4008 sgd_solver.cpp:106] Iteration 105600, lr = 0.001
I0517 23:38:52.436444  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4741	1.04167	72.5563	0	82.8838	3.64583	78.7109	0	73.4576	0	67.0861	0	57.3806	0	22.7814	1.6	
I0517 23:38:52.510805  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:38:52.512164  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:38:52.512207  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:38:52.542103  4008 solver.cpp:260]     Total regularization terms: 1.19588 loss+regular. : 2.58636
I0517 23:40:00.025380  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:40:20.616534  4008 solver.cpp:231] Iteration 105800, loss = 1.47709
I0517 23:40:20.616658  4008 solver.cpp:247]     Train net output #0: loss = 1.47709 (* 1 = 1.47709 loss)
I0517 23:40:20.616683  4008 sgd_solver.cpp:106] Iteration 105800, lr = 0.001
I0517 23:40:20.777029  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5028	1.04167	72.3206	0	82.9071	3.64583	78.7424	0	73.5087	0	67.1323	0	57.4256	0	22.7931	1.6	
I0517 23:40:20.851974  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:40:20.854426  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:40:20.854511  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:40:20.864822  4008 solver.cpp:260]     Total regularization terms: 1.19532 loss+regular. : 2.67241
I0517 23:41:50.317198  4008 solver.cpp:348] Iteration 106000, Testing net (#0)
I0517 23:42:52.384258  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:43:14.132292  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55072
I0517 23:43:14.132416  4008 solver.cpp:415]     Test net output #1: loss = 1.93291 (* 1 = 1.93291 loss)
I0517 23:43:14.221968  4008 solver.cpp:231] Iteration 106000, loss = 1.42095
I0517 23:43:14.222056  4008 solver.cpp:247]     Train net output #0: loss = 1.42095 (* 1 = 1.42095 loss)
I0517 23:43:14.222079  4008 sgd_solver.cpp:106] Iteration 106000, lr = 0.001
I0517 23:43:14.390961  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3794	1.04167	72.5527	0	82.9436	3.64583	78.7732	0	73.511	0	67.1777	0	57.4704	0	22.8053	1.6	
I0517 23:43:14.466816  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:43:14.467958  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:43:14.467999  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:43:14.477960  4008 solver.cpp:260]     Total regularization terms: 1.19467 loss+regular. : 2.61562
I0517 23:44:40.176400  4008 solver.cpp:231] Iteration 106200, loss = 1.31092
I0517 23:44:40.176730  4008 solver.cpp:247]     Train net output #0: loss = 1.31092 (* 1 = 1.31092 loss)
I0517 23:44:40.176749  4008 sgd_solver.cpp:106] Iteration 106200, lr = 0.001
I0517 23:44:40.335827  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4568	1.04167	72.6178	0	82.9519	3.64583	78.7964	0	73.5715	0	67.2236	0	57.5152	0	22.818	1.6	
I0517 23:44:40.409968  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:44:40.411530  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:44:40.411586  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:44:40.426770  4008 solver.cpp:260]     Total regularization terms: 1.19411 loss+regular. : 2.50503
I0517 23:46:05.040043  4008 solver.cpp:231] Iteration 106400, loss = 1.27938
I0517 23:46:05.040637  4008 solver.cpp:247]     Train net output #0: loss = 1.27938 (* 1 = 1.27938 loss)
I0517 23:46:05.040666  4008 sgd_solver.cpp:106] Iteration 106400, lr = 0.001
I0517 23:46:05.201345  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6577	1.04167	72.7087	0	82.9903	3.64583	78.8187	0	73.5962	0	67.2683	0	57.5593	0	22.8302	1.6	
I0517 23:46:05.275598  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:46:05.276976  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:46:05.277026  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:46:05.306350  4008 solver.cpp:260]     Total regularization terms: 1.19358 loss+regular. : 2.47297
I0517 23:47:32.269127  4008 solver.cpp:231] Iteration 106600, loss = 1.27589
I0517 23:47:32.270010  4008 solver.cpp:247]     Train net output #0: loss = 1.27589 (* 1 = 1.27589 loss)
I0517 23:47:32.270040  4008 sgd_solver.cpp:106] Iteration 106600, lr = 0.001
I0517 23:47:32.429097  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5028	1.04167	72.7663	0	83.0114	3.64583	78.8455	0	73.6308	0	67.3136	0	57.6038	0	22.8434	1.6	
I0517 23:47:32.503286  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:47:32.504748  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:47:32.504798  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:47:32.514910  4008 solver.cpp:260]     Total regularization terms: 1.193 loss+regular. : 2.4689
I0517 23:48:41.013902  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:48:58.855314  4008 solver.cpp:231] Iteration 106800, loss = 1.52338
I0517 23:48:58.855458  4008 solver.cpp:247]     Train net output #0: loss = 1.52338 (* 1 = 1.52338 loss)
I0517 23:48:58.855479  4008 sgd_solver.cpp:106] Iteration 106800, lr = 0.001
I0517 23:48:59.015578  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6778	1.04167	72.6338	0	83.0155	3.64583	78.8689	0	73.6565	0	67.3586	0	57.6492	0	22.856	1.6	
I0517 23:48:59.089644  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:48:59.091092  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:48:59.091138  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:48:59.102720  4008 solver.cpp:260]     Total regularization terms: 1.19242 loss+regular. : 2.7158
I0517 23:50:27.643004  4008 solver.cpp:348] Iteration 107000, Testing net (#0)
I0517 23:51:38.208243  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:51:58.539338  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5533
I0517 23:51:58.539441  4008 solver.cpp:415]     Test net output #1: loss = 1.92545 (* 1 = 1.92545 loss)
I0517 23:51:58.643717  4008 solver.cpp:231] Iteration 107000, loss = 1.46022
I0517 23:51:58.643836  4008 solver.cpp:247]     Train net output #0: loss = 1.46022 (* 1 = 1.46022 loss)
I0517 23:51:58.643859  4008 sgd_solver.cpp:106] Iteration 107000, lr = 0.001
I0517 23:51:58.802889  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3421	1.04167	72.6328	0	83.0309	3.64583	78.8848	0	73.6819	0	67.4044	0	57.6924	0	22.8687	1.6	
I0517 23:51:58.877328  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:51:58.878510  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:51:58.878546  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:51:58.888453  4008 solver.cpp:260]     Total regularization terms: 1.1919 loss+regular. : 2.65212
I0517 23:53:31.350170  4008 solver.cpp:231] Iteration 107200, loss = 1.72576
I0517 23:53:31.350545  4008 solver.cpp:247]     Train net output #0: loss = 1.72576 (* 1 = 1.72576 loss)
I0517 23:53:31.350566  4008 sgd_solver.cpp:106] Iteration 107200, lr = 0.001
I0517 23:53:31.509605  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3392	1.04167	72.8529	0	83.0829	3.64583	78.915	0	73.7058	0	67.4488	0	57.7368	0	22.8804	1.6	
I0517 23:53:31.583617  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:53:31.584877  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:53:31.584916  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:53:31.594735  4008 solver.cpp:260]     Total regularization terms: 1.1913 loss+regular. : 2.91706
I0517 23:54:54.145190  4008 solver.cpp:231] Iteration 107400, loss = 1.39752
I0517 23:54:54.145539  4008 solver.cpp:247]     Train net output #0: loss = 1.39752 (* 1 = 1.39752 loss)
I0517 23:54:54.145575  4008 sgd_solver.cpp:106] Iteration 107400, lr = 0.001
I0517 23:54:54.306774  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5429	1.04167	72.8171	0	83.0908	3.64583	78.945	0	73.7375	0	67.4939	0	57.781	0	22.8929	1.6	
I0517 23:54:54.381057  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:54:54.382938  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:54:54.382992  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:54:54.393473  4008 solver.cpp:260]     Total regularization terms: 1.19073 loss+regular. : 2.58825
I0517 23:56:21.312443  4008 solver.cpp:231] Iteration 107600, loss = 1.56051
I0517 23:56:21.312705  4008 solver.cpp:247]     Train net output #0: loss = 1.56051 (* 1 = 1.56051 loss)
I0517 23:56:21.312729  4008 sgd_solver.cpp:106] Iteration 107600, lr = 0.001
I0517 23:56:21.472368  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4769	1.04167	72.6357	0	83.0987	3.64583	78.9658	0	73.7569	0	67.5387	0	57.826	0	22.9058	1.6	
I0517 23:56:21.546577  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:56:21.548071  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:56:21.548121  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:56:21.558017  4008 solver.cpp:260]     Total regularization terms: 1.19013 loss+regular. : 2.75064
I0517 23:57:30.517344  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0517 23:57:44.400522  4008 solver.cpp:231] Iteration 107800, loss = 1.62009
I0517 23:57:44.400610  4008 solver.cpp:247]     Train net output #0: loss = 1.62009 (* 1 = 1.62009 loss)
I0517 23:57:44.400631  4008 sgd_solver.cpp:106] Iteration 107800, lr = 0.001
I0517 23:57:44.559501  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6376	1.04167	72.8783	0	83.1234	3.64583	78.9903	0	73.7906	0	67.5834	0	57.8693	0	22.9194	1.6	
I0517 23:57:44.633644  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0517 23:57:44.635041  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0517 23:57:44.635072  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0517 23:57:44.645057  4008 solver.cpp:260]     Total regularization terms: 1.18955 loss+regular. : 2.80964
I0517 23:59:15.513454  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_108000.caffemodel
I0518 00:02:09.572662  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_108000.solverstate
I0518 00:02:10.419834  4008 solver.cpp:348] Iteration 108000, Testing net (#0)
I0518 00:03:16.771590  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:03:38.152495  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55498
I0518 00:03:38.152603  4008 solver.cpp:415]     Test net output #1: loss = 1.92469 (* 1 = 1.92469 loss)
I0518 00:03:38.240128  4008 solver.cpp:231] Iteration 108000, loss = 1.36858
I0518 00:03:38.240219  4008 solver.cpp:247]     Train net output #0: loss = 1.36858 (* 1 = 1.36858 loss)
I0518 00:03:38.240236  4008 sgd_solver.cpp:106] Iteration 108000, lr = 0.001
I0518 00:03:38.408095  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5028	1.04167	72.9398	0	83.1368	3.64583	79.0261	0	73.8207	0	67.6279	0	57.9137	0	22.9321	1.6	
I0518 00:03:38.408962  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:03:38.410351  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:03:38.410382  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:03:38.420188  4008 solver.cpp:260]     Total regularization terms: 1.18895 loss+regular. : 2.55753
I0518 00:05:06.669323  4008 solver.cpp:231] Iteration 108200, loss = 1.33532
I0518 00:05:06.669623  4008 solver.cpp:247]     Train net output #0: loss = 1.33532 (* 1 = 1.33532 loss)
I0518 00:05:06.669646  4008 sgd_solver.cpp:106] Iteration 108200, lr = 0.001
I0518 00:05:06.830538  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4511	1.04167	72.8037	0	83.1646	3.64583	79.0511	0	73.8408	0	67.6719	0	57.9578	0	22.946	1.6	
I0518 00:05:06.907922  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:05:06.909466  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:05:06.909509  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:05:06.919303  4008 solver.cpp:260]     Total regularization terms: 1.1884 loss+regular. : 2.52372
I0518 00:06:30.308006  4008 solver.cpp:231] Iteration 108400, loss = 1.42527
I0518 00:06:30.308336  4008 solver.cpp:247]     Train net output #0: loss = 1.42527 (* 1 = 1.42527 loss)
I0518 00:06:30.308357  4008 sgd_solver.cpp:106] Iteration 108400, lr = 0.001
I0518 00:06:30.469890  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7553	1.04167	72.8594	0	83.1887	3.64583	79.0848	0	73.8738	0	67.716	0	58.001	0	22.9583	1.6	
I0518 00:06:30.544003  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:06:30.545521  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:06:30.545586  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:06:30.555661  4008 solver.cpp:260]     Total regularization terms: 1.18781 loss+regular. : 2.61308
I0518 00:07:59.024072  4008 solver.cpp:231] Iteration 108600, loss = 1.40506
I0518 00:07:59.024375  4008 solver.cpp:247]     Train net output #0: loss = 1.40506 (* 1 = 1.40506 loss)
I0518 00:07:59.024401  4008 sgd_solver.cpp:106] Iteration 108600, lr = 0.001
I0518 00:07:59.185130  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5515	1.04167	72.9443	0	83.1931	3.64583	79.0921	0	73.8962	0	67.7603	0	58.0445	0	22.9715	1.6	
I0518 00:07:59.259166  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:07:59.260673  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:07:59.260710  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:07:59.270563  4008 solver.cpp:260]     Total regularization terms: 1.18726 loss+regular. : 2.59232
I0518 00:09:14.029639  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:09:27.534366  4008 solver.cpp:231] Iteration 108800, loss = 1.40123
I0518 00:09:27.534466  4008 solver.cpp:247]     Train net output #0: loss = 1.40123 (* 1 = 1.40123 loss)
I0518 00:09:27.534488  4008 sgd_solver.cpp:106] Iteration 108800, lr = 0.001
I0518 00:09:27.696857  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.3105	1.04167	72.8493	0	83.1995	3.64583	79.0985	0	73.8846	0	67.8046	0	58.0892	0	22.9838	1.6	
I0518 00:09:27.771919  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:09:27.773429  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:09:27.773474  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:09:27.794631  4008 solver.cpp:260]     Total regularization terms: 1.18673 loss+regular. : 2.58796
I0518 00:10:56.578083  4008 solver.cpp:348] Iteration 109000, Testing net (#0)
I0518 00:12:04.062903  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:12:22.558663  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55098
I0518 00:12:22.558760  4008 solver.cpp:415]     Test net output #1: loss = 1.92932 (* 1 = 1.92932 loss)
I0518 00:12:22.646337  4008 solver.cpp:231] Iteration 109000, loss = 1.63679
I0518 00:12:22.646431  4008 solver.cpp:247]     Train net output #0: loss = 1.63679 (* 1 = 1.63679 loss)
I0518 00:12:22.646452  4008 sgd_solver.cpp:106] Iteration 109000, lr = 0.001
I0518 00:12:22.810360  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4741	1.04167	72.917	0	83.2507	3.64583	79.1445	0	73.9226	0	67.8483	0	58.1329	0	22.9965	1.6	
I0518 00:12:22.884598  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:12:22.886119  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:12:22.886162  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:12:22.896059  4008 solver.cpp:260]     Total regularization terms: 1.18613 loss+regular. : 2.82292
I0518 00:13:47.114636  4008 solver.cpp:231] Iteration 109200, loss = 1.57051
I0518 00:13:47.114984  4008 solver.cpp:247]     Train net output #0: loss = 1.57051 (* 1 = 1.57051 loss)
I0518 00:13:47.115006  4008 sgd_solver.cpp:106] Iteration 109200, lr = 0.001
I0518 00:13:47.275497  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7295	1.04167	72.903	0	83.2358	3.64583	79.1552	0	73.938	0	67.8918	0	58.1763	0	23.0094	1.6	
I0518 00:13:47.349480  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:13:47.350989  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:13:47.351038  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:13:47.361275  4008 solver.cpp:260]     Total regularization terms: 1.18562 loss+regular. : 2.75613
I0518 00:15:14.678191  4008 solver.cpp:231] Iteration 109400, loss = 1.42598
I0518 00:15:14.678477  4008 solver.cpp:247]     Train net output #0: loss = 1.42598 (* 1 = 1.42598 loss)
I0518 00:15:14.678504  4008 sgd_solver.cpp:106] Iteration 109400, lr = 0.001
I0518 00:15:14.839205  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6405	1.04167	73.1126	0	83.2998	3.64583	79.1977	0	73.9891	0	67.9345	0	58.2203	0	23.0227	1.6	
I0518 00:15:14.913764  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:15:14.915220  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:15:14.915257  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:15:14.925427  4008 solver.cpp:260]     Total regularization terms: 1.185 loss+regular. : 2.61098
I0518 00:16:49.766528  4008 solver.cpp:231] Iteration 109600, loss = 1.54299
I0518 00:16:49.766896  4008 solver.cpp:247]     Train net output #0: loss = 1.54299 (* 1 = 1.54299 loss)
I0518 00:16:49.766918  4008 sgd_solver.cpp:106] Iteration 109600, lr = 0.001
I0518 00:16:49.926692  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7008	1.04167	73.0169	0	83.3163	3.64583	79.2173	0	74.0291	0	67.9774	0	58.2631	0	23.0355	1.6	
I0518 00:16:50.000803  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:16:50.002356  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:16:50.002398  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:16:50.012207  4008 solver.cpp:260]     Total regularization terms: 1.18443 loss+regular. : 2.72742
I0518 00:18:11.861716  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:18:19.703995  4008 solver.cpp:231] Iteration 109800, loss = 1.4232
I0518 00:18:19.704140  4008 solver.cpp:247]     Train net output #0: loss = 1.4232 (* 1 = 1.4232 loss)
I0518 00:18:19.704169  4008 sgd_solver.cpp:106] Iteration 109800, lr = 0.001
I0518 00:18:19.865391  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6807	1.04167	72.9847	0	83.3102	3.64583	79.2484	0	74.0397	0	68.0201	0	58.3063	0	23.0479	1.6	
I0518 00:18:19.939393  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:18:19.940888  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:18:19.940937  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:18:19.957686  4008 solver.cpp:260]     Total regularization terms: 1.18386 loss+regular. : 2.60707
I0518 00:19:44.240731  4008 solver.cpp:348] Iteration 110000, Testing net (#0)
I0518 00:20:57.246907  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:21:16.378862  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55298
I0518 00:21:16.378959  4008 solver.cpp:415]     Test net output #1: loss = 1.9262 (* 1 = 1.9262 loss)
I0518 00:21:16.466084  4008 solver.cpp:231] Iteration 110000, loss = 1.41358
I0518 00:21:16.466187  4008 solver.cpp:247]     Train net output #0: loss = 1.41358 (* 1 = 1.41358 loss)
I0518 00:21:16.466205  4008 sgd_solver.cpp:106] Iteration 110000, lr = 0.001
I0518 00:21:16.638931  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5716	1.04167	72.945	0	83.3249	3.64583	79.2578	0	74.0662	0	68.064	0	58.3492	0	23.0592	1.6	
I0518 00:21:16.715093  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:21:16.716696  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:21:16.716742  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:21:16.729048  4008 solver.cpp:260]     Total regularization terms: 1.1833 loss+regular. : 2.59688
I0518 00:22:41.195055  4008 solver.cpp:231] Iteration 110200, loss = 1.42692
I0518 00:22:41.195402  4008 solver.cpp:247]     Train net output #0: loss = 1.42692 (* 1 = 1.42692 loss)
I0518 00:22:41.195426  4008 sgd_solver.cpp:106] Iteration 110200, lr = 0.001
I0518 00:22:41.355512  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7381	1.04167	73.0143	0	83.3553	3.64583	79.2833	0	74.0998	0	68.1071	0	58.3916	0	23.0711	1.6	
I0518 00:22:41.429620  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:22:41.431206  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:22:41.431262  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:22:41.441314  4008 solver.cpp:260]     Total regularization terms: 1.18271 loss+regular. : 2.60963
I0518 00:24:12.228360  4008 solver.cpp:231] Iteration 110400, loss = 1.43432
I0518 00:24:12.228688  4008 solver.cpp:247]     Train net output #0: loss = 1.43432 (* 1 = 1.43432 loss)
I0518 00:24:12.228718  4008 sgd_solver.cpp:106] Iteration 110400, lr = 0.001
I0518 00:24:12.388818  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5142	1.04167	72.8607	0	83.3885	3.64583	79.3156	0	74.1286	0	68.1496	0	58.4344	0	23.0823	1.6	
I0518 00:24:12.465116  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:24:12.467020  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:24:12.467068  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:24:12.477020  4008 solver.cpp:260]     Total regularization terms: 1.18228 loss+regular. : 2.6166
I0518 00:25:34.386402  4008 solver.cpp:231] Iteration 110600, loss = 1.29145
I0518 00:25:34.387367  4008 solver.cpp:247]     Train net output #0: loss = 1.29145 (* 1 = 1.29145 loss)
I0518 00:25:34.387404  4008 sgd_solver.cpp:106] Iteration 110600, lr = 0.001
I0518 00:25:34.545343  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7582	1.04167	73.1706	0	83.4227	3.64583	79.3382	0	74.1527	0	68.1924	0	58.4768	0	23.0948	1.6	
I0518 00:25:34.620612  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:25:34.622866  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:25:34.622915  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:25:34.644620  4008 solver.cpp:260]     Total regularization terms: 1.18174 loss+regular. : 2.47318
I0518 00:26:48.269444  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:26:55.186704  4008 solver.cpp:231] Iteration 110800, loss = 1.4693
I0518 00:26:55.186808  4008 solver.cpp:247]     Train net output #0: loss = 1.4693 (* 1 = 1.4693 loss)
I0518 00:26:55.186839  4008 sgd_solver.cpp:106] Iteration 110800, lr = 0.001
I0518 00:26:55.347194  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6204	1.04167	73.2083	0	83.4199	3.64583	79.374	0	74.1848	0	68.2358	0	58.5184	0	23.1066	1.6	
I0518 00:26:55.421613  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:26:55.423372  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:26:55.423419  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:26:55.433476  4008 solver.cpp:260]     Total regularization terms: 1.18109 loss+regular. : 2.6504
I0518 00:28:17.549003  4008 solver.cpp:348] Iteration 111000, Testing net (#0)
I0518 00:29:31.202134  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:29:53.809144  4008 solver.cpp:415]     Test net output #0: accuracy = 0.551279
I0518 00:29:53.809250  4008 solver.cpp:415]     Test net output #1: loss = 1.93351 (* 1 = 1.93351 loss)
I0518 00:29:53.906759  4008 solver.cpp:231] Iteration 111000, loss = 1.43799
I0518 00:29:53.906857  4008 solver.cpp:247]     Train net output #0: loss = 1.43799 (* 1 = 1.43799 loss)
I0518 00:29:53.906886  4008 sgd_solver.cpp:106] Iteration 111000, lr = 0.001
I0518 00:29:54.073777  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7352	1.04167	73.1055	0	83.4327	3.64583	79.3917	0	74.2154	0	68.2782	0	58.5609	0	23.118	1.6	
I0518 00:29:54.148531  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:29:54.150457  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:29:54.150501  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:29:54.160434  4008 solver.cpp:260]     Total regularization terms: 1.18059 loss+regular. : 2.61858
I0518 00:31:13.346321  4008 solver.cpp:231] Iteration 111200, loss = 1.43102
I0518 00:31:13.346648  4008 solver.cpp:247]     Train net output #0: loss = 1.43102 (* 1 = 1.43102 loss)
I0518 00:31:13.346678  4008 sgd_solver.cpp:106] Iteration 111200, lr = 0.001
I0518 00:31:13.508615  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.761	1.04167	73.1569	0	83.479	3.64583	79.4149	0	74.2443	0	68.3208	0	58.6035	0	23.1318	1.6	
I0518 00:31:13.583108  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:31:13.585420  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:31:13.585520  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:31:13.595870  4008 solver.cpp:260]     Total regularization terms: 1.18012 loss+regular. : 2.61114
I0518 00:32:43.300756  4008 solver.cpp:231] Iteration 111400, loss = 1.23949
I0518 00:32:43.301123  4008 solver.cpp:247]     Train net output #0: loss = 1.23949 (* 1 = 1.23949 loss)
I0518 00:32:43.301213  4008 sgd_solver.cpp:106] Iteration 111400, lr = 0.001
I0518 00:32:43.461221  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6692	1.04167	73.1683	0	83.4767	3.64583	79.4302	0	74.2637	0	68.3632	0	58.6461	0	23.1442	1.6	
I0518 00:32:43.535274  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:32:43.536923  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:32:43.536962  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:32:43.546885  4008 solver.cpp:260]     Total regularization terms: 1.17959 loss+regular. : 2.41908
I0518 00:34:10.104117  4008 solver.cpp:231] Iteration 111600, loss = 1.56541
I0518 00:34:10.104436  4008 solver.cpp:247]     Train net output #0: loss = 1.56541 (* 1 = 1.56541 loss)
I0518 00:34:10.104476  4008 sgd_solver.cpp:106] Iteration 111600, lr = 0.001
I0518 00:34:10.264081  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6147	1.04167	73.2907	0	83.5209	3.64583	79.4663	0	74.2854	0	68.405	0	58.6881	0	23.1574	1.6	
I0518 00:34:10.338963  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:34:10.341248  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:34:10.341311  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:34:10.351658  4008 solver.cpp:260]     Total regularization terms: 1.17903 loss+regular. : 2.74444
I0518 00:35:38.201254  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:35:40.711201  4008 solver.cpp:231] Iteration 111800, loss = 1.3942
I0518 00:35:40.711289  4008 solver.cpp:247]     Train net output #0: loss = 1.3942 (* 1 = 1.3942 loss)
I0518 00:35:40.711308  4008 sgd_solver.cpp:106] Iteration 111800, lr = 0.001
I0518 00:35:40.872074  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5745	1.04167	73.2298	0	83.5294	3.64583	79.4637	0	74.2979	0	68.447	0	58.7308	0	23.1704	1.6	
I0518 00:35:40.946422  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:35:40.948415  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:35:40.948457  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:35:40.958211  4008 solver.cpp:260]     Total regularization terms: 1.17851 loss+regular. : 2.57271
I0518 00:37:17.060387  4008 solver.cpp:348] Iteration 112000, Testing net (#0)
I0518 00:38:30.127288  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:38:48.209455  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55178
I0518 00:38:48.209594  4008 solver.cpp:415]     Test net output #1: loss = 1.92875 (* 1 = 1.92875 loss)
I0518 00:38:48.298418  4008 solver.cpp:231] Iteration 112000, loss = 1.46895
I0518 00:38:48.298530  4008 solver.cpp:247]     Train net output #0: loss = 1.46895 (* 1 = 1.46895 loss)
I0518 00:38:48.298560  4008 sgd_solver.cpp:106] Iteration 112000, lr = 0.001
I0518 00:38:48.463665  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.4482	1.04167	73.2702	0	83.519	3.64583	79.4762	0	74.3354	0	68.489	0	58.7732	0	23.1825	1.6	
I0518 00:38:48.538808  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:38:48.541090  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:38:48.541151  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:38:48.551338  4008 solver.cpp:260]     Total regularization terms: 1.17803 loss+regular. : 2.64697
I0518 00:40:14.525784  4008 solver.cpp:231] Iteration 112200, loss = 1.41486
I0518 00:40:14.529732  4008 solver.cpp:247]     Train net output #0: loss = 1.41486 (* 1 = 1.41486 loss)
I0518 00:40:14.529793  4008 sgd_solver.cpp:106] Iteration 112200, lr = 0.001
I0518 00:40:14.685840  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.2904	1.04167	73.2012	0	83.569	3.64583	79.5279	0	74.3591	0	68.5315	0	58.8144	0	23.1941	1.6	
I0518 00:40:14.760422  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:40:14.762641  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:40:14.762702  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:40:14.774236  4008 solver.cpp:260]     Total regularization terms: 1.1775 loss+regular. : 2.59237
I0518 00:41:44.044109  4008 solver.cpp:231] Iteration 112400, loss = 1.5046
I0518 00:41:44.044425  4008 solver.cpp:247]     Train net output #0: loss = 1.5046 (* 1 = 1.5046 loss)
I0518 00:41:44.044452  4008 sgd_solver.cpp:106] Iteration 112400, lr = 0.001
I0518 00:41:44.204372  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7266	1.04167	73.2614	0	83.6002	3.64583	79.5633	0	74.4025	0	68.5727	0	58.8555	0	23.2059	1.6	
I0518 00:41:44.278750  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:41:44.280746  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:41:44.280802  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:41:44.292378  4008 solver.cpp:260]     Total regularization terms: 1.17699 loss+regular. : 2.6816
I0518 00:43:11.084009  4008 solver.cpp:231] Iteration 112600, loss = 1.64834
I0518 00:43:11.084291  4008 solver.cpp:247]     Train net output #0: loss = 1.64834 (* 1 = 1.64834 loss)
I0518 00:43:11.084314  4008 sgd_solver.cpp:106] Iteration 112600, lr = 0.001
I0518 00:43:11.245054  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7237	1.04167	72.944	0	83.587	3.64583	79.5715	0	74.4123	0	68.6147	0	58.8971	0	23.2179	1.6	
I0518 00:43:11.319573  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:43:11.321260  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:43:11.321302  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:43:11.331220  4008 solver.cpp:260]     Total regularization terms: 1.17646 loss+regular. : 2.8248
I0518 00:44:42.274986  4008 solver.cpp:231] Iteration 112800, loss = 1.47021
I0518 00:44:42.275354  4008 solver.cpp:247]     Train net output #0: loss = 1.47021 (* 1 = 1.47021 loss)
I0518 00:44:42.275403  4008 sgd_solver.cpp:106] Iteration 112800, lr = 0.001
I0518 00:44:42.435832  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7926	1.04167	73.1006	0	83.6134	3.64583	79.6066	0	74.4412	0	68.6562	0	58.9393	0	23.2298	1.6	
I0518 00:44:42.510012  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:44:42.511308  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:44:42.511350  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:44:42.524220  4008 solver.cpp:260]     Total regularization terms: 1.17584 loss+regular. : 2.64605
I0518 00:44:42.822357  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:46:07.920336  4008 solver.cpp:348] Iteration 113000, Testing net (#0)
I0518 00:47:19.908176  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:47:38.200110  4008 solver.cpp:415]     Test net output #0: accuracy = 0.554139
I0518 00:47:38.200232  4008 solver.cpp:415]     Test net output #1: loss = 1.93171 (* 1 = 1.93171 loss)
I0518 00:47:38.287993  4008 solver.cpp:231] Iteration 113000, loss = 1.33786
I0518 00:47:38.288091  4008 solver.cpp:247]     Train net output #0: loss = 1.33786 (* 1 = 1.33786 loss)
I0518 00:47:38.288139  4008 sgd_solver.cpp:106] Iteration 113000, lr = 0.001
I0518 00:47:38.447839  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6175	1.04167	73.2695	0	83.5948	3.64583	79.6159	0	74.4611	0	68.6981	0	58.9803	0	23.2419	1.6	
I0518 00:47:38.522390  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:47:38.524019  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:47:38.524063  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:47:38.534001  4008 solver.cpp:260]     Total regularization terms: 1.1753 loss+regular. : 2.51316
I0518 00:49:07.359238  4008 solver.cpp:231] Iteration 113200, loss = 1.37668
I0518 00:49:07.359614  4008 solver.cpp:247]     Train net output #0: loss = 1.37668 (* 1 = 1.37668 loss)
I0518 00:49:07.359643  4008 sgd_solver.cpp:106] Iteration 113200, lr = 0.001
I0518 00:49:07.521155  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6663	1.04167	73.388	0	83.6706	3.64583	79.6565	0	74.5002	0	68.7403	0	59.0222	0	23.2535	1.6	
I0518 00:49:07.595618  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:49:07.597277  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:49:07.597323  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:49:07.607416  4008 solver.cpp:260]     Total regularization terms: 1.17477 loss+regular. : 2.55144
I0518 00:50:31.702919  4008 solver.cpp:231] Iteration 113400, loss = 1.65699
I0518 00:50:31.704658  4008 solver.cpp:247]     Train net output #0: loss = 1.65699 (* 1 = 1.65699 loss)
I0518 00:50:31.704695  4008 sgd_solver.cpp:106] Iteration 113400, lr = 0.001
I0518 00:50:31.864657  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6864	1.04167	73.3945	0	83.6868	3.64583	79.6976	0	74.5355	0	68.781	0	59.063	0	23.2652	1.6	
I0518 00:50:31.940174  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:50:31.942525  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:50:31.942579  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:50:31.952664  4008 solver.cpp:260]     Total regularization terms: 1.1742 loss+regular. : 2.83119
I0518 00:52:02.026854  4008 solver.cpp:231] Iteration 113600, loss = 1.31474
I0518 00:52:02.028290  4008 solver.cpp:247]     Train net output #0: loss = 1.31474 (* 1 = 1.31474 loss)
I0518 00:52:02.028321  4008 sgd_solver.cpp:106] Iteration 113600, lr = 0.001
I0518 00:52:02.189785  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6807	1.04167	73.4544	0	83.6844	3.64583	79.7083	0	74.5547	0	68.8216	0	59.1054	0	23.2776	1.6	
I0518 00:52:02.264185  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:52:02.266088  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:52:02.266146  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:52:02.277756  4008 solver.cpp:260]     Total regularization terms: 1.17376 loss+regular. : 2.4885
I0518 00:53:24.762706  4008 solver.cpp:231] Iteration 113800, loss = 1.44007
I0518 00:53:24.762986  4008 solver.cpp:247]     Train net output #0: loss = 1.44007 (* 1 = 1.44007 loss)
I0518 00:53:24.763008  4008 sgd_solver.cpp:106] Iteration 113800, lr = 0.001
I0518 00:53:24.921121  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6032	1.04167	73.1309	0	83.6867	3.64583	79.7229	0	74.5581	0	68.863	0	59.1462	0	23.2903	1.6	
I0518 00:53:24.999281  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:53:25.000831  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.64583	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:53:25.000867  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:53:25.010921  4008 solver.cpp:260]     Total regularization terms: 1.17328 loss+regular. : 2.61336
I0518 00:53:27.998126  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:54:48.192155  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_114000.caffemodel
I0518 00:56:17.581282  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_114000.solverstate
I0518 00:56:18.400524  4008 solver.cpp:348] Iteration 114000, Testing net (#0)
I0518 00:57:19.467191  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 00:57:33.427501  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55506
I0518 00:57:33.427853  4008 solver.cpp:415]     Test net output #1: loss = 1.90858 (* 1 = 1.90858 loss)
I0518 00:57:33.518379  4008 solver.cpp:231] Iteration 114000, loss = 1.39908
I0518 00:57:33.518457  4008 solver.cpp:247]     Train net output #0: loss = 1.39908 (* 1 = 1.39908 loss)
I0518 00:57:33.518478  4008 sgd_solver.cpp:106] Iteration 114000, lr = 0.001
I0518 00:57:33.678403  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8528	1.04167	73.5381	0	83.7389	3.90625	79.7577	0	74.6105	0	68.9042	0	59.1881	0	23.3018	1.6	
I0518 00:57:33.679569  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:57:33.681455  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:57:33.681485  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:57:33.691365  4008 solver.cpp:260]     Total regularization terms: 1.17265 loss+regular. : 2.57173
I0518 00:59:05.237813  4008 solver.cpp:231] Iteration 114200, loss = 1.52425
I0518 00:59:05.238507  4008 solver.cpp:247]     Train net output #0: loss = 1.52425 (* 1 = 1.52425 loss)
I0518 00:59:05.238533  4008 sgd_solver.cpp:106] Iteration 114200, lr = 0.001
I0518 00:59:05.397114  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5343	1.04167	73.4209	0	83.7468	3.90625	79.7838	0	74.6304	0	68.9456	0	59.2293	0	23.3144	1.6	
I0518 00:59:05.471635  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 00:59:05.473258  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 00:59:05.473294  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 00:59:05.483420  4008 solver.cpp:260]     Total regularization terms: 1.17218 loss+regular. : 2.69642
I0518 01:00:30.902711  4008 solver.cpp:231] Iteration 114400, loss = 1.5312
I0518 01:00:30.903101  4008 solver.cpp:247]     Train net output #0: loss = 1.5312 (* 1 = 1.5312 loss)
I0518 01:00:30.903122  4008 sgd_solver.cpp:106] Iteration 114400, lr = 0.001
I0518 01:00:31.062731  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.652	1.04167	73.4001	0	83.7702	3.90625	79.7894	0	74.6679	0	68.9862	0	59.2701	0	23.3263	1.6	
I0518 01:00:31.136988  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:00:31.138522  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:00:31.138567  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:00:31.152907  4008 solver.cpp:260]     Total regularization terms: 1.1717 loss+regular. : 2.7029
I0518 01:02:02.373939  4008 solver.cpp:231] Iteration 114600, loss = 1.35597
I0518 01:02:02.374215  4008 solver.cpp:247]     Train net output #0: loss = 1.35597 (* 1 = 1.35597 loss)
I0518 01:02:02.374235  4008 sgd_solver.cpp:106] Iteration 114600, lr = 0.001
I0518 01:02:02.534699  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8155	1.04167	73.418	0	83.7879	3.90625	79.8126	0	74.6998	0	69.0267	0	59.3114	0	23.3387	1.6	
I0518 01:02:02.608860  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:02:02.610602  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:02:02.610687  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:02:02.620707  4008 solver.cpp:260]     Total regularization terms: 1.17113 loss+regular. : 2.5271
I0518 01:03:34.893920  4008 solver.cpp:231] Iteration 114800, loss = 1.54225
I0518 01:03:34.894305  4008 solver.cpp:247]     Train net output #0: loss = 1.54225 (* 1 = 1.54225 loss)
I0518 01:03:34.894328  4008 sgd_solver.cpp:106] Iteration 114800, lr = 0.001
I0518 01:03:35.054982  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9016	1.04167	73.3021	0	83.798	3.90625	79.8203	0	74.7177	0	69.067	0	59.3524	0	23.3505	1.6	
I0518 01:03:35.129323  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:03:35.131359  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:03:35.131415  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:03:35.141969  4008 solver.cpp:260]     Total regularization terms: 1.17064 loss+regular. : 2.71289
I0518 01:03:41.080132  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:05:01.190279  4008 solver.cpp:348] Iteration 115000, Testing net (#0)
I0518 01:06:04.540273  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:06:20.433118  4008 solver.cpp:415]     Test net output #0: accuracy = 0.551
I0518 01:06:20.433234  4008 solver.cpp:415]     Test net output #1: loss = 1.92666 (* 1 = 1.92666 loss)
I0518 01:06:20.525902  4008 solver.cpp:231] Iteration 115000, loss = 1.45369
I0518 01:06:20.526053  4008 solver.cpp:247]     Train net output #0: loss = 1.45369 (* 1 = 1.45369 loss)
I0518 01:06:20.526083  4008 sgd_solver.cpp:106] Iteration 115000, lr = 0.001
I0518 01:06:20.690593  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8098	1.04167	73.4062	0	83.8142	3.90625	79.8391	0	74.7326	0	69.1073	0	59.3933	0	23.3619	1.6	
I0518 01:06:20.765712  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.607639	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:06:20.767137  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:06:20.767169  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:06:20.777087  4008 solver.cpp:260]     Total regularization terms: 1.17012 loss+regular. : 2.62381
I0518 01:07:45.926568  4008 solver.cpp:231] Iteration 115200, loss = 1.45579
I0518 01:07:45.926956  4008 solver.cpp:247]     Train net output #0: loss = 1.45579 (* 1 = 1.45579 loss)
I0518 01:07:45.926997  4008 sgd_solver.cpp:106] Iteration 115200, lr = 0.001
I0518 01:07:46.085675  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9447	1.04167	73.6035	0	83.8501	3.90625	79.8694	0	74.7773	0	69.148	0	59.4337	0	23.3733	1.6	
I0518 01:07:46.160240  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.651042	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:07:46.162215  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:07:46.162278  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:07:46.172428  4008 solver.cpp:260]     Total regularization terms: 1.16954 loss+regular. : 2.62533
I0518 01:09:15.752133  4008 solver.cpp:231] Iteration 115400, loss = 1.30352
I0518 01:09:15.752476  4008 solver.cpp:247]     Train net output #0: loss = 1.30352 (* 1 = 1.30352 loss)
I0518 01:09:15.752513  4008 sgd_solver.cpp:106] Iteration 115400, lr = 0.001
I0518 01:09:15.912832  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7868	1.04167	73.6048	0	83.8399	3.90625	79.9083	0	74.7816	0	69.1884	0	59.4741	0	23.3857	1.6	
I0518 01:09:15.988034  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.651042	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:09:15.990639  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:09:15.990700  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:09:16.000840  4008 solver.cpp:260]     Total regularization terms: 1.1691 loss+regular. : 2.47262
I0518 01:10:41.860746  4008 solver.cpp:231] Iteration 115600, loss = 1.28975
I0518 01:10:41.865665  4008 solver.cpp:247]     Train net output #0: loss = 1.28975 (* 1 = 1.28975 loss)
I0518 01:10:41.865695  4008 sgd_solver.cpp:106] Iteration 115600, lr = 0.001
I0518 01:10:42.021330  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7151	1.04167	73.682	0	83.8842	3.90625	79.9401	0	74.8051	0	69.229	0	59.5142	0	23.398	1.6	
I0518 01:10:42.095623  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.651042	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:10:42.097661  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:10:42.097729  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:10:42.107493  4008 solver.cpp:260]     Total regularization terms: 1.16864 loss+regular. : 2.45839
I0518 01:12:13.089145  4008 solver.cpp:231] Iteration 115800, loss = 1.35952
I0518 01:12:13.089419  4008 solver.cpp:247]     Train net output #0: loss = 1.35952 (* 1 = 1.35952 loss)
I0518 01:12:13.089444  4008 sgd_solver.cpp:106] Iteration 115800, lr = 0.001
I0518 01:12:13.248273  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8873	1.04167	73.708	0	83.8979	3.90625	79.9747	0	74.8307	0	69.2691	0	59.5541	0	23.4093	1.6	
I0518 01:12:13.322823  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.651042	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:12:13.325072  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:12:13.325119  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:12:13.335075  4008 solver.cpp:260]     Total regularization terms: 1.16807 loss+regular. : 2.52759
I0518 01:12:23.705580  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:13:37.197240  4008 solver.cpp:348] Iteration 116000, Testing net (#0)
I0518 01:14:50.295646  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:15:06.290838  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55298
I0518 01:15:06.290930  4008 solver.cpp:415]     Test net output #1: loss = 1.92889 (* 1 = 1.92889 loss)
I0518 01:15:06.379200  4008 solver.cpp:231] Iteration 116000, loss = 1.50041
I0518 01:15:06.379292  4008 solver.cpp:247]     Train net output #0: loss = 1.50041 (* 1 = 1.50041 loss)
I0518 01:15:06.379320  4008 sgd_solver.cpp:106] Iteration 116000, lr = 0.001
I0518 01:15:06.543488  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7725	1.04167	73.7461	0	83.9075	3.90625	79.9895	0	74.8761	0	69.3093	0	59.5938	0	23.4213	1.6	
I0518 01:15:06.617885  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.651042	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:15:06.619896  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:15:06.619938  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:15:06.629887  4008 solver.cpp:260]     Total regularization terms: 1.16752 loss+regular. : 2.66793
I0518 01:16:37.507545  4008 solver.cpp:231] Iteration 116200, loss = 1.37316
I0518 01:16:37.507943  4008 solver.cpp:247]     Train net output #0: loss = 1.37316 (* 1 = 1.37316 loss)
I0518 01:16:37.507967  4008 sgd_solver.cpp:106] Iteration 116200, lr = 0.001
I0518 01:16:37.666893  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8959	1.04167	73.679	0	83.9163	3.90625	80.0209	0	74.8956	0	69.3491	0	59.6345	0	23.4318	1.6	
I0518 01:16:37.741267  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.651042	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:16:37.743207  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:16:37.743254  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:16:37.758200  4008 solver.cpp:260]     Total regularization terms: 1.16702 loss+regular. : 2.54018
I0518 01:18:02.956195  4008 solver.cpp:231] Iteration 116400, loss = 1.27084
I0518 01:18:02.956565  4008 solver.cpp:247]     Train net output #0: loss = 1.27084 (* 1 = 1.27084 loss)
I0518 01:18:02.956598  4008 sgd_solver.cpp:106] Iteration 116400, lr = 0.001
I0518 01:18:03.117494  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7754	1.04167	73.6631	0	83.9444	3.90625	80.0299	0	74.9073	0	69.3887	0	59.6751	0	23.4429	1.6	
I0518 01:18:03.192059  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:18:03.194054  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:18:03.194085  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:18:03.203964  4008 solver.cpp:260]     Total regularization terms: 1.16653 loss+regular. : 2.43737
I0518 01:19:38.775523  4008 solver.cpp:231] Iteration 116600, loss = 1.29687
I0518 01:19:38.777688  4008 solver.cpp:247]     Train net output #0: loss = 1.29687 (* 1 = 1.29687 loss)
I0518 01:19:38.777731  4008 sgd_solver.cpp:106] Iteration 116600, lr = 0.001
I0518 01:19:38.934689  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8787	1.04167	73.5592	0	83.966	3.90625	80.0632	0	74.9313	0	69.4283	0	59.7153	0	23.4547	1.6	
I0518 01:19:39.009115  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:19:39.011250  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:19:39.011299  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:19:39.021163  4008 solver.cpp:260]     Total regularization terms: 1.16605 loss+regular. : 2.46292
I0518 01:21:13.214967  4008 solver.cpp:231] Iteration 116800, loss = 1.46762
I0518 01:21:13.215241  4008 solver.cpp:247]     Train net output #0: loss = 1.46762 (* 1 = 1.46762 loss)
I0518 01:21:13.215261  4008 sgd_solver.cpp:106] Iteration 116800, lr = 0.001
I0518 01:21:13.375679  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8098	1.04167	73.4434	0	83.9726	3.90625	80.0834	0	74.9584	0	69.4681	0	59.756	0	23.4667	1.6	
I0518 01:21:13.450446  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:21:13.452419  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:21:13.452466  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:21:13.462677  4008 solver.cpp:260]     Total regularization terms: 1.16553 loss+regular. : 2.63315
I0518 01:21:27.139045  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:22:43.094807  4008 solver.cpp:348] Iteration 117000, Testing net (#0)
I0518 01:23:49.176545  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:24:01.880340  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55358
I0518 01:24:01.880426  4008 solver.cpp:415]     Test net output #1: loss = 1.93042 (* 1 = 1.93042 loss)
I0518 01:24:01.968523  4008 solver.cpp:231] Iteration 117000, loss = 1.34206
I0518 01:24:01.968600  4008 solver.cpp:247]     Train net output #0: loss = 1.34206 (* 1 = 1.34206 loss)
I0518 01:24:01.968618  4008 sgd_solver.cpp:106] Iteration 117000, lr = 0.001
I0518 01:24:02.135851  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8069	1.04167	73.5472	0	83.9848	3.90625	80.0965	0	74.9846	0	69.5077	0	59.797	0	23.4784	1.6	
I0518 01:24:02.210258  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:24:02.212443  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:24:02.212488  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:24:02.222401  4008 solver.cpp:260]     Total regularization terms: 1.1651 loss+regular. : 2.50717
I0518 01:25:30.681617  4008 solver.cpp:231] Iteration 117200, loss = 1.21117
I0518 01:25:30.681996  4008 solver.cpp:247]     Train net output #0: loss = 1.21117 (* 1 = 1.21117 loss)
I0518 01:25:30.682019  4008 sgd_solver.cpp:106] Iteration 117200, lr = 0.001
I0518 01:25:30.842990  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8356	1.04167	73.4733	0	84.0025	3.90625	80.1266	0	75.0165	0	69.5476	0	59.8372	0	23.4903	1.6	
I0518 01:25:30.917280  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:25:30.918872  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:25:30.918920  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:25:30.928948  4008 solver.cpp:260]     Total regularization terms: 1.1646 loss+regular. : 2.37577
I0518 01:27:03.206506  4008 solver.cpp:231] Iteration 117400, loss = 1.39159
I0518 01:27:03.207113  4008 solver.cpp:247]     Train net output #0: loss = 1.39159 (* 1 = 1.39159 loss)
I0518 01:27:03.207137  4008 sgd_solver.cpp:106] Iteration 117400, lr = 0.001
I0518 01:27:03.366909  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7668	1.04167	73.5938	0	84.0542	3.90625	80.1517	0	75.0384	0	69.5874	0	59.8771	0	23.5018	1.6	
I0518 01:27:03.441495  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:27:03.442656  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:27:03.442678  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:27:03.452416  4008 solver.cpp:260]     Total regularization terms: 1.16411 loss+regular. : 2.5557
I0518 01:28:34.171717  4008 solver.cpp:231] Iteration 117600, loss = 1.43815
I0518 01:28:34.172186  4008 solver.cpp:247]     Train net output #0: loss = 1.43815 (* 1 = 1.43815 loss)
I0518 01:28:34.172214  4008 sgd_solver.cpp:106] Iteration 117600, lr = 0.001
I0518 01:28:34.332149  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9045	1.04167	73.6328	0	84.0493	3.90625	80.1529	0	75.0608	0	69.6266	0	59.9163	0	23.5127	1.6	
I0518 01:28:34.407065  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:28:34.409278  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:28:34.409323  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:28:34.424391  4008 solver.cpp:260]     Total regularization terms: 1.16354 loss+regular. : 2.60169
I0518 01:30:05.811502  4008 solver.cpp:231] Iteration 117800, loss = 1.59217
I0518 01:30:05.811812  4008 solver.cpp:247]     Train net output #0: loss = 1.59217 (* 1 = 1.59217 loss)
I0518 01:30:05.811831  4008 sgd_solver.cpp:106] Iteration 117800, lr = 0.001
I0518 01:30:05.974143  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9102	1.04167	73.7327	0	84.0791	3.90625	80.1735	0	75.0793	0	69.6653	0	59.9563	0	23.5231	1.6	
I0518 01:30:06.048260  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:30:06.049644  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:30:06.049700  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:30:06.059644  4008 solver.cpp:260]     Total regularization terms: 1.16304 loss+regular. : 2.75521
I0518 01:30:22.391669  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:31:32.211081  4008 solver.cpp:348] Iteration 118000, Testing net (#0)
I0518 01:32:47.164137  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:32:59.297694  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55576
I0518 01:32:59.297811  4008 solver.cpp:415]     Test net output #1: loss = 1.91349 (* 1 = 1.91349 loss)
I0518 01:32:59.412524  4008 solver.cpp:231] Iteration 118000, loss = 1.49455
I0518 01:32:59.412602  4008 solver.cpp:247]     Train net output #0: loss = 1.49455 (* 1 = 1.49455 loss)
I0518 01:32:59.412623  4008 sgd_solver.cpp:106] Iteration 118000, lr = 0.001
I0518 01:32:59.578802  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6204	1.04167	73.8398	0	84.1033	3.90625	80.204	0	75.101	0	69.7041	0	59.9953	0	23.5343	1.6	
I0518 01:32:59.652709  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:32:59.654156  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:32:59.654212  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:32:59.663883  4008 solver.cpp:260]     Total regularization terms: 1.16258 loss+regular. : 2.65713
I0518 01:34:37.310809  4008 solver.cpp:231] Iteration 118200, loss = 1.57409
I0518 01:34:37.311287  4008 solver.cpp:247]     Train net output #0: loss = 1.57409 (* 1 = 1.57409 loss)
I0518 01:34:37.311319  4008 sgd_solver.cpp:106] Iteration 118200, lr = 0.001
I0518 01:34:37.470700  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9217	1.04167	73.6735	0	84.1026	3.90625	80.2133	0	75.1096	0	69.743	0	60.0361	0	23.5462	1.6	
I0518 01:34:37.545217  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:34:37.546694  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:34:37.546739  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:34:37.559355  4008 solver.cpp:260]     Total regularization terms: 1.16212 loss+regular. : 2.73621
I0518 01:36:13.149984  4008 solver.cpp:231] Iteration 118400, loss = 1.63811
I0518 01:36:13.150377  4008 solver.cpp:247]     Train net output #0: loss = 1.63811 (* 1 = 1.63811 loss)
I0518 01:36:13.150403  4008 sgd_solver.cpp:106] Iteration 118400, lr = 0.001
I0518 01:36:13.309975  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7524	1.04167	73.8138	0	84.1346	3.90625	80.2543	0	75.1345	0	69.7803	0	60.0754	0	23.5579	1.6	
I0518 01:36:13.384477  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:36:13.386893  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:36:13.386946  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:36:13.397172  4008 solver.cpp:260]     Total regularization terms: 1.16157 loss+regular. : 2.79968
I0518 01:37:53.881705  4008 solver.cpp:231] Iteration 118600, loss = 1.5003
I0518 01:37:53.882015  4008 solver.cpp:247]     Train net output #0: loss = 1.5003 (* 1 = 1.5003 loss)
I0518 01:37:53.882036  4008 sgd_solver.cpp:106] Iteration 118600, lr = 0.001
I0518 01:37:54.041456  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.652	1.04167	73.4994	0	84.1229	3.90625	80.2716	0	75.1641	0	69.8194	0	60.1154	0	23.5697	1.6	
I0518 01:37:54.115783  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:37:54.117894  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:37:54.117940  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:37:54.130782  4008 solver.cpp:260]     Total regularization terms: 1.1611 loss+regular. : 2.66141
I0518 01:39:21.627540  4008 solver.cpp:231] Iteration 118800, loss = 1.62062
I0518 01:39:21.629693  4008 solver.cpp:247]     Train net output #0: loss = 1.62062 (* 1 = 1.62062 loss)
I0518 01:39:21.629751  4008 sgd_solver.cpp:106] Iteration 118800, lr = 0.001
I0518 01:39:21.787276  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.5372	1.04167	73.8669	0	84.1437	3.90625	80.2838	0	75.1856	0	69.8582	0	60.1539	0	23.5819	1.6	
I0518 01:39:21.862396  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:39:21.865344  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:39:21.865432  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:39:21.876245  4008 solver.cpp:260]     Total regularization terms: 1.16063 loss+regular. : 2.78125
I0518 01:39:41.801198  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:40:43.183262  4008 solver.cpp:348] Iteration 119000, Testing net (#0)
I0518 01:41:54.177131  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:42:05.353147  4008 solver.cpp:415]     Test net output #0: accuracy = 0.551139
I0518 01:42:05.353281  4008 solver.cpp:415]     Test net output #1: loss = 1.9145 (* 1 = 1.9145 loss)
I0518 01:42:05.441515  4008 solver.cpp:231] Iteration 119000, loss = 1.54002
I0518 01:42:05.441623  4008 solver.cpp:247]     Train net output #0: loss = 1.54002 (* 1 = 1.54002 loss)
I0518 01:42:05.441651  4008 sgd_solver.cpp:106] Iteration 119000, lr = 0.001
I0518 01:42:05.607470  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8758	1.04167	73.8662	0	84.1584	3.90625	80.3158	0	75.2055	0	69.897	0	60.1932	0	23.5932	1.6	
I0518 01:42:05.682039  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:42:05.684005  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:42:05.684048  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:42:05.693972  4008 solver.cpp:260]     Total regularization terms: 1.16012 loss+regular. : 2.70014
I0518 01:43:31.340328  4008 solver.cpp:231] Iteration 119200, loss = 1.55283
I0518 01:43:31.340636  4008 solver.cpp:247]     Train net output #0: loss = 1.55283 (* 1 = 1.55283 loss)
I0518 01:43:31.340665  4008 sgd_solver.cpp:106] Iteration 119200, lr = 0.001
I0518 01:43:31.500529  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0078	1.04167	73.8451	0	84.179	3.90625	80.3428	0	75.2193	0	69.9353	0	60.2325	0	23.6052	1.6	
I0518 01:43:31.575062  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.694444	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:43:31.577112  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:43:31.577162  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:43:31.587756  4008 solver.cpp:260]     Total regularization terms: 1.15968 loss+regular. : 2.71251
I0518 01:45:05.504325  4008 solver.cpp:231] Iteration 119400, loss = 1.42274
I0518 01:45:05.504664  4008 solver.cpp:247]     Train net output #0: loss = 1.42274 (* 1 = 1.42274 loss)
I0518 01:45:05.504689  4008 sgd_solver.cpp:106] Iteration 119400, lr = 0.001
I0518 01:45:05.665529  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8299	1.04167	73.9867	0	84.2096	3.90625	80.3693	0	75.2627	0	69.9739	0	60.2714	0	23.617	1.6	
I0518 01:45:05.743583  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.737847	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:45:05.745075  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:45:05.745120  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:45:05.755103  4008 solver.cpp:260]     Total regularization terms: 1.15919 loss+regular. : 2.58193
I0518 01:46:43.084795  4008 solver.cpp:231] Iteration 119600, loss = 1.46226
I0518 01:46:43.085114  4008 solver.cpp:247]     Train net output #0: loss = 1.46226 (* 1 = 1.46226 loss)
I0518 01:46:43.085135  4008 sgd_solver.cpp:106] Iteration 119600, lr = 0.001
I0518 01:46:43.246057  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0222	1.04167	73.8499	0	84.2428	3.90625	80.3883	0	75.2875	0	70.0122	0	60.3101	0	23.6297	1.6	
I0518 01:46:43.323295  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.737847	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:46:43.324853  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:46:43.324908  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:46:43.335451  4008 solver.cpp:260]     Total regularization terms: 1.15868 loss+regular. : 2.62093
I0518 01:48:07.136266  4008 solver.cpp:231] Iteration 119800, loss = 1.23257
I0518 01:48:07.136566  4008 solver.cpp:247]     Train net output #0: loss = 1.23257 (* 1 = 1.23257 loss)
I0518 01:48:07.136598  4008 sgd_solver.cpp:106] Iteration 119800, lr = 0.001
I0518 01:48:07.297535  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9045	1.04167	73.8294	0	84.2414	3.90625	80.4071	0	75.3111	0	70.0507	0	60.3485	0	23.6411	1.6	
I0518 01:48:07.372112  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.737847	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:48:07.374666  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:48:07.374735  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:48:07.390239  4008 solver.cpp:260]     Total regularization terms: 1.15815 loss+regular. : 2.39072
I0518 01:48:30.297472  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:49:34.272395  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_120000.caffemodel
I0518 01:53:05.908558  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_120000.solverstate
I0518 01:53:06.477007  4008 solver.cpp:348] Iteration 120000, Testing net (#0)
I0518 01:54:23.700650  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 01:54:36.258522  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55232
I0518 01:54:36.258700  4008 solver.cpp:415]     Test net output #1: loss = 1.92235 (* 1 = 1.92235 loss)
I0518 01:54:36.348098  4008 solver.cpp:231] Iteration 120000, loss = 1.5008
I0518 01:54:36.348223  4008 solver.cpp:247]     Train net output #0: loss = 1.5008 (* 1 = 1.5008 loss)
I0518 01:54:36.348266  4008 sgd_solver.cpp:106] Iteration 120000, lr = 0.001
I0518 01:54:36.513437  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.916	1.04167	74.0124	0	84.2446	3.90625	80.4202	0	75.3291	0	70.0894	0	60.3876	0	23.6527	1.6	
I0518 01:54:36.514457  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.737847	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:54:36.515893  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:54:36.515920  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:54:36.525723  4008 solver.cpp:260]     Total regularization terms: 1.15768 loss+regular. : 2.65848
I0518 01:56:08.293423  4008 solver.cpp:231] Iteration 120200, loss = 1.29669
I0518 01:56:08.299337  4008 solver.cpp:247]     Train net output #0: loss = 1.29669 (* 1 = 1.29669 loss)
I0518 01:56:08.299379  4008 sgd_solver.cpp:106] Iteration 120200, lr = 0.001
I0518 01:56:08.462965  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7208	1.04167	74.0404	0	84.263	3.90625	80.4433	0	75.3603	0	70.1273	0	60.4261	0	23.6649	1.6	
I0518 01:56:08.536995  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:56:08.538509  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:56:08.538553  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:56:08.548465  4008 solver.cpp:260]     Total regularization terms: 1.15714 loss+regular. : 2.45382
I0518 01:57:38.838976  4008 solver.cpp:231] Iteration 120400, loss = 1.57033
I0518 01:57:38.839282  4008 solver.cpp:247]     Train net output #0: loss = 1.57033 (* 1 = 1.57033 loss)
I0518 01:57:38.839305  4008 sgd_solver.cpp:106] Iteration 120400, lr = 0.001
I0518 01:57:39.000550  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0078	1.04167	73.7057	0	84.2239	3.90625	80.4602	0	75.3624	0	70.1653	0	60.4647	0	23.6756	1.6	
I0518 01:57:39.074870  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:57:39.076459  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:57:39.076500  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:57:39.086441  4008 solver.cpp:260]     Total regularization terms: 1.15684 loss+regular. : 2.72717
I0518 01:59:04.957186  4008 solver.cpp:231] Iteration 120600, loss = 1.56681
I0518 01:59:04.958169  4008 solver.cpp:247]     Train net output #0: loss = 1.56681 (* 1 = 1.56681 loss)
I0518 01:59:04.958205  4008 sgd_solver.cpp:106] Iteration 120600, lr = 0.001
I0518 01:59:05.117614  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9361	1.04167	74.0807	0	84.3134	3.90625	80.4807	0	75.4022	0	70.2032	0	60.5031	0	23.6866	1.6	
I0518 01:59:05.192965  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 01:59:05.195205  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 01:59:05.195271  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 01:59:05.205435  4008 solver.cpp:260]     Total regularization terms: 1.15635 loss+regular. : 2.72316
I0518 02:00:54.003250  4008 solver.cpp:231] Iteration 120800, loss = 1.43545
I0518 02:00:54.003717  4008 solver.cpp:247]     Train net output #0: loss = 1.43545 (* 1 = 1.43545 loss)
I0518 02:00:54.003756  4008 sgd_solver.cpp:106] Iteration 120800, lr = 0.001
I0518 02:00:54.162492  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0078	1.04167	74.111	0	84.3307	3.90625	80.5213	0	75.4282	0	70.2412	0	60.5422	0	23.6987	1.6	
I0518 02:00:54.237084  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:00:54.239267  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:00:54.239315  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:00:54.249361  4008 solver.cpp:260]     Total regularization terms: 1.1558 loss+regular. : 2.59126
I0518 02:01:19.086323  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:02:14.333278  4008 solver.cpp:348] Iteration 121000, Testing net (#0)
I0518 02:03:25.152333  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:03:38.088835  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55544
I0518 02:03:38.088924  4008 solver.cpp:415]     Test net output #1: loss = 1.91643 (* 1 = 1.91643 loss)
I0518 02:03:38.179447  4008 solver.cpp:231] Iteration 121000, loss = 1.31608
I0518 02:03:38.179527  4008 solver.cpp:247]     Train net output #0: loss = 1.31608 (* 1 = 1.31608 loss)
I0518 02:03:38.179545  4008 sgd_solver.cpp:106] Iteration 121000, lr = 0.001
I0518 02:03:38.344336  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.761	1.04167	74.1354	0	84.3294	3.90625	80.5427	0	75.4535	0	70.2784	0	60.5815	0	23.7095	1.6	
I0518 02:03:38.418669  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:03:38.420904  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:03:38.420949  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:03:38.430869  4008 solver.cpp:260]     Total regularization terms: 1.15531 loss+regular. : 2.47139
I0518 02:05:06.721290  4008 solver.cpp:231] Iteration 121200, loss = 1.34492
I0518 02:05:06.721894  4008 solver.cpp:247]     Train net output #0: loss = 1.34492 (* 1 = 1.34492 loss)
I0518 02:05:06.721917  4008 sgd_solver.cpp:106] Iteration 121200, lr = 0.001
I0518 02:05:06.881671  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0652	1.04167	74.2262	0	84.346	3.90625	80.5634	0	75.4668	0	70.3163	0	60.6199	0	23.7223	1.6	
I0518 02:05:06.955971  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:05:06.957520  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:05:06.957581  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:05:06.967543  4008 solver.cpp:260]     Total regularization terms: 1.15482 loss+regular. : 2.49974
I0518 02:06:51.888080  4008 solver.cpp:231] Iteration 121400, loss = 1.46273
I0518 02:06:51.888378  4008 solver.cpp:247]     Train net output #0: loss = 1.46273 (* 1 = 1.46273 loss)
I0518 02:06:51.888411  4008 sgd_solver.cpp:106] Iteration 121400, lr = 0.001
I0518 02:06:52.047196  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8815	1.04167	74.1992	0	84.3817	3.90625	80.5822	0	75.496	0	70.3528	0	60.6582	0	23.7336	1.6	
I0518 02:06:52.122009  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:06:52.124395  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:06:52.124442  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:06:52.134275  4008 solver.cpp:260]     Total regularization terms: 1.15434 loss+regular. : 2.61707
I0518 02:08:24.368407  4008 solver.cpp:231] Iteration 121600, loss = 1.315
I0518 02:08:24.368859  4008 solver.cpp:247]     Train net output #0: loss = 1.315 (* 1 = 1.315 loss)
I0518 02:08:24.368882  4008 sgd_solver.cpp:106] Iteration 121600, lr = 0.001
I0518 02:08:24.529111  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8844	1.04167	74.2744	0	84.3853	3.90625	80.6026	0	75.5018	0	70.3905	0	60.696	0	23.7446	1.6	
I0518 02:08:24.603237  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:08:24.604815  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:08:24.604858  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:08:24.614711  4008 solver.cpp:260]     Total regularization terms: 1.15386 loss+regular. : 2.46886
I0518 02:09:52.738621  4008 solver.cpp:231] Iteration 121800, loss = 1.57488
I0518 02:09:52.738857  4008 solver.cpp:247]     Train net output #0: loss = 1.57488 (* 1 = 1.57488 loss)
I0518 02:09:52.738884  4008 sgd_solver.cpp:106] Iteration 121800, lr = 0.001
I0518 02:09:52.900137  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0595	1.04167	74.3161	0	84.4079	3.90625	80.6286	0	75.5301	0	70.4283	0	60.7345	0	23.7562	1.6	
I0518 02:09:52.974776  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:09:52.977015  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:09:52.977061  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:09:52.986979  4008 solver.cpp:260]     Total regularization terms: 1.15335 loss+regular. : 2.72823
I0518 02:10:19.579628  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:11:22.582564  4008 solver.cpp:348] Iteration 122000, Testing net (#0)
I0518 02:12:50.554986  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:13:04.794997  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55482
I0518 02:13:04.795081  4008 solver.cpp:415]     Test net output #1: loss = 1.91979 (* 1 = 1.91979 loss)
I0518 02:13:04.884073  4008 solver.cpp:231] Iteration 122000, loss = 1.38457
I0518 02:13:04.884148  4008 solver.cpp:247]     Train net output #0: loss = 1.38457 (* 1 = 1.38457 loss)
I0518 02:13:04.884166  4008 sgd_solver.cpp:106] Iteration 122000, lr = 0.001
I0518 02:13:05.051693  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0853	1.04167	74.1585	0	84.409	3.90625	80.6283	0	75.5572	0	70.4648	0	60.773	0	23.7682	1.6	
I0518 02:13:05.126106  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:13:05.128334  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:13:05.128377  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:13:05.138396  4008 solver.cpp:260]     Total regularization terms: 1.15291 loss+regular. : 2.53748
I0518 02:14:35.633129  4008 solver.cpp:231] Iteration 122200, loss = 1.45005
I0518 02:14:35.633474  4008 solver.cpp:247]     Train net output #0: loss = 1.45005 (* 1 = 1.45005 loss)
I0518 02:14:35.633501  4008 sgd_solver.cpp:106] Iteration 122200, lr = 0.001
I0518 02:14:35.792376  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9734	1.04167	74.3011	0	84.441	3.90625	80.6654	0	75.5778	0	70.5014	0	60.8112	0	23.78	1.6	
I0518 02:14:35.866765  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:14:35.869004  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:14:35.869061  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:14:35.879106  4008 solver.cpp:260]     Total regularization terms: 1.1524 loss+regular. : 2.60245
I0518 02:15:56.375784  4008 solver.cpp:231] Iteration 122400, loss = 1.35788
I0518 02:15:56.376269  4008 solver.cpp:247]     Train net output #0: loss = 1.35788 (* 1 = 1.35788 loss)
I0518 02:15:56.376305  4008 sgd_solver.cpp:106] Iteration 122400, lr = 0.001
I0518 02:15:56.535806  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9389	1.04167	74.3682	0	84.4774	3.90625	80.6824	0	75.6142	0	70.5376	0	60.8493	0	23.7912	1.6	
I0518 02:15:56.610436  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:15:56.612776  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:15:56.612838  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:15:56.622989  4008 solver.cpp:260]     Total regularization terms: 1.15197 loss+regular. : 2.50985
I0518 02:17:19.331181  4008 solver.cpp:231] Iteration 122600, loss = 1.40274
I0518 02:17:19.333648  4008 solver.cpp:247]     Train net output #0: loss = 1.40274 (* 1 = 1.40274 loss)
I0518 02:17:19.333680  4008 sgd_solver.cpp:106] Iteration 122600, lr = 0.001
I0518 02:17:19.490978  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0422	1.04167	74.1641	0	84.4585	3.90625	80.7117	0	75.6388	0	70.5746	0	60.8871	0	23.8028	1.6	
I0518 02:17:19.565448  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:17:19.567833  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:17:19.567884  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:17:19.583245  4008 solver.cpp:260]     Total regularization terms: 1.15146 loss+regular. : 2.5542
I0518 02:18:57.365536  4008 solver.cpp:231] Iteration 122800, loss = 1.27689
I0518 02:18:57.366161  4008 solver.cpp:247]     Train net output #0: loss = 1.27689 (* 1 = 1.27689 loss)
I0518 02:18:57.366186  4008 sgd_solver.cpp:106] Iteration 122800, lr = 0.001
I0518 02:18:57.525326  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2173	1.04167	74.1888	0	84.4792	3.90625	80.7145	0	75.6513	0	70.6116	0	60.9252	0	23.8141	1.6	
I0518 02:18:57.599694  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:18:57.601902  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:18:57.601949  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:18:57.611896  4008 solver.cpp:260]     Total regularization terms: 1.15102 loss+regular. : 2.42791
I0518 02:19:30.767416  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:20:27.285878  4008 solver.cpp:348] Iteration 123000, Testing net (#0)
I0518 02:21:40.392217  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:21:50.616226  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55474
I0518 02:21:50.616313  4008 solver.cpp:415]     Test net output #1: loss = 1.9269 (* 1 = 1.9269 loss)
I0518 02:21:50.704468  4008 solver.cpp:231] Iteration 123000, loss = 1.60268
I0518 02:21:50.704548  4008 solver.cpp:247]     Train net output #0: loss = 1.60268 (* 1 = 1.60268 loss)
I0518 02:21:50.704568  4008 sgd_solver.cpp:106] Iteration 123000, lr = 0.001
I0518 02:21:50.863416  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8528	1.04167	74.1572	0	84.4954	3.90625	80.7173	0	75.6793	0	70.6478	0	60.9624	0	23.8253	1.6	
I0518 02:21:50.938197  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:21:50.940526  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:21:50.940569  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:21:50.950579  4008 solver.cpp:260]     Total regularization terms: 1.1505 loss+regular. : 2.75317
I0518 02:23:16.158634  4008 solver.cpp:231] Iteration 123200, loss = 1.44767
I0518 02:23:16.159147  4008 solver.cpp:247]     Train net output #0: loss = 1.44767 (* 1 = 1.44767 loss)
I0518 02:23:16.159193  4008 sgd_solver.cpp:106] Iteration 123200, lr = 0.001
I0518 02:23:16.320731  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9648	1.04167	74.2484	0	84.5218	3.90625	80.7429	0	75.692	0	70.684	0	60.9998	0	23.8363	1.6	
I0518 02:23:16.395231  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:23:16.397444  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:23:16.397492  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:23:16.407531  4008 solver.cpp:260]     Total regularization terms: 1.15009 loss+regular. : 2.59776
I0518 02:24:42.834642  4008 solver.cpp:231] Iteration 123400, loss = 1.30263
I0518 02:24:42.834933  4008 solver.cpp:247]     Train net output #0: loss = 1.30263 (* 1 = 1.30263 loss)
I0518 02:24:42.834954  4008 sgd_solver.cpp:106] Iteration 123400, lr = 0.001
I0518 02:24:42.994935  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0738	1.04167	74.1644	0	84.5435	3.90625	80.7815	0	75.7148	0	70.7203	0	61.037	0	23.8473	1.6	
I0518 02:24:43.068924  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:24:43.070614  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:24:43.070669  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:24:43.080696  4008 solver.cpp:260]     Total regularization terms: 1.14965 loss+regular. : 2.45228
I0518 02:26:16.092298  4008 solver.cpp:231] Iteration 123600, loss = 1.60389
I0518 02:26:16.092612  4008 solver.cpp:247]     Train net output #0: loss = 1.60389 (* 1 = 1.60389 loss)
I0518 02:26:16.092636  4008 sgd_solver.cpp:106] Iteration 123600, lr = 0.001
I0518 02:26:16.252840  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0537	1.04167	74.236	0	84.5608	3.90625	80.7956	0	75.7485	0	70.7569	0	61.0734	0	23.8591	1.6	
I0518 02:26:16.327196  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:26:16.328940  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:26:16.328989  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:26:16.338910  4008 solver.cpp:260]     Total regularization terms: 1.14922 loss+regular. : 2.75311
I0518 02:27:47.090062  4008 solver.cpp:231] Iteration 123800, loss = 1.28756
I0518 02:27:47.090317  4008 solver.cpp:247]     Train net output #0: loss = 1.28756 (* 1 = 1.28756 loss)
I0518 02:27:47.090338  4008 sgd_solver.cpp:106] Iteration 123800, lr = 0.001
I0518 02:27:47.250983  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2087	1.04167	74.1484	0	84.5725	3.90625	80.8068	0	75.758	0	70.7932	0	61.1111	0	23.8698	1.6	
I0518 02:27:47.325343  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:27:47.327255  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:27:47.327306  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:27:47.337240  4008 solver.cpp:260]     Total regularization terms: 1.14874 loss+regular. : 2.4363
I0518 02:28:20.786592  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:29:15.314582  4008 solver.cpp:348] Iteration 124000, Testing net (#0)
I0518 02:30:28.636188  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:30:38.205909  4008 solver.cpp:415]     Test net output #0: accuracy = 0.551859
I0518 02:30:38.206068  4008 solver.cpp:415]     Test net output #1: loss = 1.91787 (* 1 = 1.91787 loss)
I0518 02:30:38.295068  4008 solver.cpp:231] Iteration 124000, loss = 1.48119
I0518 02:30:38.295183  4008 solver.cpp:247]     Train net output #0: loss = 1.48119 (* 1 = 1.48119 loss)
I0518 02:30:38.295208  4008 sgd_solver.cpp:106] Iteration 124000, lr = 0.001
I0518 02:30:38.454735  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.7036	1.04167	74.4909	0	84.6203	3.90625	80.8475	0	75.7867	0	70.8291	0	61.1486	0	23.8812	1.6	
I0518 02:30:38.529384  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:30:38.530632  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:30:38.530663  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:30:38.544200  4008 solver.cpp:260]     Total regularization terms: 1.14822 loss+regular. : 2.62941
I0518 02:31:57.989354  4008 solver.cpp:231] Iteration 124200, loss = 1.44055
I0518 02:31:57.989923  4008 solver.cpp:247]     Train net output #0: loss = 1.44055 (* 1 = 1.44055 loss)
I0518 02:31:57.989945  4008 sgd_solver.cpp:106] Iteration 124200, lr = 0.001
I0518 02:31:58.149987  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.916	1.04167	74.4671	0	84.622	3.90625	80.8671	0	75.8029	0	70.8654	0	61.1872	0	23.8925	1.6	
I0518 02:31:58.224534  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:31:58.225893  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:31:58.225952  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:31:58.237426  4008 solver.cpp:260]     Total regularization terms: 1.14779 loss+regular. : 2.58834
I0518 02:33:24.666219  4008 solver.cpp:231] Iteration 124400, loss = 1.26723
I0518 02:33:24.666595  4008 solver.cpp:247]     Train net output #0: loss = 1.26723 (* 1 = 1.26723 loss)
I0518 02:33:24.666623  4008 sgd_solver.cpp:106] Iteration 124400, lr = 0.001
I0518 02:33:24.826366  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8701	1.04167	74.4046	0	84.6323	3.90625	80.8901	0	75.8326	0	70.9012	0	61.2257	0	23.9036	1.6	
I0518 02:33:24.900391  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:33:24.901849  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:33:24.901896  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:33:24.911903  4008 solver.cpp:260]     Total regularization terms: 1.1473 loss+regular. : 2.41454
I0518 02:34:59.481763  4008 solver.cpp:231] Iteration 124600, loss = 1.47231
I0518 02:34:59.482044  4008 solver.cpp:247]     Train net output #0: loss = 1.47231 (* 1 = 1.47231 loss)
I0518 02:34:59.482064  4008 sgd_solver.cpp:106] Iteration 124600, lr = 0.001
I0518 02:34:59.643270  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1513	1.04167	74.4027	0	84.6248	3.90625	80.8909	0	75.8432	0	70.9374	0	61.2633	0	23.9147	1.6	
I0518 02:34:59.721668  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:34:59.723888  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:34:59.723939  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:34:59.739218  4008 solver.cpp:260]     Total regularization terms: 1.14689 loss+regular. : 2.61921
I0518 02:36:29.008021  4008 solver.cpp:231] Iteration 124800, loss = 1.4811
I0518 02:36:29.008435  4008 solver.cpp:247]     Train net output #0: loss = 1.4811 (* 1 = 1.4811 loss)
I0518 02:36:29.008477  4008 sgd_solver.cpp:106] Iteration 124800, lr = 0.001
I0518 02:36:29.168768  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2202	1.04167	74.3079	0	84.6389	3.90625	80.8981	0	75.8803	0	70.973	0	61.3002	0	23.926	1.6	
I0518 02:36:29.243790  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:36:29.245080  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:36:29.245110  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:36:29.274613  4008 solver.cpp:260]     Total regularization terms: 1.14648 loss+regular. : 2.62758
I0518 02:37:03.857885  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:37:58.685242  4008 solver.cpp:348] Iteration 125000, Testing net (#0)
I0518 02:39:06.454993  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:39:15.985343  4008 solver.cpp:415]     Test net output #0: accuracy = 0.554
I0518 02:39:15.985430  4008 solver.cpp:415]     Test net output #1: loss = 1.91138 (* 1 = 1.91138 loss)
I0518 02:39:16.074800  4008 solver.cpp:231] Iteration 125000, loss = 1.33889
I0518 02:39:16.074908  4008 solver.cpp:247]     Train net output #0: loss = 1.33889 (* 1 = 1.33889 loss)
I0518 02:39:16.074930  4008 sgd_solver.cpp:106] Iteration 125000, lr = 0.001
I0518 02:39:16.242655  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0968	1.04167	74.4619	0	84.6577	3.90625	80.9329	0	75.8805	0	71.0088	0	61.3376	0	23.9367	1.6	
I0518 02:39:16.317572  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:39:16.319747  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:39:16.319782  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:39:16.329892  4008 solver.cpp:260]     Total regularization terms: 1.14601 loss+regular. : 2.4849
I0518 02:40:41.756829  4008 solver.cpp:231] Iteration 125200, loss = 1.34386
I0518 02:40:41.757225  4008 solver.cpp:247]     Train net output #0: loss = 1.34386 (* 1 = 1.34386 loss)
I0518 02:40:41.757247  4008 sgd_solver.cpp:106] Iteration 125200, lr = 0.001
I0518 02:40:41.916849  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1542	1.04167	74.4307	0	84.6515	3.90625	80.9347	0	75.921	0	71.0447	0	61.3737	0	23.9469	1.6	
I0518 02:40:41.991405  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:40:41.993019  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:40:41.993062  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:40:42.003146  4008 solver.cpp:260]     Total regularization terms: 1.14552 loss+regular. : 2.48938
I0518 02:42:08.274216  4008 solver.cpp:231] Iteration 125400, loss = 1.50378
I0518 02:42:08.274685  4008 solver.cpp:247]     Train net output #0: loss = 1.50378 (* 1 = 1.50378 loss)
I0518 02:42:08.274721  4008 sgd_solver.cpp:106] Iteration 125400, lr = 0.001
I0518 02:42:08.432032  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9762	1.04167	74.3151	0	84.673	3.90625	80.9403	0	75.9259	0	71.0808	0	61.4113	0	23.9582	1.6	
I0518 02:42:08.506456  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:42:08.507676  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:42:08.507710  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:42:08.517488  4008 solver.cpp:260]     Total regularization terms: 1.14516 loss+regular. : 2.64894
I0518 02:43:39.007550  4008 solver.cpp:231] Iteration 125600, loss = 1.429
I0518 02:43:39.007864  4008 solver.cpp:247]     Train net output #0: loss = 1.429 (* 1 = 1.429 loss)
I0518 02:43:39.007886  4008 sgd_solver.cpp:106] Iteration 125600, lr = 0.001
I0518 02:43:39.166501  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.289	1.04167	74.4362	0	84.6944	3.90625	80.9763	0	75.9628	0	71.1155	0	61.4482	0	23.9693	1.6	
I0518 02:43:39.240950  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:43:39.243160  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:43:39.243204  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:43:39.253046  4008 solver.cpp:260]     Total regularization terms: 1.14477 loss+regular. : 2.57377
I0518 02:45:07.014755  4008 solver.cpp:231] Iteration 125800, loss = 1.44658
I0518 02:45:07.015233  4008 solver.cpp:247]     Train net output #0: loss = 1.44658 (* 1 = 1.44658 loss)
I0518 02:45:07.015265  4008 sgd_solver.cpp:106] Iteration 125800, lr = 0.001
I0518 02:45:07.175508  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3062	1.04167	74.5967	0	84.7255	3.90625	81.0098	0	75.9906	0	71.1513	0	61.4851	0	23.9801	1.6	
I0518 02:45:07.250423  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:45:07.252445  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:45:07.252480  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:45:07.262269  4008 solver.cpp:260]     Total regularization terms: 1.1443 loss+regular. : 2.59089
I0518 02:45:46.069453  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:46:31.262362  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_126000.caffemodel
I0518 02:50:19.935020  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_126000.solverstate
I0518 02:50:20.697602  4008 solver.cpp:348] Iteration 126000, Testing net (#0)
I0518 02:51:35.087278  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:51:43.390393  4008 solver.cpp:415]     Test net output #0: accuracy = 0.552779
I0518 02:51:43.390542  4008 solver.cpp:415]     Test net output #1: loss = 1.91278 (* 1 = 1.91278 loss)
I0518 02:51:43.483888  4008 solver.cpp:231] Iteration 126000, loss = 1.47929
I0518 02:51:43.483997  4008 solver.cpp:247]     Train net output #0: loss = 1.47929 (* 1 = 1.47929 loss)
I0518 02:51:43.484025  4008 sgd_solver.cpp:106] Iteration 126000, lr = 0.001
I0518 02:51:43.645313  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2948	1.04167	74.7031	0	84.7349	3.90625	81.0325	0	76.02	0	71.1868	0	61.5219	0	23.9909	1.6	
I0518 02:51:43.646683  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:51:43.648912  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:51:43.648949  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:51:43.658895  4008 solver.cpp:260]     Total regularization terms: 1.14383 loss+regular. : 2.62312
I0518 02:53:06.126792  4008 solver.cpp:231] Iteration 126200, loss = 1.4677
I0518 02:53:06.128463  4008 solver.cpp:247]     Train net output #0: loss = 1.4677 (* 1 = 1.4677 loss)
I0518 02:53:06.128494  4008 sgd_solver.cpp:106] Iteration 126200, lr = 0.001
I0518 02:53:06.287343  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1168	1.04167	74.6725	0	84.7767	3.90625	81.058	0	76.041	0	71.2222	0	61.5578	0	24.0013	1.6	
I0518 02:53:06.362069  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:53:06.363831  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:53:06.363917  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:53:06.384493  4008 solver.cpp:260]     Total regularization terms: 1.14338 loss+regular. : 2.61108
I0518 02:54:32.148339  4008 solver.cpp:231] Iteration 126400, loss = 1.40929
I0518 02:54:32.148656  4008 solver.cpp:247]     Train net output #0: loss = 1.40929 (* 1 = 1.40929 loss)
I0518 02:54:32.148807  4008 sgd_solver.cpp:106] Iteration 126400, lr = 0.001
I0518 02:54:32.307081  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2029	1.04167	74.6862	0	84.7894	3.90625	81.0681	0	76.0417	0	71.257	0	61.5945	0	24.0125	1.6	
I0518 02:54:32.381705  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:54:32.383829  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:54:32.383872  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:54:32.393793  4008 solver.cpp:260]     Total regularization terms: 1.14303 loss+regular. : 2.55232
I0518 02:55:59.620177  4008 solver.cpp:231] Iteration 126600, loss = 1.67996
I0518 02:55:59.620637  4008 solver.cpp:247]     Train net output #0: loss = 1.67996 (* 1 = 1.67996 loss)
I0518 02:55:59.620672  4008 sgd_solver.cpp:106] Iteration 126600, lr = 0.001
I0518 02:55:59.780897  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.8844	1.04167	74.6855	0	84.8029	3.90625	81.0942	0	76.0702	0	71.2918	0	61.6317	0	24.0221	1.6	
I0518 02:55:59.856266  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:55:59.858496  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:55:59.858543  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:55:59.868517  4008 solver.cpp:260]     Total regularization terms: 1.14252 loss+regular. : 2.82247
I0518 02:57:38.988767  4008 solver.cpp:231] Iteration 126800, loss = 1.29098
I0518 02:57:38.989079  4008 solver.cpp:247]     Train net output #0: loss = 1.29098 (* 1 = 1.29098 loss)
I0518 02:57:38.989107  4008 sgd_solver.cpp:106] Iteration 126800, lr = 0.001
I0518 02:57:39.148176  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1542	1.04167	74.7028	0	84.8149	3.90625	81.1135	0	76.0799	0	71.3263	0	61.6685	0	24.0328	1.6	
I0518 02:57:39.222717  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.78125	0	0	0	0	0	0	0	0	0	0	0	
I0518 02:57:39.224481  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 02:57:39.224517  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 02:57:39.234254  4008 solver.cpp:260]     Total regularization terms: 1.14202 loss+regular. : 2.433
I0518 02:58:17.925052  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 02:58:58.098686  4008 solver.cpp:348] Iteration 127000, Testing net (#0)
I0518 03:00:10.326243  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:00:17.368556  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5544
I0518 03:00:17.368736  4008 solver.cpp:415]     Test net output #1: loss = 1.91866 (* 1 = 1.91866 loss)
I0518 03:00:17.456318  4008 solver.cpp:231] Iteration 127000, loss = 1.3651
I0518 03:00:17.456410  4008 solver.cpp:247]     Train net output #0: loss = 1.3651 (* 1 = 1.3651 loss)
I0518 03:00:17.456430  4008 sgd_solver.cpp:106] Iteration 127000, lr = 0.001
I0518 03:00:17.625067  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2948	1.04167	74.6071	0	84.8366	3.90625	81.1377	0	76.1221	0	71.3616	0	61.7049	0	24.0437	1.6	
I0518 03:00:17.701688  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.824653	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:00:17.703263  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:00:17.703305  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:00:17.715271  4008 solver.cpp:260]     Total regularization terms: 1.14163 loss+regular. : 2.50672
I0518 03:01:33.332283  4008 solver.cpp:231] Iteration 127200, loss = 1.24847
I0518 03:01:33.332723  4008 solver.cpp:247]     Train net output #0: loss = 1.24847 (* 1 = 1.24847 loss)
I0518 03:01:33.332744  4008 sgd_solver.cpp:106] Iteration 127200, lr = 0.001
I0518 03:01:33.497922  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2374	1.04167	74.5309	0	84.847	3.90625	81.1597	0	76.1407	0	71.3963	0	61.7417	0	24.0552	1.6	
I0518 03:01:33.572983  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.824653	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:01:33.574754  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:01:33.574779  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:01:33.588388  4008 solver.cpp:260]     Total regularization terms: 1.1412 loss+regular. : 2.38967
I0518 03:02:47.875172  4008 solver.cpp:231] Iteration 127400, loss = 1.55953
I0518 03:02:47.875569  4008 solver.cpp:247]     Train net output #0: loss = 1.55953 (* 1 = 1.55953 loss)
I0518 03:02:47.875618  4008 sgd_solver.cpp:106] Iteration 127400, lr = 0.001
I0518 03:02:48.035693  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2517	1.04167	74.7135	0	84.8903	3.90625	81.1772	0	76.1707	0	71.4305	0	61.7781	0	24.0655	1.6	
I0518 03:02:48.110008  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.824653	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:02:48.111126  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:02:48.111155  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:02:48.140632  4008 solver.cpp:260]     Total regularization terms: 1.14078 loss+regular. : 2.70031
I0518 03:04:04.841151  4008 solver.cpp:231] Iteration 127600, loss = 1.54835
I0518 03:04:04.841627  4008 solver.cpp:247]     Train net output #0: loss = 1.54835 (* 1 = 1.54835 loss)
I0518 03:04:04.841650  4008 sgd_solver.cpp:106] Iteration 127600, lr = 0.001
I0518 03:04:05.001420  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.6721	1.04167	74.6663	0	84.893	3.90625	81.1989	0	76.1642	0	71.4653	0	61.8136	0	24.0767	1.6	
I0518 03:04:05.075776  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.824653	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:04:05.076906  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:04:05.076933  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:04:05.086755  4008 solver.cpp:260]     Total regularization terms: 1.14032 loss+regular. : 2.68867
I0518 03:05:31.284917  4008 solver.cpp:231] Iteration 127800, loss = 1.43293
I0518 03:05:31.285166  4008 solver.cpp:247]     Train net output #0: loss = 1.43293 (* 1 = 1.43293 loss)
I0518 03:05:31.285187  4008 sgd_solver.cpp:106] Iteration 127800, lr = 0.001
I0518 03:05:31.444872  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0336	1.04167	74.7305	0	84.8893	3.90625	81.2119	0	76.1934	0	71.4994	0	61.8503	0	24.0869	1.6	
I0518 03:05:31.519053  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.824653	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:05:31.520865  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:05:31.520890  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:05:31.530632  4008 solver.cpp:260]     Total regularization terms: 1.13987 loss+regular. : 2.57279
I0518 03:06:15.403055  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:06:53.762354  4008 solver.cpp:348] Iteration 128000, Testing net (#0)
I0518 03:08:08.753484  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:08:15.692061  4008 solver.cpp:415]     Test net output #0: accuracy = 0.553619
I0518 03:08:15.692162  4008 solver.cpp:415]     Test net output #1: loss = 1.92552 (* 1 = 1.92552 loss)
I0518 03:08:15.780180  4008 solver.cpp:231] Iteration 128000, loss = 1.43918
I0518 03:08:15.780285  4008 solver.cpp:247]     Train net output #0: loss = 1.43918 (* 1 = 1.43918 loss)
I0518 03:08:15.780304  4008 sgd_solver.cpp:106] Iteration 128000, lr = 0.001
I0518 03:08:15.946458  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9877	1.04167	74.7474	0	84.904	3.90625	81.2067	0	76.2223	0	71.5334	0	61.8867	0	24.0974	1.6	
I0518 03:08:16.020696  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.824653	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:08:16.022132  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:08:16.022173  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:08:16.031955  4008 solver.cpp:260]     Total regularization terms: 1.13938 loss+regular. : 2.57856
I0518 03:09:39.447751  4008 solver.cpp:231] Iteration 128200, loss = 1.30785
I0518 03:09:39.448048  4008 solver.cpp:247]     Train net output #0: loss = 1.30785 (* 1 = 1.30785 loss)
I0518 03:09:39.448070  4008 sgd_solver.cpp:106] Iteration 128200, lr = 0.001
I0518 03:09:39.608898  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2833	1.04167	74.8685	0	84.9238	3.90625	81.2226	0	76.2438	0	71.5677	0	61.9224	0	24.108	1.6	
I0518 03:09:39.683917  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.824653	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:09:39.685315  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:09:39.685343  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:09:39.700232  4008 solver.cpp:260]     Total regularization terms: 1.13895 loss+regular. : 2.44681
I0518 03:10:54.021852  4008 solver.cpp:231] Iteration 128400, loss = 1.43832
I0518 03:10:54.027245  4008 solver.cpp:247]     Train net output #0: loss = 1.43832 (* 1 = 1.43832 loss)
I0518 03:10:54.027276  4008 sgd_solver.cpp:106] Iteration 128400, lr = 0.001
I0518 03:10:54.181773  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2489	1.04167	74.7578	0	84.9217	3.90625	81.25	0	76.2682	0	71.6017	0	61.9582	0	24.1186	1.6	
I0518 03:10:54.257297  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:10:54.259222  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:10:54.259248  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:10:54.272959  4008 solver.cpp:260]     Total regularization terms: 1.13854 loss+regular. : 2.57685
I0518 03:12:14.484419  4008 solver.cpp:231] Iteration 128600, loss = 1.41757
I0518 03:12:14.484778  4008 solver.cpp:247]     Train net output #0: loss = 1.41757 (* 1 = 1.41757 loss)
I0518 03:12:14.484799  4008 sgd_solver.cpp:106] Iteration 128600, lr = 0.001
I0518 03:12:14.645520  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9935	1.04167	74.7129	0	84.9247	3.90625	81.263	0	76.2763	0	71.6366	0	61.994	0	24.1288	1.6	
I0518 03:12:14.720674  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:12:14.721870  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:12:14.721899  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:12:14.735736  4008 solver.cpp:260]     Total regularization terms: 1.13818 loss+regular. : 2.55574
I0518 03:13:35.166717  4008 solver.cpp:231] Iteration 128800, loss = 1.37009
I0518 03:13:35.167032  4008 solver.cpp:247]     Train net output #0: loss = 1.37009 (* 1 = 1.37009 loss)
I0518 03:13:35.167055  4008 sgd_solver.cpp:106] Iteration 128800, lr = 0.001
I0518 03:13:35.326283  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1168	1.04167	74.7816	0	84.9668	3.90625	81.2904	0	76.3046	0	71.671	0	62.0299	0	24.1397	1.6	
I0518 03:13:35.401859  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:13:35.403198  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:13:35.403229  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:13:35.418278  4008 solver.cpp:260]     Total regularization terms: 1.13775 loss+regular. : 2.50784
I0518 03:14:18.711067  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:14:51.232683  4008 solver.cpp:348] Iteration 129000, Testing net (#0)
I0518 03:16:00.593214  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:16:06.553391  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5519
I0518 03:16:06.553473  4008 solver.cpp:415]     Test net output #1: loss = 1.92086 (* 1 = 1.92086 loss)
I0518 03:16:06.640802  4008 solver.cpp:231] Iteration 129000, loss = 1.57346
I0518 03:16:06.640905  4008 solver.cpp:247]     Train net output #0: loss = 1.57346 (* 1 = 1.57346 loss)
I0518 03:16:06.640941  4008 sgd_solver.cpp:106] Iteration 129000, lr = 0.001
I0518 03:16:06.806651  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2029	1.04167	74.7008	0	84.9588	3.90625	81.3228	0	76.263	0	71.7053	0	62.0658	0	24.1492	1.6	
I0518 03:16:06.880950  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:16:06.882707  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:16:06.882740  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:16:06.892654  4008 solver.cpp:260]     Total regularization terms: 1.13736 loss+regular. : 2.71082
I0518 03:17:27.993955  4008 solver.cpp:231] Iteration 129200, loss = 1.26296
I0518 03:17:27.994285  4008 solver.cpp:247]     Train net output #0: loss = 1.26296 (* 1 = 1.26296 loss)
I0518 03:17:27.994307  4008 sgd_solver.cpp:106] Iteration 129200, lr = 0.001
I0518 03:17:28.154059  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3149	1.04167	74.7979	0	84.9771	3.90625	81.303	0	76.3129	0	71.7393	0	62.1018	0	24.1601	1.6	
I0518 03:17:28.229585  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:17:28.231658  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.6	
I0518 03:17:28.231689  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:17:28.247556  4008 solver.cpp:260]     Total regularization terms: 1.13689 loss+regular. : 2.39985
I0518 03:19:00.014561  4008 solver.cpp:231] Iteration 129400, loss = 1.42879
I0518 03:19:00.014881  4008 solver.cpp:247]     Train net output #0: loss = 1.42879 (* 1 = 1.42879 loss)
I0518 03:19:00.014904  4008 sgd_solver.cpp:106] Iteration 129400, lr = 0.001
I0518 03:19:00.175477  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9389	1.04167	74.792	0	84.9921	3.90625	81.3472	0	76.364	0	71.773	0	62.1367	0	24.1707	1.7	
I0518 03:19:00.249634  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:19:00.251533  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:19:00.251564  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:19:00.261523  4008 solver.cpp:260]     Total regularization terms: 1.13645 loss+regular. : 2.56524
I0518 03:20:20.825644  4008 solver.cpp:231] Iteration 129600, loss = 1.48448
I0518 03:20:20.825922  4008 solver.cpp:247]     Train net output #0: loss = 1.48448 (* 1 = 1.48448 loss)
I0518 03:20:20.825943  4008 sgd_solver.cpp:106] Iteration 129600, lr = 0.001
I0518 03:20:20.986431  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1111	1.04167	74.6816	0	84.9891	3.90625	81.3555	0	76.3688	0	71.8067	0	62.1728	0	24.1816	1.7	
I0518 03:20:21.060626  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:20:21.062271  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:20:21.062306  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:20:21.082448  4008 solver.cpp:260]     Total regularization terms: 1.136 loss+regular. : 2.62048
I0518 03:21:39.753145  4008 solver.cpp:231] Iteration 129800, loss = 1.67824
I0518 03:21:39.753476  4008 solver.cpp:247]     Train net output #0: loss = 1.67824 (* 1 = 1.67824 loss)
I0518 03:21:39.753623  4008 sgd_solver.cpp:106] Iteration 129800, lr = 0.001
I0518 03:21:39.914098  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1255	1.04167	74.7441	0	84.9965	3.90625	81.387	0	76.3993	0	71.8401	0	62.2084	0	24.1919	1.7	
I0518 03:21:39.991293  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:21:39.993280  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:21:39.993320  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:21:40.007202  4008 solver.cpp:260]     Total regularization terms: 1.13558 loss+regular. : 2.81383
I0518 03:22:28.027674  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:23:01.007997  4008 solver.cpp:348] Iteration 130000, Testing net (#0)
I0518 03:24:10.674520  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:24:16.732229  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55448
I0518 03:24:16.732322  4008 solver.cpp:415]     Test net output #1: loss = 1.91582 (* 1 = 1.91582 loss)
I0518 03:24:16.819728  4008 solver.cpp:231] Iteration 130000, loss = 1.40119
I0518 03:24:16.819829  4008 solver.cpp:247]     Train net output #0: loss = 1.40119 (* 1 = 1.40119 loss)
I0518 03:24:16.819847  4008 sgd_solver.cpp:106] Iteration 130000, lr = 0.001
I0518 03:24:16.983460  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9188	1.04167	74.8148	0	85.028	3.90625	81.4117	0	76.4199	0	71.8739	0	62.2442	0	24.2034	1.7	
I0518 03:24:17.058522  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:24:17.060616  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:24:17.060658  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:24:17.070487  4008 solver.cpp:260]     Total regularization terms: 1.13505 loss+regular. : 2.53624
I0518 03:25:34.827469  4008 solver.cpp:231] Iteration 130200, loss = 1.45107
I0518 03:25:34.827847  4008 solver.cpp:247]     Train net output #0: loss = 1.45107 (* 1 = 1.45107 loss)
I0518 03:25:34.827862  4008 sgd_solver.cpp:106] Iteration 130200, lr = 0.001
I0518 03:25:34.987102  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1857	1.04167	74.9336	0	85.0281	3.90625	81.4384	0	76.4572	0	71.9077	0	62.2791	0	24.2139	1.7	
I0518 03:25:35.061873  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:25:35.062999  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:25:35.063021  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:25:35.077950  4008 solver.cpp:260]     Total regularization terms: 1.13459 loss+regular. : 2.58566
I0518 03:26:55.321954  4008 solver.cpp:231] Iteration 130400, loss = 1.39061
I0518 03:26:55.323041  4008 solver.cpp:247]     Train net output #0: loss = 1.39061 (* 1 = 1.39061 loss)
I0518 03:26:55.323065  4008 sgd_solver.cpp:106] Iteration 130400, lr = 0.001
I0518 03:26:55.483649  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1111	1.04167	74.681	0	85.0343	3.90625	81.415	0	76.4658	0	71.9414	0	62.3142	0	24.2246	1.7	
I0518 03:26:55.559027  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:26:55.560425  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:26:55.560458  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:26:55.581183  4008 solver.cpp:260]     Total regularization terms: 1.13424 loss+regular. : 2.52485
I0518 03:28:16.647092  4008 solver.cpp:231] Iteration 130600, loss = 1.45732
I0518 03:28:16.649654  4008 solver.cpp:247]     Train net output #0: loss = 1.45732 (* 1 = 1.45732 loss)
I0518 03:28:16.649688  4008 sgd_solver.cpp:106] Iteration 130600, lr = 0.001
I0518 03:28:16.807446  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1168	1.04167	74.8135	0	85.0766	3.90625	81.44	0	76.4852	0	71.9749	0	62.3495	0	24.2352	1.7	
I0518 03:28:16.881834  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:28:16.883747  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:28:16.883785  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:28:16.893615  4008 solver.cpp:260]     Total regularization terms: 1.1339 loss+regular. : 2.59122
I0518 03:29:42.871043  4008 solver.cpp:231] Iteration 130800, loss = 1.48874
I0518 03:29:42.871342  4008 solver.cpp:247]     Train net output #0: loss = 1.48874 (* 1 = 1.48874 loss)
I0518 03:29:42.871363  4008 sgd_solver.cpp:106] Iteration 130800, lr = 0.001
I0518 03:29:43.033947  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.959	1.04167	74.8141	0	85.0939	3.90625	81.4752	0	76.5067	0	72.0082	0	62.3844	0	24.2466	1.7	
I0518 03:29:43.109639  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:29:43.111351  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:29:43.111374  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:29:43.125563  4008 solver.cpp:260]     Total regularization terms: 1.13343 loss+regular. : 2.62217
I0518 03:30:43.546931  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:31:10.294872  4008 solver.cpp:348] Iteration 131000, Testing net (#0)
I0518 03:32:21.786958  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:32:26.908123  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55432
I0518 03:32:26.908216  4008 solver.cpp:415]     Test net output #1: loss = 1.91343 (* 1 = 1.91343 loss)
I0518 03:32:26.995740  4008 solver.cpp:231] Iteration 131000, loss = 1.42331
I0518 03:32:26.995815  4008 solver.cpp:247]     Train net output #0: loss = 1.42331 (* 1 = 1.42331 loss)
I0518 03:32:26.995832  4008 sgd_solver.cpp:106] Iteration 131000, lr = 0.001
I0518 03:32:27.156260  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0595	1.04167	74.9564	0	85.129	3.90625	81.5145	0	76.5363	0	72.042	0	62.4193	0	24.2574	1.7	
I0518 03:32:27.232259  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:32:27.234143  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:32:27.234187  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:32:27.243907  4008 solver.cpp:260]     Total regularization terms: 1.13299 loss+regular. : 2.55629
I0518 03:33:48.515928  4008 solver.cpp:231] Iteration 131200, loss = 1.60754
I0518 03:33:48.516294  4008 solver.cpp:247]     Train net output #0: loss = 1.60754 (* 1 = 1.60754 loss)
I0518 03:33:48.516315  4008 sgd_solver.cpp:106] Iteration 131200, lr = 0.001
I0518 03:33:48.676383  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0939	1.04167	75.054	0	85.1375	3.90625	81.5228	0	76.57	0	72.0755	0	62.4546	0	24.2696	1.7	
I0518 03:33:48.750669  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:33:48.752672  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:33:48.752701  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:33:48.762413  4008 solver.cpp:260]     Total regularization terms: 1.13263 loss+regular. : 2.74017
I0518 03:35:11.449761  4008 solver.cpp:231] Iteration 131400, loss = 1.35517
I0518 03:35:11.450088  4008 solver.cpp:247]     Train net output #0: loss = 1.35517 (* 1 = 1.35517 loss)
I0518 03:35:11.450109  4008 sgd_solver.cpp:106] Iteration 131400, lr = 0.001
I0518 03:35:11.611232  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3608	1.04167	75.0212	0	85.1541	3.90625	81.5366	0	76.5795	0	72.1084	0	62.4893	0	24.2794	1.7	
I0518 03:35:11.685832  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:35:11.686947  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:35:11.686970  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:35:11.701961  4008 solver.cpp:260]     Total regularization terms: 1.1322 loss+regular. : 2.48737
I0518 03:36:33.906222  4008 solver.cpp:231] Iteration 131600, loss = 1.48592
I0518 03:36:33.906508  4008 solver.cpp:247]     Train net output #0: loss = 1.48592 (* 1 = 1.48592 loss)
I0518 03:36:33.906528  4008 sgd_solver.cpp:106] Iteration 131600, lr = 0.001
I0518 03:36:34.066782  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3407	1.04167	75.0482	0	85.1561	3.90625	81.5461	0	76.5862	0	72.1415	0	62.5235	0	24.29	1.7	
I0518 03:36:34.141705  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:36:34.143409  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:36:34.143450  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:36:34.153347  4008 solver.cpp:260]     Total regularization terms: 1.13179 loss+regular. : 2.61771
I0518 03:37:59.875162  4008 solver.cpp:231] Iteration 131800, loss = 1.58758
I0518 03:37:59.876307  4008 solver.cpp:247]     Train net output #0: loss = 1.58758 (* 1 = 1.58758 loss)
I0518 03:37:59.876332  4008 sgd_solver.cpp:106] Iteration 131800, lr = 0.001
I0518 03:38:00.035051  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2144	1.04167	74.9655	0	85.1826	3.90625	81.5728	0	76.6077	0	72.1747	0	62.5573	0	24.3003	1.7	
I0518 03:38:00.109335  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:38:00.111058  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:38:00.111088  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:38:00.123318  4008 solver.cpp:260]     Total regularization terms: 1.13132 loss+regular. : 2.7189
I0518 03:38:56.557124  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:39:22.887365  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_132000.caffemodel
I0518 03:41:04.493186  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_132000.solverstate
I0518 03:41:05.026372  4008 solver.cpp:348] Iteration 132000, Testing net (#0)
I0518 03:42:10.860030  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:42:15.204007  4008 solver.cpp:415]     Test net output #0: accuracy = 0.554439
I0518 03:42:15.204109  4008 solver.cpp:415]     Test net output #1: loss = 1.92079 (* 1 = 1.92079 loss)
I0518 03:42:15.291755  4008 solver.cpp:231] Iteration 132000, loss = 1.53778
I0518 03:42:15.291847  4008 solver.cpp:247]     Train net output #0: loss = 1.53778 (* 1 = 1.53778 loss)
I0518 03:42:15.291864  4008 sgd_solver.cpp:106] Iteration 132000, lr = 0.001
I0518 03:42:15.453692  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9963	1.04167	74.8721	0	85.1877	3.90625	81.5933	0	76.6233	0	72.2084	0	62.5924	0	24.311	1.7	
I0518 03:42:15.454540  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:42:15.455852  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:42:15.455868  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:42:15.467053  4008 solver.cpp:260]     Total regularization terms: 1.13099 loss+regular. : 2.66877
I0518 03:43:33.730324  4008 solver.cpp:231] Iteration 132200, loss = 1.53196
I0518 03:43:33.732787  4008 solver.cpp:247]     Train net output #0: loss = 1.53196 (* 1 = 1.53196 loss)
I0518 03:43:33.732813  4008 sgd_solver.cpp:106] Iteration 132200, lr = 0.001
I0518 03:43:33.891633  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3895	1.04167	74.9984	0	85.1941	3.90625	81.6067	0	76.6439	0	72.2413	0	62.6265	0	24.3212	1.7	
I0518 03:43:33.965287  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:43:33.966392  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:43:33.966418  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:43:33.976032  4008 solver.cpp:260]     Total regularization terms: 1.1306 loss+regular. : 2.66256
I0518 03:44:56.534346  4008 solver.cpp:231] Iteration 132400, loss = 1.21533
I0518 03:44:56.534641  4008 solver.cpp:247]     Train net output #0: loss = 1.21533 (* 1 = 1.21533 loss)
I0518 03:44:56.534663  4008 sgd_solver.cpp:106] Iteration 132400, lr = 0.001
I0518 03:44:56.694989  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2775	1.04167	74.9339	0	85.2191	3.90625	81.6203	0	76.666	0	72.2738	0	62.6607	0	24.3313	1.7	
I0518 03:44:56.769404  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.868056	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:44:56.771318  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:44:56.771363  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:44:56.784540  4008 solver.cpp:260]     Total regularization terms: 1.13016 loss+regular. : 2.34548
I0518 03:46:18.059859  4008 solver.cpp:231] Iteration 132600, loss = 1.61503
I0518 03:46:18.060183  4008 solver.cpp:247]     Train net output #0: loss = 1.61503 (* 1 = 1.61503 loss)
I0518 03:46:18.060206  4008 sgd_solver.cpp:106] Iteration 132600, lr = 0.001
I0518 03:46:18.219753  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.378	1.04167	75.0143	0	85.2476	3.90625	81.6525	0	76.6812	0	72.3068	0	62.6953	0	24.343	1.7	
I0518 03:46:18.294476  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:46:18.296135  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	3.90625	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:46:18.296185  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:46:18.306185  4008 solver.cpp:260]     Total regularization terms: 1.12969 loss+regular. : 2.74472
I0518 03:47:36.595044  4008 solver.cpp:231] Iteration 132800, loss = 1.4497
I0518 03:47:36.601682  4008 solver.cpp:247]     Train net output #0: loss = 1.4497 (* 1 = 1.4497 loss)
I0518 03:47:36.601721  4008 sgd_solver.cpp:106] Iteration 132800, lr = 0.001
I0518 03:47:36.758481  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.444	1.04167	74.9922	0	85.2614	4.16667	81.6691	0	76.6988	0	72.3391	0	62.7293	0	24.3535	1.7	
I0518 03:47:36.833645  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:47:36.835485  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:47:36.835528  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:47:36.850823  4008 solver.cpp:260]     Total regularization terms: 1.12926 loss+regular. : 2.57896
I0518 03:48:34.706573  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:48:59.659104  4008 solver.cpp:348] Iteration 133000, Testing net (#0)
I0518 03:50:09.306229  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:50:13.162868  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55444
I0518 03:50:13.162943  4008 solver.cpp:415]     Test net output #1: loss = 1.92405 (* 1 = 1.92405 loss)
I0518 03:50:13.249861  4008 solver.cpp:231] Iteration 133000, loss = 1.36308
I0518 03:50:13.249954  4008 solver.cpp:247]     Train net output #0: loss = 1.36308 (* 1 = 1.36308 loss)
I0518 03:50:13.249970  4008 sgd_solver.cpp:106] Iteration 133000, lr = 0.001
I0518 03:50:13.415212  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0222	1.04167	75.1351	0	85.2903	4.16667	81.6828	0	76.7277	0	72.3719	0	62.7638	0	24.3643	1.7	
I0518 03:50:13.490605  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:50:13.492290  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:50:13.492333  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:50:13.503235  4008 solver.cpp:260]     Total regularization terms: 1.12879 loss+regular. : 2.49187
I0518 03:51:33.042682  4008 solver.cpp:231] Iteration 133200, loss = 1.39133
I0518 03:51:33.043572  4008 solver.cpp:247]     Train net output #0: loss = 1.39133 (* 1 = 1.39133 loss)
I0518 03:51:33.043598  4008 sgd_solver.cpp:106] Iteration 133200, lr = 0.001
I0518 03:51:33.202956  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1857	1.04167	75.237	0	85.2833	4.16667	81.7101	0	76.7456	0	72.4051	0	62.7985	0	24.3748	1.7	
I0518 03:51:33.277884  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:51:33.279659  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:51:33.279686  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:51:33.309331  4008 solver.cpp:260]     Total regularization terms: 1.12836 loss+regular. : 2.51969
I0518 03:52:55.820757  4008 solver.cpp:231] Iteration 133400, loss = 1.4867
I0518 03:52:55.821228  4008 solver.cpp:247]     Train net output #0: loss = 1.4867 (* 1 = 1.4867 loss)
I0518 03:52:55.821256  4008 sgd_solver.cpp:106] Iteration 133400, lr = 0.001
I0518 03:52:55.979737  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0882	1.04167	75.1009	0	85.2921	4.16667	81.7336	0	76.7759	0	72.437	0	62.8325	0	24.3856	1.7	
I0518 03:52:56.054025  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:52:56.055570  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:52:56.055593  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:52:56.065505  4008 solver.cpp:260]     Total regularization terms: 1.12796 loss+regular. : 2.61466
I0518 03:54:18.607381  4008 solver.cpp:231] Iteration 133600, loss = 1.36802
I0518 03:54:18.607810  4008 solver.cpp:247]     Train net output #0: loss = 1.36802 (* 1 = 1.36802 loss)
I0518 03:54:18.607832  4008 sgd_solver.cpp:106] Iteration 133600, lr = 0.001
I0518 03:54:18.768970  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3751	1.04167	74.8678	0	85.3119	4.16667	81.7333	0	76.7865	0	72.4694	0	62.8665	0	24.397	1.7	
I0518 03:54:18.843096  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:54:18.844629  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:54:18.844660  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:54:18.854251  4008 solver.cpp:260]     Total regularization terms: 1.12759 loss+regular. : 2.49561
I0518 03:55:48.980499  4008 solver.cpp:231] Iteration 133800, loss = 1.46044
I0518 03:55:48.980752  4008 solver.cpp:247]     Train net output #0: loss = 1.46044 (* 1 = 1.46044 loss)
I0518 03:55:48.980773  4008 sgd_solver.cpp:106] Iteration 133800, lr = 0.001
I0518 03:55:49.140699  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1972	1.04167	74.9958	0	85.3194	4.16667	81.7427	0	76.813	0	72.502	0	62.8992	0	24.4072	1.7	
I0518 03:55:49.216171  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:55:49.218444  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:55:49.218468  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:55:49.233255  4008 solver.cpp:260]     Total regularization terms: 1.12714 loss+regular. : 2.58758
I0518 03:56:47.983021  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:57:06.410123  4008 solver.cpp:348] Iteration 134000, Testing net (#0)
I0518 03:58:19.415665  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 03:58:22.791824  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55132
I0518 03:58:22.791903  4008 solver.cpp:415]     Test net output #1: loss = 1.926 (* 1 = 1.926 loss)
I0518 03:58:22.880882  4008 solver.cpp:231] Iteration 134000, loss = 1.32617
I0518 03:58:22.880955  4008 solver.cpp:247]     Train net output #0: loss = 1.32617 (* 1 = 1.32617 loss)
I0518 03:58:22.880972  4008 sgd_solver.cpp:106] Iteration 134000, lr = 0.001
I0518 03:58:23.041373  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2862	1.04167	75.1263	0	85.3249	4.16667	81.7675	0	76.8166	0	72.5338	0	62.934	0	24.4176	1.7	
I0518 03:58:23.115545  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:58:23.117324  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:58:23.117358  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:58:23.127041  4008 solver.cpp:260]     Total regularization terms: 1.1267 loss+regular. : 2.45287
I0518 03:59:39.850219  4008 solver.cpp:231] Iteration 134200, loss = 1.30944
I0518 03:59:39.850534  4008 solver.cpp:247]     Train net output #0: loss = 1.30944 (* 1 = 1.30944 loss)
I0518 03:59:39.850561  4008 sgd_solver.cpp:106] Iteration 134200, lr = 0.001
I0518 03:59:40.011025  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2029	1.04167	75.1107	0	85.3613	4.16667	81.7945	0	76.8516	0	72.5659	0	62.968	0	24.4278	1.7	
I0518 03:59:40.085309  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 03:59:40.087152  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.7	
I0518 03:59:40.087201  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 03:59:40.107600  4008 solver.cpp:260]     Total regularization terms: 1.12627 loss+regular. : 2.4357
I0518 04:00:59.925360  4008 solver.cpp:231] Iteration 134400, loss = 1.24615
I0518 04:00:59.925869  4008 solver.cpp:247]     Train net output #0: loss = 1.24615 (* 1 = 1.24615 loss)
I0518 04:00:59.925894  4008 sgd_solver.cpp:106] Iteration 134400, lr = 0.001
I0518 04:01:00.084995  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9389	1.04167	75.2158	0	85.4023	4.16667	81.8239	0	76.8706	0	72.5974	0	63.0013	0	24.4386	1.7	
I0518 04:01:00.159207  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:01:00.160454  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.7	
I0518 04:01:00.160475  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:01:00.170838  4008 solver.cpp:260]     Total regularization terms: 1.12587 loss+regular. : 2.37202
I0518 04:02:22.143518  4008 solver.cpp:231] Iteration 134600, loss = 1.53096
I0518 04:02:22.143847  4008 solver.cpp:247]     Train net output #0: loss = 1.53096 (* 1 = 1.53096 loss)
I0518 04:02:22.143867  4008 sgd_solver.cpp:106] Iteration 134600, lr = 0.001
I0518 04:02:22.305104  4008 sgd_solver.cpp:120]     Element Sparsity %: 
10.9447	1.04167	75.2926	0	85.3924	4.16667	81.8311	0	76.8846	0	72.6291	0	63.0359	0	24.4491	1.7	
I0518 04:02:22.380369  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:02:22.382418  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.7	
I0518 04:02:22.382462  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:02:22.397294  4008 solver.cpp:260]     Total regularization terms: 1.12545 loss+regular. : 2.6564
I0518 04:03:40.960741  4008 solver.cpp:231] Iteration 134800, loss = 1.32194
I0518 04:03:40.961010  4008 solver.cpp:247]     Train net output #0: loss = 1.32194 (* 1 = 1.32194 loss)
I0518 04:03:40.961030  4008 sgd_solver.cpp:106] Iteration 134800, lr = 0.001
I0518 04:03:41.123437  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2775	1.04167	74.8164	0	85.384	4.16667	81.8506	0	76.8858	0	72.661	0	63.0699	0	24.46	1.7	
I0518 04:03:41.198689  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:03:41.200661  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.7	
I0518 04:03:41.200700  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:03:41.215931  4008 solver.cpp:260]     Total regularization terms: 1.1251 loss+regular. : 2.44704
I0518 04:04:39.690381  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:04:56.474563  4008 solver.cpp:348] Iteration 135000, Testing net (#0)
I0518 04:06:13.784168  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:06:16.700217  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55388
I0518 04:06:16.700350  4008 solver.cpp:415]     Test net output #1: loss = 1.92249 (* 1 = 1.92249 loss)
I0518 04:06:16.787994  4008 solver.cpp:231] Iteration 135000, loss = 1.56732
I0518 04:06:16.788111  4008 solver.cpp:247]     Train net output #0: loss = 1.56732 (* 1 = 1.56732 loss)
I0518 04:06:16.788133  4008 sgd_solver.cpp:106] Iteration 135000, lr = 0.001
I0518 04:06:16.949970  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0193	1.04167	75.2139	0	85.4092	4.16667	81.8656	0	76.9142	0	72.6932	0	63.1037	0	24.47	1.8	
I0518 04:06:17.025020  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:06:17.026742  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:06:17.026775  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:06:17.036759  4008 solver.cpp:260]     Total regularization terms: 1.12466 loss+regular. : 2.69199
I0518 04:07:33.512281  4008 solver.cpp:231] Iteration 135200, loss = 1.42341
I0518 04:07:33.512717  4008 solver.cpp:247]     Train net output #0: loss = 1.42341 (* 1 = 1.42341 loss)
I0518 04:07:33.512737  4008 sgd_solver.cpp:106] Iteration 135200, lr = 0.001
I0518 04:07:33.672919  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2948	1.04167	75.3109	0	85.4431	4.16667	81.8894	0	76.9439	0	72.7252	0	63.1367	0	24.48	1.8	
I0518 04:07:33.747133  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:07:33.749092  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:07:33.749119  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:07:33.779124  4008 solver.cpp:260]     Total regularization terms: 1.12422 loss+regular. : 2.54763
I0518 04:09:04.291383  4008 solver.cpp:231] Iteration 135400, loss = 1.32802
I0518 04:09:04.291664  4008 solver.cpp:247]     Train net output #0: loss = 1.32802 (* 1 = 1.32802 loss)
I0518 04:09:04.291683  4008 sgd_solver.cpp:106] Iteration 135400, lr = 0.001
I0518 04:09:04.451537  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0078	1.04167	75.0788	0	85.4215	4.16667	81.8982	0	76.9448	0	72.7567	0	63.1701	0	24.4903	1.8	
I0518 04:09:04.526567  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:09:04.527942  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:09:04.527963  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:09:04.548882  4008 solver.cpp:260]     Total regularization terms: 1.12387 loss+regular. : 2.45189
I0518 04:10:25.098376  4008 solver.cpp:231] Iteration 135600, loss = 1.27952
I0518 04:10:25.098701  4008 solver.cpp:247]     Train net output #0: loss = 1.27952 (* 1 = 1.27952 loss)
I0518 04:10:25.098726  4008 sgd_solver.cpp:106] Iteration 135600, lr = 0.001
I0518 04:10:25.258921  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2603	1.04167	75.0163	0	85.4365	4.16667	81.9104	0	76.9644	0	72.7889	0	63.2037	0	24.5016	1.8	
I0518 04:10:25.333394  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:10:25.335141  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:10:25.335201  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:10:25.345835  4008 solver.cpp:260]     Total regularization terms: 1.12355 loss+regular. : 2.40307
I0518 04:11:51.113087  4008 solver.cpp:231] Iteration 135800, loss = 1.36888
I0518 04:11:51.114403  4008 solver.cpp:247]     Train net output #0: loss = 1.36888 (* 1 = 1.36888 loss)
I0518 04:11:51.114424  4008 sgd_solver.cpp:106] Iteration 135800, lr = 0.001
I0518 04:11:51.271694  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2603	1.04167	75.0938	0	85.4393	4.16667	81.9435	0	76.9839	0	72.8206	0	63.2374	0	24.5123	1.8	
I0518 04:11:51.346189  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:11:51.347905  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:11:51.347929  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:11:51.357715  4008 solver.cpp:260]     Total regularization terms: 1.12315 loss+regular. : 2.49203
I0518 04:13:01.377939  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:13:15.562407  4008 solver.cpp:348] Iteration 136000, Testing net (#0)
I0518 04:14:35.691485  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:14:38.229791  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55552
I0518 04:14:38.229871  4008 solver.cpp:415]     Test net output #1: loss = 1.92087 (* 1 = 1.92087 loss)
I0518 04:14:38.345901  4008 solver.cpp:231] Iteration 136000, loss = 1.40494
I0518 04:14:38.345975  4008 solver.cpp:247]     Train net output #0: loss = 1.40494 (* 1 = 1.40494 loss)
I0518 04:14:38.345994  4008 sgd_solver.cpp:106] Iteration 136000, lr = 0.001
I0518 04:14:38.513907  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1656	1.04167	75.3324	0	85.461	4.16667	81.9708	0	76.9999	0	72.8525	0	63.2701	0	24.5226	1.8	
I0518 04:14:38.588330  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:14:38.589897  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:14:38.589942  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:14:38.600054  4008 solver.cpp:260]     Total regularization terms: 1.12269 loss+regular. : 2.52764
I0518 04:16:00.246032  4008 solver.cpp:231] Iteration 136200, loss = 1.41609
I0518 04:16:00.249152  4008 solver.cpp:247]     Train net output #0: loss = 1.41609 (* 1 = 1.41609 loss)
I0518 04:16:00.249183  4008 sgd_solver.cpp:106] Iteration 136200, lr = 0.001
I0518 04:16:00.405648  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0623	1.04167	75.3955	0	85.5053	4.16667	81.9894	0	77.0198	0	72.8835	0	63.3038	0	24.5339	1.8	
I0518 04:16:00.479849  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:16:00.481278  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:16:00.481314  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:16:00.491067  4008 solver.cpp:260]     Total regularization terms: 1.12228 loss+regular. : 2.53836
I0518 04:17:24.394448  4008 solver.cpp:231] Iteration 136400, loss = 1.46452
I0518 04:17:24.394773  4008 solver.cpp:247]     Train net output #0: loss = 1.46452 (* 1 = 1.46452 loss)
I0518 04:17:24.394814  4008 sgd_solver.cpp:106] Iteration 136400, lr = 0.001
I0518 04:17:24.553115  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3321	1.04167	75.3815	0	85.5231	4.16667	81.999	0	77.0318	0	72.9146	0	63.3371	0	24.5438	1.8	
I0518 04:17:24.627347  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:17:24.628679  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:17:24.628715  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:17:24.638540  4008 solver.cpp:260]     Total regularization terms: 1.12189 loss+regular. : 2.5864
I0518 04:18:56.504521  4008 solver.cpp:231] Iteration 136600, loss = 1.48192
I0518 04:18:56.504770  4008 solver.cpp:247]     Train net output #0: loss = 1.48192 (* 1 = 1.48192 loss)
I0518 04:18:56.504791  4008 sgd_solver.cpp:106] Iteration 136600, lr = 0.001
I0518 04:18:56.665232  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1972	1.04167	75.1279	0	85.5034	4.16667	82.0023	0	77.0569	0	72.9461	0	63.3704	0	24.5537	1.8	
I0518 04:18:56.743717  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:18:56.745111  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:18:56.745146  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:18:56.755170  4008 solver.cpp:260]     Total regularization terms: 1.12152 loss+regular. : 2.60344
I0518 04:20:22.102251  4008 solver.cpp:231] Iteration 136800, loss = 1.29596
I0518 04:20:22.102535  4008 solver.cpp:247]     Train net output #0: loss = 1.29596 (* 1 = 1.29596 loss)
I0518 04:20:22.102556  4008 sgd_solver.cpp:106] Iteration 136800, lr = 0.001
I0518 04:20:22.261973  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2804	1.04167	75.1162	0	85.4923	4.16667	82.0094	0	77.0736	0	72.9777	0	63.4035	0	24.5639	1.8	
I0518 04:20:22.336323  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:20:22.337481  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:20:22.337503  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:20:22.347311  4008 solver.cpp:260]     Total regularization terms: 1.12112 loss+regular. : 2.41708
I0518 04:21:44.370123  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:21:56.124735  4008 solver.cpp:348] Iteration 137000, Testing net (#0)
I0518 04:23:16.628240  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:23:18.579247  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55382
I0518 04:23:18.579330  4008 solver.cpp:415]     Test net output #1: loss = 1.91856 (* 1 = 1.91856 loss)
I0518 04:23:18.666913  4008 solver.cpp:231] Iteration 137000, loss = 1.36608
I0518 04:23:18.666982  4008 solver.cpp:247]     Train net output #0: loss = 1.36608 (* 1 = 1.36608 loss)
I0518 04:23:18.666998  4008 sgd_solver.cpp:106] Iteration 137000, lr = 0.001
I0518 04:23:18.832779  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0135	1.04167	75.237	0	85.5151	4.16667	82.0303	0	77.0942	0	73.0092	0	63.4369	0	24.5741	1.8	
I0518 04:23:18.907428  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:23:18.909584  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:23:18.909627  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:23:18.919569  4008 solver.cpp:260]     Total regularization terms: 1.12073 loss+regular. : 2.4868
I0518 04:24:40.093921  4008 solver.cpp:231] Iteration 137200, loss = 1.35834
I0518 04:24:40.094151  4008 solver.cpp:247]     Train net output #0: loss = 1.35834 (* 1 = 1.35834 loss)
I0518 04:24:40.094172  4008 sgd_solver.cpp:106] Iteration 137200, lr = 0.001
I0518 04:24:40.254690  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0882	1.04167	75.0941	0	85.5343	4.16667	82.0525	0	77.1019	0	73.0405	0	63.4692	0	24.5845	1.8	
I0518 04:24:40.328924  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:24:40.330785  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:24:40.330843  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:24:40.340726  4008 solver.cpp:260]     Total regularization terms: 1.12036 loss+regular. : 2.47869
I0518 04:26:16.082190  4008 solver.cpp:231] Iteration 137400, loss = 1.62988
I0518 04:26:16.082427  4008 solver.cpp:247]     Train net output #0: loss = 1.62988 (* 1 = 1.62988 loss)
I0518 04:26:16.082447  4008 sgd_solver.cpp:106] Iteration 137400, lr = 0.001
I0518 04:26:16.242578  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3522	1.04167	75.1367	0	85.5664	4.16667	82.0798	0	77.1365	0	73.071	0	63.5019	0	24.5949	1.8	
I0518 04:26:16.316912  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:26:16.319068  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:26:16.319105  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:26:16.328853  4008 solver.cpp:260]     Total regularization terms: 1.11996 loss+regular. : 2.74984
I0518 04:27:37.945523  4008 solver.cpp:231] Iteration 137600, loss = 1.40225
I0518 04:27:37.945845  4008 solver.cpp:247]     Train net output #0: loss = 1.40225 (* 1 = 1.40225 loss)
I0518 04:27:37.945869  4008 sgd_solver.cpp:106] Iteration 137600, lr = 0.001
I0518 04:27:38.105738  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4928	1.04167	75.2601	0	85.5795	4.16667	82.1135	0	77.1536	0	73.1018	0	63.5342	0	24.6049	1.8	
I0518 04:27:38.180089  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:27:38.182199  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:27:38.182272  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:27:38.192209  4008 solver.cpp:260]     Total regularization terms: 1.11951 loss+regular. : 2.52176
I0518 04:28:58.173871  4008 solver.cpp:231] Iteration 137800, loss = 1.59148
I0518 04:28:58.174275  4008 solver.cpp:247]     Train net output #0: loss = 1.59148 (* 1 = 1.59148 loss)
I0518 04:28:58.174298  4008 sgd_solver.cpp:106] Iteration 137800, lr = 0.001
I0518 04:28:58.335171  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2316	1.04167	75.403	0	85.5862	4.16667	82.1074	0	77.1731	0	73.1331	0	63.5672	0	24.615	1.8	
I0518 04:28:58.410091  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:28:58.412303  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:28:58.412339  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:28:58.422480  4008 solver.cpp:260]     Total regularization terms: 1.11909 loss+regular. : 2.71058
I0518 04:30:12.422626  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:30:20.972182  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_138000.caffemodel
I0518 04:32:24.493239  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_138000.solverstate
I0518 04:32:25.266134  4008 solver.cpp:348] Iteration 138000, Testing net (#0)
I0518 04:33:46.300655  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:33:48.086035  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55522
I0518 04:33:48.086114  4008 solver.cpp:415]     Test net output #1: loss = 1.91348 (* 1 = 1.91348 loss)
I0518 04:33:48.175935  4008 solver.cpp:231] Iteration 138000, loss = 1.36115
I0518 04:33:48.176023  4008 solver.cpp:247]     Train net output #0: loss = 1.36115 (* 1 = 1.36115 loss)
I0518 04:33:48.176040  4008 sgd_solver.cpp:106] Iteration 138000, lr = 0.001
I0518 04:33:48.341172  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2661	1.04167	75.4189	0	85.6014	4.16667	82.1385	0	77.1934	0	73.1635	0	63.6006	0	24.6242	1.8	
I0518 04:33:48.342363  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:33:48.343891  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.16667	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:33:48.343926  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:33:48.354015  4008 solver.cpp:260]     Total regularization terms: 1.11867 loss+regular. : 2.47982
I0518 04:35:08.810684  4008 solver.cpp:231] Iteration 138200, loss = 1.44202
I0518 04:35:08.811699  4008 solver.cpp:247]     Train net output #0: loss = 1.44202 (* 1 = 1.44202 loss)
I0518 04:35:08.811725  4008 sgd_solver.cpp:106] Iteration 138200, lr = 0.001
I0518 04:35:08.971865  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5243	1.04167	75.2344	0	85.6224	4.42708	82.147	0	77.2124	0	73.1945	0	63.6332	0	24.6342	1.8	
I0518 04:35:09.051319  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:35:09.052881  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:35:09.052906  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:35:09.068172  4008 solver.cpp:260]     Total regularization terms: 1.11833 loss+regular. : 2.56035
I0518 04:36:31.256306  4008 solver.cpp:231] Iteration 138400, loss = 1.40771
I0518 04:36:31.256763  4008 solver.cpp:247]     Train net output #0: loss = 1.40771 (* 1 = 1.40771 loss)
I0518 04:36:31.256798  4008 sgd_solver.cpp:106] Iteration 138400, lr = 0.001
I0518 04:36:31.415571  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5358	1.04167	75.5156	0	85.642	4.42708	82.1747	0	77.2429	0	73.2249	0	63.6651	0	24.6442	1.8	
I0518 04:36:31.494637  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:36:31.496171  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:36:31.496194  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:36:31.516367  4008 solver.cpp:260]     Total regularization terms: 1.11797 loss+regular. : 2.52568
I0518 04:38:17.855060  4008 solver.cpp:231] Iteration 138600, loss = 1.32154
I0518 04:38:17.855445  4008 solver.cpp:247]     Train net output #0: loss = 1.32154 (* 1 = 1.32154 loss)
I0518 04:38:17.855466  4008 sgd_solver.cpp:106] Iteration 138600, lr = 0.001
I0518 04:38:18.014591  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3722	1.04167	75.39	0	85.6554	4.42708	82.1797	0	77.2651	0	73.2555	0	63.698	0	24.6541	1.8	
I0518 04:38:18.093653  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:38:18.096027  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:38:18.096055  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:38:18.109781  4008 solver.cpp:260]     Total regularization terms: 1.11757 loss+regular. : 2.43911
I0518 04:39:43.834556  4008 solver.cpp:231] Iteration 138800, loss = 1.35135
I0518 04:39:43.834918  4008 solver.cpp:247]     Train net output #0: loss = 1.35135 (* 1 = 1.35135 loss)
I0518 04:39:43.834940  4008 sgd_solver.cpp:106] Iteration 138800, lr = 0.001
I0518 04:39:43.993938  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3751	1.04167	75.6413	0	85.6826	4.42708	82.1945	0	77.2884	0	73.2853	0	63.7303	0	24.6644	1.8	
I0518 04:39:44.068148  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:39:44.073535  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:39:44.073622  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:39:44.087895  4008 solver.cpp:260]     Total regularization terms: 1.11718 loss+regular. : 2.46853
I0518 04:41:04.203899  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:41:09.776806  4008 solver.cpp:348] Iteration 139000, Testing net (#0)
I0518 04:42:37.828639  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:42:38.813804  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55302
I0518 04:42:38.813908  4008 solver.cpp:415]     Test net output #1: loss = 1.92079 (* 1 = 1.92079 loss)
I0518 04:42:38.905655  4008 solver.cpp:231] Iteration 139000, loss = 1.21636
I0518 04:42:38.905736  4008 solver.cpp:247]     Train net output #0: loss = 1.21636 (* 1 = 1.21636 loss)
I0518 04:42:38.905756  4008 sgd_solver.cpp:106] Iteration 139000, lr = 0.001
I0518 04:42:39.071941  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4641	1.04167	75.5316	0	85.6891	4.42708	82.2071	0	77.2791	0	73.3155	0	63.762	0	24.6743	1.8	
I0518 04:42:39.146330  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:42:39.148075  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:42:39.148120  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:42:39.158172  4008 solver.cpp:260]     Total regularization terms: 1.11674 loss+regular. : 2.3331
I0518 04:44:12.563211  4008 solver.cpp:231] Iteration 139200, loss = 1.52125
I0518 04:44:12.563627  4008 solver.cpp:247]     Train net output #0: loss = 1.52125 (* 1 = 1.52125 loss)
I0518 04:44:12.563725  4008 sgd_solver.cpp:106] Iteration 139200, lr = 0.001
I0518 04:44:12.723511  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4583	1.04167	75.4971	0	85.6902	4.42708	82.2231	0	77.3083	0	73.3461	0	63.7941	0	24.6838	1.8	
I0518 04:44:12.797796  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:44:12.799631  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:44:12.799712  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:44:12.813418  4008 solver.cpp:260]     Total regularization terms: 1.11639 loss+regular. : 2.63764
I0518 04:45:37.889307  4008 solver.cpp:231] Iteration 139400, loss = 1.42467
I0518 04:45:37.889953  4008 solver.cpp:247]     Train net output #0: loss = 1.42467 (* 1 = 1.42467 loss)
I0518 04:45:37.889974  4008 sgd_solver.cpp:106] Iteration 139400, lr = 0.001
I0518 04:45:38.048413  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4612	1.04167	75.2972	0	85.7018	4.42708	82.2311	0	77.3223	0	73.3758	0	63.8264	0	24.6937	1.8	
I0518 04:45:38.122853  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:45:38.124513  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:45:38.124558  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:45:38.134308  4008 solver.cpp:260]     Total regularization terms: 1.11608 loss+regular. : 2.54075
I0518 04:47:09.946143  4008 solver.cpp:231] Iteration 139600, loss = 1.68311
I0518 04:47:09.950114  4008 solver.cpp:247]     Train net output #0: loss = 1.68311 (* 1 = 1.68311 loss)
I0518 04:47:09.950155  4008 sgd_solver.cpp:106] Iteration 139600, lr = 0.001
I0518 04:47:10.105928  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0135	1.04167	75.5	0	85.7255	4.42708	82.2418	0	77.3266	0	73.4057	0	63.858	0	24.7032	1.8	
I0518 04:47:10.180531  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:47:10.182646  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:47:10.182701  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:47:10.192808  4008 solver.cpp:260]     Total regularization terms: 1.11565 loss+regular. : 2.79875
I0518 04:48:40.450400  4008 solver.cpp:231] Iteration 139800, loss = 1.4902
I0518 04:48:40.450811  4008 solver.cpp:247]     Train net output #0: loss = 1.4902 (* 1 = 1.4902 loss)
I0518 04:48:40.450845  4008 sgd_solver.cpp:106] Iteration 139800, lr = 0.001
I0518 04:48:40.611320  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3177	1.04167	75.4727	0	85.6882	4.42708	82.2427	0	77.3426	0	73.4363	0	63.8904	0	24.7129	1.8	
I0518 04:48:40.687033  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:48:40.688711  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:48:40.688756  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:48:40.703873  4008 solver.cpp:260]     Total regularization terms: 1.11532 loss+regular. : 2.60552
I0518 04:50:12.001307  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:50:15.161731  4008 solver.cpp:348] Iteration 140000, Testing net (#0)
I0518 04:51:43.630408  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:51:44.172396  4008 solver.cpp:415]     Test net output #0: accuracy = 0.553
I0518 04:51:44.172492  4008 solver.cpp:415]     Test net output #1: loss = 1.92866 (* 1 = 1.92866 loss)
I0518 04:51:44.267174  4008 solver.cpp:231] Iteration 140000, loss = 1.68306
I0518 04:51:44.267268  4008 solver.cpp:247]     Train net output #0: loss = 1.68306 (* 1 = 1.68306 loss)
I0518 04:51:44.267292  4008 sgd_solver.cpp:106] Iteration 140000, lr = 0.001
I0518 04:51:44.421232  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5301	1.04167	75.5967	0	85.7209	4.42708	82.2721	0	77.3675	0	73.4667	0	63.9229	0	24.7231	1.8	
I0518 04:51:44.495929  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:51:44.498273  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:51:44.498328  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:51:44.511945  4008 solver.cpp:260]     Total regularization terms: 1.11484 loss+regular. : 2.79791
I0518 04:53:27.583416  4008 solver.cpp:231] Iteration 140200, loss = 1.22617
I0518 04:53:27.583828  4008 solver.cpp:247]     Train net output #0: loss = 1.22617 (* 1 = 1.22617 loss)
I0518 04:53:27.583865  4008 sgd_solver.cpp:106] Iteration 140200, lr = 0.001
I0518 04:53:27.742754  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2489	1.04167	75.6253	0	85.755	4.42708	82.3072	0	77.3982	0	73.4968	0	63.9558	0	24.7328	1.8	
I0518 04:53:27.817538  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:53:27.819484  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:53:27.819535  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:53:27.829726  4008 solver.cpp:260]     Total regularization terms: 1.11443 loss+regular. : 2.3406
I0518 04:55:07.060173  4008 solver.cpp:231] Iteration 140400, loss = 1.54715
I0518 04:55:07.060467  4008 solver.cpp:247]     Train net output #0: loss = 1.54715 (* 1 = 1.54715 loss)
I0518 04:55:07.060489  4008 sgd_solver.cpp:106] Iteration 140400, lr = 0.001
I0518 04:55:07.219365  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3665	1.04167	75.6546	0	85.7673	4.42708	82.3088	0	77.4186	0	73.5261	0	63.9869	0	24.7421	1.8	
I0518 04:55:07.294251  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:55:07.296756  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:55:07.296805  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:55:07.306722  4008 solver.cpp:260]     Total regularization terms: 1.11411 loss+regular. : 2.66126
I0518 04:56:31.826175  4008 solver.cpp:231] Iteration 140600, loss = 1.21998
I0518 04:56:31.826475  4008 solver.cpp:247]     Train net output #0: loss = 1.21998 (* 1 = 1.21998 loss)
I0518 04:56:31.826495  4008 sgd_solver.cpp:106] Iteration 140600, lr = 0.001
I0518 04:56:31.988013  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.18	1.04167	75.6621	0	85.7751	4.42708	82.339	0	77.426	0	73.5562	0	64.0191	0	24.7516	1.8	
I0518 04:56:32.062608  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:56:32.064824  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:56:32.064878  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:56:32.075165  4008 solver.cpp:260]     Total regularization terms: 1.11372 loss+regular. : 2.3337
I0518 04:58:00.367111  4008 solver.cpp:231] Iteration 140800, loss = 1.26798
I0518 04:58:00.369647  4008 solver.cpp:247]     Train net output #0: loss = 1.26798 (* 1 = 1.26798 loss)
I0518 04:58:00.369688  4008 sgd_solver.cpp:106] Iteration 140800, lr = 0.001
I0518 04:58:00.525889  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2517	1.04167	75.3125	0	85.7815	4.42708	82.3504	0	77.4419	0	73.5861	0	64.0508	0	24.7623	1.8	
I0518 04:58:00.600312  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 04:58:00.602013  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 04:58:00.602075  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 04:58:00.611985  4008 solver.cpp:260]     Total regularization terms: 1.11332 loss+regular. : 2.3813
I0518 04:59:33.974552  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 04:59:34.354121  4008 solver.cpp:348] Iteration 141000, Testing net (#0)
I0518 05:00:57.376240  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55178
I0518 05:00:57.376664  4008 solver.cpp:415]     Test net output #1: loss = 1.92413 (* 1 = 1.92413 loss)
I0518 05:00:57.467629  4008 solver.cpp:231] Iteration 141000, loss = 1.37443
I0518 05:00:57.467722  4008 solver.cpp:247]     Train net output #0: loss = 1.37443 (* 1 = 1.37443 loss)
I0518 05:00:57.467742  4008 sgd_solver.cpp:106] Iteration 141000, lr = 0.001
I0518 05:00:57.639365  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.378	1.04167	75.7731	0	85.8253	4.42708	82.3932	0	77.493	0	73.6159	0	64.0826	0	24.7717	1.8	
I0518 05:00:57.714051  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:00:57.716205  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:00:57.716243  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:00:57.726485  4008 solver.cpp:260]     Total regularization terms: 1.11292 loss+regular. : 2.48735
I0518 05:00:59.328186  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:02:17.929332  4008 solver.cpp:231] Iteration 141200, loss = 1.36154
I0518 05:02:17.929844  4008 solver.cpp:247]     Train net output #0: loss = 1.36154 (* 1 = 1.36154 loss)
I0518 05:02:17.929869  4008 sgd_solver.cpp:106] Iteration 141200, lr = 0.001
I0518 05:02:18.089867  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6334	1.04167	75.8203	0	85.8194	4.42708	82.4011	0	77.4907	0	73.6458	0	64.1144	0	24.7817	1.8	
I0518 05:02:18.163997  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:02:18.165735  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:02:18.165779  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:02:18.175506  4008 solver.cpp:260]     Total regularization terms: 1.11258 loss+regular. : 2.47413
I0518 05:03:43.557791  4008 solver.cpp:231] Iteration 141400, loss = 1.43516
I0518 05:03:43.558145  4008 solver.cpp:247]     Train net output #0: loss = 1.43516 (* 1 = 1.43516 loss)
I0518 05:03:43.558166  4008 sgd_solver.cpp:106] Iteration 141400, lr = 0.001
I0518 05:03:43.717757  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3952	1.04167	75.7969	0	85.8493	4.42708	82.405	0	77.5162	0	73.675	0	64.1465	0	24.7917	1.8	
I0518 05:03:43.792110  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:03:43.794500  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:03:43.794564  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:03:43.804569  4008 solver.cpp:260]     Total regularization terms: 1.1122 loss+regular. : 2.54737
I0518 05:05:10.323439  4008 solver.cpp:231] Iteration 141600, loss = 1.40551
I0518 05:05:10.323853  4008 solver.cpp:247]     Train net output #0: loss = 1.40551 (* 1 = 1.40551 loss)
I0518 05:05:10.323881  4008 sgd_solver.cpp:106] Iteration 141600, lr = 0.001
I0518 05:05:10.483120  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3895	1.04167	75.7021	0	85.8598	4.42708	82.4175	0	77.5271	0	73.7046	0	64.1776	0	24.8021	1.8	
I0518 05:05:10.557273  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:05:10.558755  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:05:10.558809  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:05:10.568815  4008 solver.cpp:260]     Total regularization terms: 1.11185 loss+regular. : 2.51736
I0518 05:06:49.398622  4008 solver.cpp:231] Iteration 141800, loss = 1.56198
I0518 05:06:49.398892  4008 solver.cpp:247]     Train net output #0: loss = 1.56198 (* 1 = 1.56198 loss)
I0518 05:06:49.398916  4008 sgd_solver.cpp:106] Iteration 141800, lr = 0.001
I0518 05:06:49.557474  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3722	1.04167	75.8278	0	85.8899	4.42708	82.4354	0	77.5517	0	73.734	0	64.2094	0	24.8124	1.8	
I0518 05:06:49.632109  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:06:49.634536  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:06:49.634583  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:06:49.644459  4008 solver.cpp:260]     Total regularization terms: 1.11141 loss+regular. : 2.67339
I0518 05:08:16.527402  4008 solver.cpp:348] Iteration 142000, Testing net (#0)
I0518 05:08:17.281234  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:09:44.740034  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55352
I0518 05:09:44.740336  4008 solver.cpp:415]     Test net output #1: loss = 1.91303 (* 1 = 1.91303 loss)
I0518 05:09:44.831537  4008 solver.cpp:231] Iteration 142000, loss = 1.45151
I0518 05:09:44.831656  4008 solver.cpp:247]     Train net output #0: loss = 1.45151 (* 1 = 1.45151 loss)
I0518 05:09:44.831691  4008 sgd_solver.cpp:106] Iteration 142000, lr = 0.001
I0518 05:09:44.999465  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3435	1.04167	75.694	0	85.8768	4.42708	82.4464	0	77.5596	0	73.7636	0	64.2412	0	24.8218	1.8	
I0518 05:09:45.094755  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:09:45.096017  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:09:45.096050  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:09:45.105986  4008 solver.cpp:260]     Total regularization terms: 1.11105 loss+regular. : 2.56256
I0518 05:09:50.150861  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:11:07.682063  4008 solver.cpp:231] Iteration 142200, loss = 1.48745
I0518 05:11:07.682363  4008 solver.cpp:247]     Train net output #0: loss = 1.48745 (* 1 = 1.48745 loss)
I0518 05:11:07.682384  4008 sgd_solver.cpp:106] Iteration 142200, lr = 0.001
I0518 05:11:07.842386  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5444	1.04167	75.79	0	85.8627	4.42708	82.4728	0	77.5734	0	73.7924	0	64.2732	0	24.831	1.8	
I0518 05:11:07.916571  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:11:07.918251  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:11:07.918297  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:11:07.932034  4008 solver.cpp:260]     Total regularization terms: 1.11072 loss+regular. : 2.59817
I0518 05:12:40.326081  4008 solver.cpp:231] Iteration 142400, loss = 1.57337
I0518 05:12:40.326428  4008 solver.cpp:247]     Train net output #0: loss = 1.57337 (* 1 = 1.57337 loss)
I0518 05:12:40.326449  4008 sgd_solver.cpp:106] Iteration 142400, lr = 0.001
I0518 05:12:40.486155  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2976	1.04167	75.82	0	85.9027	4.42708	82.4897	0	77.5942	0	73.821	0	64.3055	0	24.8404	1.8	
I0518 05:12:40.560689  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:12:40.563043  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:12:40.563094  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:12:40.574565  4008 solver.cpp:260]     Total regularization terms: 1.11032 loss+regular. : 2.68369
I0518 05:14:12.936137  4008 solver.cpp:231] Iteration 142600, loss = 1.48647
I0518 05:14:12.936450  4008 solver.cpp:247]     Train net output #0: loss = 1.48647 (* 1 = 1.48647 loss)
I0518 05:14:12.936475  4008 sgd_solver.cpp:106] Iteration 142600, lr = 0.001
I0518 05:14:13.097221  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6104	1.04167	75.3555	0	85.8968	4.42708	82.5055	0	77.6017	0	73.8503	0	64.3371	0	24.8503	1.8	
I0518 05:14:13.173342  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:14:13.175463  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:14:13.175509  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:14:13.205530  4008 solver.cpp:260]     Total regularization terms: 1.10998 loss+regular. : 2.59645
I0518 05:15:50.638994  4008 solver.cpp:231] Iteration 142800, loss = 1.41616
I0518 05:15:50.643473  4008 solver.cpp:247]     Train net output #0: loss = 1.41616 (* 1 = 1.41616 loss)
I0518 05:15:50.643525  4008 sgd_solver.cpp:106] Iteration 142800, lr = 0.001
I0518 05:15:50.799844  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5243	1.04167	75.3447	0	85.9068	4.42708	82.5072	0	77.6209	0	73.8793	0	64.3687	0	24.8594	1.8	
I0518 05:15:50.874403  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:15:50.876595  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:15:50.876641  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:15:50.892141  4008 solver.cpp:260]     Total regularization terms: 1.10962 loss+regular. : 2.52578
I0518 05:17:21.361222  4008 solver.cpp:348] Iteration 143000, Testing net (#0)
I0518 05:17:22.742530  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:18:45.172233  4008 solver.cpp:415]     Test net output #0: accuracy = 0.551579
I0518 05:18:45.172606  4008 solver.cpp:415]     Test net output #1: loss = 1.92716 (* 1 = 1.92716 loss)
I0518 05:18:45.263046  4008 solver.cpp:231] Iteration 143000, loss = 1.58982
I0518 05:18:45.263135  4008 solver.cpp:247]     Train net output #0: loss = 1.58982 (* 1 = 1.58982 loss)
I0518 05:18:45.263154  4008 sgd_solver.cpp:106] Iteration 143000, lr = 0.001
I0518 05:18:45.422416  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3895	1.04167	75.5192	0	85.9231	4.42708	82.5241	0	77.6281	0	73.9085	0	64.4009	0	24.8701	1.8	
I0518 05:18:45.510877  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:18:45.512245  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:18:45.512292  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:18:45.525393  4008 solver.cpp:260]     Total regularization terms: 1.10922 loss+regular. : 2.69905
I0518 05:18:52.863071  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:20:11.533339  4008 solver.cpp:231] Iteration 143200, loss = 1.44393
I0518 05:20:11.535128  4008 solver.cpp:247]     Train net output #0: loss = 1.44393 (* 1 = 1.44393 loss)
I0518 05:20:11.535162  4008 sgd_solver.cpp:106] Iteration 143200, lr = 0.001
I0518 05:20:11.693508  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2316	1.04167	75.7067	0	85.9448	4.42708	82.5485	0	77.6586	0	73.9377	0	64.4324	0	24.88	1.8	
I0518 05:20:11.768286  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:20:11.770432  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:20:11.770489  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:20:11.780483  4008 solver.cpp:260]     Total regularization terms: 1.10892 loss+regular. : 2.55285
I0518 05:21:43.361546  4008 solver.cpp:231] Iteration 143400, loss = 1.28727
I0518 05:21:43.362020  4008 solver.cpp:247]     Train net output #0: loss = 1.28727 (* 1 = 1.28727 loss)
I0518 05:21:43.362048  4008 sgd_solver.cpp:106] Iteration 143400, lr = 0.001
I0518 05:21:43.522975  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2173	1.04167	75.7767	0	85.945	4.42708	82.556	0	77.6654	0	73.9666	0	64.4638	0	24.8897	1.8	
I0518 05:21:43.597203  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:21:43.599292  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:21:43.599352  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:21:43.609218  4008 solver.cpp:260]     Total regularization terms: 1.10858 loss+regular. : 2.39584
I0518 05:23:07.813316  4008 solver.cpp:231] Iteration 143600, loss = 1.52021
I0518 05:23:07.813705  4008 solver.cpp:247]     Train net output #0: loss = 1.52021 (* 1 = 1.52021 loss)
I0518 05:23:07.813731  4008 sgd_solver.cpp:106] Iteration 143600, lr = 0.001
I0518 05:23:07.972882  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.2575	1.04167	75.7965	0	85.9812	4.42708	82.5789	0	77.7048	0	73.9957	0	64.4949	0	24.8992	1.8	
I0518 05:23:08.047224  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:23:08.048462  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:23:08.048496  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:23:08.058482  4008 solver.cpp:260]     Total regularization terms: 1.10819 loss+regular. : 2.6284
I0518 05:24:33.430712  4008 solver.cpp:231] Iteration 143800, loss = 1.43442
I0518 05:24:33.431126  4008 solver.cpp:247]     Train net output #0: loss = 1.43442 (* 1 = 1.43442 loss)
I0518 05:24:33.431145  4008 sgd_solver.cpp:106] Iteration 143800, lr = 0.001
I0518 05:24:33.590245  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4526	1.04167	75.7028	0	85.9991	4.42708	82.5923	0	77.7131	0	74.0251	0	64.5247	0	24.9098	1.8	
I0518 05:24:33.664458  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:24:33.666138  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:24:33.666206  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:24:33.676177  4008 solver.cpp:260]     Total regularization terms: 1.10783 loss+regular. : 2.54225
I0518 05:25:53.269675  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_144000.caffemodel
I0518 05:28:45.361999  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_144000.solverstate
I0518 05:28:45.972990  4008 solver.cpp:348] Iteration 144000, Testing net (#0)
I0518 05:28:48.165874  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:30:02.853219  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5541
I0518 05:30:02.857676  4008 solver.cpp:415]     Test net output #1: loss = 1.92138 (* 1 = 1.92138 loss)
I0518 05:30:02.945682  4008 solver.cpp:231] Iteration 144000, loss = 1.4517
I0518 05:30:02.945798  4008 solver.cpp:247]     Train net output #0: loss = 1.4517 (* 1 = 1.4517 loss)
I0518 05:30:02.945816  4008 sgd_solver.cpp:106] Iteration 144000, lr = 0.001
I0518 05:30:03.114377  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5473	1.04167	75.8877	0	86.0173	4.42708	82.6279	0	77.7443	0	74.054	0	64.5563	0	24.9203	1.8	
I0518 05:30:03.115538  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:30:03.117522  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:30:03.117606  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:30:03.128069  4008 solver.cpp:260]     Total regularization terms: 1.10739 loss+regular. : 2.55909
I0518 05:30:13.559787  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:31:34.290267  4008 solver.cpp:231] Iteration 144200, loss = 1.30996
I0518 05:31:34.290714  4008 solver.cpp:247]     Train net output #0: loss = 1.30996 (* 1 = 1.30996 loss)
I0518 05:31:34.290745  4008 sgd_solver.cpp:106] Iteration 144200, lr = 0.001
I0518 05:31:34.448978  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5387	1.04167	75.9336	0	86.0164	4.42708	82.625	0	77.7513	0	74.0829	0	64.5873	0	24.9305	1.8	
I0518 05:31:34.523538  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:31:34.525231  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:31:34.525277  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:31:34.535364  4008 solver.cpp:260]     Total regularization terms: 1.10706 loss+regular. : 2.41702
I0518 05:33:02.275315  4008 solver.cpp:231] Iteration 144400, loss = 1.28198
I0518 05:33:02.275751  4008 solver.cpp:247]     Train net output #0: loss = 1.28198 (* 1 = 1.28198 loss)
I0518 05:33:02.275782  4008 sgd_solver.cpp:106] Iteration 144400, lr = 0.001
I0518 05:33:02.437860  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3062	1.04167	75.9089	0	86.0256	4.42708	82.6398	0	77.771	0	74.1118	0	64.6188	0	24.9401	1.8	
I0518 05:33:02.512007  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:33:02.513377  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:33:02.513432  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:33:02.523392  4008 solver.cpp:260]     Total regularization terms: 1.1067 loss+regular. : 2.38869
I0518 05:34:29.835432  4008 solver.cpp:231] Iteration 144600, loss = 1.30502
I0518 05:34:29.835754  4008 solver.cpp:247]     Train net output #0: loss = 1.30502 (* 1 = 1.30502 loss)
I0518 05:34:29.835783  4008 sgd_solver.cpp:106] Iteration 144600, lr = 0.001
I0518 05:34:29.993357  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.0968	1.04167	75.667	0	86.0139	4.42708	82.6405	0	77.7895	0	74.14	0	64.65	0	24.9499	1.8	
I0518 05:34:30.068063  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:34:30.070592  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:34:30.070647  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:34:30.080968  4008 solver.cpp:260]     Total regularization terms: 1.10629 loss+regular. : 2.41131
I0518 05:35:57.483855  4008 solver.cpp:231] Iteration 144800, loss = 1.47073
I0518 05:35:57.484190  4008 solver.cpp:247]     Train net output #0: loss = 1.47073 (* 1 = 1.47073 loss)
I0518 05:35:57.484213  4008 sgd_solver.cpp:106] Iteration 144800, lr = 0.001
I0518 05:35:57.645059  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5674	1.04167	75.7096	0	86.0521	4.42708	82.643	0	77.792	0	74.1684	0	64.6805	0	24.9594	1.8	
I0518 05:35:57.719933  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:35:57.721223  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:35:57.721261  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:35:57.731500  4008 solver.cpp:260]     Total regularization terms: 1.10596 loss+regular. : 2.5767
I0518 05:37:24.090176  4008 solver.cpp:348] Iteration 145000, Testing net (#0)
I0518 05:37:26.742665  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:38:45.738852  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55292
I0518 05:38:45.739121  4008 solver.cpp:415]     Test net output #1: loss = 1.91512 (* 1 = 1.91512 loss)
I0518 05:38:45.827152  4008 solver.cpp:231] Iteration 145000, loss = 1.41931
I0518 05:38:45.827229  4008 solver.cpp:247]     Train net output #0: loss = 1.41931 (* 1 = 1.41931 loss)
I0518 05:38:45.827245  4008 sgd_solver.cpp:106] Iteration 145000, lr = 0.001
I0518 05:38:45.993649  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6276	1.04167	75.7155	0	86.0606	4.42708	82.6653	0	77.8097	0	74.1967	0	64.7119	0	24.9689	1.8	
I0518 05:38:46.067806  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:38:46.069501  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:38:46.069571  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:38:46.079422  4008 solver.cpp:260]     Total regularization terms: 1.10557 loss+regular. : 2.52487
I0518 05:38:59.299513  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:40:05.831346  4008 solver.cpp:231] Iteration 145200, loss = 1.57189
I0518 05:40:05.831776  4008 solver.cpp:247]     Train net output #0: loss = 1.57189 (* 1 = 1.57189 loss)
I0518 05:40:05.831802  4008 sgd_solver.cpp:106] Iteration 145200, lr = 0.001
I0518 05:40:05.991166  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5875	1.04167	75.9398	0	86.0642	4.42708	82.7001	0	77.8397	0	74.225	0	64.7427	0	24.9785	1.8	
I0518 05:40:06.065436  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:40:06.066938  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:40:06.066987  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:40:06.076968  4008 solver.cpp:260]     Total regularization terms: 1.10518 loss+regular. : 2.67707
I0518 05:41:30.030273  4008 solver.cpp:231] Iteration 145400, loss = 1.48371
I0518 05:41:30.030763  4008 solver.cpp:247]     Train net output #0: loss = 1.48371 (* 1 = 1.48371 loss)
I0518 05:41:30.030794  4008 sgd_solver.cpp:106] Iteration 145400, lr = 0.001
I0518 05:41:30.190790  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4325	1.04167	75.5267	0	86.04	4.42708	82.7093	0	77.8325	0	74.2531	0	64.7731	0	24.9891	1.8	
I0518 05:41:30.265974  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:41:30.267607  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:41:30.267652  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:41:30.281548  4008 solver.cpp:260]     Total regularization terms: 1.10499 loss+regular. : 2.5887
I0518 05:42:56.728929  4008 solver.cpp:231] Iteration 145600, loss = 1.38666
I0518 05:42:56.729215  4008 solver.cpp:247]     Train net output #0: loss = 1.38666 (* 1 = 1.38666 loss)
I0518 05:42:56.729236  4008 sgd_solver.cpp:106] Iteration 145600, lr = 0.001
I0518 05:42:56.888958  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.51	1.04167	75.945	0	86.0911	4.42708	82.7353	0	77.875	0	74.2819	0	64.8032	0	24.9984	1.8	
I0518 05:42:56.963109  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:42:56.964846  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:42:56.964882  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:42:56.974609  4008 solver.cpp:260]     Total regularization terms: 1.10463 loss+regular. : 2.49129
I0518 05:44:24.329486  4008 solver.cpp:231] Iteration 145800, loss = 1.37425
I0518 05:44:24.329772  4008 solver.cpp:247]     Train net output #0: loss = 1.37425 (* 1 = 1.37425 loss)
I0518 05:44:24.329792  4008 sgd_solver.cpp:106] Iteration 145800, lr = 0.001
I0518 05:44:24.488142  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7166	1.04167	75.7503	0	86.1083	4.42708	82.7533	0	77.8976	0	74.31	0	64.8334	0	25.0077	1.8	
I0518 05:44:24.562288  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:44:24.563863  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:44:24.563915  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:44:24.573987  4008 solver.cpp:260]     Total regularization terms: 1.10428 loss+regular. : 2.47853
I0518 05:45:51.299093  4008 solver.cpp:348] Iteration 146000, Testing net (#0)
I0518 05:45:54.711638  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:47:18.372218  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55378
I0518 05:47:18.372459  4008 solver.cpp:415]     Test net output #1: loss = 1.9181 (* 1 = 1.9181 loss)
I0518 05:47:18.459805  4008 solver.cpp:231] Iteration 146000, loss = 1.46984
I0518 05:47:18.459897  4008 solver.cpp:247]     Train net output #0: loss = 1.46984 (* 1 = 1.46984 loss)
I0518 05:47:18.459914  4008 sgd_solver.cpp:106] Iteration 146000, lr = 0.001
I0518 05:47:18.624474  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5588	1.04167	76.0186	0	86.1286	4.42708	82.7751	0	77.9116	0	74.3379	0	64.8637	0	25.0182	1.8	
I0518 05:47:18.698779  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:47:18.700425  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:47:18.700513  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:47:18.710356  4008 solver.cpp:260]     Total regularization terms: 1.10393 loss+regular. : 2.57377
I0518 05:47:35.990309  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:48:41.938463  4008 solver.cpp:231] Iteration 146200, loss = 1.37671
I0518 05:48:41.939000  4008 solver.cpp:247]     Train net output #0: loss = 1.37671 (* 1 = 1.37671 loss)
I0518 05:48:41.939038  4008 sgd_solver.cpp:106] Iteration 146200, lr = 0.001
I0518 05:48:42.097960  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6047	1.04167	75.9023	0	86.1333	4.42708	82.7827	0	77.9256	0	74.3661	0	64.8944	0	25.0279	1.8	
I0518 05:48:42.172632  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:48:42.175086  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:48:42.175149  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:48:42.185159  4008 solver.cpp:260]     Total regularization terms: 1.10361 loss+regular. : 2.48032
I0518 05:50:07.359145  4008 solver.cpp:231] Iteration 146400, loss = 1.47318
I0518 05:50:07.359558  4008 solver.cpp:247]     Train net output #0: loss = 1.47318 (* 1 = 1.47318 loss)
I0518 05:50:07.359586  4008 sgd_solver.cpp:106] Iteration 146400, lr = 0.001
I0518 05:50:07.518331  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5473	1.04167	75.7598	0	86.1422	4.42708	82.8039	0	77.9358	0	74.3938	0	64.9255	0	25.038	1.8	
I0518 05:50:07.593209  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:50:07.595476  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:50:07.595530  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:50:07.605672  4008 solver.cpp:260]     Total regularization terms: 1.10333 loss+regular. : 2.57651
I0518 05:51:31.686358  4008 solver.cpp:231] Iteration 146600, loss = 1.64074
I0518 05:51:31.686725  4008 solver.cpp:247]     Train net output #0: loss = 1.64074 (* 1 = 1.64074 loss)
I0518 05:51:31.686749  4008 sgd_solver.cpp:106] Iteration 146600, lr = 0.001
I0518 05:51:31.846956  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6477	1.04167	75.8369	0	86.1593	4.42708	82.8169	0	77.9322	0	74.4215	0	64.9566	0	25.0474	1.8	
I0518 05:51:31.922709  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:51:31.924659  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:51:31.924706  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:51:31.944855  4008 solver.cpp:260]     Total regularization terms: 1.10294 loss+regular. : 2.74368
I0518 05:53:04.876788  4008 solver.cpp:231] Iteration 146800, loss = 1.31356
I0518 05:53:04.877967  4008 solver.cpp:247]     Train net output #0: loss = 1.31356 (* 1 = 1.31356 loss)
I0518 05:53:04.877995  4008 sgd_solver.cpp:106] Iteration 146800, lr = 0.001
I0518 05:53:05.037420  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7883	1.04167	75.9674	0	86.1708	4.42708	82.8407	0	77.9785	0	74.4493	0	64.987	0	25.0563	1.8	
I0518 05:53:05.111850  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:53:05.114089  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:53:05.114148  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:53:05.129362  4008 solver.cpp:260]     Total regularization terms: 1.10256 loss+regular. : 2.41612
I0518 05:54:25.773129  4008 solver.cpp:348] Iteration 147000, Testing net (#0)
I0518 05:54:29.734947  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:55:47.485126  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55192
I0518 05:55:47.485582  4008 solver.cpp:415]     Test net output #1: loss = 1.92337 (* 1 = 1.92337 loss)
I0518 05:55:47.575348  4008 solver.cpp:231] Iteration 147000, loss = 1.47455
I0518 05:55:47.575455  4008 solver.cpp:247]     Train net output #0: loss = 1.47455 (* 1 = 1.47455 loss)
I0518 05:55:47.575479  4008 sgd_solver.cpp:106] Iteration 147000, lr = 0.001
I0518 05:55:47.736155  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4095	1.04167	75.7529	0	86.1898	4.42708	82.8449	0	77.9919	0	74.477	0	65.0174	0	25.0658	1.8	
I0518 05:55:47.810895  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:55:47.812568  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:55:47.812618  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:55:47.822723  4008 solver.cpp:260]     Total regularization terms: 1.10225 loss+regular. : 2.57679
I0518 05:56:09.315263  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 05:57:15.068876  4008 solver.cpp:231] Iteration 147200, loss = 1.34271
I0518 05:57:15.069198  4008 solver.cpp:247]     Train net output #0: loss = 1.34271 (* 1 = 1.34271 loss)
I0518 05:57:15.069221  4008 sgd_solver.cpp:106] Iteration 147200, lr = 0.001
I0518 05:57:15.229519  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5789	1.04167	76.0055	0	86.1935	4.42708	82.8655	0	78.0142	0	74.5045	0	65.0473	0	25.075	1.8	
I0518 05:57:15.303701  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:57:15.305291  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:57:15.305340  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:57:15.315143  4008 solver.cpp:260]     Total regularization terms: 1.10196 loss+regular. : 2.44467
I0518 05:58:40.246896  4008 solver.cpp:231] Iteration 147400, loss = 1.41384
I0518 05:58:40.247272  4008 solver.cpp:247]     Train net output #0: loss = 1.41384 (* 1 = 1.41384 loss)
I0518 05:58:40.247304  4008 sgd_solver.cpp:106] Iteration 147400, lr = 0.001
I0518 05:58:40.408355  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6736	1.04167	76.0755	0	86.2162	4.42708	82.8838	0	78.0283	0	74.5319	0	65.0774	0	25.0843	1.8	
I0518 05:58:40.482616  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 05:58:40.484438  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 05:58:40.484489  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 05:58:40.494344  4008 solver.cpp:260]     Total regularization terms: 1.10159 loss+regular. : 2.51543
I0518 06:00:10.462514  4008 solver.cpp:231] Iteration 147600, loss = 1.55796
I0518 06:00:10.463016  4008 solver.cpp:247]     Train net output #0: loss = 1.55796 (* 1 = 1.55796 loss)
I0518 06:00:10.463039  4008 sgd_solver.cpp:106] Iteration 147600, lr = 0.001
I0518 06:00:10.622635  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4813	1.04167	76.0654	0	86.2527	4.42708	82.8945	0	78.0339	0	74.5589	0	65.1071	0	25.0934	1.8	
I0518 06:00:10.697170  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:00:10.698953  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:00:10.699015  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:00:10.709316  4008 solver.cpp:260]     Total regularization terms: 1.10118 loss+regular. : 2.65914
I0518 06:01:31.801084  4008 solver.cpp:231] Iteration 147800, loss = 1.41129
I0518 06:01:31.801422  4008 solver.cpp:247]     Train net output #0: loss = 1.41129 (* 1 = 1.41129 loss)
I0518 06:01:31.801447  4008 sgd_solver.cpp:106] Iteration 147800, lr = 0.001
I0518 06:01:31.960891  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8084	1.04167	76.1328	0	86.2438	4.42708	82.908	0	78.0567	0	74.5865	0	65.1379	0	25.1023	1.8	
I0518 06:01:32.035413  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:01:32.037403  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:01:32.037449  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:01:32.047540  4008 solver.cpp:260]     Total regularization terms: 1.10081 loss+regular. : 2.5121
I0518 06:02:59.396291  4008 solver.cpp:348] Iteration 148000, Testing net (#0)
I0518 06:03:03.135512  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:04:22.810920  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55334
I0518 06:04:22.811229  4008 solver.cpp:415]     Test net output #1: loss = 1.92223 (* 1 = 1.92223 loss)
I0518 06:04:22.898772  4008 solver.cpp:231] Iteration 148000, loss = 1.29823
I0518 06:04:22.898854  4008 solver.cpp:247]     Train net output #0: loss = 1.29823 (* 1 = 1.29823 loss)
I0518 06:04:22.898871  4008 sgd_solver.cpp:106] Iteration 148000, lr = 0.001
I0518 06:04:23.064676  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.685	1.04167	75.9391	0	86.2432	4.42708	82.9169	0	78.075	0	74.6143	0	65.1672	0	25.1119	1.8	
I0518 06:04:23.139374  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:04:23.141229  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:04:23.141275  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:04:23.151262  4008 solver.cpp:260]     Total regularization terms: 1.10047 loss+regular. : 2.39871
I0518 06:04:45.033349  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:05:49.781929  4008 solver.cpp:231] Iteration 148200, loss = 1.50598
I0518 06:05:49.782279  4008 solver.cpp:247]     Train net output #0: loss = 1.50598 (* 1 = 1.50598 loss)
I0518 06:05:49.782305  4008 sgd_solver.cpp:106] Iteration 148200, lr = 0.001
I0518 06:05:49.941257  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7309	1.04167	76.1462	0	86.2554	4.42708	82.9111	0	78.1047	0	74.642	0	65.1963	0	25.1216	1.8	
I0518 06:05:50.015781  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:05:50.017542  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:05:50.017606  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:05:50.027673  4008 solver.cpp:260]     Total regularization terms: 1.10012 loss+regular. : 2.6061
I0518 06:07:26.887527  4008 solver.cpp:231] Iteration 148400, loss = 1.33581
I0518 06:07:26.887838  4008 solver.cpp:247]     Train net output #0: loss = 1.33581 (* 1 = 1.33581 loss)
I0518 06:07:26.887859  4008 sgd_solver.cpp:106] Iteration 148400, lr = 0.001
I0518 06:07:27.049693  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6879	1.04167	75.8451	0	86.2373	4.42708	82.9319	0	78.0985	0	74.6688	0	65.2266	0	25.131	1.8	
I0518 06:07:27.123888  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:07:27.125452  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:07:27.125500  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:07:27.135403  4008 solver.cpp:260]     Total regularization terms: 1.09987 loss+regular. : 2.43567
I0518 06:08:56.756342  4008 solver.cpp:231] Iteration 148600, loss = 1.50633
I0518 06:08:56.756784  4008 solver.cpp:247]     Train net output #0: loss = 1.50633 (* 1 = 1.50633 loss)
I0518 06:08:56.756808  4008 sgd_solver.cpp:106] Iteration 148600, lr = 0.001
I0518 06:08:56.918710  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8486	1.04167	75.9974	0	86.2359	4.42708	82.9471	0	78.1184	0	74.6959	0	65.2565	0	25.1402	1.8	
I0518 06:08:56.993011  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:08:56.994221  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:08:56.994264  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:08:57.003942  4008 solver.cpp:260]     Total regularization terms: 1.09953 loss+regular. : 2.60586
I0518 06:10:28.836431  4008 solver.cpp:231] Iteration 148800, loss = 1.53761
I0518 06:10:28.836892  4008 solver.cpp:247]     Train net output #0: loss = 1.53761 (* 1 = 1.53761 loss)
I0518 06:10:28.836920  4008 sgd_solver.cpp:106] Iteration 148800, lr = 0.001
I0518 06:10:28.994885  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6793	1.04167	76.0729	0	86.2687	4.42708	82.9774	0	78.1618	0	74.7226	0	65.2861	0	25.1497	1.8	
I0518 06:10:29.069108  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:10:29.070929  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:10:29.070973  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:10:29.080752  4008 solver.cpp:260]     Total regularization terms: 1.09919 loss+regular. : 2.6368
I0518 06:11:51.079373  4008 solver.cpp:348] Iteration 149000, Testing net (#0)
I0518 06:11:56.035058  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:13:15.952262  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55418
I0518 06:13:15.952554  4008 solver.cpp:415]     Test net output #1: loss = 1.91326 (* 1 = 1.91326 loss)
I0518 06:13:16.040061  4008 solver.cpp:231] Iteration 149000, loss = 1.45764
I0518 06:13:16.040155  4008 solver.cpp:247]     Train net output #0: loss = 1.45764 (* 1 = 1.45764 loss)
I0518 06:13:16.040174  4008 sgd_solver.cpp:106] Iteration 149000, lr = 0.001
I0518 06:13:16.208583  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7367	1.04167	76.1699	0	86.3107	4.42708	82.9955	0	78.184	0	74.7501	0	65.3158	0	25.1593	1.8	
I0518 06:13:16.282889  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:13:16.284097  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:13:16.284131  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:13:16.294041  4008 solver.cpp:260]     Total regularization terms: 1.0988 loss+regular. : 2.55644
I0518 06:13:44.345899  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:14:43.492496  4008 solver.cpp:231] Iteration 149200, loss = 1.55551
I0518 06:14:43.492841  4008 solver.cpp:247]     Train net output #0: loss = 1.55551 (* 1 = 1.55551 loss)
I0518 06:14:43.492861  4008 sgd_solver.cpp:106] Iteration 149200, lr = 0.001
I0518 06:14:43.652734  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7309	1.04167	76.2227	0	86.3143	4.42708	83.0045	0	78.21	0	74.7765	0	65.3451	0	25.1688	1.8	
I0518 06:14:43.726984  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:14:43.728611  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:14:43.728657  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:14:43.743716  4008 solver.cpp:260]     Total regularization terms: 1.0985 loss+regular. : 2.654
I0518 06:16:13.606248  4008 solver.cpp:231] Iteration 149400, loss = 1.50122
I0518 06:16:13.606598  4008 solver.cpp:247]     Train net output #0: loss = 1.50122 (* 1 = 1.50122 loss)
I0518 06:16:13.606626  4008 sgd_solver.cpp:106] Iteration 149400, lr = 0.001
I0518 06:16:13.766710  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4411	1.04167	76.2591	0	86.3324	4.42708	83.0084	0	78.2156	0	74.8032	0	65.3749	0	25.1785	1.8	
I0518 06:16:13.841401  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:16:13.843165  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:16:13.843221  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:16:13.853159  4008 solver.cpp:260]     Total regularization terms: 1.09816 loss+regular. : 2.59937
I0518 06:17:39.923570  4008 solver.cpp:231] Iteration 149600, loss = 1.34304
I0518 06:17:39.924111  4008 solver.cpp:247]     Train net output #0: loss = 1.34304 (* 1 = 1.34304 loss)
I0518 06:17:39.924142  4008 sgd_solver.cpp:106] Iteration 149600, lr = 0.001
I0518 06:17:40.084321  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4842	1.04167	76.0586	0	86.342	4.42708	83.0316	0	78.2217	0	74.8302	0	65.4039	0	25.1885	1.8	
I0518 06:17:40.162734  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:17:40.164355  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:17:40.164404  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:17:40.174533  4008 solver.cpp:260]     Total regularization terms: 1.09776 loss+regular. : 2.4408
I0518 06:19:05.250998  4008 solver.cpp:231] Iteration 149800, loss = 1.34943
I0518 06:19:05.251274  4008 solver.cpp:247]     Train net output #0: loss = 1.34943 (* 1 = 1.34943 loss)
I0518 06:19:05.251293  4008 sgd_solver.cpp:106] Iteration 149800, lr = 0.001
I0518 06:19:05.411479  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4469	1.04167	75.8333	0	86.3159	4.42708	83.0357	0	78.2412	0	74.8566	0	65.4334	0	25.1977	1.8	
I0518 06:19:05.485718  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:19:05.487540  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:19:05.487601  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:19:05.501293  4008 solver.cpp:260]     Total regularization terms: 1.09751 loss+regular. : 2.44693
I0518 06:20:35.459933  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_150000.caffemodel
I0518 06:23:45.140614  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_150000.solverstate
I0518 06:23:45.803719  4008 solver.cpp:348] Iteration 150000, Testing net (#0)
I0518 06:23:52.060119  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:25:17.939857  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55354
I0518 06:25:17.940248  4008 solver.cpp:415]     Test net output #1: loss = 1.91723 (* 1 = 1.91723 loss)
I0518 06:25:18.028126  4008 solver.cpp:231] Iteration 150000, loss = 1.45521
I0518 06:25:18.028234  4008 solver.cpp:247]     Train net output #0: loss = 1.45521 (* 1 = 1.45521 loss)
I0518 06:25:18.028259  4008 sgd_solver.cpp:106] Iteration 150000, lr = 0.001
I0518 06:25:18.193578  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5272	1.04167	75.987	0	86.3478	4.42708	83.0449	0	78.243	0	74.8834	0	65.4634	0	25.207	1.8	
I0518 06:25:18.194936  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:25:18.197033  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:25:18.197078  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:25:18.206979  4008 solver.cpp:260]     Total regularization terms: 1.09712 loss+regular. : 2.55233
I0518 06:25:46.347151  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:26:40.850266  4008 solver.cpp:231] Iteration 150200, loss = 1.24665
I0518 06:26:40.850615  4008 solver.cpp:247]     Train net output #0: loss = 1.24665 (* 1 = 1.24665 loss)
I0518 06:26:40.850641  4008 sgd_solver.cpp:106] Iteration 150200, lr = 0.001
I0518 06:26:41.010121  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5042	1.04167	76.2048	0	86.3715	4.42708	83.0589	0	78.2624	0	74.9105	0	65.4929	0	25.2165	1.8	
I0518 06:26:41.084187  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:26:41.085724  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:26:41.085772  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:26:41.115510  4008 solver.cpp:260]     Total regularization terms: 1.09672 loss+regular. : 2.34338
I0518 06:28:03.121487  4008 solver.cpp:231] Iteration 150400, loss = 1.59803
I0518 06:28:03.122014  4008 solver.cpp:247]     Train net output #0: loss = 1.59803 (* 1 = 1.59803 loss)
I0518 06:28:03.122038  4008 sgd_solver.cpp:106] Iteration 150400, lr = 0.001
I0518 06:28:03.281563  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5358	1.04167	76.1585	0	86.3663	4.42708	83.0862	0	78.2667	0	74.9371	0	65.5217	0	25.2268	1.8	
I0518 06:28:03.355695  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:28:03.356897  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:28:03.356920  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:28:03.366664  4008 solver.cpp:260]     Total regularization terms: 1.09646 loss+regular. : 2.69449
I0518 06:29:32.623693  4008 solver.cpp:231] Iteration 150600, loss = 1.37163
I0518 06:29:32.624027  4008 solver.cpp:247]     Train net output #0: loss = 1.37163 (* 1 = 1.37163 loss)
I0518 06:29:32.624045  4008 sgd_solver.cpp:106] Iteration 150600, lr = 0.001
I0518 06:29:32.785632  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7568	1.04167	76.0296	0	86.3932	4.42708	83.0949	0	78.2988	0	74.9641	0	65.5511	0	25.2362	1.8	
I0518 06:29:32.859957  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:29:32.861860  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:29:32.861907  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:29:32.871745  4008 solver.cpp:260]     Total regularization terms: 1.09616 loss+regular. : 2.46779
I0518 06:30:58.150840  4008 solver.cpp:231] Iteration 150800, loss = 1.4634
I0518 06:30:58.151154  4008 solver.cpp:247]     Train net output #0: loss = 1.4634 (* 1 = 1.4634 loss)
I0518 06:30:58.151180  4008 sgd_solver.cpp:106] Iteration 150800, lr = 0.001
I0518 06:30:58.310142  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.553	1.04167	76.2969	0	86.4118	4.42708	83.1147	0	78.3104	0	74.991	0	65.58	0	25.2461	1.8	
I0518 06:30:58.385475  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:30:58.386721  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:30:58.386749  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:30:58.400228  4008 solver.cpp:260]     Total regularization terms: 1.09573 loss+regular. : 2.55913
I0518 06:32:26.721834  4008 solver.cpp:348] Iteration 151000, Testing net (#0)
I0518 06:32:33.130825  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:33:49.628386  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55326
I0518 06:33:49.628723  4008 solver.cpp:415]     Test net output #1: loss = 1.92476 (* 1 = 1.92476 loss)
I0518 06:33:49.719413  4008 solver.cpp:231] Iteration 151000, loss = 1.56692
I0518 06:33:49.719498  4008 solver.cpp:247]     Train net output #0: loss = 1.56692 (* 1 = 1.56692 loss)
I0518 06:33:49.719517  4008 sgd_solver.cpp:106] Iteration 151000, lr = 0.001
I0518 06:33:49.879672  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3005	1.04167	76.167	0	86.4202	4.42708	83.1014	0	78.3162	0	75.0176	0	65.609	0	25.2554	1.8	
I0518 06:33:49.955620  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:33:49.957334  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:33:49.957376  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:33:49.967334  4008 solver.cpp:260]     Total regularization terms: 1.09544 loss+regular. : 2.66236
I0518 06:34:23.462554  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:35:14.433109  4008 solver.cpp:231] Iteration 151200, loss = 1.32031
I0518 06:35:14.433483  4008 solver.cpp:247]     Train net output #0: loss = 1.32031 (* 1 = 1.32031 loss)
I0518 06:35:14.433503  4008 sgd_solver.cpp:106] Iteration 151200, lr = 0.001
I0518 06:35:14.593767  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3895	1.04167	76.2484	0	86.4275	4.42708	83.1418	0	78.3343	0	75.0442	0	65.6389	0	25.2645	1.8	
I0518 06:35:14.667872  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:35:14.669390  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.8	
I0518 06:35:14.669437  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:35:14.684521  4008 solver.cpp:260]     Total regularization terms: 1.09512 loss+regular. : 2.41544
I0518 06:36:33.713582  4008 solver.cpp:231] Iteration 151400, loss = 1.41068
I0518 06:36:33.713872  4008 solver.cpp:247]     Train net output #0: loss = 1.41068 (* 1 = 1.41068 loss)
I0518 06:36:33.713893  4008 sgd_solver.cpp:106] Iteration 151400, lr = 0.001
I0518 06:36:33.873303  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4296	1.04167	76.3734	0	86.4198	4.42708	83.1519	0	78.3364	0	75.0705	0	65.6684	0	25.2732	1.9	
I0518 06:36:33.947260  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:36:33.948416  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:36:33.948441  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:36:33.963487  4008 solver.cpp:260]     Total regularization terms: 1.09475 loss+regular. : 2.50542
I0518 06:37:57.776744  4008 solver.cpp:231] Iteration 151600, loss = 1.48481
I0518 06:37:57.777160  4008 solver.cpp:247]     Train net output #0: loss = 1.48481 (* 1 = 1.48481 loss)
I0518 06:37:57.777197  4008 sgd_solver.cpp:106] Iteration 151600, lr = 0.001
I0518 06:37:57.937170  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1255	1.04167	76.4023	0	86.4426	4.42708	83.1787	0	78.3694	0	75.0968	0	65.6969	0	25.2825	1.9	
I0518 06:37:58.011768  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:37:58.013335  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:37:58.013376  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:37:58.023270  4008 solver.cpp:260]     Total regularization terms: 1.09442 loss+regular. : 2.57923
I0518 06:39:26.826300  4008 solver.cpp:231] Iteration 151800, loss = 1.44331
I0518 06:39:26.826601  4008 solver.cpp:247]     Train net output #0: loss = 1.44331 (* 1 = 1.44331 loss)
I0518 06:39:26.826624  4008 sgd_solver.cpp:106] Iteration 151800, lr = 0.001
I0518 06:39:26.985080  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.487	1.04167	76.319	0	86.4336	4.42708	83.1784	0	78.3762	0	75.1232	0	65.7254	0	25.2918	1.9	
I0518 06:39:27.059396  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:39:27.061218  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:39:27.061286  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:39:27.071161  4008 solver.cpp:260]     Total regularization terms: 1.09415 loss+regular. : 2.53746
I0518 06:40:51.924612  4008 solver.cpp:348] Iteration 152000, Testing net (#0)
I0518 06:40:58.759111  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:42:18.232749  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5538
I0518 06:42:18.233142  4008 solver.cpp:415]     Test net output #1: loss = 1.92615 (* 1 = 1.92615 loss)
I0518 06:42:18.324558  4008 solver.cpp:231] Iteration 152000, loss = 1.32593
I0518 06:42:18.324645  4008 solver.cpp:247]     Train net output #0: loss = 1.32593 (* 1 = 1.32593 loss)
I0518 06:42:18.324662  4008 sgd_solver.cpp:106] Iteration 152000, lr = 0.001
I0518 06:42:18.494855  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6276	1.04167	76.3268	0	86.4176	4.42708	83.1956	0	78.3712	0	75.1499	0	65.7555	0	25.301	1.9	
I0518 06:42:18.569146  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:42:18.570983  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:42:18.571032  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:42:18.583385  4008 solver.cpp:260]     Total regularization terms: 1.09386 loss+regular. : 2.41979
I0518 06:42:57.924983  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:43:47.486980  4008 solver.cpp:231] Iteration 152200, loss = 1.50676
I0518 06:43:47.492022  4008 solver.cpp:247]     Train net output #0: loss = 1.50676 (* 1 = 1.50676 loss)
I0518 06:43:47.492074  4008 sgd_solver.cpp:106] Iteration 152200, lr = 0.001
I0518 06:43:47.646445  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4641	1.04167	76.3473	0	86.4523	4.42708	83.2067	0	78.4028	0	75.1757	0	65.7843	0	25.3103	1.9	
I0518 06:43:47.720902  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:43:47.722467  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:43:47.722517  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:43:47.732414  4008 solver.cpp:260]     Total regularization terms: 1.09352 loss+regular. : 2.60028
I0518 06:45:14.437595  4008 solver.cpp:231] Iteration 152400, loss = 1.35856
I0518 06:45:14.437911  4008 solver.cpp:247]     Train net output #0: loss = 1.35856 (* 1 = 1.35856 loss)
I0518 06:45:14.437929  4008 sgd_solver.cpp:106] Iteration 152400, lr = 0.001
I0518 06:45:14.598469  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6736	1.04167	76.3711	0	86.4764	4.42708	83.2318	0	78.4279	0	75.201	0	65.8133	0	25.3202	1.9	
I0518 06:45:14.672631  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:45:14.674515  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:45:14.674564  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:45:14.684397  4008 solver.cpp:260]     Total regularization terms: 1.09316 loss+regular. : 2.45172
I0518 06:46:38.745159  4008 solver.cpp:231] Iteration 152600, loss = 1.5286
I0518 06:46:38.745499  4008 solver.cpp:247]     Train net output #0: loss = 1.5286 (* 1 = 1.5286 loss)
I0518 06:46:38.745630  4008 sgd_solver.cpp:106] Iteration 152600, lr = 0.001
I0518 06:46:38.906677  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3722	1.04167	76.39	0	86.4827	4.42708	83.252	0	78.4512	0	75.2269	0	65.8418	0	25.3291	1.9	
I0518 06:46:38.981811  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:46:38.983738  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:46:38.983785  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:46:39.004993  4008 solver.cpp:260]     Total regularization terms: 1.09282 loss+regular. : 2.62141
I0518 06:48:00.766801  4008 solver.cpp:231] Iteration 152800, loss = 1.20547
I0518 06:48:00.767179  4008 solver.cpp:247]     Train net output #0: loss = 1.20547 (* 1 = 1.20547 loss)
I0518 06:48:00.767207  4008 sgd_solver.cpp:106] Iteration 152800, lr = 0.001
I0518 06:48:00.926707  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4497	1.04167	76.3271	0	86.5017	4.42708	83.2611	0	78.4711	0	75.2527	0	65.8713	0	25.3385	1.9	
I0518 06:48:01.000929  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:48:01.002640  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:48:01.002689  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:48:01.013448  4008 solver.cpp:260]     Total regularization terms: 1.09246 loss+regular. : 2.29792
I0518 06:49:29.577052  4008 solver.cpp:348] Iteration 153000, Testing net (#0)
I0518 06:49:35.951659  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:50:52.823030  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55272
I0518 06:50:52.823391  4008 solver.cpp:415]     Test net output #1: loss = 1.92173 (* 1 = 1.92173 loss)
I0518 06:50:52.914546  4008 solver.cpp:231] Iteration 153000, loss = 1.52231
I0518 06:50:52.914633  4008 solver.cpp:247]     Train net output #0: loss = 1.52231 (* 1 = 1.52231 loss)
I0518 06:50:52.914651  4008 sgd_solver.cpp:106] Iteration 153000, lr = 0.001
I0518 06:50:53.075822  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3235	1.04167	76.3258	0	86.5139	4.42708	83.2785	0	78.4858	0	75.2787	0	65.8996	0	25.347	1.9	
I0518 06:50:53.151888  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:50:53.153321  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:50:53.153368  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:50:53.163395  4008 solver.cpp:260]     Total regularization terms: 1.09213 loss+regular. : 2.61444
I0518 06:51:31.067998  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:52:16.498088  4008 solver.cpp:231] Iteration 153200, loss = 1.43442
I0518 06:52:16.498396  4008 solver.cpp:247]     Train net output #0: loss = 1.43442 (* 1 = 1.43442 loss)
I0518 06:52:16.498427  4008 sgd_solver.cpp:106] Iteration 153200, lr = 0.001
I0518 06:52:16.657639  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6276	1.04167	76.4697	0	86.5282	4.42708	83.281	0	78.5039	0	75.3046	0	65.9285	0	25.3557	1.9	
I0518 06:52:16.731978  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:52:16.733541  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:52:16.733613  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:52:16.743779  4008 solver.cpp:260]     Total regularization terms: 1.09178 loss+regular. : 2.5262
I0518 06:53:33.172340  4008 solver.cpp:231] Iteration 153400, loss = 1.37634
I0518 06:53:33.172658  4008 solver.cpp:247]     Train net output #0: loss = 1.37634 (* 1 = 1.37634 loss)
I0518 06:53:33.172688  4008 sgd_solver.cpp:106] Iteration 153400, lr = 0.001
I0518 06:53:33.331840  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5272	1.04167	76.4277	0	86.5101	4.42708	83.2916	0	78.5181	0	75.3304	0	65.9578	0	25.3645	1.9	
I0518 06:53:33.406023  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:53:33.407690  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:53:33.407747  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:53:33.419188  4008 solver.cpp:260]     Total regularization terms: 1.09145 loss+regular. : 2.46779
I0518 06:54:54.001567  4008 solver.cpp:231] Iteration 153600, loss = 1.29917
I0518 06:54:54.001857  4008 solver.cpp:247]     Train net output #0: loss = 1.29917 (* 1 = 1.29917 loss)
I0518 06:54:54.001885  4008 sgd_solver.cpp:106] Iteration 153600, lr = 0.001
I0518 06:54:54.163442  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6879	1.04167	76.4515	0	86.544	4.42708	83.3061	0	78.5296	0	75.356	0	65.9861	0	25.373	1.9	
I0518 06:54:54.238632  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:54:54.240475  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:54:54.240519  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:54:54.270539  4008 solver.cpp:260]     Total regularization terms: 1.09114 loss+regular. : 2.3903
I0518 06:56:16.126359  4008 solver.cpp:231] Iteration 153800, loss = 1.64147
I0518 06:56:16.126665  4008 solver.cpp:247]     Train net output #0: loss = 1.64147 (* 1 = 1.64147 loss)
I0518 06:56:16.126693  4008 sgd_solver.cpp:106] Iteration 153800, lr = 0.001
I0518 06:56:16.286916  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6104	1.04167	76.3682	0	86.5237	4.42708	83.3272	0	78.552	0	75.3816	0	66.015	0	25.3823	1.9	
I0518 06:56:16.360741  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:56:16.362041  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:56:16.362074  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:56:16.371713  4008 solver.cpp:260]     Total regularization terms: 1.09086 loss+regular. : 2.73233
I0518 06:57:47.628286  4008 solver.cpp:348] Iteration 154000, Testing net (#0)
I0518 06:57:56.870594  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 06:59:25.412000  4008 solver.cpp:415]     Test net output #0: accuracy = 0.548659
I0518 06:59:25.412269  4008 solver.cpp:415]     Test net output #1: loss = 1.93788 (* 1 = 1.93788 loss)
I0518 06:59:25.500489  4008 solver.cpp:231] Iteration 154000, loss = 1.24454
I0518 06:59:25.500613  4008 solver.cpp:247]     Train net output #0: loss = 1.24454 (* 1 = 1.24454 loss)
I0518 06:59:25.500640  4008 sgd_solver.cpp:106] Iteration 154000, lr = 0.001
I0518 06:59:25.665386  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.685	1.04167	76.179	0	86.5304	4.42708	83.341	0	78.578	0	75.4071	0	66.0434	0	25.3918	1.9	
I0518 06:59:25.742523  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 06:59:25.744509  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 06:59:25.744554  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 06:59:25.758038  4008 solver.cpp:260]     Total regularization terms: 1.09053 loss+regular. : 2.33506
I0518 07:00:09.332289  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:00:55.882992  4008 solver.cpp:231] Iteration 154200, loss = 1.38282
I0518 07:00:55.883328  4008 solver.cpp:247]     Train net output #0: loss = 1.38282 (* 1 = 1.38282 loss)
I0518 07:00:55.883357  4008 sgd_solver.cpp:106] Iteration 154200, lr = 0.001
I0518 07:00:56.044400  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7137	1.04167	76.5296	0	86.5586	4.42708	83.3568	0	78.5805	0	75.4327	0	66.0722	0	25.4012	1.9	
I0518 07:00:56.119874  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:00:56.121731  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:00:56.121783  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:00:56.136778  4008 solver.cpp:260]     Total regularization terms: 1.09019 loss+regular. : 2.47301
I0518 07:02:17.068696  4008 solver.cpp:231] Iteration 154400, loss = 1.64515
I0518 07:02:17.069057  4008 solver.cpp:247]     Train net output #0: loss = 1.64515 (* 1 = 1.64515 loss)
I0518 07:02:17.069082  4008 sgd_solver.cpp:106] Iteration 154400, lr = 0.001
I0518 07:02:17.229158  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6965	1.04167	76.4606	0	86.5656	4.42708	83.3764	0	78.6038	0	75.4583	0	66.1003	0	25.4106	1.9	
I0518 07:02:17.303405  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:02:17.304785  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:02:17.304826  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:02:17.324937  4008 solver.cpp:260]     Total regularization terms: 1.08989 loss+regular. : 2.73504
I0518 07:03:45.555337  4008 solver.cpp:231] Iteration 154600, loss = 1.46806
I0518 07:03:45.556692  4008 solver.cpp:247]     Train net output #0: loss = 1.46806 (* 1 = 1.46806 loss)
I0518 07:03:45.556721  4008 sgd_solver.cpp:106] Iteration 154600, lr = 0.001
I0518 07:03:45.715472  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5329	1.04167	76.3805	0	86.554	4.42708	83.3681	0	78.6253	0	75.4839	0	66.129	0	25.4195	1.9	
I0518 07:03:45.789824  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:03:45.791545  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:03:45.791587  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:03:45.801661  4008 solver.cpp:260]     Total regularization terms: 1.08959 loss+regular. : 2.55765
I0518 07:05:10.480036  4008 solver.cpp:231] Iteration 154800, loss = 1.3339
I0518 07:05:10.481214  4008 solver.cpp:247]     Train net output #0: loss = 1.3339 (* 1 = 1.3339 loss)
I0518 07:05:10.481261  4008 sgd_solver.cpp:106] Iteration 154800, lr = 0.001
I0518 07:05:10.640661  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6133	1.04167	76.4196	0	86.5787	4.42708	83.3813	0	78.6357	0	75.5097	0	66.1571	0	25.4291	1.9	
I0518 07:05:10.715247  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:05:10.717234  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:05:10.717284  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:05:10.727375  4008 solver.cpp:260]     Total regularization terms: 1.08926 loss+regular. : 2.42316
I0518 07:06:40.189039  4008 solver.cpp:348] Iteration 155000, Testing net (#0)
I0518 07:06:49.852047  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:08:16.683260  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55392
I0518 07:08:16.683542  4008 solver.cpp:415]     Test net output #1: loss = 1.91932 (* 1 = 1.91932 loss)
I0518 07:08:16.771975  4008 solver.cpp:231] Iteration 155000, loss = 1.54684
I0518 07:08:16.772068  4008 solver.cpp:247]     Train net output #0: loss = 1.54684 (* 1 = 1.54684 loss)
I0518 07:08:16.772090  4008 sgd_solver.cpp:106] Iteration 155000, lr = 0.001
I0518 07:08:16.937921  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6822	1.04167	76.4893	0	86.6111	4.42708	83.4055	0	78.6612	0	75.5347	0	66.1847	0	25.4379	1.9	
I0518 07:08:17.012436  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:08:17.014655  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:08:17.014717  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:08:17.024672  4008 solver.cpp:260]     Total regularization terms: 1.08891 loss+regular. : 2.63575
I0518 07:09:06.198266  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:09:51.009546  4008 solver.cpp:231] Iteration 155200, loss = 1.3484
I0518 07:09:51.009817  4008 solver.cpp:247]     Train net output #0: loss = 1.3484 (* 1 = 1.3484 loss)
I0518 07:09:51.009838  4008 sgd_solver.cpp:106] Iteration 155200, lr = 0.001
I0518 07:09:51.170425  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8314	1.04167	76.6175	0	86.6309	4.42708	83.423	0	78.6861	0	75.5608	0	66.2121	0	25.4478	1.9	
I0518 07:09:51.245086  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:09:51.247372  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:09:51.247427  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:09:51.262712  4008 solver.cpp:260]     Total regularization terms: 1.08854 loss+regular. : 2.43694
I0518 07:11:17.443253  4008 solver.cpp:231] Iteration 155400, loss = 1.39645
I0518 07:11:17.443604  4008 solver.cpp:247]     Train net output #0: loss = 1.39645 (* 1 = 1.39645 loss)
I0518 07:11:17.443636  4008 sgd_solver.cpp:106] Iteration 155400, lr = 0.001
I0518 07:11:17.603819  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7855	1.04167	76.4844	0	86.5815	4.42708	83.4316	0	78.6863	0	75.5862	0	66.2401	0	25.4575	1.9	
I0518 07:11:17.678496  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:11:17.680451  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:11:17.680496  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:11:17.690925  4008 solver.cpp:260]     Total regularization terms: 1.08824 loss+regular. : 2.4847
I0518 07:12:44.594668  4008 solver.cpp:231] Iteration 155600, loss = 1.35908
I0518 07:12:44.595093  4008 solver.cpp:247]     Train net output #0: loss = 1.35908 (* 1 = 1.35908 loss)
I0518 07:12:44.595124  4008 sgd_solver.cpp:106] Iteration 155600, lr = 0.001
I0518 07:12:44.754043  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.817	1.04167	76.2965	0	86.6239	4.42708	83.4343	0	78.7017	0	75.6113	0	66.2678	0	25.4666	1.9	
I0518 07:12:44.829056  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:12:44.831887  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	1.04167	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:12:44.831949  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:12:44.842129  4008 solver.cpp:260]     Total regularization terms: 1.08797 loss+regular. : 2.44705
I0518 07:14:08.738370  4008 solver.cpp:231] Iteration 155800, loss = 1.39726
I0518 07:14:08.738728  4008 solver.cpp:247]     Train net output #0: loss = 1.39726 (* 1 = 1.39726 loss)
I0518 07:14:08.738750  4008 sgd_solver.cpp:106] Iteration 155800, lr = 0.001
I0518 07:14:08.898248  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8457	2.08333	76.2295	0	86.6314	4.42708	83.4559	0	78.6978	0	75.6368	0	66.2956	0	25.4761	1.9	
I0518 07:14:08.973165  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:14:08.975811  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:14:08.975868  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:14:08.985837  4008 solver.cpp:260]     Total regularization terms: 1.0876 loss+regular. : 2.48486
I0518 07:15:35.206817  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_156000.caffemodel
I0518 07:18:28.172853  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_156000.solverstate
I0518 07:18:28.861304  4008 solver.cpp:348] Iteration 156000, Testing net (#0)
I0518 07:18:37.560269  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:19:52.410991  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5547
I0518 07:19:52.411403  4008 solver.cpp:415]     Test net output #1: loss = 1.91226 (* 1 = 1.91226 loss)
I0518 07:19:52.498766  4008 solver.cpp:231] Iteration 156000, loss = 1.49263
I0518 07:19:52.498859  4008 solver.cpp:247]     Train net output #0: loss = 1.49263 (* 1 = 1.49263 loss)
I0518 07:19:52.498878  4008 sgd_solver.cpp:106] Iteration 156000, lr = 0.001
I0518 07:19:52.665645  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5588	2.08333	76.4704	0	86.6573	4.42708	83.4757	0	78.7245	0	75.6621	0	66.323	0	25.4852	1.9	
I0518 07:19:52.666745  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:19:52.668454  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:19:52.668493  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:19:52.678221  4008 solver.cpp:260]     Total regularization terms: 1.08728 loss+regular. : 2.5799
I0518 07:20:39.681187  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:21:24.009111  4008 solver.cpp:231] Iteration 156200, loss = 1.4269
I0518 07:21:24.009430  4008 solver.cpp:247]     Train net output #0: loss = 1.4269 (* 1 = 1.4269 loss)
I0518 07:21:24.009452  4008 sgd_solver.cpp:106] Iteration 156200, lr = 0.001
I0518 07:21:24.169160  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8601	2.08333	76.5303	0	86.6549	4.42708	83.4711	0	78.7387	0	75.6875	0	66.3509	0	25.4943	1.9	
I0518 07:21:24.243690  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:21:24.245527  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:21:24.245589  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:21:24.255432  4008 solver.cpp:260]     Total regularization terms: 1.08696 loss+regular. : 2.51386
I0518 07:22:48.985190  4008 solver.cpp:231] Iteration 156400, loss = 1.48264
I0518 07:22:48.985817  4008 solver.cpp:247]     Train net output #0: loss = 1.48264 (* 1 = 1.48264 loss)
I0518 07:22:48.985849  4008 sgd_solver.cpp:106] Iteration 156400, lr = 0.001
I0518 07:22:49.145177  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6219	2.08333	76.5036	0	86.6423	4.42708	83.4946	0	78.7453	0	75.7129	0	66.3792	0	25.5033	1.9	
I0518 07:22:49.223649  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:22:49.225303  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:22:49.225355  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:22:49.246332  4008 solver.cpp:260]     Total regularization terms: 1.08662 loss+regular. : 2.56927
I0518 07:24:09.010551  4008 solver.cpp:231] Iteration 156600, loss = 1.3058
I0518 07:24:09.010797  4008 solver.cpp:247]     Train net output #0: loss = 1.3058 (* 1 = 1.3058 loss)
I0518 07:24:09.010818  4008 sgd_solver.cpp:106] Iteration 156600, lr = 0.001
I0518 07:24:09.173223  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5616	2.08333	76.6921	0	86.7035	4.42708	83.5279	0	78.7806	0	75.7378	0	66.4068	0	25.5132	1.9	
I0518 07:24:09.248759  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:24:09.250586  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:24:09.250639  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:24:09.270212  4008 solver.cpp:260]     Total regularization terms: 1.08631 loss+regular. : 2.3921
I0518 07:25:35.837565  4008 solver.cpp:231] Iteration 156800, loss = 1.46995
I0518 07:25:35.838001  4008 solver.cpp:247]     Train net output #0: loss = 1.46995 (* 1 = 1.46995 loss)
I0518 07:25:35.838023  4008 sgd_solver.cpp:106] Iteration 156800, lr = 0.001
I0518 07:25:35.997792  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7539	2.08333	76.637	0	86.6846	4.42708	83.5412	0	78.7923	0	75.7631	0	66.4339	0	25.5231	1.9	
I0518 07:25:36.071971  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:25:36.073640  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:25:36.073689  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:25:36.083593  4008 solver.cpp:260]     Total regularization terms: 1.08603 loss+regular. : 2.55598
I0518 07:27:02.022609  4008 solver.cpp:348] Iteration 157000, Testing net (#0)
I0518 07:27:10.824434  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:28:20.124507  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55314
I0518 07:28:20.124794  4008 solver.cpp:415]     Test net output #1: loss = 1.92024 (* 1 = 1.92024 loss)
I0518 07:28:20.215663  4008 solver.cpp:231] Iteration 157000, loss = 1.65614
I0518 07:28:20.215754  4008 solver.cpp:247]     Train net output #0: loss = 1.65614 (* 1 = 1.65614 loss)
I0518 07:28:20.215775  4008 sgd_solver.cpp:106] Iteration 157000, lr = 0.001
I0518 07:28:20.376763  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6707	2.08333	76.6419	0	86.7063	4.42708	83.5419	0	78.8161	0	75.7879	0	66.4612	0	25.5322	1.9	
I0518 07:28:20.451618  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:28:20.453825  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:28:20.453869  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:28:20.468837  4008 solver.cpp:260]     Total regularization terms: 1.08568 loss+regular. : 2.74182
I0518 07:29:14.861488  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:29:47.953598  4008 solver.cpp:231] Iteration 157200, loss = 1.38283
I0518 07:29:47.953922  4008 solver.cpp:247]     Train net output #0: loss = 1.38283 (* 1 = 1.38283 loss)
I0518 07:29:47.953960  4008 sgd_solver.cpp:106] Iteration 157200, lr = 0.001
I0518 07:29:48.115145  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7625	2.08333	76.7923	0	86.7314	4.42708	83.5642	0	78.8228	0	75.8125	0	66.4885	0	25.5416	1.9	
I0518 07:29:48.190623  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:29:48.191929  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:29:48.191970  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:29:48.201858  4008 solver.cpp:260]     Total regularization terms: 1.08534 loss+regular. : 2.46817
I0518 07:31:20.545730  4008 solver.cpp:231] Iteration 157400, loss = 1.41306
I0518 07:31:20.546386  4008 solver.cpp:247]     Train net output #0: loss = 1.41306 (* 1 = 1.41306 loss)
I0518 07:31:20.546409  4008 sgd_solver.cpp:106] Iteration 157400, lr = 0.001
I0518 07:31:20.705796  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8113	2.08333	76.4896	0	86.7088	4.42708	83.5418	0	78.8371	0	75.8375	0	66.5151	0	25.5501	1.9	
I0518 07:31:20.780475  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:31:20.782299  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:31:20.782348  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:31:20.792214  4008 solver.cpp:260]     Total regularization terms: 1.08504 loss+regular. : 2.49811
I0518 07:32:53.633203  4008 solver.cpp:231] Iteration 157600, loss = 1.35766
I0518 07:32:53.633520  4008 solver.cpp:247]     Train net output #0: loss = 1.35766 (* 1 = 1.35766 loss)
I0518 07:32:53.633544  4008 sgd_solver.cpp:106] Iteration 157600, lr = 0.001
I0518 07:32:53.792683  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7855	2.08333	76.7035	0	86.7597	4.42708	83.587	0	78.8545	0	75.8622	0	66.5432	0	25.5593	1.9	
I0518 07:32:53.867532  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:32:53.870146  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:32:53.870199  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:32:53.880260  4008 solver.cpp:260]     Total regularization terms: 1.08468 loss+regular. : 2.44234
I0518 07:34:27.606266  4008 solver.cpp:231] Iteration 157800, loss = 1.46573
I0518 07:34:27.606770  4008 solver.cpp:247]     Train net output #0: loss = 1.46573 (* 1 = 1.46573 loss)
I0518 07:34:27.606789  4008 sgd_solver.cpp:106] Iteration 157800, lr = 0.001
I0518 07:34:27.766782  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8371	2.08333	76.835	0	86.7524	4.42708	83.5992	0	78.861	0	75.8869	0	66.5715	0	25.5679	1.9	
I0518 07:34:27.841943  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:34:27.843690  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:34:27.843729  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:34:27.858814  4008 solver.cpp:260]     Total regularization terms: 1.08434 loss+regular. : 2.55007
I0518 07:35:55.182088  4008 solver.cpp:348] Iteration 158000, Testing net (#0)
I0518 07:36:05.016605  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:37:19.363068  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55534
I0518 07:37:19.363358  4008 solver.cpp:415]     Test net output #1: loss = 1.91402 (* 1 = 1.91402 loss)
I0518 07:37:19.450974  4008 solver.cpp:231] Iteration 158000, loss = 1.6252
I0518 07:37:19.451078  4008 solver.cpp:247]     Train net output #0: loss = 1.6252 (* 1 = 1.6252 loss)
I0518 07:37:19.451138  4008 sgd_solver.cpp:106] Iteration 158000, lr = 0.001
I0518 07:37:19.618973  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5272	2.08333	76.6709	0	86.7937	4.42708	83.6225	0	78.8805	0	75.9113	0	66.5991	0	25.5774	1.9	
I0518 07:37:19.696920  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:37:19.698626  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:37:19.698678  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:37:19.708675  4008 solver.cpp:260]     Total regularization terms: 1.08402 loss+regular. : 2.70923
I0518 07:38:08.658139  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:38:40.158112  4008 solver.cpp:231] Iteration 158200, loss = 1.50063
I0518 07:38:40.158372  4008 solver.cpp:247]     Train net output #0: loss = 1.50063 (* 1 = 1.50063 loss)
I0518 07:38:40.158393  4008 sgd_solver.cpp:106] Iteration 158200, lr = 0.001
I0518 07:38:40.318616  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9318	2.08333	76.7028	0	86.7714	4.42708	83.6162	0	78.8947	0	75.9363	0	66.6263	0	25.5869	1.9	
I0518 07:38:40.392784  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:38:40.394412  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:38:40.394475  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:38:40.404419  4008 solver.cpp:260]     Total regularization terms: 1.08372 loss+regular. : 2.58435
I0518 07:40:11.300185  4008 solver.cpp:231] Iteration 158400, loss = 1.50472
I0518 07:40:11.300539  4008 solver.cpp:247]     Train net output #0: loss = 1.50472 (* 1 = 1.50472 loss)
I0518 07:40:11.300559  4008 sgd_solver.cpp:106] Iteration 158400, lr = 0.001
I0518 07:40:11.460140  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6449	2.08333	76.6758	0	86.7584	4.42708	83.6373	0	78.9198	0	75.9613	0	66.6534	0	25.5947	1.9	
I0518 07:40:11.534437  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:40:11.536523  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:40:11.536571  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:40:11.546344  4008 solver.cpp:260]     Total regularization terms: 1.08345 loss+regular. : 2.58817
I0518 07:41:39.199800  4008 solver.cpp:231] Iteration 158600, loss = 1.45614
I0518 07:41:39.200805  4008 solver.cpp:247]     Train net output #0: loss = 1.45614 (* 1 = 1.45614 loss)
I0518 07:41:39.200831  4008 sgd_solver.cpp:106] Iteration 158600, lr = 0.001
I0518 07:41:39.361246  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9031	2.08333	76.793	0	86.7833	4.42708	83.653	0	78.9438	0	75.986	0	66.6799	0	25.6039	1.9	
I0518 07:41:39.440297  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:41:39.441851  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:41:39.441898  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:41:39.463183  4008 solver.cpp:260]     Total regularization terms: 1.08312 loss+regular. : 2.53926
I0518 07:43:02.457602  4008 solver.cpp:231] Iteration 158800, loss = 1.43939
I0518 07:43:02.457933  4008 solver.cpp:247]     Train net output #0: loss = 1.43939 (* 1 = 1.43939 loss)
I0518 07:43:02.457955  4008 sgd_solver.cpp:106] Iteration 158800, lr = 0.001
I0518 07:43:02.616252  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8314	2.08333	76.5967	0	86.8222	4.42708	83.6668	0	78.9445	0	76.0102	0	66.7072	0	25.6135	1.9	
I0518 07:43:02.690521  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:43:02.692054  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:43:02.692132  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:43:02.701982  4008 solver.cpp:260]     Total regularization terms: 1.08285 loss+regular. : 2.52224
I0518 07:44:33.841219  4008 solver.cpp:348] Iteration 159000, Testing net (#0)
I0518 07:44:45.922616  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:45:57.524132  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55336
I0518 07:45:57.524447  4008 solver.cpp:415]     Test net output #1: loss = 1.91983 (* 1 = 1.91983 loss)
I0518 07:45:57.611979  4008 solver.cpp:231] Iteration 159000, loss = 1.32537
I0518 07:45:57.612057  4008 solver.cpp:247]     Train net output #0: loss = 1.32537 (* 1 = 1.32537 loss)
I0518 07:45:57.612074  4008 sgd_solver.cpp:106] Iteration 159000, lr = 0.001
I0518 07:45:57.777237  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9031	2.08333	76.6839	0	86.8443	4.42708	83.6765	0	78.9804	0	76.0346	0	66.7348	0	25.6225	1.9	
I0518 07:45:57.852063  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:45:57.854051  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.390625	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:45:57.854106  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:45:57.864053  4008 solver.cpp:260]     Total regularization terms: 1.08251 loss+regular. : 2.40789
I0518 07:46:52.932189  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:47:21.521245  4008 solver.cpp:231] Iteration 159200, loss = 1.16567
I0518 07:47:21.521345  4008 solver.cpp:247]     Train net output #0: loss = 1.16567 (* 1 = 1.16567 loss)
I0518 07:47:21.521368  4008 sgd_solver.cpp:106] Iteration 159200, lr = 0.001
I0518 07:47:21.682328  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7596	2.08333	76.488	0	86.8536	4.42708	83.6949	0	78.9802	0	76.059	0	66.7613	0	25.6317	1.9	
I0518 07:47:21.756418  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:47:21.758173  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:47:21.758222  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:47:21.768461  4008 solver.cpp:260]     Total regularization terms: 1.08223 loss+regular. : 2.2479
I0518 07:48:45.887014  4008 solver.cpp:231] Iteration 159400, loss = 1.33289
I0518 07:48:45.887291  4008 solver.cpp:247]     Train net output #0: loss = 1.33289 (* 1 = 1.33289 loss)
I0518 07:48:45.887311  4008 sgd_solver.cpp:106] Iteration 159400, lr = 0.001
I0518 07:48:46.046524  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.642	2.08333	76.7207	0	86.854	4.42708	83.7229	0	79.0001	0	76.0836	0	66.7878	0	25.6407	1.9	
I0518 07:48:46.120761  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:48:46.122483  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:48:46.122535  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:48:46.132557  4008 solver.cpp:260]     Total regularization terms: 1.08194 loss+regular. : 2.41483
I0518 07:50:18.211195  4008 solver.cpp:231] Iteration 159600, loss = 1.24103
I0518 07:50:18.211493  4008 solver.cpp:247]     Train net output #0: loss = 1.24103 (* 1 = 1.24103 loss)
I0518 07:50:18.211515  4008 sgd_solver.cpp:106] Iteration 159600, lr = 0.001
I0518 07:50:18.371707  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7367	2.08333	76.6999	0	86.8629	4.42708	83.7247	0	79.0193	0	76.1074	0	66.8148	0	25.6496	1.9	
I0518 07:50:18.446395  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:50:18.448673  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:50:18.448719  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:50:18.460299  4008 solver.cpp:260]     Total regularization terms: 1.08155 loss+regular. : 2.32258
I0518 07:51:51.657009  4008 solver.cpp:231] Iteration 159800, loss = 1.4364
I0518 07:51:51.657549  4008 solver.cpp:247]     Train net output #0: loss = 1.4364 (* 1 = 1.4364 loss)
I0518 07:51:51.657594  4008 sgd_solver.cpp:106] Iteration 159800, lr = 0.001
I0518 07:51:51.818821  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3694	2.08333	76.7689	0	86.8729	4.42708	83.7285	0	79.0116	0	76.1312	0	66.8415	0	25.659	1.9	
I0518 07:51:51.894096  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:51:51.896809  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:51:51.896857  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:51:51.906911  4008 solver.cpp:260]     Total regularization terms: 1.08128 loss+regular. : 2.51768
I0518 07:53:17.124392  4008 solver.cpp:348] Iteration 160000, Testing net (#0)
I0518 07:53:28.914995  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:54:45.482470  4008 solver.cpp:415]     Test net output #0: accuracy = 0.548519
I0518 07:54:45.482744  4008 solver.cpp:415]     Test net output #1: loss = 1.94598 (* 1 = 1.94598 loss)
I0518 07:54:45.583374  4008 solver.cpp:231] Iteration 160000, loss = 1.36924
I0518 07:54:45.583457  4008 solver.cpp:247]     Train net output #0: loss = 1.36924 (* 1 = 1.36924 loss)
I0518 07:54:45.583482  4008 sgd_solver.cpp:106] Iteration 160000, lr = 0.001
I0518 07:54:45.743876  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9261	2.08333	76.7952	0	86.887	4.42708	83.7356	0	79.0265	0	76.155	0	66.8692	0	25.6681	1.9	
I0518 07:54:45.818568  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:54:45.820592  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:54:45.820642  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:54:45.835180  4008 solver.cpp:260]     Total regularization terms: 1.08095 loss+regular. : 2.45019
I0518 07:55:41.267855  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 07:56:06.316110  4008 solver.cpp:231] Iteration 160200, loss = 1.37073
I0518 07:56:06.316268  4008 solver.cpp:247]     Train net output #0: loss = 1.37073 (* 1 = 1.37073 loss)
I0518 07:56:06.316296  4008 sgd_solver.cpp:106] Iteration 160200, lr = 0.001
I0518 07:56:06.476295  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8486	2.08333	76.7484	0	86.8839	4.42708	83.752	0	79.0636	0	76.1792	0	66.8962	0	25.6768	1.9	
I0518 07:56:06.550834  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:56:06.552119  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:56:06.552158  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:56:06.562036  4008 solver.cpp:260]     Total regularization terms: 1.08065 loss+regular. : 2.45137
I0518 07:57:34.388028  4008 solver.cpp:231] Iteration 160400, loss = 1.39239
I0518 07:57:34.388351  4008 solver.cpp:247]     Train net output #0: loss = 1.39239 (* 1 = 1.39239 loss)
I0518 07:57:34.388391  4008 sgd_solver.cpp:106] Iteration 160400, lr = 0.001
I0518 07:57:34.546545  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1643	2.08333	76.5758	0	86.88	4.42708	83.7405	0	79.0645	0	76.2034	0	66.9239	0	25.6845	1.9	
I0518 07:57:34.621347  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:57:34.623358  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:57:34.623414  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:57:34.633358  4008 solver.cpp:260]     Total regularization terms: 1.0804 loss+regular. : 2.47278
I0518 07:58:56.570631  4008 solver.cpp:231] Iteration 160600, loss = 1.27951
I0518 07:58:56.571023  4008 solver.cpp:247]     Train net output #0: loss = 1.27951 (* 1 = 1.27951 loss)
I0518 07:58:56.571041  4008 sgd_solver.cpp:106] Iteration 160600, lr = 0.001
I0518 07:58:56.731747  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.061	2.08333	76.7158	0	86.9247	4.42708	83.7815	0	79.0891	0	76.2268	0	66.9503	0	25.6935	1.9	
I0518 07:58:56.805930  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 07:58:56.807690  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 07:58:56.807742  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 07:58:56.817651  4008 solver.cpp:260]     Total regularization terms: 1.08009 loss+regular. : 2.3596
I0518 08:00:25.412231  4008 solver.cpp:231] Iteration 160800, loss = 1.42866
I0518 08:00:25.412466  4008 solver.cpp:247]     Train net output #0: loss = 1.42866 (* 1 = 1.42866 loss)
I0518 08:00:25.412485  4008 sgd_solver.cpp:106] Iteration 160800, lr = 0.001
I0518 08:00:25.572466  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0294	2.08333	76.5853	0	86.9199	4.42708	83.7903	0	79.0941	0	76.2506	0	66.9767	0	25.7034	1.9	
I0518 08:00:25.646663  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:00:25.648267  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:00:25.648306  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:00:25.658221  4008 solver.cpp:260]     Total regularization terms: 1.07974 loss+regular. : 2.5084
I0518 08:01:49.367105  4008 solver.cpp:348] Iteration 161000, Testing net (#0)
I0518 08:02:02.830829  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:03:13.446679  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55262
I0518 08:03:13.447093  4008 solver.cpp:415]     Test net output #1: loss = 1.91637 (* 1 = 1.91637 loss)
I0518 08:03:13.535598  4008 solver.cpp:231] Iteration 161000, loss = 1.46793
I0518 08:03:13.535719  4008 solver.cpp:247]     Train net output #0: loss = 1.46793 (* 1 = 1.46793 loss)
I0518 08:03:13.535747  4008 sgd_solver.cpp:106] Iteration 161000, lr = 0.001
I0518 08:03:13.701570  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0638	2.08333	76.7539	0	86.9463	4.42708	83.8175	0	79.1135	0	76.2746	0	67.003	0	25.7114	1.9	
I0518 08:03:13.776203  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:03:13.778038  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:03:13.778102  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:03:13.788223  4008 solver.cpp:260]     Total regularization terms: 1.07948 loss+regular. : 2.54741
I0518 08:04:19.016351  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:04:44.541270  4008 solver.cpp:231] Iteration 161200, loss = 1.4152
I0518 08:04:44.541370  4008 solver.cpp:247]     Train net output #0: loss = 1.4152 (* 1 = 1.4152 loss)
I0518 08:04:44.541389  4008 sgd_solver.cpp:106] Iteration 161200, lr = 0.001
I0518 08:04:44.701563  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.104	2.08333	76.9027	0	86.954	4.42708	83.8352	0	79.1366	0	76.2986	0	67.0304	0	25.7208	1.9	
I0518 08:04:44.775935  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:04:44.777792  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:04:44.777834  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:04:44.807523  4008 solver.cpp:260]     Total regularization terms: 1.07913 loss+regular. : 2.49433
I0518 08:06:06.462946  4008 solver.cpp:231] Iteration 161400, loss = 1.38931
I0518 08:06:06.463366  4008 solver.cpp:247]     Train net output #0: loss = 1.38931 (* 1 = 1.38931 loss)
I0518 08:06:06.463384  4008 sgd_solver.cpp:106] Iteration 161400, lr = 0.001
I0518 08:06:06.622573  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9261	2.08333	76.9759	0	86.9233	4.42708	83.8185	0	79.0866	0	76.3225	0	67.057	0	25.7308	1.9	
I0518 08:06:06.697793  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:06:06.699535  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:06:06.699596  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:06:06.719785  4008 solver.cpp:260]     Total regularization terms: 1.07887 loss+regular. : 2.46817
I0518 08:07:30.804425  4008 solver.cpp:231] Iteration 161600, loss = 1.32016
I0518 08:07:30.804838  4008 solver.cpp:247]     Train net output #0: loss = 1.32016 (* 1 = 1.32016 loss)
I0518 08:07:30.804863  4008 sgd_solver.cpp:106] Iteration 161600, lr = 0.001
I0518 08:07:30.964596  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8027	2.08333	76.9287	0	86.9622	4.42708	83.8643	0	79.1402	0	76.346	0	67.0833	0	25.7396	1.9	
I0518 08:07:31.038981  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:07:31.040467  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:07:31.040511  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:07:31.050564  4008 solver.cpp:260]     Total regularization terms: 1.07855 loss+regular. : 2.39871
I0518 08:08:58.610304  4008 solver.cpp:231] Iteration 161800, loss = 1.40602
I0518 08:08:58.618688  4008 solver.cpp:247]     Train net output #0: loss = 1.40602 (* 1 = 1.40602 loss)
I0518 08:08:58.618722  4008 sgd_solver.cpp:106] Iteration 161800, lr = 0.001
I0518 08:08:58.770493  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8859	2.08333	76.8496	0	86.9526	4.42708	83.8667	0	79.1698	0	76.3694	0	67.1102	0	25.748	1.9	
I0518 08:08:58.845582  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:08:58.847358  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:08:58.847404  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:08:58.857411  4008 solver.cpp:260]     Total regularization terms: 1.07823 loss+regular. : 2.48425
I0518 08:10:26.287144  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_162000.caffemodel
I0518 08:14:27.432096  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_162000.solverstate
I0518 08:14:27.956511  4008 solver.cpp:348] Iteration 162000, Testing net (#0)
I0518 08:14:40.488272  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:15:55.148278  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55166
I0518 08:15:55.148664  4008 solver.cpp:415]     Test net output #1: loss = 1.93005 (* 1 = 1.93005 loss)
I0518 08:15:55.238472  4008 solver.cpp:231] Iteration 162000, loss = 1.53514
I0518 08:15:55.238557  4008 solver.cpp:247]     Train net output #0: loss = 1.53514 (* 1 = 1.53514 loss)
I0518 08:15:55.238576  4008 sgd_solver.cpp:106] Iteration 162000, lr = 0.001
I0518 08:15:55.405256  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9892	2.08333	76.8421	0	86.9568	4.42708	83.8442	0	79.1825	0	76.3932	0	67.1369	0	25.757	1.9	
I0518 08:15:55.406553  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:15:55.408483  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:15:55.408535  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:15:55.421928  4008 solver.cpp:260]     Total regularization terms: 1.07792 loss+regular. : 2.61306
I0518 08:17:01.989190  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:17:23.636493  4008 solver.cpp:231] Iteration 162200, loss = 1.33661
I0518 08:17:23.636620  4008 solver.cpp:247]     Train net output #0: loss = 1.33661 (* 1 = 1.33661 loss)
I0518 08:17:23.636642  4008 sgd_solver.cpp:106] Iteration 162200, lr = 0.001
I0518 08:17:23.797497  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9691	2.08333	76.9528	0	86.9648	4.42708	83.8924	0	79.1879	0	76.4169	0	67.1629	0	25.7654	1.9	
I0518 08:17:23.872627  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:17:23.874485  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:17:23.874534  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:17:23.889535  4008 solver.cpp:260]     Total regularization terms: 1.07757 loss+regular. : 2.41419
I0518 08:18:47.873047  4008 solver.cpp:231] Iteration 162400, loss = 1.34919
I0518 08:18:47.873483  4008 solver.cpp:247]     Train net output #0: loss = 1.34919 (* 1 = 1.34919 loss)
I0518 08:18:47.873525  4008 sgd_solver.cpp:106] Iteration 162400, lr = 0.001
I0518 08:18:48.034247  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5243	2.08333	76.9173	0	86.9685	4.42708	83.8775	0	79.2105	0	76.4406	0	67.1895	0	25.7732	1.9	
I0518 08:18:48.108516  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:18:48.110522  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:18:48.110569  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:18:48.120434  4008 solver.cpp:260]     Total regularization terms: 1.07737 loss+regular. : 2.42657
I0518 08:20:17.705159  4008 solver.cpp:231] Iteration 162600, loss = 1.34365
I0518 08:20:17.705483  4008 solver.cpp:247]     Train net output #0: loss = 1.34365 (* 1 = 1.34365 loss)
I0518 08:20:17.705503  4008 sgd_solver.cpp:106] Iteration 162600, lr = 0.001
I0518 08:20:17.865836  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8572	2.08333	76.957	0	87.0067	4.42708	83.9107	0	79.2248	0	76.464	0	67.2157	0	25.7828	1.9	
I0518 08:20:17.939970  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:20:17.941648  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:20:17.941686  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:20:17.951378  4008 solver.cpp:260]     Total regularization terms: 1.07699 loss+regular. : 2.42064
I0518 08:21:47.288255  4008 solver.cpp:231] Iteration 162800, loss = 1.3538
I0518 08:21:47.288557  4008 solver.cpp:247]     Train net output #0: loss = 1.3538 (* 1 = 1.3538 loss)
I0518 08:21:47.288575  4008 sgd_solver.cpp:106] Iteration 162800, lr = 0.001
I0518 08:21:47.449745  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8744	2.08333	76.7451	0	87.001	4.42708	83.9178	0	79.246	0	76.4871	0	67.2416	0	25.7912	1.9	
I0518 08:21:47.523883  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:21:47.525369  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:21:47.525411  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:21:47.535266  4008 solver.cpp:260]     Total regularization terms: 1.07668 loss+regular. : 2.43048
I0518 08:23:20.649844  4008 solver.cpp:348] Iteration 163000, Testing net (#0)
I0518 08:23:35.139746  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:24:44.832362  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55384
I0518 08:24:44.832661  4008 solver.cpp:415]     Test net output #1: loss = 1.91 (* 1 = 1.91 loss)
I0518 08:24:44.921331  4008 solver.cpp:231] Iteration 163000, loss = 1.52865
I0518 08:24:44.921442  4008 solver.cpp:247]     Train net output #0: loss = 1.52865 (* 1 = 1.52865 loss)
I0518 08:24:44.921468  4008 sgd_solver.cpp:106] Iteration 163000, lr = 0.001
I0518 08:24:45.087148  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8744	2.08333	76.986	0	87.0207	4.42708	83.9298	0	79.2499	0	76.5102	0	67.2684	0	25.8002	1.9	
I0518 08:24:45.161891  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:24:45.163873  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:24:45.163923  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:24:45.173954  4008 solver.cpp:260]     Total regularization terms: 1.07633 loss+regular. : 2.60498
I0518 08:25:49.666332  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:26:08.732831  4008 solver.cpp:231] Iteration 163200, loss = 1.3114
I0518 08:26:08.732928  4008 solver.cpp:247]     Train net output #0: loss = 1.3114 (* 1 = 1.3114 loss)
I0518 08:26:08.732945  4008 sgd_solver.cpp:106] Iteration 163200, lr = 0.001
I0518 08:26:08.892834  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8658	2.08333	77.1387	0	87.0512	4.42708	83.9654	0	79.2829	0	76.5334	0	67.2937	0	25.8091	1.9	
I0518 08:26:08.967108  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:26:08.969030  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:26:08.969081  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:26:08.978958  4008 solver.cpp:260]     Total regularization terms: 1.07606 loss+regular. : 2.38746
I0518 08:27:39.370442  4008 solver.cpp:231] Iteration 163400, loss = 1.37046
I0518 08:27:39.377663  4008 solver.cpp:247]     Train net output #0: loss = 1.37046 (* 1 = 1.37046 loss)
I0518 08:27:39.377701  4008 sgd_solver.cpp:106] Iteration 163400, lr = 0.001
I0518 08:27:39.528998  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8199	2.08333	76.8584	0	87.037	4.42708	83.9594	0	79.2765	0	76.5562	0	67.3198	0	25.8176	1.9	
I0518 08:27:39.604488  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:27:39.606396  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:27:39.606422  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:27:39.626736  4008 solver.cpp:260]     Total regularization terms: 1.07581 loss+regular. : 2.44627
I0518 08:29:06.602390  4008 solver.cpp:231] Iteration 163600, loss = 1.49133
I0518 08:29:06.602777  4008 solver.cpp:247]     Train net output #0: loss = 1.49133 (* 1 = 1.49133 loss)
I0518 08:29:06.602804  4008 sgd_solver.cpp:106] Iteration 163600, lr = 0.001
I0518 08:29:06.762395  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9978	2.08333	77.0863	0	87.0492	4.42708	83.9848	0	79.3111	0	76.5791	0	67.3458	0	25.8262	1.9	
I0518 08:29:06.836980  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:29:06.838881  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:29:06.838942  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:29:06.848994  4008 solver.cpp:260]     Total regularization terms: 1.07548 loss+regular. : 2.56681
I0518 08:30:30.089737  4008 solver.cpp:231] Iteration 163800, loss = 1.36102
I0518 08:30:30.090070  4008 solver.cpp:247]     Train net output #0: loss = 1.36102 (* 1 = 1.36102 loss)
I0518 08:30:30.090092  4008 sgd_solver.cpp:106] Iteration 163800, lr = 0.001
I0518 08:30:30.248924  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8716	2.08333	76.8766	0	87.0225	4.42708	83.9931	0	79.3165	0	76.6022	0	67.3716	0	25.8358	1.9	
I0518 08:30:30.323343  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:30:30.325127  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:30:30.325194  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:30:30.336565  4008 solver.cpp:260]     Total regularization terms: 1.07522 loss+regular. : 2.43624
I0518 08:32:14.340623  4008 solver.cpp:348] Iteration 164000, Testing net (#0)
I0518 08:32:27.755354  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:33:37.179332  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55212
I0518 08:33:37.179702  4008 solver.cpp:415]     Test net output #1: loss = 1.92249 (* 1 = 1.92249 loss)
I0518 08:33:37.266656  4008 solver.cpp:231] Iteration 164000, loss = 1.48822
I0518 08:33:37.266748  4008 solver.cpp:247]     Train net output #0: loss = 1.48822 (* 1 = 1.48822 loss)
I0518 08:33:37.266764  4008 sgd_solver.cpp:106] Iteration 164000, lr = 0.001
I0518 08:33:37.427106  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8744	2.08333	76.9027	0	87.0599	4.42708	83.9946	0	79.3269	0	76.6254	0	67.3977	0	25.8447	1.9	
I0518 08:33:37.501296  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:33:37.502619  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:33:37.502653  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:33:37.516103  4008 solver.cpp:260]     Total regularization terms: 1.07493 loss+regular. : 2.56315
I0518 08:34:51.239719  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:35:06.205512  4008 solver.cpp:231] Iteration 164200, loss = 1.40395
I0518 08:35:06.205636  4008 solver.cpp:247]     Train net output #0: loss = 1.40395 (* 1 = 1.40395 loss)
I0518 08:35:06.205670  4008 sgd_solver.cpp:106] Iteration 164200, lr = 0.001
I0518 08:35:06.365902  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8687	2.08333	76.9525	0	87.0537	4.42708	83.9875	0	79.3249	0	76.6482	0	67.4243	0	25.8542	1.9	
I0518 08:35:06.440299  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:35:06.442314  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:35:06.442368  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:35:06.455366  4008 solver.cpp:260]     Total regularization terms: 1.07464 loss+regular. : 2.47859
I0518 08:36:32.359168  4008 solver.cpp:231] Iteration 164400, loss = 1.52946
I0518 08:36:32.359545  4008 solver.cpp:247]     Train net output #0: loss = 1.52946 (* 1 = 1.52946 loss)
I0518 08:36:32.359570  4008 sgd_solver.cpp:106] Iteration 164400, lr = 0.001
I0518 08:36:32.519315  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7022	2.08333	76.9089	0	87.0647	4.42708	84.0074	0	79.3495	0	76.6704	0	67.4509	0	25.8631	1.9	
I0518 08:36:32.593544  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:36:32.595361  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:36:32.595404  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:36:32.605171  4008 solver.cpp:260]     Total regularization terms: 1.07438 loss+regular. : 2.60384
I0518 08:38:12.600041  4008 solver.cpp:231] Iteration 164600, loss = 1.47666
I0518 08:38:12.600548  4008 solver.cpp:247]     Train net output #0: loss = 1.47666 (* 1 = 1.47666 loss)
I0518 08:38:12.600584  4008 sgd_solver.cpp:106] Iteration 164600, lr = 0.001
I0518 08:38:12.759768  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9691	2.08333	77.0898	0	87.0895	4.42708	84.0261	0	79.3672	0	76.6928	0	67.4768	0	25.8717	1.9	
I0518 08:38:12.834447  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:38:12.836307  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:38:12.836350  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:38:12.846344  4008 solver.cpp:260]     Total regularization terms: 1.07402 loss+regular. : 2.55069
I0518 08:39:44.224330  4008 solver.cpp:231] Iteration 164800, loss = 1.45575
I0518 08:39:44.225652  4008 solver.cpp:247]     Train net output #0: loss = 1.45575 (* 1 = 1.45575 loss)
I0518 08:39:44.225682  4008 sgd_solver.cpp:106] Iteration 164800, lr = 0.001
I0518 08:39:44.382902  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5502	2.08333	76.6732	0	87.0964	4.42708	84.0459	0	79.3832	0	76.7158	0	67.5024	0	25.8807	1.9	
I0518 08:39:44.457208  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:39:44.459075  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:39:44.459128  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:39:44.470849  4008 solver.cpp:260]     Total regularization terms: 1.0738 loss+regular. : 2.52956
I0518 08:41:14.151216  4008 solver.cpp:348] Iteration 165000, Testing net (#0)
I0518 08:41:27.977625  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:42:36.146600  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55172
I0518 08:42:36.146919  4008 solver.cpp:415]     Test net output #1: loss = 1.92517 (* 1 = 1.92517 loss)
I0518 08:42:36.236155  4008 solver.cpp:231] Iteration 165000, loss = 1.2322
I0518 08:42:36.236243  4008 solver.cpp:247]     Train net output #0: loss = 1.2322 (* 1 = 1.2322 loss)
I0518 08:42:36.236259  4008 sgd_solver.cpp:106] Iteration 165000, lr = 0.001
I0518 08:42:36.406945  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3866	2.08333	76.9704	0	87.1124	4.42708	84.0404	0	79.3954	0	76.7384	0	67.5284	0	25.8893	1.9	
I0518 08:42:36.481155  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:42:36.483114  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:42:36.483147  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:42:36.495306  4008 solver.cpp:260]     Total regularization terms: 1.07344 loss+regular. : 2.30563
I0518 08:43:45.994748  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:43:56.644132  4008 solver.cpp:231] Iteration 165200, loss = 1.47964
I0518 08:43:56.644246  4008 solver.cpp:247]     Train net output #0: loss = 1.47964 (* 1 = 1.47964 loss)
I0518 08:43:56.644273  4008 sgd_solver.cpp:106] Iteration 165200, lr = 0.001
I0518 08:43:56.803750  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5702	2.08333	77.151	0	87.1383	4.42708	84.0695	0	79.4119	0	76.7616	0	67.5541	0	25.8989	1.9	
I0518 08:43:56.877912  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:43:56.879752  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:43:56.879797  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:43:56.894763  4008 solver.cpp:260]     Total regularization terms: 1.07314 loss+regular. : 2.55278
I0518 08:45:23.490952  4008 solver.cpp:231] Iteration 165400, loss = 1.30094
I0518 08:45:23.493665  4008 solver.cpp:247]     Train net output #0: loss = 1.30094 (* 1 = 1.30094 loss)
I0518 08:45:23.493695  4008 sgd_solver.cpp:106] Iteration 165400, lr = 0.001
I0518 08:45:23.652814  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7568	2.08333	77.0921	0	87.1449	4.42708	84.0856	0	79.4325	0	76.7844	0	67.58	0	25.9073	1.9	
I0518 08:45:23.727071  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:45:23.729027  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:45:23.729080  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:45:23.739068  4008 solver.cpp:260]     Total regularization terms: 1.0729 loss+regular. : 2.37385
I0518 08:46:54.383329  4008 solver.cpp:231] Iteration 165600, loss = 1.45014
I0518 08:46:54.383697  4008 solver.cpp:247]     Train net output #0: loss = 1.45014 (* 1 = 1.45014 loss)
I0518 08:46:54.383718  4008 sgd_solver.cpp:106] Iteration 165600, lr = 0.001
I0518 08:46:54.543154  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.1943	2.08333	76.9505	0	87.1408	4.42708	84.1006	0	79.4411	0	76.8066	0	67.6063	0	25.9164	1.9	
I0518 08:46:54.617791  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:46:54.619702  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:46:54.619804  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:46:54.629710  4008 solver.cpp:260]     Total regularization terms: 1.07262 loss+regular. : 2.52276
I0518 08:48:17.267041  4008 solver.cpp:231] Iteration 165800, loss = 1.5054
I0518 08:48:17.267453  4008 solver.cpp:247]     Train net output #0: loss = 1.5054 (* 1 = 1.5054 loss)
I0518 08:48:17.267474  4008 sgd_solver.cpp:106] Iteration 165800, lr = 0.001
I0518 08:48:17.428001  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5502	2.08333	77.1885	0	87.1581	4.42708	84.0992	0	79.4406	0	76.8297	0	67.6311	0	25.9261	1.9	
I0518 08:48:17.502373  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:48:17.504318  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:48:17.504369  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:48:17.519440  4008 solver.cpp:260]     Total regularization terms: 1.07229 loss+regular. : 2.57768
I0518 08:49:43.342113  4008 solver.cpp:348] Iteration 166000, Testing net (#0)
I0518 08:49:59.015377  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:51:04.355260  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55256
I0518 08:51:04.355715  4008 solver.cpp:415]     Test net output #1: loss = 1.92442 (* 1 = 1.92442 loss)
I0518 08:51:04.448030  4008 solver.cpp:231] Iteration 166000, loss = 1.35765
I0518 08:51:04.448184  4008 solver.cpp:247]     Train net output #0: loss = 1.35765 (* 1 = 1.35765 loss)
I0518 08:51:04.448225  4008 sgd_solver.cpp:106] Iteration 166000, lr = 0.001
I0518 08:51:04.623021  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5932	2.08333	77.0671	0	87.1539	4.42708	84.1295	0	79.4721	0	76.8525	0	67.6566	0	25.9352	1.9	
I0518 08:51:04.723059  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:51:04.726424  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:51:04.726501  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:51:04.736661  4008 solver.cpp:260]     Total regularization terms: 1.07205 loss+regular. : 2.4297
I0518 08:52:23.479733  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:52:31.882650  4008 solver.cpp:231] Iteration 166200, loss = 1.43581
I0518 08:52:31.882863  4008 solver.cpp:247]     Train net output #0: loss = 1.43581 (* 1 = 1.43581 loss)
I0518 08:52:31.882906  4008 sgd_solver.cpp:106] Iteration 166200, lr = 0.001
I0518 08:52:32.041050  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5014	2.08333	77.1214	0	87.1564	4.42708	84.1218	0	79.4829	0	76.8748	0	67.6831	0	25.9432	1.9	
I0518 08:52:32.115348  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:52:32.117130  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:52:32.117175  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:52:32.127002  4008 solver.cpp:260]     Total regularization terms: 1.07174 loss+regular. : 2.50756
I0518 08:53:55.962332  4008 solver.cpp:231] Iteration 166400, loss = 1.34416
I0518 08:53:55.962667  4008 solver.cpp:247]     Train net output #0: loss = 1.34416 (* 1 = 1.34416 loss)
I0518 08:53:55.962694  4008 sgd_solver.cpp:106] Iteration 166400, lr = 0.001
I0518 08:53:56.122470  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7855	2.08333	76.832	0	87.1108	4.42708	84.1122	0	79.4646	0	76.8972	0	67.709	0	25.9525	1.9	
I0518 08:53:56.197345  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:53:56.199210  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:53:56.199266  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:53:56.209290  4008 solver.cpp:260]     Total regularization terms: 1.07158 loss+regular. : 2.41574
I0518 08:55:24.950614  4008 solver.cpp:231] Iteration 166600, loss = 1.67486
I0518 08:55:24.956454  4008 solver.cpp:247]     Train net output #0: loss = 1.67486 (* 1 = 1.67486 loss)
I0518 08:55:24.956522  4008 sgd_solver.cpp:106] Iteration 166600, lr = 0.001
I0518 08:55:25.110493  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8256	2.08333	77.0439	0	87.1605	4.42708	84.128	0	79.4879	0	76.9192	0	67.735	0	25.9619	1.9	
I0518 08:55:25.185338  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:55:25.187924  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:55:25.188004  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:55:25.198259  4008 solver.cpp:260]     Total regularization terms: 1.07129 loss+regular. : 2.74615
I0518 08:56:56.786957  4008 solver.cpp:231] Iteration 166800, loss = 1.48022
I0518 08:56:56.787319  4008 solver.cpp:247]     Train net output #0: loss = 1.48022 (* 1 = 1.48022 loss)
I0518 08:56:56.787343  4008 sgd_solver.cpp:106] Iteration 166800, lr = 0.001
I0518 08:56:56.946256  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6592	2.08333	77.1514	0	87.1761	4.42708	84.1512	0	79.5017	0	76.9416	0	67.7607	0	25.9705	1.9	
I0518 08:56:57.020567  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:56:57.022636  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:56:57.022694  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:56:57.032963  4008 solver.cpp:260]     Total regularization terms: 1.07099 loss+regular. : 2.5512
I0518 08:58:30.423121  4008 solver.cpp:348] Iteration 167000, Testing net (#0)
I0518 08:58:47.648365  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 08:59:54.553434  4008 solver.cpp:415]     Test net output #0: accuracy = 0.555099
I0518 08:59:54.553779  4008 solver.cpp:415]     Test net output #1: loss = 1.92097 (* 1 = 1.92097 loss)
I0518 08:59:54.641624  4008 solver.cpp:231] Iteration 167000, loss = 1.50041
I0518 08:59:54.641754  4008 solver.cpp:247]     Train net output #0: loss = 1.50041 (* 1 = 1.50041 loss)
I0518 08:59:54.641799  4008 sgd_solver.cpp:106] Iteration 167000, lr = 0.001
I0518 08:59:54.808226  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7625	2.08333	76.9932	0	87.1825	4.42708	84.1526	0	79.5039	0	76.9644	0	67.7859	0	25.9791	1.9	
I0518 08:59:54.883446  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 08:59:54.886101  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 08:59:54.886152  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 08:59:54.896232  4008 solver.cpp:260]     Total regularization terms: 1.0707 loss+regular. : 2.57111
I0518 09:01:21.662616  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:01:27.404737  4008 solver.cpp:231] Iteration 167200, loss = 1.17998
I0518 09:01:27.404844  4008 solver.cpp:247]     Train net output #0: loss = 1.17998 (* 1 = 1.17998 loss)
I0518 09:01:27.404866  4008 sgd_solver.cpp:106] Iteration 167200, lr = 0.001
I0518 09:01:27.564815  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9691	2.08333	77.2793	0	87.2268	4.42708	84.1895	0	79.536	0	76.9866	0	67.8107	0	25.9875	1.9	
I0518 09:01:27.639685  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:01:27.642007  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:01:27.642055  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:01:27.655709  4008 solver.cpp:260]     Total regularization terms: 1.07038 loss+regular. : 2.25036
I0518 09:02:54.493682  4008 solver.cpp:231] Iteration 167400, loss = 1.60742
I0518 09:02:54.495164  4008 solver.cpp:247]     Train net output #0: loss = 1.60742 (* 1 = 1.60742 loss)
I0518 09:02:54.495209  4008 sgd_solver.cpp:106] Iteration 167400, lr = 0.001
I0518 09:02:54.654459  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0036	2.08333	77.2614	0	87.2267	4.42708	84.1721	0	79.5268	0	77.0088	0	67.8356	0	25.9967	1.9	
I0518 09:02:54.729163  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:02:54.731503  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:02:54.731556  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:02:54.741542  4008 solver.cpp:260]     Total regularization terms: 1.07016 loss+regular. : 2.67758
I0518 09:04:16.046193  4008 solver.cpp:231] Iteration 167600, loss = 1.30344
I0518 09:04:16.046663  4008 solver.cpp:247]     Train net output #0: loss = 1.30344 (* 1 = 1.30344 loss)
I0518 09:04:16.046720  4008 sgd_solver.cpp:106] Iteration 167600, lr = 0.001
I0518 09:04:16.205809  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8084	2.08333	77.2673	0	87.2407	4.42708	84.202	0	79.5611	0	77.031	0	67.8612	0	26.0062	1.9	
I0518 09:04:16.281354  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:04:16.284628  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:04:16.284699  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:04:16.294862  4008 solver.cpp:260]     Total regularization terms: 1.06988 loss+regular. : 2.37332
I0518 09:05:41.209223  4008 solver.cpp:231] Iteration 167800, loss = 1.34162
I0518 09:05:41.209633  4008 solver.cpp:247]     Train net output #0: loss = 1.34162 (* 1 = 1.34162 loss)
I0518 09:05:41.209668  4008 sgd_solver.cpp:106] Iteration 167800, lr = 0.001
I0518 09:05:41.369027  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0409	2.08333	77.1517	0	87.251	4.42708	84.1951	0	79.5736	0	77.0528	0	67.8865	0	26.0143	1.9	
I0518 09:05:41.443545  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:05:41.445060  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:05:41.445107  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:05:41.455250  4008 solver.cpp:260]     Total regularization terms: 1.06955 loss+regular. : 2.41117
I0518 09:07:15.114215  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_168000.caffemodel
I0518 09:10:23.375730  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_168000.solverstate
I0518 09:10:24.061015  4008 solver.cpp:348] Iteration 168000, Testing net (#0)
I0518 09:10:39.761674  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:11:51.650432  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55414
I0518 09:11:51.650799  4008 solver.cpp:415]     Test net output #1: loss = 1.91339 (* 1 = 1.91339 loss)
I0518 09:11:51.741369  4008 solver.cpp:231] Iteration 168000, loss = 1.31683
I0518 09:11:51.741466  4008 solver.cpp:247]     Train net output #0: loss = 1.31683 (* 1 = 1.31683 loss)
I0518 09:11:51.741492  4008 sgd_solver.cpp:106] Iteration 168000, lr = 0.001
I0518 09:11:51.907671  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7367	2.08333	76.9922	0	87.2726	4.42708	84.1949	0	79.5774	0	77.0751	0	67.912	0	26.0227	1.9	
I0518 09:11:51.909984  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:11:51.913617  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:11:51.913704  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:11:51.925607  4008 solver.cpp:260]     Total regularization terms: 1.06923 loss+regular. : 2.38606
I0518 09:13:12.275651  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:13:15.300716  4008 solver.cpp:231] Iteration 168200, loss = 1.38947
I0518 09:13:15.300886  4008 solver.cpp:247]     Train net output #0: loss = 1.38947 (* 1 = 1.38947 loss)
I0518 09:13:15.300909  4008 sgd_solver.cpp:106] Iteration 168200, lr = 0.001
I0518 09:13:15.462208  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5961	2.08333	77.2451	0	87.285	4.42708	84.2153	0	79.5835	0	77.097	0	67.937	0	26.0319	1.9	
I0518 09:13:15.536597  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:13:15.538811  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:13:15.538885  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:13:15.549111  4008 solver.cpp:260]     Total regularization terms: 1.06896 loss+regular. : 2.45843
I0518 09:14:39.203534  4008 solver.cpp:231] Iteration 168400, loss = 1.45289
I0518 09:14:39.203869  4008 solver.cpp:247]     Train net output #0: loss = 1.45289 (* 1 = 1.45289 loss)
I0518 09:14:39.203899  4008 sgd_solver.cpp:106] Iteration 168400, lr = 0.001
I0518 09:14:39.363155  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5875	2.08333	77.1569	0	87.2863	4.42708	84.2606	0	79.5975	0	77.1185	0	67.962	0	26.0408	1.9	
I0518 09:14:39.438102  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:14:39.440335  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:14:39.440404  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:14:39.450533  4008 solver.cpp:260]     Total regularization terms: 1.06872 loss+regular. : 2.52161
I0518 09:16:09.191925  4008 solver.cpp:231] Iteration 168600, loss = 1.43678
I0518 09:16:09.192176  4008 solver.cpp:247]     Train net output #0: loss = 1.43678 (* 1 = 1.43678 loss)
I0518 09:16:09.192204  4008 sgd_solver.cpp:106] Iteration 168600, lr = 0.001
I0518 09:16:09.351570  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4583	2.08333	77.277	0	87.3099	4.42708	84.2752	0	79.6283	0	77.1408	0	67.9868	0	26.0497	1.9	
I0518 09:16:09.426208  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:16:09.428706  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:16:09.428757  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:16:09.442600  4008 solver.cpp:260]     Total regularization terms: 1.06834 loss+regular. : 2.50512
I0518 09:17:43.268373  4008 solver.cpp:231] Iteration 168800, loss = 1.44509
I0518 09:17:43.268682  4008 solver.cpp:247]     Train net output #0: loss = 1.44509 (* 1 = 1.44509 loss)
I0518 09:17:43.268699  4008 sgd_solver.cpp:106] Iteration 168800, lr = 0.001
I0518 09:17:43.429327  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7338	2.08333	77.3105	0	87.2886	4.42708	84.2596	0	79.6455	0	77.1628	0	68.0119	0	26.0583	1.9	
I0518 09:17:43.503670  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:17:43.505679  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:17:43.505728  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:17:43.515516  4008 solver.cpp:260]     Total regularization terms: 1.0681 loss+regular. : 2.51319
I0518 09:19:10.556839  4008 solver.cpp:348] Iteration 169000, Testing net (#0)
I0518 09:19:25.706919  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:20:38.027180  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55162
I0518 09:20:38.027520  4008 solver.cpp:415]     Test net output #1: loss = 1.92639 (* 1 = 1.92639 loss)
I0518 09:20:38.120275  4008 solver.cpp:231] Iteration 169000, loss = 1.32
I0518 09:20:38.120400  4008 solver.cpp:247]     Train net output #0: loss = 1.32 (* 1 = 1.32 loss)
I0518 09:20:38.120430  4008 sgd_solver.cpp:106] Iteration 169000, lr = 0.001
I0518 09:20:38.286289  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9146	2.08333	77.0645	0	87.3188	4.42708	84.2784	0	79.6644	0	77.1845	0	68.037	0	26.0669	1.9	
I0518 09:20:38.361505  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:20:38.364195  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:20:38.364244  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:20:38.374215  4008 solver.cpp:260]     Total regularization terms: 1.06783 loss+regular. : 2.38783
I0518 09:22:00.497357  4008 solver.cpp:231] Iteration 169200, loss = 1.33414
I0518 09:22:00.497809  4008 solver.cpp:247]     Train net output #0: loss = 1.33414 (* 1 = 1.33414 loss)
I0518 09:22:00.497835  4008 sgd_solver.cpp:106] Iteration 169200, lr = 0.001
I0518 09:22:00.658097  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6908	2.08333	77.2689	0	87.3253	4.42708	84.2951	0	79.6717	0	77.2058	0	68.0622	0	26.0753	1.9	
I0518 09:22:00.733382  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:22:00.736243  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:22:00.736296  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:22:00.746273  4008 solver.cpp:260]     Total regularization terms: 1.06752 loss+regular. : 2.40167
I0518 09:22:01.113299  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:23:27.315701  4008 solver.cpp:231] Iteration 169400, loss = 1.39223
I0518 09:23:27.315984  4008 solver.cpp:247]     Train net output #0: loss = 1.39223 (* 1 = 1.39223 loss)
I0518 09:23:27.316004  4008 sgd_solver.cpp:106] Iteration 169400, lr = 0.001
I0518 09:23:27.477855  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6449	2.08333	77.153	0	87.3273	4.42708	84.2843	0	79.6703	0	77.2277	0	68.0871	0	26.083	1.9	
I0518 09:23:27.552544  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:23:27.554767  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:23:27.554824  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:23:27.570507  4008 solver.cpp:260]     Total regularization terms: 1.06732 loss+regular. : 2.45955
I0518 09:24:58.259871  4008 solver.cpp:231] Iteration 169600, loss = 1.25243
I0518 09:24:58.260246  4008 solver.cpp:247]     Train net output #0: loss = 1.25243 (* 1 = 1.25243 loss)
I0518 09:24:58.260277  4008 sgd_solver.cpp:106] Iteration 169600, lr = 0.001
I0518 09:24:58.419963  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.3292	2.08333	77.2816	0	87.3315	4.42708	84.3064	0	79.6999	0	77.2487	0	68.1112	0	26.091	1.9	
I0518 09:24:58.494249  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:24:58.495625  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:24:58.495668  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:24:58.505700  4008 solver.cpp:260]     Total regularization terms: 1.06707 loss+regular. : 2.3195
I0518 09:26:25.886879  4008 solver.cpp:231] Iteration 169800, loss = 1.36764
I0518 09:26:25.889226  4008 solver.cpp:247]     Train net output #0: loss = 1.36764 (* 1 = 1.36764 loss)
I0518 09:26:25.889257  4008 sgd_solver.cpp:106] Iteration 169800, lr = 0.001
I0518 09:26:26.046874  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.5502	2.08333	77.0853	0	87.3406	4.42708	84.3308	0	79.7097	0	77.2704	0	68.1365	0	26.0991	1.9	
I0518 09:26:26.122102  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:26:26.124735  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:26:26.124800  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:26:26.135431  4008 solver.cpp:260]     Total regularization terms: 1.06685 loss+regular. : 2.43448
I0518 09:27:57.606452  4008 solver.cpp:348] Iteration 170000, Testing net (#0)
I0518 09:28:15.404388  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:29:21.884536  4008 solver.cpp:415]     Test net output #0: accuracy = 0.555659
I0518 09:29:21.884865  4008 solver.cpp:415]     Test net output #1: loss = 1.91106 (* 1 = 1.91106 loss)
I0518 09:29:21.973299  4008 solver.cpp:231] Iteration 170000, loss = 1.45009
I0518 09:29:21.973397  4008 solver.cpp:247]     Train net output #0: loss = 1.45009 (* 1 = 1.45009 loss)
I0518 09:29:21.973424  4008 sgd_solver.cpp:106] Iteration 170000, lr = 0.001
I0518 09:29:22.135347  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8056	2.08333	77.3685	0	87.3368	4.42708	84.3516	0	79.7277	0	77.2917	0	68.1618	0	26.1075	1.9	
I0518 09:29:22.210306  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:29:22.212209  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:29:22.212262  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:29:22.222321  4008 solver.cpp:260]     Total regularization terms: 1.06647 loss+regular. : 2.51656
I0518 09:30:47.177497  4008 solver.cpp:231] Iteration 170200, loss = 1.32982
I0518 09:30:47.177808  4008 solver.cpp:247]     Train net output #0: loss = 1.32982 (* 1 = 1.32982 loss)
I0518 09:30:47.177830  4008 sgd_solver.cpp:106] Iteration 170200, lr = 0.001
I0518 09:30:47.337908  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7596	2.08333	77.291	0	87.3617	4.42708	84.3432	0	79.7537	0	77.3133	0	68.1864	0	26.1166	1.9	
I0518 09:30:47.412642  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:30:47.414448  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:30:47.414504  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:30:47.424455  4008 solver.cpp:260]     Total regularization terms: 1.06617 loss+regular. : 2.396
I0518 09:30:51.091346  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:32:17.983072  4008 solver.cpp:231] Iteration 170400, loss = 1.4499
I0518 09:32:17.983412  4008 solver.cpp:247]     Train net output #0: loss = 1.4499 (* 1 = 1.4499 loss)
I0518 09:32:17.983439  4008 sgd_solver.cpp:106] Iteration 170400, lr = 0.001
I0518 09:32:18.144032  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8744	2.08333	77.2458	0	87.3617	4.42708	84.3488	0	79.7519	0	77.3354	0	68.2105	0	26.1252	1.9	
I0518 09:32:18.219878  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:32:18.222074  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:32:18.222126  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:32:18.232547  4008 solver.cpp:260]     Total regularization terms: 1.06594 loss+regular. : 2.51584
I0518 09:33:48.190511  4008 solver.cpp:231] Iteration 170600, loss = 1.61337
I0518 09:33:48.190878  4008 solver.cpp:247]     Train net output #0: loss = 1.61337 (* 1 = 1.61337 loss)
I0518 09:33:48.190907  4008 sgd_solver.cpp:106] Iteration 170600, lr = 0.001
I0518 09:33:48.349663  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0495	2.08333	77.3167	0	87.3898	4.42708	84.3418	0	79.7723	0	77.3565	0	68.2345	0	26.134	1.9	
I0518 09:33:48.424830  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:33:48.427942  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:33:48.428019  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:33:48.438539  4008 solver.cpp:260]     Total regularization terms: 1.06572 loss+regular. : 2.6791
I0518 09:35:18.898263  4008 solver.cpp:231] Iteration 170800, loss = 1.32027
I0518 09:35:18.898602  4008 solver.cpp:247]     Train net output #0: loss = 1.32027 (* 1 = 1.32027 loss)
I0518 09:35:18.898646  4008 sgd_solver.cpp:106] Iteration 170800, lr = 0.001
I0518 09:35:19.057075  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8687	2.08333	77.2458	0	87.3845	4.42708	84.3851	0	79.7885	0	77.3785	0	68.2594	0	26.1423	1.9	
I0518 09:35:19.131763  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:35:19.134199  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:35:19.134253  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:35:19.144263  4008 solver.cpp:260]     Total regularization terms: 1.06539 loss+regular. : 2.38566
I0518 09:36:46.683117  4008 solver.cpp:348] Iteration 171000, Testing net (#0)
I0518 09:37:05.419415  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:38:07.824225  4008 solver.cpp:415]     Test net output #0: accuracy = 0.554719
I0518 09:38:07.825095  4008 solver.cpp:415]     Test net output #1: loss = 1.9172 (* 1 = 1.9172 loss)
I0518 09:38:07.919176  4008 solver.cpp:231] Iteration 171000, loss = 1.324
I0518 09:38:07.919261  4008 solver.cpp:247]     Train net output #0: loss = 1.324 (* 1 = 1.324 loss)
I0518 09:38:07.919286  4008 sgd_solver.cpp:106] Iteration 171000, lr = 0.001
I0518 09:38:08.083776  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0667	2.08333	77.2279	0	87.3835	4.42708	84.3984	0	79.8008	0	77.3998	0	68.2836	0	26.1508	1.9	
I0518 09:38:08.158404  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:38:08.160167  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:38:08.160204  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:38:08.170140  4008 solver.cpp:260]     Total regularization terms: 1.06514 loss+regular. : 2.38914
I0518 09:39:31.813148  4008 solver.cpp:231] Iteration 171200, loss = 1.36105
I0518 09:39:31.814344  4008 solver.cpp:247]     Train net output #0: loss = 1.36105 (* 1 = 1.36105 loss)
I0518 09:39:31.814401  4008 sgd_solver.cpp:106] Iteration 171200, lr = 0.001
I0518 09:39:31.973819  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8543	2.08333	77.4072	0	87.3933	4.42708	84.4187	0	79.8082	0	77.4213	0	68.3077	0	26.1589	1.9	
I0518 09:39:32.048470  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:39:32.050302  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:39:32.050355  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:39:32.079665  4008 solver.cpp:260]     Total regularization terms: 1.06492 loss+regular. : 2.42596
I0518 09:39:37.509799  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:40:59.080277  4008 solver.cpp:231] Iteration 171400, loss = 1.41971
I0518 09:40:59.080679  4008 solver.cpp:247]     Train net output #0: loss = 1.41971 (* 1 = 1.41971 loss)
I0518 09:40:59.080703  4008 sgd_solver.cpp:106] Iteration 171400, lr = 0.001
I0518 09:40:59.240787  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.4842	2.08333	77.5273	0	87.4133	4.42708	84.4365	0	79.8091	0	77.4425	0	68.3317	0	26.1678	1.9	
I0518 09:40:59.315500  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:40:59.318167  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:40:59.318253  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:40:59.328402  4008 solver.cpp:260]     Total regularization terms: 1.06467 loss+regular. : 2.48438
I0518 09:42:24.658761  4008 solver.cpp:231] Iteration 171600, loss = 1.67572
I0518 09:42:24.659253  4008 solver.cpp:247]     Train net output #0: loss = 1.67572 (* 1 = 1.67572 loss)
I0518 09:42:24.659274  4008 sgd_solver.cpp:106] Iteration 171600, lr = 0.001
I0518 09:42:24.818922  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7883	2.08333	77.3988	0	87.4046	4.42708	84.4559	0	79.8351	0	77.4633	0	68.3567	0	26.1762	1.9	
I0518 09:42:24.893344  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:42:24.895256  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:42:24.895308  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:42:24.906738  4008 solver.cpp:260]     Total regularization terms: 1.06443 loss+regular. : 2.74015
I0518 09:43:47.790395  4008 solver.cpp:231] Iteration 171800, loss = 1.32203
I0518 09:43:47.791812  4008 solver.cpp:247]     Train net output #0: loss = 1.32203 (* 1 = 1.32203 loss)
I0518 09:43:47.791853  4008 sgd_solver.cpp:106] Iteration 171800, lr = 0.001
I0518 09:43:47.950731  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9806	2.08333	77.3486	0	87.4121	4.42708	84.4641	0	79.8417	0	77.4844	0	68.3807	0	26.1859	1.9	
I0518 09:43:48.025477  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:43:48.027549  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:43:48.027632  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:43:48.037825  4008 solver.cpp:260]     Total regularization terms: 1.06414 loss+regular. : 2.38617
I0518 09:45:12.837667  4008 solver.cpp:348] Iteration 172000, Testing net (#0)
I0518 09:45:30.352219  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:46:33.984083  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55358
I0518 09:46:33.985139  4008 solver.cpp:415]     Test net output #1: loss = 1.91971 (* 1 = 1.91971 loss)
I0518 09:46:34.131728  4008 solver.cpp:231] Iteration 172000, loss = 1.33801
I0518 09:46:34.131813  4008 solver.cpp:247]     Train net output #0: loss = 1.33801 (* 1 = 1.33801 loss)
I0518 09:46:34.131829  4008 sgd_solver.cpp:106] Iteration 172000, lr = 0.001
I0518 09:46:34.295373  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7223	2.08333	77.3805	0	87.4061	4.42708	84.4689	0	79.8503	0	77.5054	0	68.4057	0	26.1939	1.9	
I0518 09:46:34.370287  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:46:34.371788  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:46:34.371834  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:46:34.381752  4008 solver.cpp:260]     Total regularization terms: 1.06379 loss+regular. : 2.4018
I0518 09:48:07.012367  4008 solver.cpp:231] Iteration 172200, loss = 1.44057
I0518 09:48:07.012878  4008 solver.cpp:247]     Train net output #0: loss = 1.44057 (* 1 = 1.44057 loss)
I0518 09:48:07.012902  4008 sgd_solver.cpp:106] Iteration 172200, lr = 0.001
I0518 09:48:07.170511  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0122	2.08333	77.3877	0	87.4367	4.42708	84.4862	0	79.8686	0	77.5262	0	68.4297	0	26.2024	1.9	
I0518 09:48:07.245039  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:48:07.247098  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:48:07.247164  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:48:07.257417  4008 solver.cpp:260]     Total regularization terms: 1.06359 loss+regular. : 2.50417
I0518 09:48:18.102216  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:49:32.306371  4008 solver.cpp:231] Iteration 172400, loss = 1.48149
I0518 09:49:32.310771  4008 solver.cpp:247]     Train net output #0: loss = 1.48149 (* 1 = 1.48149 loss)
I0518 09:49:32.310796  4008 sgd_solver.cpp:106] Iteration 172400, lr = 0.001
I0518 09:49:32.468298  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9117	2.08333	77.431	0	87.4068	4.42708	84.4835	0	79.8819	0	77.547	0	68.4538	0	26.2098	1.9	
I0518 09:49:32.542811  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:49:32.544390  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:49:32.544466  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:49:32.554488  4008 solver.cpp:260]     Total regularization terms: 1.06333 loss+regular. : 2.54482
I0518 09:50:58.814106  4008 solver.cpp:231] Iteration 172600, loss = 1.54338
I0518 09:50:58.814504  4008 solver.cpp:247]     Train net output #0: loss = 1.54338 (* 1 = 1.54338 loss)
I0518 09:50:58.814527  4008 sgd_solver.cpp:106] Iteration 172600, lr = 0.001
I0518 09:50:58.974828  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9203	2.08333	77.6436	0	87.4658	4.42708	84.5097	0	79.9034	0	77.5679	0	68.478	0	26.2184	1.9	
I0518 09:50:59.050134  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:50:59.052086  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:50:59.052127  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:50:59.067234  4008 solver.cpp:260]     Total regularization terms: 1.06306 loss+regular. : 2.60644
I0518 09:52:32.446970  4008 solver.cpp:231] Iteration 172800, loss = 1.44189
I0518 09:52:32.447329  4008 solver.cpp:247]     Train net output #0: loss = 1.44189 (* 1 = 1.44189 loss)
I0518 09:52:32.447347  4008 sgd_solver.cpp:106] Iteration 172800, lr = 0.001
I0518 09:52:32.608417  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2905	2.08333	77.3965	0	87.439	4.42708	84.5158	0	79.9007	0	77.5892	0	68.5021	0	26.2266	1.9	
I0518 09:52:32.682803  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:52:32.684622  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:52:32.684684  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:52:32.694694  4008 solver.cpp:260]     Total regularization terms: 1.06281 loss+regular. : 2.5047
I0518 09:53:59.885023  4008 solver.cpp:348] Iteration 173000, Testing net (#0)
I0518 09:54:23.196626  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:55:29.528663  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55418
I0518 09:55:29.529162  4008 solver.cpp:415]     Test net output #1: loss = 1.92081 (* 1 = 1.92081 loss)
I0518 09:55:29.616776  4008 solver.cpp:231] Iteration 173000, loss = 1.48258
I0518 09:55:29.616864  4008 solver.cpp:247]     Train net output #0: loss = 1.48258 (* 1 = 1.48258 loss)
I0518 09:55:29.616883  4008 sgd_solver.cpp:106] Iteration 173000, lr = 0.001
I0518 09:55:29.776854  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7941	2.08333	77.458	0	87.4573	4.42708	84.5221	0	79.9165	0	77.6101	0	68.5257	0	26.2345	1.9	
I0518 09:55:29.854804  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:55:29.857750  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:55:29.857805  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:55:29.867699  4008 solver.cpp:260]     Total regularization terms: 1.06246 loss+regular. : 2.54504
I0518 09:57:06.783706  4008 solver.cpp:231] Iteration 173200, loss = 1.27964
I0518 09:57:06.784003  4008 solver.cpp:247]     Train net output #0: loss = 1.27964 (* 1 = 1.27964 loss)
I0518 09:57:06.784032  4008 sgd_solver.cpp:106] Iteration 173200, lr = 0.001
I0518 09:57:06.944561  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9777	2.08333	77.4023	0	87.4671	4.42708	84.523	0	79.9185	0	77.6314	0	68.5496	0	26.2431	1.9	
I0518 09:57:07.019405  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:57:07.021308  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	1.9	
I0518 09:57:07.021358  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:57:07.031342  4008 solver.cpp:260]     Total regularization terms: 1.06218 loss+regular. : 2.34182
I0518 09:57:18.903045  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 09:58:34.183533  4008 solver.cpp:231] Iteration 173400, loss = 1.44074
I0518 09:58:34.185667  4008 solver.cpp:247]     Train net output #0: loss = 1.44074 (* 1 = 1.44074 loss)
I0518 09:58:34.185701  4008 sgd_solver.cpp:106] Iteration 173400, lr = 0.001
I0518 09:58:34.345423  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1585	2.08333	77.3073	0	87.4764	4.42708	84.5463	0	79.9411	0	77.6526	0	68.5742	0	26.2513	2	
I0518 09:58:34.421223  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 09:58:34.423140  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 09:58:34.423192  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 09:58:34.438487  4008 solver.cpp:260]     Total regularization terms: 1.06196 loss+regular. : 2.5027
I0518 10:00:04.539772  4008 solver.cpp:231] Iteration 173600, loss = 1.33216
I0518 10:00:04.540182  4008 solver.cpp:247]     Train net output #0: loss = 1.33216 (* 1 = 1.33216 loss)
I0518 10:00:04.540310  4008 sgd_solver.cpp:106] Iteration 173600, lr = 0.001
I0518 10:00:04.699959  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1442	2.08333	77.1865	0	87.4892	4.42708	84.57	0	79.9606	0	77.6732	0	68.5982	0	26.2605	2	
I0518 10:00:04.775080  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:00:04.776945  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:00:04.776989  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:00:04.786993  4008 solver.cpp:260]     Total regularization terms: 1.0616 loss+regular. : 2.39376
I0518 10:01:32.269867  4008 solver.cpp:231] Iteration 173800, loss = 1.41398
I0518 10:01:32.270234  4008 solver.cpp:247]     Train net output #0: loss = 1.41398 (* 1 = 1.41398 loss)
I0518 10:01:32.270257  4008 sgd_solver.cpp:106] Iteration 173800, lr = 0.001
I0518 10:01:32.428675  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8945	2.08333	77.2806	0	87.4664	4.42708	84.5539	0	79.9714	0	77.6938	0	68.6219	0	26.2686	2	
I0518 10:01:32.502996  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:01:32.504739  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:01:32.504786  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:01:32.519539  4008 solver.cpp:260]     Total regularization terms: 1.06133 loss+regular. : 2.47531
I0518 10:03:05.345666  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_174000.caffemodel
I0518 10:06:33.059870  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_174000.solverstate
I0518 10:06:33.843037  4008 solver.cpp:348] Iteration 174000, Testing net (#0)
I0518 10:06:51.755414  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:07:49.126998  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55312
I0518 10:07:49.127305  4008 solver.cpp:415]     Test net output #1: loss = 1.92406 (* 1 = 1.92406 loss)
I0518 10:07:49.215302  4008 solver.cpp:231] Iteration 174000, loss = 1.33234
I0518 10:07:49.215384  4008 solver.cpp:247]     Train net output #0: loss = 1.33234 (* 1 = 1.33234 loss)
I0518 10:07:49.215404  4008 sgd_solver.cpp:106] Iteration 174000, lr = 0.001
I0518 10:07:49.381609  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9949	2.08333	77.4004	0	87.5173	4.42708	84.5843	0	79.9436	0	77.715	0	68.6464	0	26.2766	2	
I0518 10:07:49.383098  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:07:49.384910  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:07:49.384955  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:07:49.394870  4008 solver.cpp:260]     Total regularization terms: 1.06107 loss+regular. : 2.39341
I0518 10:09:23.629380  4008 solver.cpp:231] Iteration 174200, loss = 1.33114
I0518 10:09:23.629969  4008 solver.cpp:247]     Train net output #0: loss = 1.33114 (* 1 = 1.33114 loss)
I0518 10:09:23.629993  4008 sgd_solver.cpp:106] Iteration 174200, lr = 0.001
I0518 10:09:23.789046  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0122	2.08333	77.5778	0	87.5162	4.42708	84.5798	0	79.9798	0	77.7358	0	68.6705	0	26.2851	2	
I0518 10:09:23.864104  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:09:23.866753  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:09:23.866821  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:09:23.876833  4008 solver.cpp:260]     Total regularization terms: 1.06077 loss+regular. : 2.39191
I0518 10:09:40.316848  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:10:52.170789  4008 solver.cpp:231] Iteration 174400, loss = 1.47907
I0518 10:10:52.171129  4008 solver.cpp:247]     Train net output #0: loss = 1.47907 (* 1 = 1.47907 loss)
I0518 10:10:52.171154  4008 sgd_solver.cpp:106] Iteration 174400, lr = 0.001
I0518 10:10:52.330029  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9462	2.08333	77.5156	0	87.5302	4.42708	84.5882	0	80.0015	0	77.7567	0	68.694	0	26.2931	2	
I0518 10:10:52.404633  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:10:52.406582  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:10:52.406636  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:10:52.416520  4008 solver.cpp:260]     Total regularization terms: 1.06049 loss+regular. : 2.53955
I0518 10:12:16.869042  4008 solver.cpp:231] Iteration 174600, loss = 1.33586
I0518 10:12:16.869355  4008 solver.cpp:247]     Train net output #0: loss = 1.33586 (* 1 = 1.33586 loss)
I0518 10:12:16.869382  4008 sgd_solver.cpp:106] Iteration 174600, lr = 0.001
I0518 10:12:17.028002  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1327	2.08333	77.5557	0	87.5461	4.42708	84.5961	0	80.0132	0	77.7774	0	68.7178	0	26.3025	2	
I0518 10:12:17.102273  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:12:17.104041  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:12:17.104089  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:12:17.114014  4008 solver.cpp:260]     Total regularization terms: 1.06021 loss+regular. : 2.39607
I0518 10:13:45.283223  4008 solver.cpp:231] Iteration 174800, loss = 1.57876
I0518 10:13:45.283568  4008 solver.cpp:247]     Train net output #0: loss = 1.57876 (* 1 = 1.57876 loss)
I0518 10:13:45.283594  4008 sgd_solver.cpp:106] Iteration 174800, lr = 0.001
I0518 10:13:45.443655  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2676	2.08333	77.4593	0	87.57	4.42708	84.6119	0	80.0277	0	77.7977	0	68.7408	0	26.3106	2	
I0518 10:13:45.518546  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:13:45.521011  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:13:45.521060  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:13:45.530967  4008 solver.cpp:260]     Total regularization terms: 1.05992 loss+regular. : 2.63868
I0518 10:15:14.267668  4008 solver.cpp:348] Iteration 175000, Testing net (#0)
I0518 10:15:35.238049  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:16:40.411685  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55582
I0518 10:16:40.412068  4008 solver.cpp:415]     Test net output #1: loss = 1.90762 (* 1 = 1.90762 loss)
I0518 10:16:40.503629  4008 solver.cpp:231] Iteration 175000, loss = 1.46879
I0518 10:16:40.503748  4008 solver.cpp:247]     Train net output #0: loss = 1.46879 (* 1 = 1.46879 loss)
I0518 10:16:40.503783  4008 sgd_solver.cpp:106] Iteration 175000, lr = 0.001
I0518 10:16:40.664062  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7051	2.08333	77.4714	0	87.5578	4.42708	84.6261	0	80.0304	0	77.8183	0	68.7646	0	26.3197	2	
I0518 10:16:40.743973  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:16:40.746245  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:16:40.746304  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:16:40.760085  4008 solver.cpp:260]     Total regularization terms: 1.0596 loss+regular. : 2.52839
I0518 10:18:07.797333  4008 solver.cpp:231] Iteration 175200, loss = 1.19358
I0518 10:18:07.801673  4008 solver.cpp:247]     Train net output #0: loss = 1.19358 (* 1 = 1.19358 loss)
I0518 10:18:07.801717  4008 sgd_solver.cpp:106] Iteration 175200, lr = 0.001
I0518 10:18:07.955813  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0294	2.08333	77.5075	0	87.5791	4.42708	84.6408	0	80.053	0	77.8391	0	68.7884	0	26.3283	2	
I0518 10:18:08.030248  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:18:08.032871  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:18:08.032917  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:18:08.042785  4008 solver.cpp:260]     Total regularization terms: 1.05935 loss+regular. : 2.25293
I0518 10:18:24.903327  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:19:31.934223  4008 solver.cpp:231] Iteration 175400, loss = 1.35043
I0518 10:19:31.934514  4008 solver.cpp:247]     Train net output #0: loss = 1.35043 (* 1 = 1.35043 loss)
I0518 10:19:31.934532  4008 sgd_solver.cpp:106] Iteration 175400, lr = 0.001
I0518 10:19:32.095543  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9978	2.08333	77.4622	0	87.5613	4.42708	84.631	0	80.0571	0	77.8594	0	68.8122	0	26.3366	2	
I0518 10:19:32.171726  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:19:32.173707  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:19:32.173758  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:19:32.195119  4008 solver.cpp:260]     Total regularization terms: 1.05914 loss+regular. : 2.40957
I0518 10:20:55.169524  4008 solver.cpp:231] Iteration 175600, loss = 1.2793
I0518 10:20:55.173696  4008 solver.cpp:247]     Train net output #0: loss = 1.2793 (* 1 = 1.2793 loss)
I0518 10:20:55.173732  4008 sgd_solver.cpp:106] Iteration 175600, lr = 0.001
I0518 10:20:55.330802  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9175	2.08333	77.1634	0	87.5935	4.42708	84.6344	0	80.0815	0	77.8801	0	68.8362	0	26.3455	2	
I0518 10:20:55.405670  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:20:55.407719  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:20:55.407788  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:20:55.417906  4008 solver.cpp:260]     Total regularization terms: 1.05895 loss+regular. : 2.33825
I0518 10:22:20.817631  4008 solver.cpp:231] Iteration 175800, loss = 1.48816
I0518 10:22:20.817956  4008 solver.cpp:247]     Train net output #0: loss = 1.48816 (* 1 = 1.48816 loss)
I0518 10:22:20.817981  4008 sgd_solver.cpp:106] Iteration 175800, lr = 0.001
I0518 10:22:20.979897  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9978	2.08333	77.2201	0	87.562	4.42708	84.6419	0	80.0738	0	77.9005	0	68.8594	0	26.3534	2	
I0518 10:22:21.054790  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:22:21.056530  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:22:21.056605  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:22:21.066414  4008 solver.cpp:260]     Total regularization terms: 1.05868 loss+regular. : 2.54683
I0518 10:23:55.841441  4008 solver.cpp:348] Iteration 176000, Testing net (#0)
I0518 10:24:18.244320  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:25:27.820760  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5547
I0518 10:25:27.821084  4008 solver.cpp:415]     Test net output #1: loss = 1.91746 (* 1 = 1.91746 loss)
I0518 10:25:27.909482  4008 solver.cpp:231] Iteration 176000, loss = 1.32383
I0518 10:25:27.909592  4008 solver.cpp:247]     Train net output #0: loss = 1.32383 (* 1 = 1.32383 loss)
I0518 10:25:27.909616  4008 sgd_solver.cpp:106] Iteration 176000, lr = 0.001
I0518 10:25:28.076088  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0782	2.08333	77.4398	0	87.6004	4.42708	84.6689	0	80.098	0	77.9212	0	68.8824	0	26.362	2	
I0518 10:25:28.151917  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:25:28.154623  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:25:28.154678  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:25:28.167484  4008 solver.cpp:260]     Total regularization terms: 1.05842 loss+regular. : 2.38225
I0518 10:26:55.087786  4008 solver.cpp:231] Iteration 176200, loss = 1.41025
I0518 10:26:55.088264  4008 solver.cpp:247]     Train net output #0: loss = 1.41025 (* 1 = 1.41025 loss)
I0518 10:26:55.088294  4008 sgd_solver.cpp:106] Iteration 176200, lr = 0.001
I0518 10:26:55.248093  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2016	2.08333	77.4443	0	87.5538	4.42708	84.6781	0	80.1055	0	77.9414	0	68.9064	0	26.3712	2	
I0518 10:26:55.323093  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:26:55.325640  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:26:55.325695  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:26:55.335801  4008 solver.cpp:260]     Total regularization terms: 1.05818 loss+regular. : 2.46843
I0518 10:27:18.282902  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:28:22.683748  4008 solver.cpp:231] Iteration 176400, loss = 1.42798
I0518 10:28:22.684250  4008 solver.cpp:247]     Train net output #0: loss = 1.42798 (* 1 = 1.42798 loss)
I0518 10:28:22.684295  4008 sgd_solver.cpp:106] Iteration 176400, lr = 0.001
I0518 10:28:22.842888  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1155	2.08333	77.667	0	87.5951	4.42708	84.6862	0	80.1222	0	77.962	0	68.9292	0	26.38	2	
I0518 10:28:22.917657  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:28:22.919554  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:28:22.919610  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:28:22.929569  4008 solver.cpp:260]     Total regularization terms: 1.05792 loss+regular. : 2.48591
I0518 10:29:53.117100  4008 solver.cpp:231] Iteration 176600, loss = 1.24144
I0518 10:29:53.117456  4008 solver.cpp:247]     Train net output #0: loss = 1.24144 (* 1 = 1.24144 loss)
I0518 10:29:53.117491  4008 sgd_solver.cpp:106] Iteration 176600, lr = 0.001
I0518 10:29:53.278286  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9749	2.08333	77.6367	0	87.6185	4.42708	84.716	0	80.1315	0	77.9825	0	68.9521	0	26.3884	2	
I0518 10:29:53.353782  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:29:53.355494  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:29:53.355562  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:29:53.371000  4008 solver.cpp:260]     Total regularization terms: 1.05765 loss+regular. : 2.29909
I0518 10:31:17.186041  4008 solver.cpp:231] Iteration 176800, loss = 1.47044
I0518 10:31:17.186522  4008 solver.cpp:247]     Train net output #0: loss = 1.47044 (* 1 = 1.47044 loss)
I0518 10:31:17.186547  4008 sgd_solver.cpp:106] Iteration 176800, lr = 0.001
I0518 10:31:17.345998  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8773	2.08333	77.4027	0	87.6213	4.42708	84.7257	0	80.1496	0	78.0023	0	68.9753	0	26.3967	2	
I0518 10:31:17.420348  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:31:17.422150  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:31:17.422199  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:31:17.432082  4008 solver.cpp:260]     Total regularization terms: 1.05741 loss+regular. : 2.52785
I0518 10:32:41.455808  4008 solver.cpp:348] Iteration 177000, Testing net (#0)
I0518 10:33:02.092944  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:34:09.399668  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55072
I0518 10:34:09.399969  4008 solver.cpp:415]     Test net output #1: loss = 1.93871 (* 1 = 1.93871 loss)
I0518 10:34:09.488054  4008 solver.cpp:231] Iteration 177000, loss = 1.56582
I0518 10:34:09.488157  4008 solver.cpp:247]     Train net output #0: loss = 1.56582 (* 1 = 1.56582 loss)
I0518 10:34:09.488181  4008 sgd_solver.cpp:106] Iteration 177000, lr = 0.001
I0518 10:34:09.647851  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1556	2.08333	77.4671	0	87.6351	4.42708	84.745	0	80.1636	0	78.0226	0	68.9983	0	26.4049	2	
I0518 10:34:09.724171  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:34:09.726147  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:34:09.726199  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:34:09.736106  4008 solver.cpp:260]     Total regularization terms: 1.05716 loss+regular. : 2.62298
I0518 10:35:31.716091  4008 solver.cpp:231] Iteration 177200, loss = 1.4389
I0518 10:35:31.716426  4008 solver.cpp:247]     Train net output #0: loss = 1.4389 (* 1 = 1.4389 loss)
I0518 10:35:31.716456  4008 sgd_solver.cpp:106] Iteration 177200, lr = 0.001
I0518 10:35:31.877650  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1843	2.08333	77.7204	0	87.636	4.42708	84.7701	0	80.1855	0	78.0426	0	69.022	0	26.4128	2	
I0518 10:35:31.952673  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:35:31.954947  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:35:31.955000  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:35:31.965272  4008 solver.cpp:260]     Total regularization terms: 1.05687 loss+regular. : 2.49577
I0518 10:35:56.426746  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:36:57.233379  4008 solver.cpp:231] Iteration 177400, loss = 1.36918
I0518 10:36:57.233752  4008 solver.cpp:247]     Train net output #0: loss = 1.36918 (* 1 = 1.36918 loss)
I0518 10:36:57.233774  4008 sgd_solver.cpp:106] Iteration 177400, lr = 0.001
I0518 10:36:57.393049  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3737	2.08333	77.6471	0	87.6416	4.42708	84.7692	0	80.1959	0	78.0625	0	69.0448	0	26.4207	2	
I0518 10:36:57.467928  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:36:57.470584  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:36:57.470634  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:36:57.480521  4008 solver.cpp:260]     Total regularization terms: 1.05666 loss+regular. : 2.42584
I0518 10:38:22.671639  4008 solver.cpp:231] Iteration 177600, loss = 1.44025
I0518 10:38:22.672137  4008 solver.cpp:247]     Train net output #0: loss = 1.44025 (* 1 = 1.44025 loss)
I0518 10:38:22.672158  4008 sgd_solver.cpp:106] Iteration 177600, lr = 0.001
I0518 10:38:22.831734  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1241	2.08333	77.3805	0	87.6508	4.42708	84.7494	0	80.209	0	78.0827	0	69.0686	0	26.4287	2	
I0518 10:38:22.906139  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:38:22.907737  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:38:22.907786  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:38:22.917851  4008 solver.cpp:260]     Total regularization terms: 1.05642 loss+regular. : 2.49667
I0518 10:39:54.246304  4008 solver.cpp:231] Iteration 177800, loss = 1.35738
I0518 10:39:54.249264  4008 solver.cpp:247]     Train net output #0: loss = 1.35738 (* 1 = 1.35738 loss)
I0518 10:39:54.249295  4008 sgd_solver.cpp:106] Iteration 177800, lr = 0.001
I0518 10:39:54.406882  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9289	2.08333	77.668	0	87.6814	4.42708	84.787	0	80.2303	0	78.1024	0	69.0918	0	26.4371	2	
I0518 10:39:54.481900  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:39:54.483820  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:39:54.483880  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:39:54.493957  4008 solver.cpp:260]     Total regularization terms: 1.05605 loss+regular. : 2.41343
I0518 10:41:18.372719  4008 solver.cpp:348] Iteration 178000, Testing net (#0)
I0518 10:41:37.515219  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:42:34.954269  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55454
I0518 10:42:34.954581  4008 solver.cpp:415]     Test net output #1: loss = 1.91515 (* 1 = 1.91515 loss)
I0518 10:42:35.043850  4008 solver.cpp:231] Iteration 178000, loss = 1.55432
I0518 10:42:35.043932  4008 solver.cpp:247]     Train net output #0: loss = 1.55432 (* 1 = 1.55432 loss)
I0518 10:42:35.043953  4008 sgd_solver.cpp:106] Iteration 178000, lr = 0.001
I0518 10:42:35.211163  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9519	2.08333	77.6012	0	87.6781	4.42708	84.7944	0	80.244	0	78.1218	0	69.1149	0	26.4455	2	
I0518 10:42:35.286344  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:42:35.288987  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:42:35.289036  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:42:35.299055  4008 solver.cpp:260]     Total regularization terms: 1.0558 loss+regular. : 2.61012
I0518 10:43:57.243729  4008 solver.cpp:231] Iteration 178200, loss = 1.46096
I0518 10:43:57.244117  4008 solver.cpp:247]     Train net output #0: loss = 1.46096 (* 1 = 1.46096 loss)
I0518 10:43:57.244151  4008 sgd_solver.cpp:106] Iteration 178200, lr = 0.001
I0518 10:43:57.403759  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.015	2.08333	77.7061	0	87.681	4.42708	84.8033	0	80.2244	0	78.1419	0	69.1376	0	26.4539	2	
I0518 10:43:57.479576  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:43:57.481988  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:43:57.482059  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:43:57.492449  4008 solver.cpp:260]     Total regularization terms: 1.05553 loss+regular. : 2.51649
I0518 10:44:32.828290  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:45:39.957804  4008 solver.cpp:231] Iteration 178400, loss = 1.48461
I0518 10:45:39.958176  4008 solver.cpp:247]     Train net output #0: loss = 1.48461 (* 1 = 1.48461 loss)
I0518 10:45:39.958199  4008 sgd_solver.cpp:106] Iteration 178400, lr = 0.001
I0518 10:45:40.118147  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.345	2.08333	77.4762	0	87.6964	4.42708	84.8113	0	80.2601	0	78.1617	0	69.1602	0	26.4619	2	
I0518 10:45:40.192778  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:45:40.195509  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:45:40.195559  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:45:40.216017  4008 solver.cpp:260]     Total regularization terms: 1.05529 loss+regular. : 2.5399
I0518 10:47:06.428613  4008 solver.cpp:231] Iteration 178600, loss = 1.24711
I0518 10:47:06.429028  4008 solver.cpp:247]     Train net output #0: loss = 1.24711 (* 1 = 1.24711 loss)
I0518 10:47:06.429050  4008 sgd_solver.cpp:106] Iteration 178600, lr = 0.001
I0518 10:47:06.588672  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2676	2.08333	77.4238	0	87.6989	4.42708	84.8166	0	80.2752	0	78.1813	0	69.1826	0	26.4697	2	
I0518 10:47:06.663486  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:47:06.666045  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:47:06.666095  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:47:06.676156  4008 solver.cpp:260]     Total regularization terms: 1.0551 loss+regular. : 2.30222
I0518 10:48:25.727965  4008 solver.cpp:231] Iteration 178800, loss = 1.52309
I0518 10:48:25.728273  4008 solver.cpp:247]     Train net output #0: loss = 1.52309 (* 1 = 1.52309 loss)
I0518 10:48:25.728314  4008 sgd_solver.cpp:106] Iteration 178800, lr = 0.001
I0518 10:48:25.888949  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8027	2.08333	77.7552	0	87.712	4.42708	84.8334	0	80.2904	0	78.201	0	69.2055	0	26.4784	2	
I0518 10:48:25.963469  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:48:25.965272  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:48:25.965324  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:48:25.975323  4008 solver.cpp:260]     Total regularization terms: 1.05477 loss+regular. : 2.57786
I0518 10:49:45.105810  4008 solver.cpp:348] Iteration 179000, Testing net (#0)
I0518 10:50:08.470275  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:51:10.080977  4008 solver.cpp:415]     Test net output #0: accuracy = 0.54976
I0518 10:51:10.081323  4008 solver.cpp:415]     Test net output #1: loss = 1.92706 (* 1 = 1.92706 loss)
I0518 10:51:10.169149  4008 solver.cpp:231] Iteration 179000, loss = 1.23629
I0518 10:51:10.169262  4008 solver.cpp:247]     Train net output #0: loss = 1.23629 (* 1 = 1.23629 loss)
I0518 10:51:10.169292  4008 sgd_solver.cpp:106] Iteration 179000, lr = 0.001
I0518 10:51:10.336807  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3364	2.08333	77.5339	0	87.718	4.42708	84.8601	0	80.2838	0	78.2206	0	69.2292	0	26.4863	2	
I0518 10:51:10.411561  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:51:10.413267  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:51:10.413316  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:51:10.427387  4008 solver.cpp:260]     Total regularization terms: 1.05454 loss+regular. : 2.29083
I0518 10:52:33.498352  4008 solver.cpp:231] Iteration 179200, loss = 1.35845
I0518 10:52:33.498704  4008 solver.cpp:247]     Train net output #0: loss = 1.35845 (* 1 = 1.35845 loss)
I0518 10:52:33.498733  4008 sgd_solver.cpp:106] Iteration 179200, lr = 0.001
I0518 10:52:33.658257  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.391	2.08333	77.512	0	87.7187	4.42708	84.8497	0	80.3019	0	78.2401	0	69.2524	0	26.4944	2	
I0518 10:52:33.732525  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:52:33.734383  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:52:33.734441  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:52:33.744701  4008 solver.cpp:260]     Total regularization terms: 1.05431 loss+regular. : 2.41276
I0518 10:53:02.519145  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 10:53:59.917198  4008 solver.cpp:231] Iteration 179400, loss = 1.2428
I0518 10:53:59.917620  4008 solver.cpp:247]     Train net output #0: loss = 1.2428 (* 1 = 1.2428 loss)
I0518 10:53:59.917650  4008 sgd_solver.cpp:106] Iteration 179400, lr = 0.001
I0518 10:54:00.077569  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2159	2.08333	77.7363	0	87.7239	4.42708	84.8458	0	80.3318	0	78.2591	0	69.2746	0	26.5025	2	
I0518 10:54:00.152458  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:54:00.154994  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:54:00.155062  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:54:00.165241  4008 solver.cpp:260]     Total regularization terms: 1.05405 loss+regular. : 2.29685
I0518 10:55:28.163775  4008 solver.cpp:231] Iteration 179600, loss = 1.34007
I0518 10:55:28.164352  4008 solver.cpp:247]     Train net output #0: loss = 1.34007 (* 1 = 1.34007 loss)
I0518 10:55:28.164388  4008 sgd_solver.cpp:106] Iteration 179600, lr = 0.001
I0518 10:55:28.322291  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1155	2.08333	77.5599	0	87.7413	4.42708	84.8821	0	80.3361	0	78.2791	0	69.297	0	26.511	2	
I0518 10:55:28.397634  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:55:28.400236  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:55:28.400288  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:55:28.410439  4008 solver.cpp:260]     Total regularization terms: 1.05374 loss+regular. : 2.39381
I0518 10:56:59.082758  4008 solver.cpp:231] Iteration 179800, loss = 1.40794
I0518 10:56:59.083081  4008 solver.cpp:247]     Train net output #0: loss = 1.40794 (* 1 = 1.40794 loss)
I0518 10:56:59.083099  4008 sgd_solver.cpp:106] Iteration 179800, lr = 0.001
I0518 10:56:59.242831  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9289	2.08333	77.5872	0	87.7602	4.42708	84.8875	0	80.3415	0	78.2984	0	69.3201	0	26.5186	2	
I0518 10:56:59.317284  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 10:56:59.319257  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 10:56:59.319308  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 10:56:59.329103  4008 solver.cpp:260]     Total regularization terms: 1.05344 loss+regular. : 2.46138
I0518 10:58:27.818023  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_180000.caffemodel
I0518 11:01:08.193254  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_180000.solverstate
I0518 11:01:08.722337  4008 solver.cpp:348] Iteration 180000, Testing net (#0)
I0518 11:01:30.744374  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:02:35.428186  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55394
I0518 11:02:35.428598  4008 solver.cpp:415]     Test net output #1: loss = 1.91531 (* 1 = 1.91531 loss)
I0518 11:02:35.521400  4008 solver.cpp:231] Iteration 180000, loss = 1.61859
I0518 11:02:35.521539  4008 solver.cpp:247]     Train net output #0: loss = 1.61859 (* 1 = 1.61859 loss)
I0518 11:02:35.521589  4008 sgd_solver.cpp:106] Iteration 180000, lr = 0.001
I0518 11:02:35.687510  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1585	2.08333	77.7985	0	87.7472	4.42708	84.8749	0	80.3514	0	78.318	0	69.3432	0	26.5265	2	
I0518 11:02:35.688771  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:02:35.690729  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:02:35.690820  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:02:35.700772  4008 solver.cpp:260]     Total regularization terms: 1.05315 loss+regular. : 2.67174
I0518 11:04:00.225319  4008 solver.cpp:231] Iteration 180200, loss = 1.28402
I0518 11:04:00.225890  4008 solver.cpp:247]     Train net output #0: loss = 1.28402 (* 1 = 1.28402 loss)
I0518 11:04:00.225916  4008 sgd_solver.cpp:106] Iteration 180200, lr = 0.001
I0518 11:04:00.383198  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.972	2.08333	77.7048	0	87.747	4.42708	84.9115	0	80.384	0	78.3377	0	69.3665	0	26.5342	2	
I0518 11:04:00.457689  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:04:00.459549  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:04:00.459599  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:04:00.469861  4008 solver.cpp:260]     Total regularization terms: 1.05288 loss+regular. : 2.3369
I0518 11:04:31.356145  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:05:21.390740  4008 solver.cpp:231] Iteration 180400, loss = 1.3057
I0518 11:05:21.391077  4008 solver.cpp:247]     Train net output #0: loss = 1.3057 (* 1 = 1.3057 loss)
I0518 11:05:21.391093  4008 sgd_solver.cpp:106] Iteration 180400, lr = 0.001
I0518 11:05:21.552376  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1384	2.08333	77.7155	0	87.7403	4.42708	84.9196	0	80.3747	0	78.3579	0	69.3891	0	26.5423	2	
I0518 11:05:21.627727  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:05:21.629181  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:05:21.629220  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:05:21.659071  4008 solver.cpp:260]     Total regularization terms: 1.05269 loss+regular. : 2.35839
I0518 11:06:43.363385  4008 solver.cpp:231] Iteration 180600, loss = 1.12467
I0518 11:06:43.364248  4008 solver.cpp:247]     Train net output #0: loss = 1.12467 (* 1 = 1.12467 loss)
I0518 11:06:43.364289  4008 sgd_solver.cpp:106] Iteration 180600, lr = 0.001
I0518 11:06:43.522778  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.949	2.08333	77.4447	0	87.7549	4.42708	84.9133	0	80.3951	0	78.3777	0	69.4118	0	26.5501	2	
I0518 11:06:43.597040  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:06:43.599009  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:06:43.599074  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:06:43.610512  4008 solver.cpp:260]     Total regularization terms: 1.05252 loss+regular. : 2.17719
I0518 11:08:09.675518  4008 solver.cpp:231] Iteration 180800, loss = 1.3326
I0518 11:08:09.677670  4008 solver.cpp:247]     Train net output #0: loss = 1.3326 (* 1 = 1.3326 loss)
I0518 11:08:09.677711  4008 sgd_solver.cpp:106] Iteration 180800, lr = 0.001
I0518 11:08:09.835187  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2016	2.08333	77.6035	0	87.7932	4.42708	84.935	0	80.417	0	78.3969	0	69.4338	0	26.5578	2	
I0518 11:08:09.909626  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:08:09.912225  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:08:09.912272  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:08:09.924737  4008 solver.cpp:260]     Total regularization terms: 1.05227 loss+regular. : 2.38487
I0518 11:09:34.777688  4008 solver.cpp:348] Iteration 181000, Testing net (#0)
I0518 11:10:01.876209  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:11:05.036382  4008 solver.cpp:415]     Test net output #0: accuracy = 0.553659
I0518 11:11:05.036826  4008 solver.cpp:415]     Test net output #1: loss = 1.91393 (* 1 = 1.91393 loss)
I0518 11:11:05.132161  4008 solver.cpp:231] Iteration 181000, loss = 1.56775
I0518 11:11:05.132243  4008 solver.cpp:247]     Train net output #0: loss = 1.56775 (* 1 = 1.56775 loss)
I0518 11:11:05.132259  4008 sgd_solver.cpp:106] Iteration 181000, lr = 0.001
I0518 11:11:05.291661  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3823	2.08333	77.804	0	87.7968	4.42708	84.9753	0	80.4226	0	78.4161	0	69.4565	0	26.5659	2	
I0518 11:11:05.366160  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:11:05.368001  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:11:05.368042  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:11:05.378007  4008 solver.cpp:260]     Total regularization terms: 1.05197 loss+regular. : 2.61972
I0518 11:12:36.713788  4008 solver.cpp:231] Iteration 181200, loss = 1.32522
I0518 11:12:36.717690  4008 solver.cpp:247]     Train net output #0: loss = 1.32522 (* 1 = 1.32522 loss)
I0518 11:12:36.717721  4008 sgd_solver.cpp:106] Iteration 181200, lr = 0.001
I0518 11:12:36.873133  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3278	2.08333	77.9036	0	87.7814	4.42708	84.9747	0	80.4407	0	78.4355	0	69.4793	0	26.5743	2	
I0518 11:12:36.947532  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:12:36.949579  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:12:36.949632  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:12:36.963245  4008 solver.cpp:260]     Total regularization terms: 1.0517 loss+regular. : 2.37692
I0518 11:13:12.322466  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:14:09.607911  4008 solver.cpp:231] Iteration 181400, loss = 1.47224
I0518 11:14:09.608266  4008 solver.cpp:247]     Train net output #0: loss = 1.47224 (* 1 = 1.47224 loss)
I0518 11:14:09.608299  4008 sgd_solver.cpp:106] Iteration 181400, lr = 0.001
I0518 11:14:09.766707  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1298	2.08333	77.6846	0	87.8075	4.42708	84.9748	0	80.4421	0	78.4548	0	69.5019	0	26.5819	2	
I0518 11:14:09.841182  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:14:09.842857  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:14:09.842900  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:14:09.858060  4008 solver.cpp:260]     Total regularization terms: 1.05149 loss+regular. : 2.52373
I0518 11:15:44.561406  4008 solver.cpp:231] Iteration 181600, loss = 1.17732
I0518 11:15:44.562048  4008 solver.cpp:247]     Train net output #0: loss = 1.17732 (* 1 = 1.17732 loss)
I0518 11:15:44.562072  4008 sgd_solver.cpp:106] Iteration 181600, lr = 0.001
I0518 11:15:44.719544  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7539	2.08333	77.9108	0	87.8111	4.42708	84.9964	0	80.4527	0	78.4738	0	69.5246	0	26.5896	2	
I0518 11:15:44.794481  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:15:44.796561  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:15:44.796615  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:15:44.806555  4008 solver.cpp:260]     Total regularization terms: 1.05121 loss+regular. : 2.22853
I0518 11:17:13.183200  4008 solver.cpp:231] Iteration 181800, loss = 1.49537
I0518 11:17:13.187647  4008 solver.cpp:247]     Train net output #0: loss = 1.49537 (* 1 = 1.49537 loss)
I0518 11:17:13.187680  4008 sgd_solver.cpp:106] Iteration 181800, lr = 0.001
I0518 11:17:13.342926  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9777	2.08333	77.8083	0	87.823	4.42708	85.0134	0	80.4681	0	78.4927	0	69.5467	0	26.5971	2	
I0518 11:17:13.417747  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:17:13.420469  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:17:13.420516  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:17:13.431742  4008 solver.cpp:260]     Total regularization terms: 1.05095 loss+regular. : 2.54632
I0518 11:18:40.113400  4008 solver.cpp:348] Iteration 182000, Testing net (#0)
I0518 11:19:03.816121  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:20:05.824537  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5511
I0518 11:20:05.825671  4008 solver.cpp:415]     Test net output #1: loss = 1.94341 (* 1 = 1.94341 loss)
I0518 11:20:05.923272  4008 solver.cpp:231] Iteration 182000, loss = 1.46767
I0518 11:20:05.923355  4008 solver.cpp:247]     Train net output #0: loss = 1.46767 (* 1 = 1.46767 loss)
I0518 11:20:05.923378  4008 sgd_solver.cpp:106] Iteration 182000, lr = 0.001
I0518 11:20:06.083611  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.906	2.08333	77.3877	0	87.8268	4.42708	85.0176	0	80.4778	0	78.512	0	69.5696	0	26.6054	2	
I0518 11:20:06.160692  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:20:06.163758  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:20:06.163812  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:20:06.174499  4008 solver.cpp:260]     Total regularization terms: 1.05073 loss+regular. : 2.5184
I0518 11:21:31.580624  4008 solver.cpp:231] Iteration 182200, loss = 1.52219
I0518 11:21:31.580936  4008 solver.cpp:247]     Train net output #0: loss = 1.52219 (* 1 = 1.52219 loss)
I0518 11:21:31.580960  4008 sgd_solver.cpp:106] Iteration 182200, lr = 0.001
I0518 11:21:31.742168  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0122	2.08333	77.6296	0	87.8108	4.42708	85.0197	0	80.4941	0	78.5313	0	69.5917	0	26.6138	2	
I0518 11:21:31.817044  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:21:31.819612  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:21:31.819664  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:21:31.829485  4008 solver.cpp:260]     Total regularization terms: 1.05054 loss+regular. : 2.57273
I0518 11:22:15.518708  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:23:08.912093  4008 solver.cpp:231] Iteration 182400, loss = 1.43819
I0518 11:23:08.912498  4008 solver.cpp:247]     Train net output #0: loss = 1.43819 (* 1 = 1.43819 loss)
I0518 11:23:08.912525  4008 sgd_solver.cpp:106] Iteration 182400, lr = 0.001
I0518 11:23:09.072022  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8658	2.08333	77.7607	0	87.866	4.42708	85.0503	0	80.5058	0	78.5499	0	69.6142	0	26.6212	2	
I0518 11:23:09.147238  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:23:09.149255  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:23:09.149303  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:23:09.163128  4008 solver.cpp:260]     Total regularization terms: 1.05029 loss+regular. : 2.48847
I0518 11:24:36.103432  4008 solver.cpp:231] Iteration 182600, loss = 1.5603
I0518 11:24:36.105134  4008 solver.cpp:247]     Train net output #0: loss = 1.5603 (* 1 = 1.5603 loss)
I0518 11:24:36.105176  4008 sgd_solver.cpp:106] Iteration 182600, lr = 0.001
I0518 11:24:36.263108  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0294	2.08333	77.5827	0	87.8564	4.42708	85.0581	0	80.4979	0	78.5691	0	69.6367	0	26.6287	2	
I0518 11:24:36.338340  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:24:36.340510  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:24:36.340709  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:24:36.351228  4008 solver.cpp:260]     Total regularization terms: 1.05008 loss+regular. : 2.61038
I0518 11:26:02.102751  4008 solver.cpp:231] Iteration 182800, loss = 1.47982
I0518 11:26:02.103324  4008 solver.cpp:247]     Train net output #0: loss = 1.47982 (* 1 = 1.47982 loss)
I0518 11:26:02.103355  4008 sgd_solver.cpp:106] Iteration 182800, lr = 0.001
I0518 11:26:02.263130  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1585	2.08333	77.5592	0	87.8107	4.42708	85.0592	0	80.4932	0	78.5879	0	69.6586	0	26.6371	2	
I0518 11:26:02.338901  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:26:02.340993  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:26:02.341042  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:26:02.356492  4008 solver.cpp:260]     Total regularization terms: 1.04981 loss+regular. : 2.52963
I0518 11:27:29.431618  4008 solver.cpp:348] Iteration 183000, Testing net (#0)
I0518 11:28:00.477548  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:29:00.928268  4008 solver.cpp:415]     Test net output #0: accuracy = 0.553999
I0518 11:29:00.928606  4008 solver.cpp:415]     Test net output #1: loss = 1.91574 (* 1 = 1.91574 loss)
I0518 11:29:01.016016  4008 solver.cpp:231] Iteration 183000, loss = 1.68466
I0518 11:29:01.016101  4008 solver.cpp:247]     Train net output #0: loss = 1.68466 (* 1 = 1.68466 loss)
I0518 11:29:01.016121  4008 sgd_solver.cpp:106] Iteration 183000, lr = 0.001
I0518 11:29:01.183408  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.7166	2.08333	77.7578	0	87.8529	4.42708	85.0658	0	80.5366	0	78.6066	0	69.6808	0	26.6457	2	
I0518 11:29:01.258059  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:29:01.259762  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:29:01.259807  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:29:01.269809  4008 solver.cpp:260]     Total regularization terms: 1.04952 loss+regular. : 2.73418
I0518 11:30:25.621431  4008 solver.cpp:231] Iteration 183200, loss = 1.57564
I0518 11:30:25.621784  4008 solver.cpp:247]     Train net output #0: loss = 1.57564 (* 1 = 1.57564 loss)
I0518 11:30:25.621812  4008 sgd_solver.cpp:106] Iteration 183200, lr = 0.001
I0518 11:30:25.780760  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9806	2.08333	77.9701	0	87.8725	4.42708	85.0728	0	80.5429	0	78.6256	0	69.7028	0	26.6536	2	
I0518 11:30:25.855150  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:30:25.857172  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:30:25.857224  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:30:25.872444  4008 solver.cpp:260]     Total regularization terms: 1.04923 loss+regular. : 2.62487
I0518 11:31:08.786877  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:31:54.738031  4008 solver.cpp:231] Iteration 183400, loss = 1.4658
I0518 11:31:54.739001  4008 solver.cpp:247]     Train net output #0: loss = 1.4658 (* 1 = 1.4658 loss)
I0518 11:31:54.739023  4008 sgd_solver.cpp:106] Iteration 183400, lr = 0.001
I0518 11:31:54.898000  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0007	2.08333	77.8577	0	87.8878	4.42708	85.0646	0	80.5447	0	78.6442	0	69.7252	0	26.6606	2	
I0518 11:31:54.972312  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:31:54.974232  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:31:54.974284  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:31:54.984074  4008 solver.cpp:260]     Total regularization terms: 1.04904 loss+regular. : 2.51485
I0518 11:33:15.152487  4008 solver.cpp:231] Iteration 183600, loss = 1.47323
I0518 11:33:15.152909  4008 solver.cpp:247]     Train net output #0: loss = 1.47323 (* 1 = 1.47323 loss)
I0518 11:33:15.152936  4008 sgd_solver.cpp:106] Iteration 183600, lr = 0.001
I0518 11:33:15.313707  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1499	2.08333	77.9141	0	87.8987	4.42708	85.094	0	80.5773	0	78.6632	0	69.7469	0	26.6685	2	
I0518 11:33:15.388227  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:33:15.389994  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:33:15.390044  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:33:15.399869  4008 solver.cpp:260]     Total regularization terms: 1.04874 loss+regular. : 2.52197
I0518 11:34:58.232630  4008 solver.cpp:231] Iteration 183800, loss = 1.56046
I0518 11:34:58.233119  4008 solver.cpp:247]     Train net output #0: loss = 1.56046 (* 1 = 1.56046 loss)
I0518 11:34:58.233147  4008 sgd_solver.cpp:106] Iteration 183800, lr = 0.001
I0518 11:34:58.392595  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4024	2.08333	77.7643	0	87.8962	4.42708	85.1083	0	80.5908	0	78.682	0	69.769	0	26.6768	2	
I0518 11:34:58.466907  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:34:58.468786  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:34:58.468837  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:34:58.478785  4008 solver.cpp:260]     Total regularization terms: 1.04855 loss+regular. : 2.60901
I0518 11:36:22.982499  4008 solver.cpp:348] Iteration 184000, Testing net (#0)
I0518 11:36:49.527884  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:37:48.372575  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55342
I0518 11:37:48.372953  4008 solver.cpp:415]     Test net output #1: loss = 1.91959 (* 1 = 1.91959 loss)
I0518 11:37:48.465423  4008 solver.cpp:231] Iteration 184000, loss = 1.48532
I0518 11:37:48.465504  4008 solver.cpp:247]     Train net output #0: loss = 1.48532 (* 1 = 1.48532 loss)
I0518 11:37:48.465522  4008 sgd_solver.cpp:106] Iteration 184000, lr = 0.001
I0518 11:37:48.631711  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1356	2.08333	77.693	0	87.8719	4.42708	85.1107	0	80.5707	0	78.701	0	69.7905	0	26.6849	2	
I0518 11:37:48.706243  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:37:48.707931  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:37:48.707973  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:37:48.720801  4008 solver.cpp:260]     Total regularization terms: 1.04829 loss+regular. : 2.53361
I0518 11:39:16.114421  4008 solver.cpp:231] Iteration 184200, loss = 1.23773
I0518 11:39:16.114718  4008 solver.cpp:247]     Train net output #0: loss = 1.23773 (* 1 = 1.23773 loss)
I0518 11:39:16.114739  4008 sgd_solver.cpp:106] Iteration 184200, lr = 0.001
I0518 11:39:16.274380  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3881	2.08333	77.8587	0	87.8807	4.42708	85.1061	0	80.5888	0	78.7201	0	69.8125	0	26.6929	2	
I0518 11:39:16.348790  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:39:16.350816  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:39:16.350872  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:39:16.380167  4008 solver.cpp:260]     Total regularization terms: 1.04804 loss+regular. : 2.28577
I0518 11:39:58.821084  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:40:37.753239  4008 solver.cpp:231] Iteration 184400, loss = 1.29186
I0518 11:40:37.753727  4008 solver.cpp:247]     Train net output #0: loss = 1.29186 (* 1 = 1.29186 loss)
I0518 11:40:37.753754  4008 sgd_solver.cpp:106] Iteration 184400, lr = 0.001
I0518 11:40:37.914219  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0581	2.08333	77.8623	0	87.8907	4.42708	85.1249	0	80.617	0	78.7387	0	69.8336	0	26.7001	2	
I0518 11:40:37.988893  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:40:37.991194  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:40:37.991250  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:40:38.001237  4008 solver.cpp:260]     Total regularization terms: 1.04781 loss+regular. : 2.33967
I0518 11:42:01.541509  4008 solver.cpp:231] Iteration 184600, loss = 1.33361
I0518 11:42:01.541944  4008 solver.cpp:247]     Train net output #0: loss = 1.33361 (* 1 = 1.33361 loss)
I0518 11:42:01.541972  4008 sgd_solver.cpp:106] Iteration 184600, lr = 0.001
I0518 11:42:01.701397  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1097	2.08333	77.8138	0	87.9193	4.42708	85.1315	0	80.6241	0	78.7575	0	69.8557	0	26.7083	2	
I0518 11:42:01.776166  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:42:01.778666  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:42:01.778712  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:42:01.788631  4008 solver.cpp:260]     Total regularization terms: 1.04755 loss+regular. : 2.38117
I0518 11:43:33.924489  4008 solver.cpp:231] Iteration 184800, loss = 1.36139
I0518 11:43:33.925676  4008 solver.cpp:247]     Train net output #0: loss = 1.36139 (* 1 = 1.36139 loss)
I0518 11:43:33.925712  4008 sgd_solver.cpp:106] Iteration 184800, lr = 0.001
I0518 11:43:34.085677  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.038	2.08333	77.7171	0	87.9207	4.42708	85.1361	0	80.6528	0	78.776	0	69.8773	0	26.7154	2	
I0518 11:43:34.161886  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:43:34.165138  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:43:34.165208  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:43:34.175359  4008 solver.cpp:260]     Total regularization terms: 1.04732 loss+regular. : 2.40871
I0518 11:45:05.246116  4008 solver.cpp:348] Iteration 185000, Testing net (#0)
I0518 11:45:34.736582  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:46:35.386690  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55218
I0518 11:46:35.387187  4008 solver.cpp:415]     Test net output #1: loss = 1.92278 (* 1 = 1.92278 loss)
I0518 11:46:35.475307  4008 solver.cpp:231] Iteration 185000, loss = 1.59737
I0518 11:46:35.475414  4008 solver.cpp:247]     Train net output #0: loss = 1.59737 (* 1 = 1.59737 loss)
I0518 11:46:35.475441  4008 sgd_solver.cpp:106] Iteration 185000, lr = 0.001
I0518 11:46:35.634019  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8888	2.08333	77.8346	0	87.9286	4.42708	85.1531	0	80.665	0	78.7946	0	69.8998	0	26.7231	2	
I0518 11:46:35.708864  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:46:35.712160  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:46:35.712209  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:46:35.725206  4008 solver.cpp:260]     Total regularization terms: 1.04704 loss+regular. : 2.64442
I0518 11:48:03.848860  4008 solver.cpp:231] Iteration 185200, loss = 1.3099
I0518 11:48:03.849252  4008 solver.cpp:247]     Train net output #0: loss = 1.3099 (* 1 = 1.3099 loss)
I0518 11:48:03.849299  4008 sgd_solver.cpp:106] Iteration 185200, lr = 0.001
I0518 11:48:04.009232  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9318	2.08333	78.0046	0	87.9735	4.42708	85.1507	0	80.6749	0	78.8131	0	69.9217	0	26.7313	2	
I0518 11:48:04.084615  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:48:04.087393  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:48:04.087504  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:48:04.097970  4008 solver.cpp:260]     Total regularization terms: 1.04675 loss+regular. : 2.35665
I0518 11:48:53.262495  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:49:37.186817  4008 solver.cpp:231] Iteration 185400, loss = 1.46814
I0518 11:49:37.187232  4008 solver.cpp:247]     Train net output #0: loss = 1.46814 (* 1 = 1.46814 loss)
I0518 11:49:37.187270  4008 sgd_solver.cpp:106] Iteration 185400, lr = 0.001
I0518 11:49:37.347501  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0351	2.08333	77.7266	0	87.9232	4.42708	85.1468	0	80.6473	0	78.8319	0	69.9436	0	26.7397	2	
I0518 11:49:37.423178  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:49:37.426574  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:49:37.426637  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:49:37.437052  4008 solver.cpp:260]     Total regularization terms: 1.04656 loss+regular. : 2.5147
I0518 11:51:09.408061  4008 solver.cpp:231] Iteration 185600, loss = 1.2092
I0518 11:51:09.411183  4008 solver.cpp:247]     Train net output #0: loss = 1.2092 (* 1 = 1.2092 loss)
I0518 11:51:09.411217  4008 sgd_solver.cpp:106] Iteration 185600, lr = 0.001
I0518 11:51:09.568820  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3135	2.08333	77.6673	0	87.9608	4.42708	85.1865	0	80.6828	0	78.8505	0	69.9658	0	26.7468	2	
I0518 11:51:09.644672  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:51:09.647228  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:51:09.647279  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:51:09.662364  4008 solver.cpp:260]     Total regularization terms: 1.04631 loss+regular. : 2.25551
I0518 11:52:42.110529  4008 solver.cpp:231] Iteration 185800, loss = 1.15984
I0518 11:52:42.111034  4008 solver.cpp:247]     Train net output #0: loss = 1.15984 (* 1 = 1.15984 loss)
I0518 11:52:42.111065  4008 sgd_solver.cpp:106] Iteration 185800, lr = 0.001
I0518 11:52:42.268944  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2274	2.08333	77.8568	0	87.9909	4.42708	85.1755	0	80.6975	0	78.8691	0	69.9874	0	26.7549	2	
I0518 11:52:42.344200  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:52:42.347834  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:52:42.347901  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:52:42.358045  4008 solver.cpp:260]     Total regularization terms: 1.046 loss+regular. : 2.20584
I0518 11:54:17.000721  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_186000.caffemodel
I0518 11:58:19.127910  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_186000.solverstate
I0518 11:58:19.656332  4008 solver.cpp:348] Iteration 186000, Testing net (#0)
I0518 11:58:47.308333  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 11:59:44.044082  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5539
I0518 11:59:44.044438  4008 solver.cpp:415]     Test net output #1: loss = 1.92463 (* 1 = 1.92463 loss)
I0518 11:59:44.132146  4008 solver.cpp:231] Iteration 186000, loss = 1.39494
I0518 11:59:44.132228  4008 solver.cpp:247]     Train net output #0: loss = 1.39494 (* 1 = 1.39494 loss)
I0518 11:59:44.132247  4008 sgd_solver.cpp:106] Iteration 186000, lr = 0.001
I0518 11:59:44.294899  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4483	2.08333	77.7979	0	87.9673	4.42708	85.2031	0	80.7118	0	78.8879	0	70.0088	0	26.7627	2	
I0518 11:59:44.296111  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 11:59:44.297734  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 11:59:44.297863  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 11:59:44.311257  4008 solver.cpp:260]     Total regularization terms: 1.04585 loss+regular. : 2.44079
I0518 12:01:07.915273  4008 solver.cpp:231] Iteration 186200, loss = 1.40764
I0518 12:01:07.915662  4008 solver.cpp:247]     Train net output #0: loss = 1.40764 (* 1 = 1.40764 loss)
I0518 12:01:07.915688  4008 sgd_solver.cpp:106] Iteration 186200, lr = 0.001
I0518 12:01:08.076102  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3336	2.08333	77.9782	0	87.9605	4.42708	85.1893	0	80.7192	0	78.9068	0	70.0305	0	26.7698	2	
I0518 12:01:08.150969  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:01:08.153545  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:01:08.153614  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:01:08.163568  4008 solver.cpp:260]     Total regularization terms: 1.04556 loss+regular. : 2.4532
I0518 12:02:01.782642  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:02:37.939121  4008 solver.cpp:231] Iteration 186400, loss = 1.42764
I0518 12:02:37.939507  4008 solver.cpp:247]     Train net output #0: loss = 1.42764 (* 1 = 1.42764 loss)
I0518 12:02:37.939529  4008 sgd_solver.cpp:106] Iteration 186400, lr = 0.001
I0518 12:02:38.099823  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3163	2.08333	78.1296	0	87.979	4.42708	85.1926	0	80.7432	0	78.925	0	70.0517	0	26.7776	2	
I0518 12:02:38.174325  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:02:38.176445  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:02:38.176491  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:02:38.186313  4008 solver.cpp:260]     Total regularization terms: 1.04535 loss+regular. : 2.47298
I0518 12:04:14.950636  4008 solver.cpp:231] Iteration 186600, loss = 1.37461
I0518 12:04:14.950911  4008 solver.cpp:247]     Train net output #0: loss = 1.37461 (* 1 = 1.37461 loss)
I0518 12:04:14.950930  4008 sgd_solver.cpp:106] Iteration 186600, lr = 0.001
I0518 12:04:15.111346  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0925	2.08333	78.1211	0	88.0162	4.42708	85.234	0	80.7495	0	78.9434	0	70.0735	0	26.7856	2	
I0518 12:04:15.186022  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:04:15.187990  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:04:15.188019  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:04:15.198002  4008 solver.cpp:260]     Total regularization terms: 1.04509 loss+regular. : 2.4197
I0518 12:06:01.439374  4008 solver.cpp:231] Iteration 186800, loss = 1.26211
I0518 12:06:01.439635  4008 solver.cpp:247]     Train net output #0: loss = 1.26211 (* 1 = 1.26211 loss)
I0518 12:06:01.439656  4008 sgd_solver.cpp:106] Iteration 186800, lr = 0.001
I0518 12:06:01.599822  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1413	2.08333	77.7438	0	87.9838	4.42708	85.2134	0	80.7567	0	78.9619	0	70.0947	0	26.7937	2	
I0518 12:06:01.674585  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:06:01.677341  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:06:01.677383  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:06:01.687280  4008 solver.cpp:260]     Total regularization terms: 1.04484 loss+regular. : 2.30695
I0518 12:07:37.724575  4008 solver.cpp:348] Iteration 187000, Testing net (#0)
I0518 12:08:04.974205  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:09:06.218592  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5537
I0518 12:09:06.219002  4008 solver.cpp:415]     Test net output #1: loss = 1.9163 (* 1 = 1.9163 loss)
I0518 12:09:06.308015  4008 solver.cpp:231] Iteration 187000, loss = 1.35429
I0518 12:09:06.308142  4008 solver.cpp:247]     Train net output #0: loss = 1.35429 (* 1 = 1.35429 loss)
I0518 12:09:06.308176  4008 sgd_solver.cpp:106] Iteration 187000, lr = 0.001
I0518 12:09:06.473150  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1958	2.08333	78.0446	0	88.0075	4.42708	85.2479	0	80.7669	0	78.9801	0	70.1159	0	26.8019	2	
I0518 12:09:06.548547  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:09:06.550520  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:09:06.550591  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:09:06.560953  4008 solver.cpp:260]     Total regularization terms: 1.04462 loss+regular. : 2.39891
I0518 12:10:32.474164  4008 solver.cpp:231] Iteration 187200, loss = 1.28942
I0518 12:10:32.474534  4008 solver.cpp:247]     Train net output #0: loss = 1.28942 (* 1 = 1.28942 loss)
I0518 12:10:32.474562  4008 sgd_solver.cpp:106] Iteration 187200, lr = 0.001
I0518 12:10:32.635179  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1958	2.08333	78.0511	0	87.9954	4.42708	85.2637	0	80.7615	0	78.9984	0	70.1373	0	26.8092	2	
I0518 12:10:32.709468  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:10:32.711175  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:10:32.711226  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:10:32.721127  4008 solver.cpp:260]     Total regularization terms: 1.0444 loss+regular. : 2.33383
I0518 12:11:31.002800  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:12:02.952487  4008 solver.cpp:231] Iteration 187400, loss = 1.27534
I0518 12:12:02.952814  4008 solver.cpp:247]     Train net output #0: loss = 1.27534 (* 1 = 1.27534 loss)
I0518 12:12:02.952836  4008 sgd_solver.cpp:106] Iteration 187400, lr = 0.001
I0518 12:12:03.111313  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2819	2.08333	77.8945	0	88.0292	4.42708	85.2824	0	80.8078	0	79.0163	0	70.1581	0	26.817	2	
I0518 12:12:03.185631  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:12:03.187283  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:12:03.187330  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:12:03.197224  4008 solver.cpp:260]     Total regularization terms: 1.04414 loss+regular. : 2.31948
I0518 12:13:28.853863  4008 solver.cpp:231] Iteration 187600, loss = 1.41452
I0518 12:13:28.854256  4008 solver.cpp:247]     Train net output #0: loss = 1.41452 (* 1 = 1.41452 loss)
I0518 12:13:28.854277  4008 sgd_solver.cpp:106] Iteration 187600, lr = 0.001
I0518 12:13:29.013057  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3077	2.08333	77.8607	0	88.0354	4.42708	85.267	0	80.8191	0	79.0344	0	70.1798	0	26.8241	2	
I0518 12:13:29.087685  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:13:29.090018  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:13:29.090075  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:13:29.099922  4008 solver.cpp:260]     Total regularization terms: 1.04393 loss+regular. : 2.45845
I0518 12:14:57.349736  4008 solver.cpp:231] Iteration 187800, loss = 1.41087
I0518 12:14:57.350100  4008 solver.cpp:247]     Train net output #0: loss = 1.41087 (* 1 = 1.41087 loss)
I0518 12:14:57.350138  4008 sgd_solver.cpp:106] Iteration 187800, lr = 0.001
I0518 12:14:57.511629  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3106	2.08333	77.8073	0	88.0336	4.42708	85.2818	0	80.8144	0	79.0526	0	70.2013	0	26.8316	2	
I0518 12:14:57.586626  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:14:57.589323  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:14:57.589381  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:14:57.599732  4008 solver.cpp:260]     Total regularization terms: 1.04365 loss+regular. : 2.45452
I0518 12:16:21.454694  4008 solver.cpp:348] Iteration 188000, Testing net (#0)
I0518 12:16:55.008204  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:17:52.773031  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55412
I0518 12:17:52.773322  4008 solver.cpp:415]     Test net output #1: loss = 1.91752 (* 1 = 1.91752 loss)
I0518 12:17:52.890961  4008 solver.cpp:231] Iteration 188000, loss = 1.51807
I0518 12:17:52.891068  4008 solver.cpp:247]     Train net output #0: loss = 1.51807 (* 1 = 1.51807 loss)
I0518 12:17:52.891090  4008 sgd_solver.cpp:106] Iteration 188000, lr = 0.001
I0518 12:17:53.055950  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0896	2.08333	78.152	0	88.0634	4.42708	85.2856	0	80.8286	0	79.0705	0	70.2227	0	26.8395	2	
I0518 12:17:53.130699  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:17:53.132330  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:17:53.132380  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:17:53.146041  4008 solver.cpp:260]     Total regularization terms: 1.04336 loss+regular. : 2.56142
I0518 12:19:22.524760  4008 solver.cpp:231] Iteration 188200, loss = 1.31317
I0518 12:19:22.525985  4008 solver.cpp:247]     Train net output #0: loss = 1.31317 (* 1 = 1.31317 loss)
I0518 12:19:22.526021  4008 sgd_solver.cpp:106] Iteration 188200, lr = 0.001
I0518 12:19:22.684325  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9203	2.08333	77.9352	0	88.032	4.42708	85.3143	0	80.8408	0	79.0889	0	70.2441	0	26.8475	2	
I0518 12:19:22.759830  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:19:22.762676  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:19:22.762959  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:19:22.773643  4008 solver.cpp:260]     Total regularization terms: 1.04316 loss+regular. : 2.35633
I0518 12:20:20.241094  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:20:45.677814  4008 solver.cpp:231] Iteration 188400, loss = 1.28976
I0518 12:20:45.677942  4008 solver.cpp:247]     Train net output #0: loss = 1.28976 (* 1 = 1.28976 loss)
I0518 12:20:45.678088  4008 sgd_solver.cpp:106] Iteration 188400, lr = 0.001
I0518 12:20:45.837512  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.236	2.08333	77.998	0	88.0441	4.42708	85.3103	0	80.854	0	79.1068	0	70.2657	0	26.8561	2	
I0518 12:20:45.911794  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:20:45.913105  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:20:45.913131  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:20:45.924433  4008 solver.cpp:260]     Total regularization terms: 1.04296 loss+regular. : 2.33272
I0518 12:22:08.231737  4008 solver.cpp:231] Iteration 188600, loss = 1.24394
I0518 12:22:08.233670  4008 solver.cpp:247]     Train net output #0: loss = 1.24394 (* 1 = 1.24394 loss)
I0518 12:22:08.233698  4008 sgd_solver.cpp:106] Iteration 188600, lr = 0.001
I0518 12:22:08.391543  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3479	2.08333	78.0729	0	88.0961	4.42708	85.344	0	80.8628	0	79.1251	0	70.2871	0	26.8644	2	
I0518 12:22:08.465905  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:22:08.467789  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:22:08.467875  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:22:08.481654  4008 solver.cpp:260]     Total regularization terms: 1.0427 loss+regular. : 2.28664
I0518 12:23:34.743432  4008 solver.cpp:231] Iteration 188800, loss = 1.3856
I0518 12:23:34.744015  4008 solver.cpp:247]     Train net output #0: loss = 1.3856 (* 1 = 1.3856 loss)
I0518 12:23:34.744036  4008 sgd_solver.cpp:106] Iteration 188800, lr = 0.001
I0518 12:23:34.903767  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0667	2.08333	78.0423	0	88.0883	4.42708	85.3401	0	80.8827	0	79.1432	0	70.308	0	26.872	2	
I0518 12:23:34.978392  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:23:34.980017  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:23:34.980057  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:23:34.994927  4008 solver.cpp:260]     Total regularization terms: 1.04248 loss+regular. : 2.42809
I0518 12:24:59.220854  4008 solver.cpp:348] Iteration 189000, Testing net (#0)
I0518 12:25:23.806627  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:26:18.141042  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55554
I0518 12:26:18.141315  4008 solver.cpp:415]     Test net output #1: loss = 1.9057 (* 1 = 1.9057 loss)
I0518 12:26:18.228852  4008 solver.cpp:231] Iteration 189000, loss = 1.37612
I0518 12:26:18.229043  4008 solver.cpp:247]     Train net output #0: loss = 1.37612 (* 1 = 1.37612 loss)
I0518 12:26:18.229059  4008 sgd_solver.cpp:106] Iteration 189000, lr = 0.001
I0518 12:26:18.394932  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1327	2.08333	77.9209	0	88.0934	4.42708	85.3392	0	80.8555	0	79.1614	0	70.3298	0	26.88	2	
I0518 12:26:18.469410  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:26:18.471199  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:26:18.471264  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:26:18.481698  4008 solver.cpp:260]     Total regularization terms: 1.04226 loss+regular. : 2.41837
I0518 12:27:43.127357  4008 solver.cpp:231] Iteration 189200, loss = 1.43897
I0518 12:27:43.127667  4008 solver.cpp:247]     Train net output #0: loss = 1.43897 (* 1 = 1.43897 loss)
I0518 12:27:43.127687  4008 sgd_solver.cpp:106] Iteration 189200, lr = 0.001
I0518 12:27:43.287513  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.193	2.08333	78.0195	0	88.1106	4.42708	85.3681	0	80.8818	0	79.1791	0	70.3511	0	26.8883	2	
I0518 12:27:43.362995  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:27:43.365231  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:27:43.365285  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:27:43.379215  4008 solver.cpp:260]     Total regularization terms: 1.04203 loss+regular. : 2.48101
I0518 12:28:46.157243  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:29:10.362159  4008 solver.cpp:231] Iteration 189400, loss = 1.48538
I0518 12:29:10.362268  4008 solver.cpp:247]     Train net output #0: loss = 1.48538 (* 1 = 1.48538 loss)
I0518 12:29:10.362296  4008 sgd_solver.cpp:106] Iteration 189400, lr = 0.001
I0518 12:29:10.522902  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0581	2.08333	78.0508	0	88.1333	4.42708	85.3751	0	80.8955	0	79.1966	0	70.3723	0	26.8959	2	
I0518 12:29:10.598268  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:29:10.600069  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:29:10.600118  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:29:10.615202  4008 solver.cpp:260]     Total regularization terms: 1.04181 loss+regular. : 2.52719
I0518 12:30:34.812628  4008 solver.cpp:231] Iteration 189600, loss = 1.28735
I0518 12:30:34.812947  4008 solver.cpp:247]     Train net output #0: loss = 1.28735 (* 1 = 1.28735 loss)
I0518 12:30:34.812968  4008 sgd_solver.cpp:106] Iteration 189600, lr = 0.001
I0518 12:30:34.973568  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.6104	2.08333	78.0192	0	88.1339	4.42708	85.373	0	80.891	0	79.2142	0	70.3927	0	26.9037	2	
I0518 12:30:35.048779  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:30:35.051085  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:30:35.051137  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:30:35.080772  4008 solver.cpp:260]     Total regularization terms: 1.04156 loss+regular. : 2.32891
I0518 12:32:07.069078  4008 solver.cpp:231] Iteration 189800, loss = 1.48646
I0518 12:32:07.069356  4008 solver.cpp:247]     Train net output #0: loss = 1.48646 (* 1 = 1.48646 loss)
I0518 12:32:07.069378  4008 sgd_solver.cpp:106] Iteration 189800, lr = 0.001
I0518 12:32:07.230198  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9978	2.08333	77.8301	0	88.1246	4.42708	85.3424	0	80.9186	0	79.2318	0	70.4137	0	26.9108	2	
I0518 12:32:07.306143  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:32:07.308997  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:32:07.309048  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:32:07.319675  4008 solver.cpp:260]     Total regularization terms: 1.04136 loss+regular. : 2.52782
I0518 12:33:39.640892  4008 solver.cpp:348] Iteration 190000, Testing net (#0)
I0518 12:34:19.397521  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:35:10.883149  4008 solver.cpp:415]     Test net output #0: accuracy = 0.553079
I0518 12:35:10.883558  4008 solver.cpp:415]     Test net output #1: loss = 1.92087 (* 1 = 1.92087 loss)
I0518 12:35:10.975391  4008 solver.cpp:231] Iteration 190000, loss = 1.38046
I0518 12:35:10.975479  4008 solver.cpp:247]     Train net output #0: loss = 1.38046 (* 1 = 1.38046 loss)
I0518 12:35:10.975497  4008 sgd_solver.cpp:106] Iteration 190000, lr = 0.001
I0518 12:35:11.134410  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8572	2.08333	77.9355	0	88.1402	4.42708	85.3831	0	80.9141	0	79.2495	0	70.435	0	26.9192	2	
I0518 12:35:11.210901  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:35:11.212548  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:35:11.212591  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:35:11.222398  4008 solver.cpp:260]     Total regularization terms: 1.04109 loss+regular. : 2.42155
I0518 12:36:31.840306  4008 solver.cpp:231] Iteration 190200, loss = 1.35288
I0518 12:36:31.840667  4008 solver.cpp:247]     Train net output #0: loss = 1.35288 (* 1 = 1.35288 loss)
I0518 12:36:31.840777  4008 sgd_solver.cpp:106] Iteration 190200, lr = 0.001
I0518 12:36:31.998916  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0409	2.08333	77.8509	0	88.16	4.42708	85.3901	0	80.9525	0	79.2669	0	70.456	0	26.9271	2	
I0518 12:36:32.073583  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:36:32.075474  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:36:32.075532  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:36:32.085367  4008 solver.cpp:260]     Total regularization terms: 1.04082 loss+regular. : 2.3937
I0518 12:37:37.712411  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:37:59.210352  4008 solver.cpp:231] Iteration 190400, loss = 1.64098
I0518 12:37:59.210465  4008 solver.cpp:247]     Train net output #0: loss = 1.64098 (* 1 = 1.64098 loss)
I0518 12:37:59.210492  4008 sgd_solver.cpp:106] Iteration 190400, lr = 0.001
I0518 12:37:59.371495  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8457	2.08333	77.904	0	88.163	4.42708	85.4013	0	80.9555	0	79.2844	0	70.4769	0	26.9354	2	
I0518 12:37:59.446388  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:37:59.448460  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:37:59.448515  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:37:59.468561  4008 solver.cpp:260]     Total regularization terms: 1.04072 loss+regular. : 2.68171
I0518 12:39:22.641652  4008 solver.cpp:231] Iteration 190600, loss = 1.6216
I0518 12:39:22.642055  4008 solver.cpp:247]     Train net output #0: loss = 1.6216 (* 1 = 1.6216 loss)
I0518 12:39:22.642077  4008 sgd_solver.cpp:106] Iteration 190600, lr = 0.001
I0518 12:39:22.802202  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2561	2.08333	78.1289	0	88.1933	4.42708	85.4479	0	80.9765	0	79.3016	0	70.498	0	26.9435	2	
I0518 12:39:22.876104  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:39:22.877549  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:39:22.877593  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:39:22.887457  4008 solver.cpp:260]     Total regularization terms: 1.04046 loss+regular. : 2.66206
I0518 12:40:49.833241  4008 solver.cpp:231] Iteration 190800, loss = 1.53741
I0518 12:40:49.833626  4008 solver.cpp:247]     Train net output #0: loss = 1.53741 (* 1 = 1.53741 loss)
I0518 12:40:49.833788  4008 sgd_solver.cpp:106] Iteration 190800, lr = 0.001
I0518 12:40:49.993286  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0667	2.08333	77.9271	0	88.1338	4.42708	85.4162	0	80.9575	0	79.3194	0	70.5193	0	26.9513	2	
I0518 12:40:50.068017  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:40:50.069335  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:40:50.069362  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:40:50.079107  4008 solver.cpp:260]     Total regularization terms: 1.04026 loss+regular. : 2.57767
I0518 12:42:10.761998  4008 solver.cpp:348] Iteration 191000, Testing net (#0)
I0518 12:42:37.332798  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:43:30.684190  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55124
I0518 12:43:30.684731  4008 solver.cpp:415]     Test net output #1: loss = 1.92717 (* 1 = 1.92717 loss)
I0518 12:43:30.772423  4008 solver.cpp:231] Iteration 191000, loss = 1.52243
I0518 12:43:30.772532  4008 solver.cpp:247]     Train net output #0: loss = 1.52243 (* 1 = 1.52243 loss)
I0518 12:43:30.772558  4008 sgd_solver.cpp:106] Iteration 191000, lr = 0.001
I0518 12:43:30.938627  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2016	2.08333	78.0807	0	88.1669	4.42708	85.4542	0	80.9921	0	79.337	0	70.5397	0	26.9589	2	
I0518 12:43:31.012997  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:43:31.015049  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:43:31.015108  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:43:31.028590  4008 solver.cpp:260]     Total regularization terms: 1.04 loss+regular. : 2.56243
I0518 12:44:48.936939  4008 solver.cpp:231] Iteration 191200, loss = 1.47927
I0518 12:44:48.937412  4008 solver.cpp:247]     Train net output #0: loss = 1.47927 (* 1 = 1.47927 loss)
I0518 12:44:48.937444  4008 sgd_solver.cpp:106] Iteration 191200, lr = 0.001
I0518 12:44:49.096581  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0323	2.08333	78.0898	0	88.1363	4.42708	85.4271	0	80.9959	0	79.3545	0	70.5608	0	26.9661	2	
I0518 12:44:49.171416  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:44:49.173732  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:44:49.173800  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:44:49.184026  4008 solver.cpp:260]     Total regularization terms: 1.03977 loss+regular. : 2.51904
I0518 12:46:01.633793  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:46:19.965430  4008 solver.cpp:231] Iteration 191400, loss = 1.45757
I0518 12:46:19.965545  4008 solver.cpp:247]     Train net output #0: loss = 1.45757 (* 1 = 1.45757 loss)
I0518 12:46:19.965590  4008 sgd_solver.cpp:106] Iteration 191400, lr = 0.001
I0518 12:46:20.124725  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8859	2.08333	78.2887	0	88.2039	4.42708	85.4753	0	81.0228	0	79.3719	0	70.5819	0	26.9737	2	
I0518 12:46:20.199133  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:46:20.201006  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:46:20.201050  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:46:20.211127  4008 solver.cpp:260]     Total regularization terms: 1.03952 loss+regular. : 2.49709
I0518 12:47:43.910938  4008 solver.cpp:231] Iteration 191600, loss = 1.61786
I0518 12:47:43.911200  4008 solver.cpp:247]     Train net output #0: loss = 1.61786 (* 1 = 1.61786 loss)
I0518 12:47:43.911228  4008 sgd_solver.cpp:106] Iteration 191600, lr = 0.001
I0518 12:47:44.070169  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0523	2.08333	78.3597	0	88.1985	4.42708	85.4766	0	81.0151	0	79.3894	0	70.603	0	26.9822	2	
I0518 12:47:44.144474  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:47:44.146494  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:47:44.146549  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:47:44.156787  4008 solver.cpp:260]     Total regularization terms: 1.03933 loss+regular. : 2.65719
I0518 12:49:05.435017  4008 solver.cpp:231] Iteration 191800, loss = 1.61981
I0518 12:49:05.435374  4008 solver.cpp:247]     Train net output #0: loss = 1.61981 (* 1 = 1.61981 loss)
I0518 12:49:05.435398  4008 sgd_solver.cpp:106] Iteration 191800, lr = 0.001
I0518 12:49:05.596474  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8687	2.08333	77.9421	0	88.218	4.42708	85.4846	0	81.0314	0	79.4075	0	70.6237	0	26.9893	2	
I0518 12:49:05.676604  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:49:05.678632  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:49:05.678676  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:49:05.688364  4008 solver.cpp:260]     Total regularization terms: 1.03914 loss+regular. : 2.65895
I0518 12:50:28.216830  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_192000.caffemodel
I0518 12:53:44.512377  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_192000.solverstate
I0518 12:53:45.366379  4008 solver.cpp:348] Iteration 192000, Testing net (#0)
I0518 12:54:12.268801  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:55:06.963086  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55272
I0518 12:55:06.969668  4008 solver.cpp:415]     Test net output #1: loss = 1.92207 (* 1 = 1.92207 loss)
I0518 12:55:07.061221  4008 solver.cpp:231] Iteration 192000, loss = 1.42132
I0518 12:55:07.061306  4008 solver.cpp:247]     Train net output #0: loss = 1.42132 (* 1 = 1.42132 loss)
I0518 12:55:07.061324  4008 sgd_solver.cpp:106] Iteration 192000, lr = 0.001
I0518 12:55:07.229838  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.015	2.08333	78.0775	0	88.2003	4.42708	85.4678	0	81.0178	0	79.425	0	70.6444	0	26.997	2	
I0518 12:55:07.231577  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:55:07.234076  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:55:07.234133  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:55:07.244010  4008 solver.cpp:260]     Total regularization terms: 1.03892 loss+regular. : 2.46024
I0518 12:56:26.804837  4008 solver.cpp:231] Iteration 192200, loss = 1.42605
I0518 12:56:26.805250  4008 solver.cpp:247]     Train net output #0: loss = 1.42605 (* 1 = 1.42605 loss)
I0518 12:56:26.805276  4008 sgd_solver.cpp:106] Iteration 192200, lr = 0.001
I0518 12:56:26.966145  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2073	2.08333	78.1875	0	88.2236	4.42708	85.5062	0	81.0414	0	79.4429	0	70.6647	0	27.0043	2	
I0518 12:56:27.040621  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:56:27.042424  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:56:27.042486  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:56:27.052799  4008 solver.cpp:260]     Total regularization terms: 1.03872 loss+regular. : 2.46477
I0518 12:57:37.147646  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 12:57:50.942651  4008 solver.cpp:231] Iteration 192400, loss = 1.30649
I0518 12:57:50.942764  4008 solver.cpp:247]     Train net output #0: loss = 1.30649 (* 1 = 1.30649 loss)
I0518 12:57:50.942785  4008 sgd_solver.cpp:106] Iteration 192400, lr = 0.001
I0518 12:57:51.102618  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0208	2.08333	78.2233	0	88.2219	4.42708	85.5289	0	81.0653	0	79.4599	0	70.6847	0	27.0118	2	
I0518 12:57:51.177419  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:57:51.182926  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:57:51.182996  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:57:51.193197  4008 solver.cpp:260]     Total regularization terms: 1.03851 loss+regular. : 2.345
I0518 12:59:19.741046  4008 solver.cpp:231] Iteration 192600, loss = 1.34234
I0518 12:59:19.741530  4008 solver.cpp:247]     Train net output #0: loss = 1.34234 (* 1 = 1.34234 loss)
I0518 12:59:19.741564  4008 sgd_solver.cpp:106] Iteration 192600, lr = 0.001
I0518 12:59:19.901478  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9863	2.08333	78.0518	0	88.2365	4.42708	85.5261	0	81.0771	0	79.4773	0	70.7056	0	27.0195	2	
I0518 12:59:19.975868  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 12:59:19.977706  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 12:59:19.977763  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 12:59:19.988013  4008 solver.cpp:260]     Total regularization terms: 1.0383 loss+regular. : 2.38065
I0518 13:00:44.617234  4008 solver.cpp:231] Iteration 192800, loss = 1.3994
I0518 13:00:44.618063  4008 solver.cpp:247]     Train net output #0: loss = 1.3994 (* 1 = 1.3994 loss)
I0518 13:00:44.618093  4008 sgd_solver.cpp:106] Iteration 192800, lr = 0.001
I0518 13:00:44.777422  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2274	2.08333	78.0723	0	88.2428	4.42708	85.5395	0	81.0755	0	79.4944	0	70.7263	0	27.0274	2	
I0518 13:00:44.851945  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:00:44.853899  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 13:00:44.853946  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:00:44.863828  4008 solver.cpp:260]     Total regularization terms: 1.03799 loss+regular. : 2.43739
I0518 13:02:18.056985  4008 solver.cpp:348] Iteration 193000, Testing net (#0)
I0518 13:02:47.650825  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:03:34.598734  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55368
I0518 13:03:34.599038  4008 solver.cpp:415]     Test net output #1: loss = 1.91668 (* 1 = 1.91668 loss)
I0518 13:03:34.688459  4008 solver.cpp:231] Iteration 193000, loss = 1.46478
I0518 13:03:34.688565  4008 solver.cpp:247]     Train net output #0: loss = 1.46478 (* 1 = 1.46478 loss)
I0518 13:03:34.688591  4008 sgd_solver.cpp:106] Iteration 193000, lr = 0.001
I0518 13:03:34.854181  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.213	2.08333	78.4082	0	88.2601	4.42708	85.5335	0	81.0737	0	79.512	0	70.7461	0	27.0348	2	
I0518 13:03:34.929313  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:03:34.931290  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 13:03:34.931336  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:03:34.941195  4008 solver.cpp:260]     Total regularization terms: 1.03772 loss+regular. : 2.50251
I0518 13:05:07.730072  4008 solver.cpp:231] Iteration 193200, loss = 1.21293
I0518 13:05:07.732409  4008 solver.cpp:247]     Train net output #0: loss = 1.21293 (* 1 = 1.21293 loss)
I0518 13:05:07.732458  4008 sgd_solver.cpp:106] Iteration 193200, lr = 0.001
I0518 13:05:07.889315  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2934	2.08333	78.2842	0	88.2738	4.42708	85.5531	0	81.1042	0	79.5294	0	70.7665	0	27.0423	2	
I0518 13:05:07.963557  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:05:07.965600  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 13:05:07.965658  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:05:07.975504  4008 solver.cpp:260]     Total regularization terms: 1.03752 loss+regular. : 2.25045
I0518 13:06:16.054483  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:06:30.523409  4008 solver.cpp:231] Iteration 193400, loss = 1.40318
I0518 13:06:30.523501  4008 solver.cpp:247]     Train net output #0: loss = 1.40318 (* 1 = 1.40318 loss)
I0518 13:06:30.523519  4008 sgd_solver.cpp:106] Iteration 193400, lr = 0.001
I0518 13:06:30.685811  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4426	2.08333	78.1582	0	88.2685	4.42708	85.5562	0	81.1295	0	79.5469	0	70.7865	0	27.05	2	
I0518 13:06:30.760388  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:06:30.762334  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 13:06:30.762382  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:06:30.772438  4008 solver.cpp:260]     Total regularization terms: 1.03731 loss+regular. : 2.44049
I0518 13:07:52.568105  4008 solver.cpp:231] Iteration 193600, loss = 1.57615
I0518 13:07:52.568507  4008 solver.cpp:247]     Train net output #0: loss = 1.57615 (* 1 = 1.57615 loss)
I0518 13:07:52.568529  4008 sgd_solver.cpp:106] Iteration 193600, lr = 0.001
I0518 13:07:52.728253  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2991	2.08333	78.1888	0	88.2775	4.42708	85.5836	0	81.1211	0	79.5639	0	70.8069	0	27.058	2	
I0518 13:07:52.802505  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:07:52.804437  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 13:07:52.804496  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:07:52.814357  4008 solver.cpp:260]     Total regularization terms: 1.03707 loss+regular. : 2.61322
I0518 13:09:24.304796  4008 solver.cpp:231] Iteration 193800, loss = 1.39643
I0518 13:09:24.305074  4008 solver.cpp:247]     Train net output #0: loss = 1.39643 (* 1 = 1.39643 loss)
I0518 13:09:24.305095  4008 sgd_solver.cpp:106] Iteration 193800, lr = 0.001
I0518 13:09:24.466652  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1442	2.08333	78.3229	0	88.2996	4.42708	85.6118	0	81.1243	0	79.5817	0	70.827	0	27.0653	2	
I0518 13:09:24.541224  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:09:24.543069  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 13:09:24.543131  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:09:24.553390  4008 solver.cpp:260]     Total regularization terms: 1.03688 loss+regular. : 2.43331
I0518 13:11:05.470304  4008 solver.cpp:348] Iteration 194000, Testing net (#0)
I0518 13:11:35.455765  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:12:30.554689  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55282
I0518 13:12:30.555080  4008 solver.cpp:415]     Test net output #1: loss = 1.92238 (* 1 = 1.92238 loss)
I0518 13:12:30.642901  4008 solver.cpp:231] Iteration 194000, loss = 1.27263
I0518 13:12:30.643025  4008 solver.cpp:247]     Train net output #0: loss = 1.27263 (* 1 = 1.27263 loss)
I0518 13:12:30.643049  4008 sgd_solver.cpp:106] Iteration 194000, lr = 0.001
I0518 13:12:30.812100  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9519	2.08333	78.2757	0	88.2839	4.42708	85.599	0	81.1329	0	79.5985	0	70.8476	0	27.0734	2	
I0518 13:12:30.886556  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:12:30.888360  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 13:12:30.888403  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:12:30.899966  4008 solver.cpp:260]     Total regularization terms: 1.03664 loss+regular. : 2.30927
I0518 13:13:59.291110  4008 solver.cpp:231] Iteration 194200, loss = 1.38098
I0518 13:13:59.291452  4008 solver.cpp:247]     Train net output #0: loss = 1.38098 (* 1 = 1.38098 loss)
I0518 13:13:59.291474  4008 sgd_solver.cpp:106] Iteration 194200, lr = 0.001
I0518 13:13:59.450201  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.774	2.08333	78.2588	0	88.2985	4.42708	85.5808	0	81.156	0	79.6157	0	70.8682	0	27.0803	2	
I0518 13:13:59.524688  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:13:59.526180  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.42708	0	0	0	0	0	0	0	0	0	2	
I0518 13:13:59.526221  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:13:59.535908  4008 solver.cpp:260]     Total regularization terms: 1.03645 loss+regular. : 2.41743
I0518 13:15:28.024740  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:15:38.127094  4008 solver.cpp:231] Iteration 194400, loss = 1.42467
I0518 13:15:38.127207  4008 solver.cpp:247]     Train net output #0: loss = 1.42467 (* 1 = 1.42467 loss)
I0518 13:15:38.127226  4008 sgd_solver.cpp:106] Iteration 194400, lr = 0.001
I0518 13:15:38.289345  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0896	2.08333	77.721	0	88.2925	4.6875	85.5963	0	81.1548	0	79.6324	0	70.8885	0	27.0874	2	
I0518 13:15:38.363620  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:15:38.365510  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:15:38.365566  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:15:38.375411  4008 solver.cpp:260]     Total regularization terms: 1.03629 loss+regular. : 2.46096
I0518 13:17:06.176708  4008 solver.cpp:231] Iteration 194600, loss = 1.61783
I0518 13:17:06.177054  4008 solver.cpp:247]     Train net output #0: loss = 1.61783 (* 1 = 1.61783 loss)
I0518 13:17:06.177083  4008 sgd_solver.cpp:106] Iteration 194600, lr = 0.001
I0518 13:17:06.336237  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1183	2.08333	78.2207	0	88.323	4.6875	85.6124	0	81.1542	0	79.6495	0	70.9083	0	27.095	2	
I0518 13:17:06.410770  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:17:06.412639  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:17:06.412684  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:17:06.422926  4008 solver.cpp:260]     Total regularization terms: 1.03606 loss+regular. : 2.65389
I0518 13:18:40.376523  4008 solver.cpp:231] Iteration 194800, loss = 1.57636
I0518 13:18:40.377022  4008 solver.cpp:247]     Train net output #0: loss = 1.57636 (* 1 = 1.57636 loss)
I0518 13:18:40.377054  4008 sgd_solver.cpp:106] Iteration 194800, lr = 0.001
I0518 13:18:40.536979  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4283	2.08333	78.1325	0	88.3336	4.6875	85.6319	0	81.1862	0	79.6663	0	70.929	0	27.1022	2	
I0518 13:18:40.612133  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:18:40.614657  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:18:40.614701  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:18:40.624707  4008 solver.cpp:260]     Total regularization terms: 1.03577 loss+regular. : 2.61212
I0518 13:20:07.017204  4008 solver.cpp:348] Iteration 195000, Testing net (#0)
I0518 13:20:36.926168  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:21:31.240869  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55102
I0518 13:21:31.241901  4008 solver.cpp:415]     Test net output #1: loss = 1.93036 (* 1 = 1.93036 loss)
I0518 13:21:31.336038  4008 solver.cpp:231] Iteration 195000, loss = 1.54993
I0518 13:21:31.336138  4008 solver.cpp:247]     Train net output #0: loss = 1.54993 (* 1 = 1.54993 loss)
I0518 13:21:31.336158  4008 sgd_solver.cpp:106] Iteration 195000, lr = 0.001
I0518 13:21:31.495322  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2044	2.08333	78.2103	0	88.3059	4.6875	85.5993	0	81.1625	0	79.6828	0	70.949	0	27.1106	2	
I0518 13:21:31.572722  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:21:31.580773  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:21:31.580843  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:21:31.591609  4008 solver.cpp:260]     Total regularization terms: 1.03552 loss+regular. : 2.58546
I0518 13:22:58.575778  4008 solver.cpp:231] Iteration 195200, loss = 1.52054
I0518 13:22:58.577687  4008 solver.cpp:247]     Train net output #0: loss = 1.52054 (* 1 = 1.52054 loss)
I0518 13:22:58.577724  4008 sgd_solver.cpp:106] Iteration 195200, lr = 0.001
I0518 13:22:58.735440  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1757	2.08333	78.3018	0	88.345	4.6875	85.6427	0	81.2023	0	79.6999	0	70.9686	0	27.1192	2	
I0518 13:22:58.810832  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:22:58.814435  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:22:58.814501  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:22:58.827425  4008 solver.cpp:260]     Total regularization terms: 1.03535 loss+regular. : 2.55589
I0518 13:24:23.106758  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:24:29.546885  4008 solver.cpp:231] Iteration 195400, loss = 1.46256
I0518 13:24:29.547003  4008 solver.cpp:247]     Train net output #0: loss = 1.46256 (* 1 = 1.46256 loss)
I0518 13:24:29.547029  4008 sgd_solver.cpp:106] Iteration 195400, lr = 0.001
I0518 13:24:29.706868  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.236	2.08333	78.0781	0	88.3407	4.6875	85.6433	0	81.2003	0	79.7167	0	70.9886	0	27.1271	2	
I0518 13:24:29.782383  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:24:29.784976  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:24:29.785024  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:24:29.795137  4008 solver.cpp:260]     Total regularization terms: 1.03515 loss+regular. : 2.49771
I0518 13:26:00.468472  4008 solver.cpp:231] Iteration 195600, loss = 1.42439
I0518 13:26:00.469156  4008 solver.cpp:247]     Train net output #0: loss = 1.42439 (* 1 = 1.42439 loss)
I0518 13:26:00.469223  4008 sgd_solver.cpp:106] Iteration 195600, lr = 0.001
I0518 13:26:00.628866  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1901	2.08333	78.4147	0	88.3673	4.6875	85.6576	0	81.2168	0	79.7336	0	71.0091	0	27.1346	2	
I0518 13:26:00.703104  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:26:00.704610  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:26:00.704650  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:26:00.716035  4008 solver.cpp:260]     Total regularization terms: 1.03487 loss+regular. : 2.45925
I0518 13:27:23.984954  4008 solver.cpp:231] Iteration 195800, loss = 1.50957
I0518 13:27:23.985288  4008 solver.cpp:247]     Train net output #0: loss = 1.50957 (* 1 = 1.50957 loss)
I0518 13:27:23.985311  4008 sgd_solver.cpp:106] Iteration 195800, lr = 0.001
I0518 13:27:24.146628  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2733	2.08333	78.2464	0	88.385	4.6875	85.6717	0	81.2294	0	79.7504	0	71.0291	0	27.1409	2	
I0518 13:27:24.221654  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:27:24.224681  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:27:24.224730  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:27:24.234681  4008 solver.cpp:260]     Total regularization terms: 1.03463 loss+regular. : 2.5442
I0518 13:28:56.444628  4008 solver.cpp:348] Iteration 196000, Testing net (#0)
I0518 13:29:26.460393  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:30:27.846390  4008 solver.cpp:415]     Test net output #0: accuracy = 0.554
I0518 13:30:27.847096  4008 solver.cpp:415]     Test net output #1: loss = 1.91365 (* 1 = 1.91365 loss)
I0518 13:30:27.945166  4008 solver.cpp:231] Iteration 196000, loss = 1.46498
I0518 13:30:27.945250  4008 solver.cpp:247]     Train net output #0: loss = 1.46498 (* 1 = 1.46498 loss)
I0518 13:30:27.945271  4008 sgd_solver.cpp:106] Iteration 196000, lr = 0.001
I0518 13:30:28.112243  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3106	2.08333	78.2682	0	88.3802	4.6875	85.6786	0	81.2428	0	79.7675	0	71.0495	0	27.1488	2	
I0518 13:30:28.187237  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:30:28.190390  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:30:28.190439  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:30:28.200418  4008 solver.cpp:260]     Total regularization terms: 1.03443 loss+regular. : 2.49941
I0518 13:32:04.733186  4008 solver.cpp:231] Iteration 196200, loss = 1.52461
I0518 13:32:04.733505  4008 solver.cpp:247]     Train net output #0: loss = 1.52461 (* 1 = 1.52461 loss)
I0518 13:32:04.733525  4008 sgd_solver.cpp:106] Iteration 196200, lr = 0.001
I0518 13:32:04.894434  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5115	2.08333	78.3854	0	88.3805	4.6875	85.7087	0	81.2527	0	79.7844	0	71.0692	0	27.1567	2	
I0518 13:32:04.969146  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:32:04.970988  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:32:04.971047  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:32:04.981078  4008 solver.cpp:260]     Total regularization terms: 1.03417 loss+regular. : 2.55878
I0518 13:33:25.328327  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:33:27.836367  4008 solver.cpp:231] Iteration 196400, loss = 1.5286
I0518 13:33:27.836506  4008 solver.cpp:247]     Train net output #0: loss = 1.5286 (* 1 = 1.5286 loss)
I0518 13:33:27.836558  4008 sgd_solver.cpp:106] Iteration 196400, lr = 0.001
I0518 13:33:27.996891  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6722	2.08333	78.5273	0	88.4068	4.6875	85.7089	0	81.271	0	79.8007	0	71.0888	0	27.1635	2	
I0518 13:33:28.071657  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:33:28.073501  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:33:28.073561  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:33:28.085203  4008 solver.cpp:260]     Total regularization terms: 1.03397 loss+regular. : 2.56257
I0518 13:34:58.087162  4008 solver.cpp:231] Iteration 196600, loss = 1.28573
I0518 13:34:58.087604  4008 solver.cpp:247]     Train net output #0: loss = 1.28573 (* 1 = 1.28573 loss)
I0518 13:34:58.087632  4008 sgd_solver.cpp:106] Iteration 196600, lr = 0.001
I0518 13:34:58.244976  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5316	2.08333	78.2913	0	88.3616	4.6875	85.719	0	81.2857	0	79.8171	0	71.1086	0	27.1712	2	
I0518 13:34:58.319411  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:34:58.321120  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:34:58.321161  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:34:58.331086  4008 solver.cpp:260]     Total regularization terms: 1.0338 loss+regular. : 2.31952
I0518 13:36:34.154788  4008 solver.cpp:231] Iteration 196800, loss = 1.32118
I0518 13:36:34.155117  4008 solver.cpp:247]     Train net output #0: loss = 1.32118 (* 1 = 1.32118 loss)
I0518 13:36:34.155138  4008 sgd_solver.cpp:106] Iteration 196800, lr = 0.001
I0518 13:36:34.314807  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3766	2.08333	78.5101	0	88.3753	4.6875	85.7371	0	81.2936	0	79.8337	0	71.1283	0	27.1795	2	
I0518 13:36:34.389222  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:36:34.391185  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:36:34.391229  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:36:34.401101  4008 solver.cpp:260]     Total regularization terms: 1.0335 loss+regular. : 2.35468
I0518 13:37:59.820614  4008 solver.cpp:348] Iteration 197000, Testing net (#0)
I0518 13:38:36.900166  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:39:26.695806  4008 solver.cpp:415]     Test net output #0: accuracy = 0.552
I0518 13:39:26.696102  4008 solver.cpp:415]     Test net output #1: loss = 1.929 (* 1 = 1.929 loss)
I0518 13:39:26.786658  4008 solver.cpp:231] Iteration 197000, loss = 1.46294
I0518 13:39:26.786762  4008 solver.cpp:247]     Train net output #0: loss = 1.46294 (* 1 = 1.46294 loss)
I0518 13:39:26.786785  4008 sgd_solver.cpp:106] Iteration 197000, lr = 0.001
I0518 13:39:26.951918  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.434	2.08333	78.2601	0	88.4042	4.6875	85.7362	0	81.2995	0	79.85	0	71.1476	0	27.1872	2	
I0518 13:39:27.026741  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.911458	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:39:27.028687  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:39:27.028733  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:39:27.038604  4008 solver.cpp:260]     Total regularization terms: 1.03325 loss+regular. : 2.49619
I0518 13:40:54.800402  4008 solver.cpp:231] Iteration 197200, loss = 1.27029
I0518 13:40:54.800885  4008 solver.cpp:247]     Train net output #0: loss = 1.27029 (* 1 = 1.27029 loss)
I0518 13:40:54.800920  4008 sgd_solver.cpp:106] Iteration 197200, lr = 0.001
I0518 13:40:54.959931  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4627	2.08333	78.2188	0	88.3739	4.6875	85.7149	0	81.2902	0	79.8669	0	71.1672	0	27.1953	2	
I0518 13:40:55.034692  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:40:55.036309  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:40:55.036361  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:40:55.046339  4008 solver.cpp:260]     Total regularization terms: 1.03308 loss+regular. : 2.30337
I0518 13:42:24.688946  4008 solver.cpp:231] Iteration 197400, loss = 1.52213
I0518 13:42:24.689400  4008 solver.cpp:247]     Train net output #0: loss = 1.52213 (* 1 = 1.52213 loss)
I0518 13:42:24.689429  4008 sgd_solver.cpp:106] Iteration 197400, lr = 0.001
I0518 13:42:24.848582  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4455	2.08333	78.3711	0	88.4195	4.6875	85.7607	0	81.3316	0	79.8836	0	71.1874	0	27.2025	2	
I0518 13:42:24.923203  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:42:24.925143  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:42:24.925191  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:42:24.935091  4008 solver.cpp:260]     Total regularization terms: 1.03285 loss+regular. : 2.55498
I0518 13:42:24.935379  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:43:50.298602  4008 solver.cpp:231] Iteration 197600, loss = 1.37923
I0518 13:43:50.299093  4008 solver.cpp:247]     Train net output #0: loss = 1.37923 (* 1 = 1.37923 loss)
I0518 13:43:50.299130  4008 sgd_solver.cpp:106] Iteration 197600, lr = 0.001
I0518 13:43:50.458330  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2216	2.08333	78.1758	0	88.4022	4.6875	85.7484	0	81.3307	0	79.9002	0	71.2071	0	27.2089	2	
I0518 13:43:50.532871  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:43:50.534587  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:43:50.534634  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:43:50.544469  4008 solver.cpp:260]     Total regularization terms: 1.03269 loss+regular. : 2.41192
I0518 13:45:18.591895  4008 solver.cpp:231] Iteration 197800, loss = 1.17679
I0518 13:45:18.592149  4008 solver.cpp:247]     Train net output #0: loss = 1.17679 (* 1 = 1.17679 loss)
I0518 13:45:18.592173  4008 sgd_solver.cpp:106] Iteration 197800, lr = 0.001
I0518 13:45:18.753319  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2762	2.08333	78.4092	0	88.4135	4.6875	85.7464	0	81.33	0	79.9162	0	71.2265	0	27.2154	2	
I0518 13:45:18.827934  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:45:18.829859  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:45:18.829898  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:45:18.839807  4008 solver.cpp:260]     Total regularization terms: 1.03237 loss+regular. : 2.20916
I0518 13:46:49.992538  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_198000.caffemodel
I0518 13:48:13.482990  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_198000.solverstate
I0518 13:48:14.315675  4008 solver.cpp:348] Iteration 198000, Testing net (#0)
I0518 13:48:52.294019  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:49:40.857076  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55598
I0518 13:49:40.857378  4008 solver.cpp:415]     Test net output #1: loss = 1.91319 (* 1 = 1.91319 loss)
I0518 13:49:40.946380  4008 solver.cpp:231] Iteration 198000, loss = 1.36324
I0518 13:49:40.946461  4008 solver.cpp:247]     Train net output #0: loss = 1.36324 (* 1 = 1.36324 loss)
I0518 13:49:40.946486  4008 sgd_solver.cpp:106] Iteration 198000, lr = 0.001
I0518 13:49:41.112867  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4426	2.08333	78.306	0	88.4407	4.6875	85.7619	0	81.3506	0	79.9329	0	71.2462	0	27.2225	2	
I0518 13:49:41.114416  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:49:41.116221  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:49:41.116250  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:49:41.126199  4008 solver.cpp:260]     Total regularization terms: 1.03213 loss+regular. : 2.39537
I0518 13:51:12.628005  4008 solver.cpp:231] Iteration 198200, loss = 1.40214
I0518 13:51:12.628608  4008 solver.cpp:247]     Train net output #0: loss = 1.40214 (* 1 = 1.40214 loss)
I0518 13:51:12.628631  4008 sgd_solver.cpp:106] Iteration 198200, lr = 0.001
I0518 13:51:12.787029  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3422	2.08333	78.248	0	88.4293	4.6875	85.7767	0	81.3497	0	79.949	0	71.266	0	27.23	2	
I0518 13:51:12.861779  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:51:12.863770  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:51:12.863821  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:51:12.873702  4008 solver.cpp:260]     Total regularization terms: 1.03199 loss+regular. : 2.43413
I0518 13:52:32.496328  4008 solver.cpp:231] Iteration 198400, loss = 1.46761
I0518 13:52:32.496667  4008 solver.cpp:247]     Train net output #0: loss = 1.46761 (* 1 = 1.46761 loss)
I0518 13:52:32.496695  4008 sgd_solver.cpp:106] Iteration 198400, lr = 0.001
I0518 13:52:32.656503  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.543	2.08333	78.3356	0	88.4309	4.6875	85.7803	0	81.351	0	79.9652	0	71.2853	0	27.2375	2	
I0518 13:52:32.731091  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:52:32.733319  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:52:32.733355  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:52:32.748273  4008 solver.cpp:260]     Total regularization terms: 1.03177 loss+regular. : 2.49939
I0518 13:52:35.518476  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:53:48.725124  4008 solver.cpp:231] Iteration 198600, loss = 1.43832
I0518 13:53:48.725447  4008 solver.cpp:247]     Train net output #0: loss = 1.43832 (* 1 = 1.43832 loss)
I0518 13:53:48.725466  4008 sgd_solver.cpp:106] Iteration 198600, lr = 0.001
I0518 13:53:48.886452  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4197	2.08333	77.9909	0	88.4358	4.6875	85.7856	0	81.3775	0	79.9811	0	71.3052	0	27.2449	2	
I0518 13:53:48.960697  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:53:48.962422  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:53:48.962469  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:53:48.972720  4008 solver.cpp:260]     Total regularization terms: 1.03158 loss+regular. : 2.4699
I0518 13:55:12.753343  4008 solver.cpp:231] Iteration 198800, loss = 1.3077
I0518 13:55:12.753662  4008 solver.cpp:247]     Train net output #0: loss = 1.3077 (* 1 = 1.3077 loss)
I0518 13:55:12.753698  4008 sgd_solver.cpp:106] Iteration 198800, lr = 0.001
I0518 13:55:12.914772  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4455	2.08333	78.4242	0	88.4618	4.6875	85.8126	0	81.3886	0	79.9971	0	71.3248	0	27.2527	2	
I0518 13:55:12.990166  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:55:12.992308  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:55:12.992347  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:55:13.007279  4008 solver.cpp:260]     Total regularization terms: 1.03138 loss+regular. : 2.33908
I0518 13:56:31.781986  4008 solver.cpp:348] Iteration 199000, Testing net (#0)
I0518 13:57:03.358924  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 13:57:49.074237  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55398
I0518 13:57:49.077647  4008 solver.cpp:415]     Test net output #1: loss = 1.90838 (* 1 = 1.90838 loss)
I0518 13:57:49.165338  4008 solver.cpp:231] Iteration 199000, loss = 1.32777
I0518 13:57:49.165427  4008 solver.cpp:247]     Train net output #0: loss = 1.32777 (* 1 = 1.32777 loss)
I0518 13:57:49.165451  4008 sgd_solver.cpp:106] Iteration 199000, lr = 0.001
I0518 13:57:49.332026  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.236	2.08333	78.4408	0	88.4619	4.6875	85.835	0	81.3958	0	80.0134	0	71.3447	0	27.2609	2	
I0518 13:57:49.406668  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:57:49.408454  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:57:49.408498  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:57:49.418411  4008 solver.cpp:260]     Total regularization terms: 1.03115 loss+regular. : 2.35892
I0518 13:59:06.798890  4008 solver.cpp:231] Iteration 199200, loss = 1.46428
I0518 13:59:06.799207  4008 solver.cpp:247]     Train net output #0: loss = 1.46428 (* 1 = 1.46428 loss)
I0518 13:59:06.799238  4008 sgd_solver.cpp:106] Iteration 199200, lr = 0.001
I0518 13:59:06.960376  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4483	2.08333	78.5911	0	88.5007	4.6875	85.8528	0	81.4128	0	80.0297	0	71.3646	0	27.2681	2	
I0518 13:59:07.035614  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 13:59:07.037130  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 13:59:07.037171  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 13:59:07.052573  4008 solver.cpp:260]     Total regularization terms: 1.03086 loss+regular. : 2.49514
I0518 14:00:27.018824  4008 solver.cpp:231] Iteration 199400, loss = 1.55712
I0518 14:00:27.019116  4008 solver.cpp:247]     Train net output #0: loss = 1.55712 (* 1 = 1.55712 loss)
I0518 14:00:27.019142  4008 sgd_solver.cpp:106] Iteration 199400, lr = 0.001
I0518 14:00:27.179051  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4053	2.08333	78.4938	0	88.4691	4.6875	85.8171	0	81.4116	0	80.0459	0	71.384	0	27.2756	2	
I0518 14:00:27.253975  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:00:27.255791  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:00:27.255832  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:00:27.265621  4008 solver.cpp:260]     Total regularization terms: 1.03064 loss+regular. : 2.58775
I0518 14:00:33.249166  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:01:53.113070  4008 solver.cpp:231] Iteration 199600, loss = 1.31931
I0518 14:01:53.113405  4008 solver.cpp:247]     Train net output #0: loss = 1.31931 (* 1 = 1.31931 loss)
I0518 14:01:53.113423  4008 sgd_solver.cpp:106] Iteration 199600, lr = 0.001
I0518 14:01:53.273993  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.83	2.08333	78.4326	0	88.4633	4.6875	85.8073	0	81.3965	0	80.0621	0	71.4035	0	27.2832	2	
I0518 14:01:53.348412  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:01:53.350260  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:01:53.350313  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:01:53.360281  4008 solver.cpp:260]     Total regularization terms: 1.03042 loss+regular. : 2.34973
I0518 14:03:25.719310  4008 solver.cpp:231] Iteration 199800, loss = 1.27167
I0518 14:03:25.719784  4008 solver.cpp:247]     Train net output #0: loss = 1.27167 (* 1 = 1.27167 loss)
I0518 14:03:25.719826  4008 sgd_solver.cpp:106] Iteration 199800, lr = 0.001
I0518 14:03:25.878733  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2188	2.08333	78.2594	0	88.4616	4.6875	85.8438	0	81.4485	0	80.0784	0	71.4225	0	27.2902	2	
I0518 14:03:25.953043  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:03:25.954576  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:03:25.954614  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:03:25.964398  4008 solver.cpp:260]     Total regularization terms: 1.03026 loss+regular. : 2.30193
I0518 14:04:53.974061  4008 solver.cpp:348] Iteration 200000, Testing net (#0)
I0518 14:05:29.000267  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:06:15.593148  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55218
I0518 14:06:15.593370  4008 solver.cpp:415]     Test net output #1: loss = 1.92057 (* 1 = 1.92057 loss)
I0518 14:06:15.692104  4008 solver.cpp:231] Iteration 200000, loss = 1.46669
I0518 14:06:15.692205  4008 solver.cpp:247]     Train net output #0: loss = 1.46669 (* 1 = 1.46669 loss)
I0518 14:06:15.692226  4008 sgd_solver.cpp:106] Iteration 200000, lr = 0.001
I0518 14:06:15.856664  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3565	2.08333	78.3311	0	88.4762	4.6875	85.8451	0	81.4449	0	80.0948	0	71.4419	0	27.2975	2	
I0518 14:06:15.931146  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:06:15.932878  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:06:15.932906  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:06:15.942678  4008 solver.cpp:260]     Total regularization terms: 1.02999 loss+regular. : 2.49667
I0518 14:07:37.463789  4008 solver.cpp:231] Iteration 200200, loss = 1.33648
I0518 14:07:37.464110  4008 solver.cpp:247]     Train net output #0: loss = 1.33648 (* 1 = 1.33648 loss)
I0518 14:07:37.464251  4008 sgd_solver.cpp:106] Iteration 200200, lr = 0.001
I0518 14:07:37.626210  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.391	2.08333	78.6025	0	88.494	4.6875	85.8618	0	81.4521	0	80.111	0	71.4611	0	27.3045	2	
I0518 14:07:37.701525  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:07:37.703102  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:07:37.703116  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:07:37.718228  4008 solver.cpp:260]     Total regularization terms: 1.02977 loss+regular. : 2.36625
I0518 14:08:50.120007  4008 solver.cpp:231] Iteration 200400, loss = 1.17284
I0518 14:08:50.120285  4008 solver.cpp:247]     Train net output #0: loss = 1.17284 (* 1 = 1.17284 loss)
I0518 14:08:50.120304  4008 sgd_solver.cpp:106] Iteration 200400, lr = 0.001
I0518 14:08:50.281430  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4082	2.08333	78.6136	0	88.4728	4.6875	85.8373	0	81.4639	0	80.1267	0	71.4805	0	27.312	2	
I0518 14:08:50.356660  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:08:50.358718  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:08:50.358752  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:08:50.372396  4008 solver.cpp:260]     Total regularization terms: 1.02959 loss+regular. : 2.20243
I0518 14:08:57.879343  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:10:14.993454  4008 solver.cpp:231] Iteration 200600, loss = 1.32435
I0518 14:10:14.993908  4008 solver.cpp:247]     Train net output #0: loss = 1.32435 (* 1 = 1.32435 loss)
I0518 14:10:14.993928  4008 sgd_solver.cpp:106] Iteration 200600, lr = 0.001
I0518 14:10:15.154199  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4742	2.08333	78.402	0	88.4795	4.6875	85.8643	0	81.4752	0	80.1427	0	71.4997	0	27.3201	2	
I0518 14:10:15.229228  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:10:15.230849  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:10:15.230871  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:10:15.245764  4008 solver.cpp:260]     Total regularization terms: 1.02943 loss+regular. : 2.35378
I0518 14:11:33.655915  4008 solver.cpp:231] Iteration 200800, loss = 1.367
I0518 14:11:33.656213  4008 solver.cpp:247]     Train net output #0: loss = 1.367 (* 1 = 1.367 loss)
I0518 14:11:33.656235  4008 sgd_solver.cpp:106] Iteration 200800, lr = 0.001
I0518 14:11:33.817294  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1212	2.08333	78.0371	0	88.4771	4.6875	85.859	0	81.4747	0	80.159	0	71.5192	0	27.3276	2	
I0518 14:11:33.891767  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:11:33.894209  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:11:33.894245  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:11:33.903944  4008 solver.cpp:260]     Total regularization terms: 1.02924 loss+regular. : 2.39623
I0518 14:13:05.549739  4008 solver.cpp:348] Iteration 201000, Testing net (#0)
I0518 14:13:38.964164  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:14:22.764760  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55408
I0518 14:14:22.765053  4008 solver.cpp:415]     Test net output #1: loss = 1.9161 (* 1 = 1.9161 loss)
I0518 14:14:22.852397  4008 solver.cpp:231] Iteration 201000, loss = 1.47747
I0518 14:14:22.852468  4008 solver.cpp:247]     Train net output #0: loss = 1.47747 (* 1 = 1.47747 loss)
I0518 14:14:22.852486  4008 sgd_solver.cpp:106] Iteration 201000, lr = 0.001
I0518 14:14:23.016984  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3163	2.08333	78.5869	0	88.504	4.6875	85.8823	0	81.4758	0	80.175	0	71.5381	0	27.3351	2	
I0518 14:14:23.091693  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:14:23.093585  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:14:23.093618  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:14:23.106014  4008 solver.cpp:260]     Total regularization terms: 1.02903 loss+regular. : 2.5065
I0518 14:15:54.401922  4008 solver.cpp:231] Iteration 201200, loss = 1.25793
I0518 14:15:54.403816  4008 solver.cpp:247]     Train net output #0: loss = 1.25793 (* 1 = 1.25793 loss)
I0518 14:15:54.403964  4008 sgd_solver.cpp:106] Iteration 201200, lr = 0.001
I0518 14:15:54.563736  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5545	2.08333	78.7458	0	88.5119	4.6875	85.8955	0	81.5023	0	80.1909	0	71.5574	0	27.3424	2	
I0518 14:15:54.638429  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.954861	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:15:54.640348  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:15:54.640385  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:15:54.650276  4008 solver.cpp:260]     Total regularization terms: 1.0288 loss+regular. : 2.28673
I0518 14:17:10.767277  4008 solver.cpp:231] Iteration 201400, loss = 1.67571
I0518 14:17:10.767621  4008 solver.cpp:247]     Train net output #0: loss = 1.67571 (* 1 = 1.67571 loss)
I0518 14:17:10.767654  4008 sgd_solver.cpp:106] Iteration 201400, lr = 0.001
I0518 14:17:10.927245  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6463	2.08333	78.6188	0	88.5195	4.6875	85.9165	0	81.5021	0	80.2068	0	71.5763	0	27.3494	2	
I0518 14:17:11.001106  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:17:11.002449  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:17:11.002465  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:17:11.012209  4008 solver.cpp:260]     Total regularization terms: 1.02861 loss+regular. : 2.70432
I0518 14:17:23.575700  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:18:33.301092  4008 solver.cpp:231] Iteration 201600, loss = 1.61735
I0518 14:18:33.301488  4008 solver.cpp:247]     Train net output #0: loss = 1.61735 (* 1 = 1.61735 loss)
I0518 14:18:33.301518  4008 sgd_solver.cpp:106] Iteration 201600, lr = 0.001
I0518 14:18:33.461746  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6205	2.08333	78.6712	0	88.5653	4.6875	85.9265	0	81.505	0	80.2226	0	71.5948	0	27.3567	2	
I0518 14:18:33.537353  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:18:33.539845  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:18:33.539887  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:18:33.560072  4008 solver.cpp:260]     Total regularization terms: 1.02834 loss+regular. : 2.64569
I0518 14:19:55.171124  4008 solver.cpp:231] Iteration 201800, loss = 1.41944
I0518 14:19:55.173657  4008 solver.cpp:247]     Train net output #0: loss = 1.41944 (* 1 = 1.41944 loss)
I0518 14:19:55.173684  4008 sgd_solver.cpp:106] Iteration 201800, lr = 0.001
I0518 14:19:55.332634  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0724	2.08333	78.5026	0	88.5246	4.6875	85.9435	0	81.5063	0	80.2385	0	71.6134	0	27.3632	2	
I0518 14:19:55.407712  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:19:55.409179  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:19:55.409211  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:19:55.419365  4008 solver.cpp:260]     Total regularization terms: 1.02816 loss+regular. : 2.4476
I0518 14:21:16.901634  4008 solver.cpp:348] Iteration 202000, Testing net (#0)
I0518 14:21:51.052106  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:22:34.837044  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55432
I0518 14:22:34.837285  4008 solver.cpp:415]     Test net output #1: loss = 1.9203 (* 1 = 1.9203 loss)
I0518 14:22:34.924806  4008 solver.cpp:231] Iteration 202000, loss = 1.25083
I0518 14:22:34.924883  4008 solver.cpp:247]     Train net output #0: loss = 1.25083 (* 1 = 1.25083 loss)
I0518 14:22:34.924899  4008 sgd_solver.cpp:106] Iteration 202000, lr = 0.001
I0518 14:22:35.092890  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6463	2.08333	78.6865	0	88.5672	4.6875	85.9571	0	81.531	0	80.2541	0	71.6324	0	27.3705	2	
I0518 14:22:35.167701  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:22:35.169646  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:22:35.169677  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:22:35.179432  4008 solver.cpp:260]     Total regularization terms: 1.0279 loss+regular. : 2.27873
I0518 14:23:58.400431  4008 solver.cpp:231] Iteration 202200, loss = 1.34901
I0518 14:23:58.400755  4008 solver.cpp:247]     Train net output #0: loss = 1.34901 (* 1 = 1.34901 loss)
I0518 14:23:58.400775  4008 sgd_solver.cpp:106] Iteration 202200, lr = 0.001
I0518 14:23:58.559329  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4397	2.08333	78.4456	0	88.5838	4.6875	85.9648	0	81.5452	0	80.2699	0	71.6511	0	27.3773	2	
I0518 14:23:58.634322  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:23:58.636029  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.6875	0	0	0	0	0	0	0	0	0	2	
I0518 14:23:58.636049  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:23:58.650888  4008 solver.cpp:260]     Total regularization terms: 1.02781 loss+regular. : 2.37683
I0518 14:25:16.733280  4008 solver.cpp:231] Iteration 202400, loss = 1.36611
I0518 14:25:16.735054  4008 solver.cpp:247]     Train net output #0: loss = 1.36611 (* 1 = 1.36611 loss)
I0518 14:25:16.735090  4008 sgd_solver.cpp:106] Iteration 202400, lr = 0.001
I0518 14:25:16.893910  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6119	2.08333	78.5527	0	88.6017	4.94792	85.9771	0	81.5502	0	80.2856	0	71.6701	0	27.3846	2	
I0518 14:25:16.968757  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:25:16.970226  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:25:16.970257  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:25:16.990489  4008 solver.cpp:260]     Total regularization terms: 1.02764 loss+regular. : 2.39375
I0518 14:25:32.163750  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:26:43.687949  4008 solver.cpp:231] Iteration 202600, loss = 1.31358
I0518 14:26:43.688844  4008 solver.cpp:247]     Train net output #0: loss = 1.31358 (* 1 = 1.31358 loss)
I0518 14:26:43.688866  4008 sgd_solver.cpp:106] Iteration 202600, lr = 0.001
I0518 14:26:43.847384  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.391	2.08333	78.5339	0	88.6034	4.94792	85.9704	0	81.5681	0	80.3014	0	71.6886	0	27.3921	2	
I0518 14:26:43.922354  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:26:43.924588  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:26:43.924626  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:26:43.934756  4008 solver.cpp:260]     Total regularization terms: 1.02746 loss+regular. : 2.34104
I0518 14:28:04.263206  4008 solver.cpp:231] Iteration 202800, loss = 1.40199
I0518 14:28:04.263427  4008 solver.cpp:247]     Train net output #0: loss = 1.40199 (* 1 = 1.40199 loss)
I0518 14:28:04.263445  4008 sgd_solver.cpp:106] Iteration 202800, lr = 0.001
I0518 14:28:04.424412  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4082	2.08333	78.7279	0	88.5686	4.94792	85.9924	0	81.5724	0	80.3167	0	71.7076	0	27.3993	2	
I0518 14:28:04.499699  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:28:04.501829  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:28:04.501879  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:28:04.515799  4008 solver.cpp:260]     Total regularization terms: 1.02716 loss+regular. : 2.42916
I0518 14:29:23.638134  4008 solver.cpp:348] Iteration 203000, Testing net (#0)
I0518 14:29:56.215311  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:30:46.248373  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5569
I0518 14:30:46.248683  4008 solver.cpp:415]     Test net output #1: loss = 1.90743 (* 1 = 1.90743 loss)
I0518 14:30:46.342279  4008 solver.cpp:231] Iteration 203000, loss = 1.41011
I0518 14:30:46.342367  4008 solver.cpp:247]     Train net output #0: loss = 1.41011 (* 1 = 1.41011 loss)
I0518 14:30:46.342417  4008 sgd_solver.cpp:106] Iteration 203000, lr = 0.001
I0518 14:30:46.509126  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4455	2.08333	78.5374	0	88.5946	4.94792	86.0009	0	81.5932	0	80.3326	0	71.7264	0	27.4062	2	
I0518 14:30:46.583791  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:30:46.586395  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:30:46.586447  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:30:46.596770  4008 solver.cpp:260]     Total regularization terms: 1.02692 loss+regular. : 2.43703
I0518 14:32:17.811847  4008 solver.cpp:231] Iteration 203200, loss = 1.33578
I0518 14:32:17.815068  4008 solver.cpp:247]     Train net output #0: loss = 1.33578 (* 1 = 1.33578 loss)
I0518 14:32:17.815101  4008 sgd_solver.cpp:106] Iteration 203200, lr = 0.001
I0518 14:32:17.971504  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5373	2.08333	78.7113	0	88.6027	4.94792	86.0181	0	81.6051	0	80.3485	0	71.7455	0	27.4131	2	
I0518 14:32:18.045671  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:32:18.047504  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:32:18.047539  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:32:18.057145  4008 solver.cpp:260]     Total regularization terms: 1.02666 loss+regular. : 2.36244
I0518 14:33:47.284246  4008 solver.cpp:231] Iteration 203400, loss = 1.45797
I0518 14:33:47.284600  4008 solver.cpp:247]     Train net output #0: loss = 1.45797 (* 1 = 1.45797 loss)
I0518 14:33:47.284621  4008 sgd_solver.cpp:106] Iteration 203400, lr = 0.001
I0518 14:33:47.445008  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6722	2.08333	78.8252	0	88.6149	4.94792	86.0346	0	81.6291	0	80.3641	0	71.7648	0	27.4205	2	
I0518 14:33:47.519660  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:33:47.522171  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:33:47.522210  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:33:47.534492  4008 solver.cpp:260]     Total regularization terms: 1.02646 loss+regular. : 2.48443
I0518 14:34:05.580204  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:35:07.737993  4008 solver.cpp:231] Iteration 203600, loss = 1.44705
I0518 14:35:07.740061  4008 solver.cpp:247]     Train net output #0: loss = 1.44705 (* 1 = 1.44705 loss)
I0518 14:35:07.740087  4008 sgd_solver.cpp:106] Iteration 203600, lr = 0.001
I0518 14:35:07.898728  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5631	2.08333	78.5592	0	88.6262	4.94792	86.0534	0	81.6334	0	80.3795	0	71.7837	0	27.4273	2	
I0518 14:35:07.973332  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:35:07.975738  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:35:07.975777  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:35:07.985649  4008 solver.cpp:260]     Total regularization terms: 1.02627 loss+regular. : 2.47332
I0518 14:36:31.550268  4008 solver.cpp:231] Iteration 203800, loss = 1.29416
I0518 14:36:31.550545  4008 solver.cpp:247]     Train net output #0: loss = 1.29416 (* 1 = 1.29416 loss)
I0518 14:36:31.550566  4008 sgd_solver.cpp:106] Iteration 203800, lr = 0.001
I0518 14:36:31.712709  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5832	2.08333	78.7721	0	88.6121	4.94792	86.0688	0	81.6427	0	80.3948	0	71.8025	0	27.4351	2	
I0518 14:36:31.787016  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:36:31.789091  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:36:31.789120  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:36:31.798871  4008 solver.cpp:260]     Total regularization terms: 1.0261 loss+regular. : 2.32026
I0518 14:37:49.426771  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_204000.caffemodel
I0518 14:38:56.738139  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_204000.solverstate
I0518 14:38:57.249893  4008 solver.cpp:348] Iteration 204000, Testing net (#0)
I0518 14:39:28.744019  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:40:15.226385  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5529
I0518 14:40:15.226676  4008 solver.cpp:415]     Test net output #1: loss = 1.91863 (* 1 = 1.91863 loss)
I0518 14:40:15.315464  4008 solver.cpp:231] Iteration 204000, loss = 1.35851
I0518 14:40:15.315541  4008 solver.cpp:247]     Train net output #0: loss = 1.35851 (* 1 = 1.35851 loss)
I0518 14:40:15.315590  4008 sgd_solver.cpp:106] Iteration 204000, lr = 0.001
I0518 14:40:15.482337  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1987	2.08333	78.8154	0	88.6232	4.94792	86.0587	0	81.6632	0	80.4104	0	71.8218	0	27.4425	2	
I0518 14:40:15.483577  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:40:15.484943  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:40:15.484961  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:40:15.494628  4008 solver.cpp:260]     Total regularization terms: 1.02586 loss+regular. : 2.38437
I0518 14:41:46.009449  4008 solver.cpp:231] Iteration 204200, loss = 1.43198
I0518 14:41:46.009929  4008 solver.cpp:247]     Train net output #0: loss = 1.43198 (* 1 = 1.43198 loss)
I0518 14:41:46.009953  4008 sgd_solver.cpp:106] Iteration 204200, lr = 0.001
I0518 14:41:46.170547  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6837	2.08333	78.8076	0	88.6423	4.94792	86.0603	0	81.658	0	80.4259	0	71.8406	0	27.4498	2	
I0518 14:41:46.247489  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:41:46.249346  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:41:46.249377  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:41:46.264415  4008 solver.cpp:260]     Total regularization terms: 1.02565 loss+regular. : 2.45763
I0518 14:43:03.585019  4008 solver.cpp:231] Iteration 204400, loss = 1.25497
I0518 14:43:03.585301  4008 solver.cpp:247]     Train net output #0: loss = 1.25497 (* 1 = 1.25497 loss)
I0518 14:43:03.585328  4008 sgd_solver.cpp:106] Iteration 204400, lr = 0.001
I0518 14:43:03.745343  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5115	2.08333	78.8119	0	88.6429	4.94792	86.0768	0	81.6646	0	80.4415	0	71.8593	0	27.4574	2	
I0518 14:43:03.820117  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:43:03.821548  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:43:03.821593  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:43:03.850484  4008 solver.cpp:260]     Total regularization terms: 1.02542 loss+regular. : 2.28039
I0518 14:43:21.674433  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:44:21.020663  4008 solver.cpp:231] Iteration 204600, loss = 1.40155
I0518 14:44:21.021034  4008 solver.cpp:247]     Train net output #0: loss = 1.40155 (* 1 = 1.40155 loss)
I0518 14:44:21.021060  4008 sgd_solver.cpp:106] Iteration 204600, lr = 0.001
I0518 14:44:21.180013  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6148	2.08333	78.5824	0	88.6284	4.94792	86.0582	0	81.6485	0	80.457	0	71.8777	0	27.4647	2	
I0518 14:44:21.255136  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:44:21.256536  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:44:21.256557  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:44:21.271420  4008 solver.cpp:260]     Total regularization terms: 1.02522 loss+regular. : 2.42678
I0518 14:45:34.710688  4008 solver.cpp:231] Iteration 204800, loss = 1.20683
I0518 14:45:34.717702  4008 solver.cpp:247]     Train net output #0: loss = 1.20683 (* 1 = 1.20683 loss)
I0518 14:45:34.717733  4008 sgd_solver.cpp:106] Iteration 204800, lr = 0.001
I0518 14:45:34.872001  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6435	2.08333	78.1266	0	88.5872	4.94792	86.0437	0	81.6546	0	80.4723	0	71.896	0	27.472	2	
I0518 14:45:34.947196  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:45:34.948827  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:45:34.948866  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:45:34.963835  4008 solver.cpp:260]     Total regularization terms: 1.02514 loss+regular. : 2.23196
I0518 14:46:53.725953  4008 solver.cpp:348] Iteration 205000, Testing net (#0)
I0518 14:47:29.483110  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:48:16.212100  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55108
I0518 14:48:16.212436  4008 solver.cpp:415]     Test net output #1: loss = 1.93182 (* 1 = 1.93182 loss)
I0518 14:48:16.303314  4008 solver.cpp:231] Iteration 205000, loss = 1.38228
I0518 14:48:16.303406  4008 solver.cpp:247]     Train net output #0: loss = 1.38228 (* 1 = 1.38228 loss)
I0518 14:48:16.303423  4008 sgd_solver.cpp:106] Iteration 205000, lr = 0.001
I0518 14:48:16.470988  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4971	2.08333	78.5212	0	88.6021	4.94792	86.0443	0	81.6542	0	80.4875	0	71.9141	0	27.4791	2	
I0518 14:48:16.545301  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:48:16.547514  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:48:16.547572  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:48:16.557837  4008 solver.cpp:260]     Total regularization terms: 1.02486 loss+regular. : 2.40714
I0518 14:49:44.682229  4008 solver.cpp:231] Iteration 205200, loss = 1.46121
I0518 14:49:44.682451  4008 solver.cpp:247]     Train net output #0: loss = 1.46121 (* 1 = 1.46121 loss)
I0518 14:49:44.682471  4008 sgd_solver.cpp:106] Iteration 205200, lr = 0.001
I0518 14:49:44.842242  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3881	2.08333	78.6813	0	88.6096	4.94792	86.06	0	81.6772	0	80.5033	0	71.9328	0	27.4856	2	
I0518 14:49:44.916432  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:49:44.918167  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:49:44.918231  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:49:44.928010  4008 solver.cpp:260]     Total regularization terms: 1.02464 loss+regular. : 2.48585
I0518 14:51:15.892976  4008 solver.cpp:231] Iteration 205400, loss = 1.48129
I0518 14:51:15.897658  4008 solver.cpp:247]     Train net output #0: loss = 1.48129 (* 1 = 1.48129 loss)
I0518 14:51:15.897687  4008 sgd_solver.cpp:106] Iteration 205400, lr = 0.001
I0518 14:51:16.052935  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5115	2.08333	78.7702	0	88.6484	4.94792	86.0874	0	81.7057	0	80.5187	0	71.9511	0	27.4932	2	
I0518 14:51:16.127349  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:51:16.128929  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:51:16.128962  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:51:16.138994  4008 solver.cpp:260]     Total regularization terms: 1.02443 loss+regular. : 2.50572
I0518 14:51:46.277683  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:52:51.137307  4008 solver.cpp:231] Iteration 205600, loss = 1.53846
I0518 14:52:51.137536  4008 solver.cpp:247]     Train net output #0: loss = 1.53846 (* 1 = 1.53846 loss)
I0518 14:52:51.137565  4008 sgd_solver.cpp:106] Iteration 205600, lr = 0.001
I0518 14:52:51.298420  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6004	2.08333	78.8392	0	88.6628	4.94792	86.0968	0	81.7191	0	80.5341	0	71.9693	0	27.5006	2	
I0518 14:52:51.373227  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:52:51.374647  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:52:51.374675  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:52:51.394496  4008 solver.cpp:260]     Total regularization terms: 1.02422 loss+regular. : 2.56268
I0518 14:54:05.770326  4008 solver.cpp:231] Iteration 205800, loss = 1.33027
I0518 14:54:05.770735  4008 solver.cpp:247]     Train net output #0: loss = 1.33027 (* 1 = 1.33027 loss)
I0518 14:54:05.770766  4008 sgd_solver.cpp:106] Iteration 205800, lr = 0.001
I0518 14:54:05.932363  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5143	2.08333	78.7096	0	88.6947	4.94792	86.101	0	81.7164	0	80.55	0	71.9877	0	27.508	2	
I0518 14:54:06.007153  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:54:06.008510  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:54:06.008527  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:54:06.021823  4008 solver.cpp:260]     Total regularization terms: 1.02399 loss+regular. : 2.35426
I0518 14:55:32.774832  4008 solver.cpp:348] Iteration 206000, Testing net (#0)
I0518 14:56:12.296083  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 14:57:02.503633  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55422
I0518 14:57:02.503939  4008 solver.cpp:415]     Test net output #1: loss = 1.91437 (* 1 = 1.91437 loss)
I0518 14:57:02.600597  4008 solver.cpp:231] Iteration 206000, loss = 1.63308
I0518 14:57:02.600678  4008 solver.cpp:247]     Train net output #0: loss = 1.63308 (* 1 = 1.63308 loss)
I0518 14:57:02.600699  4008 sgd_solver.cpp:106] Iteration 206000, lr = 0.001
I0518 14:57:02.770081  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4053	2.08333	78.7295	0	88.6822	4.94792	86.1223	0	81.7218	0	80.5653	0	72.0065	0	27.5148	2	
I0518 14:57:02.844794  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	0.998264	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:57:02.846333  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:57:02.846359  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:57:02.859346  4008 solver.cpp:260]     Total regularization terms: 1.02384 loss+regular. : 2.65692
I0518 14:58:28.644304  4008 solver.cpp:231] Iteration 206200, loss = 1.33885
I0518 14:58:28.644652  4008 solver.cpp:247]     Train net output #0: loss = 1.33885 (* 1 = 1.33885 loss)
I0518 14:58:28.644675  4008 sgd_solver.cpp:106] Iteration 206200, lr = 0.001
I0518 14:58:28.804975  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6636	2.08333	78.8551	0	88.6759	4.94792	86.1358	0	81.7349	0	80.5805	0	72.0252	0	27.5229	2	
I0518 14:58:28.879552  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:58:28.882069  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:58:28.882113  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:58:28.891988  4008 solver.cpp:260]     Total regularization terms: 1.02358 loss+regular. : 2.36244
I0518 14:59:50.179723  4008 solver.cpp:231] Iteration 206400, loss = 1.41944
I0518 14:59:50.179996  4008 solver.cpp:247]     Train net output #0: loss = 1.41944 (* 1 = 1.41944 loss)
I0518 14:59:50.180019  4008 sgd_solver.cpp:106] Iteration 206400, lr = 0.001
I0518 14:59:50.340229  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3594	2.08333	79.0094	0	88.7201	4.94792	86.1275	0	81.7613	0	80.5956	0	72.0433	0	27.5301	2	
I0518 14:59:50.414676  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 14:59:50.416385  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 14:59:50.416426  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 14:59:50.446521  4008 solver.cpp:260]     Total regularization terms: 1.02336 loss+regular. : 2.4428
I0518 15:00:20.824568  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:01:16.876834  4008 solver.cpp:231] Iteration 206600, loss = 1.48599
I0518 15:01:16.881690  4008 solver.cpp:247]     Train net output #0: loss = 1.48599 (* 1 = 1.48599 loss)
I0518 15:01:16.881727  4008 sgd_solver.cpp:106] Iteration 206600, lr = 0.001
I0518 15:01:17.039125  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3278	2.08333	78.9066	0	88.714	4.94792	86.1206	0	81.7695	0	80.6108	0	72.0622	0	27.5366	2	
I0518 15:01:17.113629  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:01:17.115631  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:01:17.115675  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:01:17.125569  4008 solver.cpp:260]     Total regularization terms: 1.02313 loss+regular. : 2.50912
I0518 15:02:45.325837  4008 solver.cpp:231] Iteration 206800, loss = 1.52577
I0518 15:02:45.329689  4008 solver.cpp:247]     Train net output #0: loss = 1.52577 (* 1 = 1.52577 loss)
I0518 15:02:45.329720  4008 sgd_solver.cpp:106] Iteration 206800, lr = 0.001
I0518 15:02:45.485077  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.589	2.08333	78.7679	0	88.727	4.94792	86.1533	0	81.7912	0	80.6257	0	72.08	0	27.5439	2	
I0518 15:02:45.559581  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:02:45.561599  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:02:45.561645  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:02:45.571445  4008 solver.cpp:260]     Total regularization terms: 1.02295 loss+regular. : 2.54871
I0518 15:04:13.677778  4008 solver.cpp:348] Iteration 207000, Testing net (#0)
I0518 15:04:57.502305  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:05:37.896221  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5568
I0518 15:05:37.896489  4008 solver.cpp:415]     Test net output #1: loss = 1.909 (* 1 = 1.909 loss)
I0518 15:05:38.020748  4008 solver.cpp:231] Iteration 207000, loss = 1.23845
I0518 15:05:38.020822  4008 solver.cpp:247]     Train net output #0: loss = 1.23845 (* 1 = 1.23845 loss)
I0518 15:05:38.020838  4008 sgd_solver.cpp:106] Iteration 207000, lr = 0.001
I0518 15:05:38.182050  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5517	2.08333	78.8975	0	88.7227	4.94792	86.1744	0	81.8032	0	80.641	0	72.0988	0	27.5511	2	
I0518 15:05:38.256536  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:05:38.258595  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:05:38.258641  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:05:38.268465  4008 solver.cpp:260]     Total regularization terms: 1.02274 loss+regular. : 2.26119
I0518 15:07:12.899463  4008 solver.cpp:231] Iteration 207200, loss = 1.54136
I0518 15:07:12.899921  4008 solver.cpp:247]     Train net output #0: loss = 1.54136 (* 1 = 1.54136 loss)
I0518 15:07:12.899942  4008 sgd_solver.cpp:106] Iteration 207200, lr = 0.001
I0518 15:07:13.058820  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8673	2.08333	78.5283	0	88.7175	4.94792	86.1741	0	81.8149	0	80.6564	0	72.1167	0	27.5577	2	
I0518 15:07:13.133911  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:07:13.137243  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:07:13.137320  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:07:13.147480  4008 solver.cpp:260]     Total regularization terms: 1.02263 loss+regular. : 2.56399
I0518 15:08:44.120661  4008 solver.cpp:231] Iteration 207400, loss = 1.4545
I0518 15:08:44.121016  4008 solver.cpp:247]     Train net output #0: loss = 1.4545 (* 1 = 1.4545 loss)
I0518 15:08:44.121037  4008 sgd_solver.cpp:106] Iteration 207400, lr = 0.001
I0518 15:08:44.280875  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7497	2.08333	78.8073	0	88.72	4.94792	86.1895	0	81.8337	0	80.671	0	72.1345	0	27.5648	2	
I0518 15:08:44.362947  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:08:44.365803  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:08:44.365897  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:08:44.391711  4008 solver.cpp:260]     Total regularization terms: 1.02246 loss+regular. : 2.47696
I0518 15:09:18.527528  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:10:15.100301  4008 solver.cpp:231] Iteration 207600, loss = 1.28215
I0518 15:10:15.100687  4008 solver.cpp:247]     Train net output #0: loss = 1.28215 (* 1 = 1.28215 loss)
I0518 15:10:15.100823  4008 sgd_solver.cpp:106] Iteration 207600, lr = 0.001
I0518 15:10:15.261499  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5086	2.08333	78.6667	0	88.7248	4.94792	86.1776	0	81.7905	0	80.6861	0	72.1529	0	27.5725	2	
I0518 15:10:15.339545  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:10:15.341488  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:10:15.341532  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:10:15.351409  4008 solver.cpp:260]     Total regularization terms: 1.02228 loss+regular. : 2.30443
I0518 15:11:44.777928  4008 solver.cpp:231] Iteration 207800, loss = 1.43184
I0518 15:11:44.778249  4008 solver.cpp:247]     Train net output #0: loss = 1.43184 (* 1 = 1.43184 loss)
I0518 15:11:44.778269  4008 sgd_solver.cpp:106] Iteration 207800, lr = 0.001
I0518 15:11:44.938603  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7324	2.08333	78.9023	0	88.7502	4.94792	86.1928	0	81.8138	0	80.7014	0	72.171	0	27.5804	2	
I0518 15:11:45.013716  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:11:45.017488  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:11:45.017545  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:11:45.027426  4008 solver.cpp:260]     Total regularization terms: 1.02199 loss+regular. : 2.45384
I0518 15:13:13.937103  4008 solver.cpp:348] Iteration 208000, Testing net (#0)
I0518 15:13:52.802350  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:14:37.978313  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55426
I0518 15:14:37.982133  4008 solver.cpp:415]     Test net output #1: loss = 1.9146 (* 1 = 1.9146 loss)
I0518 15:14:38.073127  4008 solver.cpp:231] Iteration 208000, loss = 1.47778
I0518 15:14:38.073221  4008 solver.cpp:247]     Train net output #0: loss = 1.47778 (* 1 = 1.47778 loss)
I0518 15:14:38.073246  4008 sgd_solver.cpp:106] Iteration 208000, lr = 0.001
I0518 15:14:38.232986  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3135	2.08333	78.709	0	88.7517	4.94792	86.194	0	81.809	0	80.7167	0	72.189	0	27.5876	2	
I0518 15:14:38.309062  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:14:38.312680  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:14:38.312744  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:14:38.325613  4008 solver.cpp:260]     Total regularization terms: 1.02182 loss+regular. : 2.4996
I0518 15:16:11.990247  4008 solver.cpp:231] Iteration 208200, loss = 1.33307
I0518 15:16:11.990517  4008 solver.cpp:247]     Train net output #0: loss = 1.33307 (* 1 = 1.33307 loss)
I0518 15:16:11.990543  4008 sgd_solver.cpp:106] Iteration 208200, lr = 0.001
I0518 15:16:12.150521  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5057	2.08333	78.8366	0	88.7392	4.94792	86.1703	0	81.8382	0	80.7316	0	72.2071	0	27.5942	2	
I0518 15:16:12.226495  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:16:12.230872  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:16:12.230945  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:16:12.241255  4008 solver.cpp:260]     Total regularization terms: 1.02159 loss+regular. : 2.35466
I0518 15:17:46.760828  4008 solver.cpp:231] Iteration 208400, loss = 1.24979
I0518 15:17:46.762008  4008 solver.cpp:247]     Train net output #0: loss = 1.24979 (* 1 = 1.24979 loss)
I0518 15:17:46.762050  4008 sgd_solver.cpp:106] Iteration 208400, lr = 0.001
I0518 15:17:46.921520  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5143	2.08333	78.7982	0	88.753	4.94792	86.164	0	81.8445	0	80.7466	0	72.2253	0	27.6013	2	
I0518 15:17:46.996616  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:17:46.999102  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:17:46.999148  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:17:47.014116  4008 solver.cpp:260]     Total regularization terms: 1.02141 loss+regular. : 2.2712
I0518 15:18:17.852413  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:19:16.197000  4008 solver.cpp:231] Iteration 208600, loss = 1.3355
I0518 15:19:16.197309  4008 solver.cpp:247]     Train net output #0: loss = 1.3355 (* 1 = 1.3355 loss)
I0518 15:19:16.197330  4008 sgd_solver.cpp:106] Iteration 208600, lr = 0.001
I0518 15:19:16.357506  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7525	2.08333	78.9658	0	88.7807	4.94792	86.2151	0	81.8719	0	80.7612	0	72.2435	0	27.6088	2	
I0518 15:19:16.432618  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:19:16.435497  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:19:16.435546  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:19:16.445617  4008 solver.cpp:260]     Total regularization terms: 1.02121 loss+regular. : 2.35671
I0518 15:20:44.252573  4008 solver.cpp:231] Iteration 208800, loss = 1.32339
I0518 15:20:44.254591  4008 solver.cpp:247]     Train net output #0: loss = 1.32339 (* 1 = 1.32339 loss)
I0518 15:20:44.254621  4008 sgd_solver.cpp:106] Iteration 208800, lr = 0.001
I0518 15:20:44.414258  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3393	2.08333	78.9883	0	88.7797	4.94792	86.2339	0	81.8877	0	80.776	0	72.2617	0	27.6156	2	
I0518 15:20:44.489251  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:20:44.492122  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:20:44.492175  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:20:44.502105  4008 solver.cpp:260]     Total regularization terms: 1.02093 loss+regular. : 2.34433
I0518 15:22:13.640738  4008 solver.cpp:348] Iteration 209000, Testing net (#0)
I0518 15:22:55.084918  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:23:39.802942  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55412
I0518 15:23:39.803218  4008 solver.cpp:415]     Test net output #1: loss = 1.91313 (* 1 = 1.91313 loss)
I0518 15:23:39.890885  4008 solver.cpp:231] Iteration 209000, loss = 1.35734
I0518 15:23:39.890969  4008 solver.cpp:247]     Train net output #0: loss = 1.35734 (* 1 = 1.35734 loss)
I0518 15:23:39.890987  4008 sgd_solver.cpp:106] Iteration 209000, lr = 0.001
I0518 15:23:40.051666  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0523	2.08333	78.6986	0	88.7759	4.94792	86.2146	0	81.8762	0	80.7906	0	72.2795	0	27.6218	2	
I0518 15:23:40.128121  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:23:40.130738  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:23:40.130784  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:23:40.140619  4008 solver.cpp:260]     Total regularization terms: 1.02074 loss+regular. : 2.37808
I0518 15:25:09.592905  4008 solver.cpp:231] Iteration 209200, loss = 1.49733
I0518 15:25:09.593190  4008 solver.cpp:247]     Train net output #0: loss = 1.49733 (* 1 = 1.49733 loss)
I0518 15:25:09.593219  4008 sgd_solver.cpp:106] Iteration 209200, lr = 0.001
I0518 15:25:09.753199  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5488	2.08333	78.9434	0	88.7991	4.94792	86.216	0	81.8909	0	80.8056	0	72.2974	0	27.6284	2	
I0518 15:25:09.828117  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:25:09.830636  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:25:09.830688  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:25:09.841028  4008 solver.cpp:260]     Total regularization terms: 1.02059 loss+regular. : 2.51792
I0518 15:26:40.783427  4008 solver.cpp:231] Iteration 209400, loss = 1.40606
I0518 15:26:40.783810  4008 solver.cpp:247]     Train net output #0: loss = 1.40606 (* 1 = 1.40606 loss)
I0518 15:26:40.783833  4008 sgd_solver.cpp:106] Iteration 209400, lr = 0.001
I0518 15:26:40.943625  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7037	2.08333	78.8294	0	88.8108	4.94792	86.2535	0	81.8997	0	80.8206	0	72.3151	0	27.6354	2	
I0518 15:26:41.018452  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:26:41.021239  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:26:41.021281  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:26:41.030999  4008 solver.cpp:260]     Total regularization terms: 1.02037 loss+regular. : 2.42644
I0518 15:27:18.322515  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:28:10.768292  4008 solver.cpp:231] Iteration 209600, loss = 1.28575
I0518 15:28:10.768723  4008 solver.cpp:247]     Train net output #0: loss = 1.28575 (* 1 = 1.28575 loss)
I0518 15:28:10.768745  4008 sgd_solver.cpp:106] Iteration 209600, lr = 0.001
I0518 15:28:10.929406  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4541	2.08333	78.8268	0	88.8116	4.94792	86.2525	0	81.9137	0	80.8355	0	72.3337	0	27.6428	2	
I0518 15:28:11.004767  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:28:11.008132  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:28:11.008208  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:28:11.019058  4008 solver.cpp:260]     Total regularization terms: 1.02016 loss+regular. : 2.30591
I0518 15:29:38.192405  4008 solver.cpp:231] Iteration 209800, loss = 1.52749
I0518 15:29:38.193714  4008 solver.cpp:247]     Train net output #0: loss = 1.52749 (* 1 = 1.52749 loss)
I0518 15:29:38.193743  4008 sgd_solver.cpp:106] Iteration 209800, lr = 0.001
I0518 15:29:38.351634  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4082	2.08333	78.5055	0	88.7782	4.94792	86.2317	0	81.9284	0	80.8501	0	72.3521	0	27.6498	2	
I0518 15:29:38.426496  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:29:38.428555  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:29:38.428592  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:29:38.438433  4008 solver.cpp:260]     Total regularization terms: 1.01998 loss+regular. : 2.54747
I0518 15:31:07.682394  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_210000.caffemodel
I0518 15:33:51.852557  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_210000.solverstate
I0518 15:33:52.713938  4008 solver.cpp:348] Iteration 210000, Testing net (#0)
I0518 15:34:36.096262  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:35:14.759019  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55428
I0518 15:35:14.760164  4008 solver.cpp:415]     Test net output #1: loss = 1.9144 (* 1 = 1.9144 loss)
I0518 15:35:14.860597  4008 solver.cpp:231] Iteration 210000, loss = 1.35263
I0518 15:35:14.860702  4008 solver.cpp:247]     Train net output #0: loss = 1.35263 (* 1 = 1.35263 loss)
I0518 15:35:14.860720  4008 sgd_solver.cpp:106] Iteration 210000, lr = 0.001
I0518 15:35:15.026269  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1442	2.08333	78.8906	0	88.8017	4.94792	86.2442	0	81.9286	0	80.8647	0	72.3699	0	27.6572	2	
I0518 15:35:15.027837  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:35:15.029803  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:35:15.029829  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:35:15.039541  4008 solver.cpp:260]     Total regularization terms: 1.01974 loss+regular. : 2.37237
I0518 15:36:33.571660  4008 solver.cpp:231] Iteration 210200, loss = 1.4797
I0518 15:36:33.572024  4008 solver.cpp:247]     Train net output #0: loss = 1.4797 (* 1 = 1.4797 loss)
I0518 15:36:33.572055  4008 sgd_solver.cpp:106] Iteration 210200, lr = 0.001
I0518 15:36:33.732530  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.9146	2.08333	78.9938	0	88.8239	4.94792	86.277	0	81.9641	0	80.8797	0	72.3875	0	27.6646	2	
I0518 15:36:33.807142  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:36:33.808873  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:36:33.808897  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:36:33.818892  4008 solver.cpp:260]     Total regularization terms: 1.01953 loss+regular. : 2.49924
I0518 15:37:59.123879  4008 solver.cpp:231] Iteration 210400, loss = 1.40133
I0518 15:37:59.124259  4008 solver.cpp:247]     Train net output #0: loss = 1.40133 (* 1 = 1.40133 loss)
I0518 15:37:59.124281  4008 sgd_solver.cpp:106] Iteration 210400, lr = 0.001
I0518 15:37:59.285279  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3221	2.08333	78.9414	0	88.8305	4.94792	86.2826	0	81.9433	0	80.8945	0	72.4056	0	27.6719	2	
I0518 15:37:59.360883  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:37:59.363082  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:37:59.363109  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:37:59.378142  4008 solver.cpp:260]     Total regularization terms: 1.01942 loss+regular. : 2.42075
I0518 15:38:34.488088  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:39:14.931732  4008 solver.cpp:231] Iteration 210600, loss = 1.30339
I0518 15:39:14.932000  4008 solver.cpp:247]     Train net output #0: loss = 1.30339 (* 1 = 1.30339 loss)
I0518 15:39:14.932019  4008 sgd_solver.cpp:106] Iteration 210600, lr = 0.001
I0518 15:39:15.093578  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2991	2.08333	78.9463	0	88.8137	4.94792	86.2891	0	81.9661	0	80.9095	0	72.4238	0	27.679	2	
I0518 15:39:15.169175  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:39:15.171627  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	2.08333	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:39:15.171656  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:39:15.186625  4008 solver.cpp:260]     Total regularization terms: 1.01919 loss+regular. : 2.32258
I0518 15:40:39.193531  4008 solver.cpp:231] Iteration 210800, loss = 1.37847
I0518 15:40:39.193800  4008 solver.cpp:247]     Train net output #0: loss = 1.37847 (* 1 = 1.37847 loss)
I0518 15:40:39.193820  4008 sgd_solver.cpp:106] Iteration 210800, lr = 0.001
I0518 15:40:39.355273  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.411	3.125	78.8177	0	88.8069	4.94792	86.3021	0	81.9686	0	80.9241	0	72.4417	0	27.6862	2	
I0518 15:40:39.430711  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:40:39.433192  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:40:39.433253  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:40:39.453403  4008 solver.cpp:260]     Total regularization terms: 1.01899 loss+regular. : 2.39745
I0518 15:42:01.111719  4008 solver.cpp:348] Iteration 211000, Testing net (#0)
I0518 15:42:39.968155  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:43:23.544719  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55324
I0518 15:43:23.545037  4008 solver.cpp:415]     Test net output #1: loss = 1.91939 (* 1 = 1.91939 loss)
I0518 15:43:23.632766  4008 solver.cpp:231] Iteration 211000, loss = 1.25939
I0518 15:43:23.632838  4008 solver.cpp:247]     Train net output #0: loss = 1.25939 (* 1 = 1.25939 loss)
I0518 15:43:23.632856  4008 sgd_solver.cpp:106] Iteration 211000, lr = 0.001
I0518 15:43:23.793709  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5	3.125	78.931	0	88.8449	4.94792	86.3109	0	81.9978	0	80.9389	0	72.4599	0	27.693	2	
I0518 15:43:23.869925  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:43:23.871953  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:43:23.871990  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:43:23.881655  4008 solver.cpp:260]     Total regularization terms: 1.01877 loss+regular. : 2.27816
I0518 15:44:51.576912  4008 solver.cpp:231] Iteration 211200, loss = 1.30718
I0518 15:44:51.577172  4008 solver.cpp:247]     Train net output #0: loss = 1.30718 (* 1 = 1.30718 loss)
I0518 15:44:51.577194  4008 sgd_solver.cpp:106] Iteration 211200, lr = 0.001
I0518 15:44:51.737843  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6865	3.125	78.9619	0	88.8362	4.94792	86.3168	0	81.9964	0	80.9536	0	72.4775	0	27.6999	2	
I0518 15:44:51.812530  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:44:51.814890  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:44:51.814930  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:44:51.824687  4008 solver.cpp:260]     Total regularization terms: 1.01855 loss+regular. : 2.32574
I0518 15:46:18.453881  4008 solver.cpp:231] Iteration 211400, loss = 1.18956
I0518 15:46:18.454216  4008 solver.cpp:247]     Train net output #0: loss = 1.18956 (* 1 = 1.18956 loss)
I0518 15:46:18.454236  4008 sgd_solver.cpp:106] Iteration 211400, lr = 0.001
I0518 15:46:18.612740  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5947	3.125	78.9645	0	88.871	4.94792	86.3274	0	82.0073	0	80.9681	0	72.4954	0	27.7074	2	
I0518 15:46:18.687284  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:46:18.689044  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:46:18.689070  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:46:18.698803  4008 solver.cpp:260]     Total regularization terms: 1.01837 loss+regular. : 2.20793
I0518 15:47:00.688969  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:47:41.780797  4008 solver.cpp:231] Iteration 211600, loss = 1.42188
I0518 15:47:41.781139  4008 solver.cpp:247]     Train net output #0: loss = 1.42188 (* 1 = 1.42188 loss)
I0518 15:47:41.781160  4008 sgd_solver.cpp:106] Iteration 211600, lr = 0.001
I0518 15:47:41.940804  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6377	3.125	78.9642	0	88.8732	4.94792	86.3342	0	82.0261	0	80.9824	0	72.5129	0	27.7139	2	
I0518 15:47:42.015749  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:47:42.017137  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:47:42.017155  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:47:42.032009  4008 solver.cpp:260]     Total regularization terms: 1.01811 loss+regular. : 2.43999
I0518 15:49:06.194241  4008 solver.cpp:231] Iteration 211800, loss = 1.2209
I0518 15:49:06.194610  4008 solver.cpp:247]     Train net output #0: loss = 1.2209 (* 1 = 1.2209 loss)
I0518 15:49:06.194631  4008 sgd_solver.cpp:106] Iteration 211800, lr = 0.001
I0518 15:49:06.354245  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6377	3.125	78.9769	0	88.8544	4.94792	86.3334	0	82.0136	0	80.9972	0	72.5308	0	27.7212	2	
I0518 15:49:06.428961  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:49:06.431321  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:49:06.431360  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:49:06.441236  4008 solver.cpp:260]     Total regularization terms: 1.01794 loss+regular. : 2.23885
I0518 15:50:25.929661  4008 solver.cpp:348] Iteration 212000, Testing net (#0)
I0518 15:51:18.871006  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:51:59.329012  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55312
I0518 15:51:59.329294  4008 solver.cpp:415]     Test net output #1: loss = 1.92083 (* 1 = 1.92083 loss)
I0518 15:51:59.416517  4008 solver.cpp:231] Iteration 212000, loss = 1.43487
I0518 15:51:59.416641  4008 solver.cpp:247]     Train net output #0: loss = 1.43487 (* 1 = 1.43487 loss)
I0518 15:51:59.416663  4008 sgd_solver.cpp:106] Iteration 212000, lr = 0.001
I0518 15:51:59.583389  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6693	3.125	79.0631	0	88.8437	4.94792	86.3343	0	82.0288	0	81.0117	0	72.5487	0	27.7275	2	
I0518 15:51:59.658116  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.04167	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:51:59.659900  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:51:59.659947  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:51:59.669766  4008 solver.cpp:260]     Total regularization terms: 1.01768 loss+regular. : 2.45255
I0518 15:53:24.278831  4008 solver.cpp:231] Iteration 212200, loss = 1.60752
I0518 15:53:24.281658  4008 solver.cpp:247]     Train net output #0: loss = 1.60752 (* 1 = 1.60752 loss)
I0518 15:53:24.281694  4008 sgd_solver.cpp:106] Iteration 212200, lr = 0.001
I0518 15:53:24.439479  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.962	3.125	78.8727	0	88.8575	4.94792	86.3747	0	82.0369	0	81.0262	0	72.5658	0	27.734	2	
I0518 15:53:24.514400  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:53:24.516146  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:53:24.516191  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:53:24.526298  4008 solver.cpp:260]     Total regularization terms: 1.01755 loss+regular. : 2.62507
I0518 15:54:49.297477  4008 solver.cpp:231] Iteration 212400, loss = 1.33028
I0518 15:54:49.297783  4008 solver.cpp:247]     Train net output #0: loss = 1.33028 (* 1 = 1.33028 loss)
I0518 15:54:49.297803  4008 sgd_solver.cpp:106] Iteration 212400, lr = 0.001
I0518 15:54:49.458292  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0022	3.125	79.0055	0	88.8978	4.94792	86.4042	0	82.0643	0	81.0406	0	72.5831	0	27.7411	2	
I0518 15:54:49.532801  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:54:49.534634  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:54:49.534680  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:54:49.544491  4008 solver.cpp:260]     Total regularization terms: 1.0173 loss+regular. : 2.34757
I0518 15:55:31.195900  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 15:56:11.412441  4008 solver.cpp:231] Iteration 212600, loss = 1.23214
I0518 15:56:11.412752  4008 solver.cpp:247]     Train net output #0: loss = 1.23214 (* 1 = 1.23214 loss)
I0518 15:56:11.412778  4008 sgd_solver.cpp:106] Iteration 212600, lr = 0.001
I0518 15:56:11.571718  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7669	3.125	79.0553	0	88.8727	4.94792	86.3834	0	82.045	0	81.0545	0	72.6002	0	27.7477	2	
I0518 15:56:11.647243  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:56:11.649303  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:56:11.649356  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:56:11.659415  4008 solver.cpp:260]     Total regularization terms: 1.01717 loss+regular. : 2.24931
I0518 15:57:44.453761  4008 solver.cpp:231] Iteration 212800, loss = 1.46444
I0518 15:57:44.457708  4008 solver.cpp:247]     Train net output #0: loss = 1.46444 (* 1 = 1.46444 loss)
I0518 15:57:44.457737  4008 sgd_solver.cpp:106] Iteration 212800, lr = 0.001
I0518 15:57:44.615941  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9706	3.125	79.1064	0	88.9037	4.94792	86.3974	0	82.0697	0	81.069	0	72.6175	0	27.7545	2	
I0518 15:57:44.690767  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 15:57:44.692162  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 15:57:44.692183  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 15:57:44.706799  4008 solver.cpp:260]     Total regularization terms: 1.01694 loss+regular. : 2.48138
I0518 15:59:00.493844  4008 solver.cpp:348] Iteration 213000, Testing net (#0)
I0518 15:59:39.972167  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:00:14.692957  4008 solver.cpp:415]     Test net output #0: accuracy = 0.555219
I0518 16:00:14.697669  4008 solver.cpp:415]     Test net output #1: loss = 1.91283 (* 1 = 1.91283 loss)
I0518 16:00:14.785414  4008 solver.cpp:231] Iteration 213000, loss = 1.30819
I0518 16:00:14.785529  4008 solver.cpp:247]     Train net output #0: loss = 1.30819 (* 1 = 1.30819 loss)
I0518 16:00:14.785548  4008 sgd_solver.cpp:106] Iteration 213000, lr = 0.001
I0518 16:00:14.951334  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4885	3.125	79.0117	0	88.9247	4.94792	86.3982	0	82.0955	0	81.0833	0	72.6349	0	27.7616	2	
I0518 16:00:15.026569  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:00:15.029140  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:00:15.029183  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:00:15.038996  4008 solver.cpp:260]     Total regularization terms: 1.01675 loss+regular. : 2.32493
I0518 16:01:34.059728  4008 solver.cpp:231] Iteration 213200, loss = 1.17757
I0518 16:01:34.059998  4008 solver.cpp:247]     Train net output #0: loss = 1.17757 (* 1 = 1.17757 loss)
I0518 16:01:34.060015  4008 sgd_solver.cpp:106] Iteration 213200, lr = 0.001
I0518 16:01:34.221112  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6406	3.125	79.0804	0	88.9274	4.94792	86.3872	0	82.1004	0	81.0976	0	72.6516	0	27.769	2	
I0518 16:01:34.298362  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:01:34.300333  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:01:34.300361  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:01:34.310148  4008 solver.cpp:260]     Total regularization terms: 1.01652 loss+regular. : 2.19409
I0518 16:03:02.218526  4008 solver.cpp:231] Iteration 213400, loss = 1.58582
I0518 16:03:02.218796  4008 solver.cpp:247]     Train net output #0: loss = 1.58582 (* 1 = 1.58582 loss)
I0518 16:03:02.218827  4008 sgd_solver.cpp:106] Iteration 213400, lr = 0.001
I0518 16:03:02.378885  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.523	3.125	79.0758	0	88.9348	4.94792	86.4065	0	82.0982	0	81.1118	0	72.6693	0	27.7756	2	
I0518 16:03:02.453282  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:03:02.454768  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:03:02.454836  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:03:02.465255  4008 solver.cpp:260]     Total regularization terms: 1.01635 loss+regular. : 2.60217
I0518 16:03:47.839819  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:04:29.383951  4008 solver.cpp:231] Iteration 213600, loss = 1.6098
I0518 16:04:29.384305  4008 solver.cpp:247]     Train net output #0: loss = 1.6098 (* 1 = 1.6098 loss)
I0518 16:04:29.384325  4008 sgd_solver.cpp:106] Iteration 213600, lr = 0.001
I0518 16:04:29.543989  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6636	3.125	78.7637	0	88.9153	4.94792	86.4315	0	82.116	0	81.1262	0	72.6866	0	27.7828	2	
I0518 16:04:29.618835  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:04:29.620682  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:04:29.620705  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:04:29.641846  4008 solver.cpp:260]     Total regularization terms: 1.01618 loss+regular. : 2.62599
I0518 16:05:49.591439  4008 solver.cpp:231] Iteration 213800, loss = 1.46157
I0518 16:05:49.591799  4008 solver.cpp:247]     Train net output #0: loss = 1.46157 (* 1 = 1.46157 loss)
I0518 16:05:49.591819  4008 sgd_solver.cpp:106] Iteration 213800, lr = 0.001
I0518 16:05:49.754398  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5689	3.125	79.0573	0	88.9353	4.94792	86.4487	0	82.1278	0	81.1404	0	72.7041	0	27.7893	2	
I0518 16:05:49.829787  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:05:49.831737  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:05:49.831774  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:05:49.852524  4008 solver.cpp:260]     Total regularization terms: 1.01599 loss+regular. : 2.47757
I0518 16:07:07.362484  4008 solver.cpp:348] Iteration 214000, Testing net (#0)
I0518 16:07:47.292232  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:08:23.480041  4008 solver.cpp:415]     Test net output #0: accuracy = 0.54938
I0518 16:08:23.480322  4008 solver.cpp:415]     Test net output #1: loss = 1.93658 (* 1 = 1.93658 loss)
I0518 16:08:23.567520  4008 solver.cpp:231] Iteration 214000, loss = 1.29038
I0518 16:08:23.567603  4008 solver.cpp:247]     Train net output #0: loss = 1.29038 (* 1 = 1.29038 loss)
I0518 16:08:23.567620  4008 sgd_solver.cpp:106] Iteration 214000, lr = 0.001
I0518 16:08:23.732748  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0954	3.125	78.7982	0	88.9003	4.94792	86.4342	0	82.1208	0	81.1548	0	72.7215	0	27.7963	2	
I0518 16:08:23.806977  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:08:23.808590  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:08:23.808616  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:08:23.818305  4008 solver.cpp:260]     Total regularization terms: 1.01585 loss+regular. : 2.30623
I0518 16:09:45.336138  4008 solver.cpp:231] Iteration 214200, loss = 1.35285
I0518 16:09:45.336400  4008 solver.cpp:247]     Train net output #0: loss = 1.35285 (* 1 = 1.35285 loss)
I0518 16:09:45.336421  4008 sgd_solver.cpp:106] Iteration 214200, lr = 0.001
I0518 16:09:45.495296  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5545	3.125	78.8958	0	88.9248	4.94792	86.4175	0	82.135	0	81.1693	0	72.7391	0	27.8031	2	
I0518 16:09:45.569602  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:09:45.571390  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:09:45.571418  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:09:45.582054  4008 solver.cpp:260]     Total regularization terms: 1.01565 loss+regular. : 2.36849
I0518 16:11:08.708149  4008 solver.cpp:231] Iteration 214400, loss = 1.53984
I0518 16:11:08.711163  4008 solver.cpp:247]     Train net output #0: loss = 1.53984 (* 1 = 1.53984 loss)
I0518 16:11:08.711189  4008 sgd_solver.cpp:106] Iteration 214400, lr = 0.001
I0518 16:11:08.869741  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3651	3.125	78.7786	0	88.929	4.94792	86.4393	0	82.1594	0	81.1835	0	72.7562	0	27.8101	2	
I0518 16:11:08.943990  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:11:08.945401  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:11:08.945426  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:11:08.955111  4008 solver.cpp:260]     Total regularization terms: 1.01544 loss+regular. : 2.55527
I0518 16:11:58.726691  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:12:38.916321  4008 solver.cpp:231] Iteration 214600, loss = 1.51733
I0518 16:12:38.916574  4008 solver.cpp:247]     Train net output #0: loss = 1.51733 (* 1 = 1.51733 loss)
I0518 16:12:38.916594  4008 sgd_solver.cpp:106] Iteration 214600, lr = 0.001
I0518 16:12:39.075795  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3766	3.125	79.0446	0	88.9544	4.94792	86.462	0	82.1526	0	81.1974	0	72.7733	0	27.8171	2	
I0518 16:12:39.150547  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:12:39.152840  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:12:39.152869  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:12:39.162566  4008 solver.cpp:260]     Total regularization terms: 1.0152 loss+regular. : 2.53252
I0518 16:14:03.050294  4008 solver.cpp:231] Iteration 214800, loss = 1.39847
I0518 16:14:03.050595  4008 solver.cpp:247]     Train net output #0: loss = 1.39847 (* 1 = 1.39847 loss)
I0518 16:14:03.050621  4008 sgd_solver.cpp:106] Iteration 214800, lr = 0.001
I0518 16:14:03.211904  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4053	3.125	79.0612	0	88.9498	4.94792	86.4439	0	82.1619	0	81.212	0	72.7904	0	27.8237	2	
I0518 16:14:03.289389  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:14:03.291625  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:14:03.291671  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:14:03.301599  4008 solver.cpp:260]     Total regularization terms: 1.01501 loss+regular. : 2.41348
I0518 16:15:37.856323  4008 solver.cpp:348] Iteration 215000, Testing net (#0)
I0518 16:16:23.252297  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:17:06.852061  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55162
I0518 16:17:06.852310  4008 solver.cpp:415]     Test net output #1: loss = 1.92339 (* 1 = 1.92339 loss)
I0518 16:17:06.943001  4008 solver.cpp:231] Iteration 215000, loss = 1.74783
I0518 16:17:06.943078  4008 solver.cpp:247]     Train net output #0: loss = 1.74783 (* 1 = 1.74783 loss)
I0518 16:17:06.943096  4008 sgd_solver.cpp:106] Iteration 215000, lr = 0.001
I0518 16:17:07.109807  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4541	3.125	79.1335	0	88.9254	4.94792	86.4467	0	82.1612	0	81.2263	0	72.8074	0	27.8301	2	
I0518 16:17:07.185655  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.08507	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:17:07.187883  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:17:07.187923  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:17:07.198698  4008 solver.cpp:260]     Total regularization terms: 1.01482 loss+regular. : 2.76265
I0518 16:18:33.157560  4008 solver.cpp:231] Iteration 215200, loss = 1.36687
I0518 16:18:33.161658  4008 solver.cpp:247]     Train net output #0: loss = 1.36687 (* 1 = 1.36687 loss)
I0518 16:18:33.161686  4008 sgd_solver.cpp:106] Iteration 215200, lr = 0.001
I0518 16:18:33.317034  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1843	3.125	78.902	0	88.9627	4.94792	86.4696	0	82.1811	0	81.2403	0	72.8244	0	27.8369	2	
I0518 16:18:33.392542  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.12847	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:18:33.395241  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:18:33.395289  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:18:33.405524  4008 solver.cpp:260]     Total regularization terms: 1.01458 loss+regular. : 2.38145
I0518 16:19:58.317493  4008 solver.cpp:231] Iteration 215400, loss = 1.42557
I0518 16:19:58.317888  4008 solver.cpp:247]     Train net output #0: loss = 1.42557 (* 1 = 1.42557 loss)
I0518 16:19:58.317911  4008 sgd_solver.cpp:106] Iteration 215400, lr = 0.001
I0518 16:19:58.477015  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7755	3.125	79.0026	0	88.9552	4.94792	86.4707	0	82.1678	0	81.2542	0	72.8413	0	27.8436	2	
I0518 16:19:58.552266  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.12847	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:19:58.559625  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:19:58.559681  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:19:58.580739  4008 solver.cpp:260]     Total regularization terms: 1.01446 loss+regular. : 2.44002
I0518 16:20:57.904841  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:21:31.221310  4008 solver.cpp:231] Iteration 215600, loss = 1.42763
I0518 16:21:31.221488  4008 solver.cpp:247]     Train net output #0: loss = 1.42763 (* 1 = 1.42763 loss)
I0518 16:21:31.221508  4008 sgd_solver.cpp:106] Iteration 215600, lr = 0.001
I0518 16:21:31.382490  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2704	3.125	78.9297	0	88.976	4.94792	86.4725	0	82.1775	0	81.2687	0	72.8584	0	27.8507	2	
I0518 16:21:31.457460  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.12847	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:21:31.466246  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:21:31.466301  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:21:31.481470  4008 solver.cpp:260]     Total regularization terms: 1.01423 loss+regular. : 2.44185
I0518 16:22:59.345686  4008 solver.cpp:231] Iteration 215800, loss = 1.50886
I0518 16:22:59.346022  4008 solver.cpp:247]     Train net output #0: loss = 1.50886 (* 1 = 1.50886 loss)
I0518 16:22:59.346051  4008 sgd_solver.cpp:106] Iteration 215800, lr = 0.001
I0518 16:22:59.506345  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2905	3.125	78.8994	0	88.9734	4.94792	86.4677	0	82.1913	0	81.2823	0	72.8755	0	27.8582	2	
I0518 16:22:59.581439  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.12847	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:22:59.584046  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:22:59.584105  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:22:59.599177  4008 solver.cpp:260]     Total regularization terms: 1.01404 loss+regular. : 2.5229
I0518 16:24:25.719403  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_216000.caffemodel
I0518 16:26:23.959005  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_216000.solverstate
I0518 16:26:24.501725  4008 solver.cpp:348] Iteration 216000, Testing net (#0)
I0518 16:27:14.631130  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:27:54.383110  4008 solver.cpp:415]     Test net output #0: accuracy = 0.551579
I0518 16:27:54.383327  4008 solver.cpp:415]     Test net output #1: loss = 1.92989 (* 1 = 1.92989 loss)
I0518 16:27:54.471113  4008 solver.cpp:231] Iteration 216000, loss = 1.57349
I0518 16:27:54.471215  4008 solver.cpp:247]     Train net output #0: loss = 1.57349 (* 1 = 1.57349 loss)
I0518 16:27:54.471235  4008 sgd_solver.cpp:106] Iteration 216000, lr = 0.001
I0518 16:27:54.639392  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5976	3.125	79.0277	0	88.9879	4.94792	86.4942	0	82.2125	0	81.2963	0	72.8929	0	27.8654	2	
I0518 16:27:54.641880  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.12847	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:27:54.645278  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:27:54.645336  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:27:54.655474  4008 solver.cpp:260]     Total regularization terms: 1.01389 loss+regular. : 2.58738
I0518 16:29:22.557967  4008 solver.cpp:231] Iteration 216200, loss = 1.34728
I0518 16:29:22.558392  4008 solver.cpp:247]     Train net output #0: loss = 1.34728 (* 1 = 1.34728 loss)
I0518 16:29:22.558424  4008 sgd_solver.cpp:106] Iteration 216200, lr = 0.001
I0518 16:29:22.716979  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3737	3.125	78.973	0	88.9742	4.94792	86.5035	0	82.2347	0	81.3106	0	72.91	0	27.872	2	
I0518 16:29:22.791802  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.12847	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:29:22.794008  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:29:22.794062  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:29:22.804096  4008 solver.cpp:260]     Total regularization terms: 1.01372 loss+regular. : 2.361
I0518 16:30:55.245236  4008 solver.cpp:231] Iteration 216400, loss = 1.4308
I0518 16:30:55.245534  4008 solver.cpp:247]     Train net output #0: loss = 1.4308 (* 1 = 1.4308 loss)
I0518 16:30:55.245571  4008 sgd_solver.cpp:106] Iteration 216400, lr = 0.001
I0518 16:30:55.403698  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6349	3.125	79.0589	0	88.9926	4.94792	86.5016	0	82.2042	0	81.3247	0	72.9268	0	27.8789	2	
I0518 16:30:55.478261  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.12847	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:30:55.479682  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:30:55.479710  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:30:55.489346  4008 solver.cpp:260]     Total regularization terms: 1.01349 loss+regular. : 2.44429
I0518 16:31:53.403172  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:32:20.918954  4008 solver.cpp:231] Iteration 216600, loss = 1.18969
I0518 16:32:20.919050  4008 solver.cpp:247]     Train net output #0: loss = 1.18969 (* 1 = 1.18969 loss)
I0518 16:32:20.919072  4008 sgd_solver.cpp:106] Iteration 216600, lr = 0.001
I0518 16:32:21.079432  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5115	3.125	78.9108	0	89.0005	4.94792	86.5106	0	82.2123	0	81.3384	0	72.9435	0	27.8862	2	
I0518 16:32:21.155207  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.12847	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:32:21.157219  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:32:21.157253  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:32:21.172440  4008 solver.cpp:260]     Total regularization terms: 1.0133 loss+regular. : 2.20299
I0518 16:33:50.971401  4008 solver.cpp:231] Iteration 216800, loss = 1.42598
I0518 16:33:50.971717  4008 solver.cpp:247]     Train net output #0: loss = 1.42598 (* 1 = 1.42598 loss)
I0518 16:33:50.971743  4008 sgd_solver.cpp:106] Iteration 216800, lr = 0.001
I0518 16:33:51.131533  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0753	3.125	78.6475	0	88.9955	4.94792	86.5293	0	82.2257	0	81.3523	0	72.9606	0	27.8926	2	
I0518 16:33:51.206882  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.12847	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:33:51.209002  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:33:51.209080  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:33:51.218948  4008 solver.cpp:260]     Total regularization terms: 1.01313 loss+regular. : 2.43911
I0518 16:35:14.685153  4008 solver.cpp:348] Iteration 217000, Testing net (#0)
I0518 16:36:03.292399  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:36:41.618294  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55508
I0518 16:36:41.618638  4008 solver.cpp:415]     Test net output #1: loss = 1.91526 (* 1 = 1.91526 loss)
I0518 16:36:41.709866  4008 solver.cpp:231] Iteration 217000, loss = 1.23135
I0518 16:36:41.709997  4008 solver.cpp:247]     Train net output #0: loss = 1.23135 (* 1 = 1.23135 loss)
I0518 16:36:41.710024  4008 sgd_solver.cpp:106] Iteration 217000, lr = 0.001
I0518 16:36:41.870560  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4799	3.125	78.8024	0	89.0093	4.94792	86.5237	0	82.2112	0	81.3661	0	72.9776	0	27.9003	2	
I0518 16:36:41.945981  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.17188	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:36:41.948889  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:36:41.948951  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:36:41.959031  4008 solver.cpp:260]     Total regularization terms: 1.01296 loss+regular. : 2.24431
I0518 16:38:08.380975  4008 solver.cpp:231] Iteration 217200, loss = 1.54044
I0518 16:38:08.382467  4008 solver.cpp:247]     Train net output #0: loss = 1.54044 (* 1 = 1.54044 loss)
I0518 16:38:08.382513  4008 sgd_solver.cpp:106] Iteration 217200, lr = 0.001
I0518 16:38:08.540194  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7124	3.125	79.0251	0	89.0151	4.94792	86.5275	0	82.2261	0	81.3802	0	72.9944	0	27.9064	2	
I0518 16:38:08.615824  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.17188	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:38:08.619065  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:38:08.619139  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:38:08.629485  4008 solver.cpp:260]     Total regularization terms: 1.01275 loss+regular. : 2.5532
I0518 16:39:35.665164  4008 solver.cpp:231] Iteration 217400, loss = 1.3392
I0518 16:39:35.670308  4008 solver.cpp:247]     Train net output #0: loss = 1.3392 (* 1 = 1.3392 loss)
I0518 16:39:35.670342  4008 sgd_solver.cpp:106] Iteration 217400, lr = 0.001
I0518 16:39:35.826041  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7898	3.125	79.1917	0	89.0487	4.94792	86.5772	0	82.2578	0	81.3943	0	73.0115	0	27.914	2	
I0518 16:39:35.901015  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.17188	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:39:35.903761  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:39:35.903818  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:39:35.913872  4008 solver.cpp:260]     Total regularization terms: 1.01251 loss+regular. : 2.3517
I0518 16:40:38.171576  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:41:05.291640  4008 solver.cpp:231] Iteration 217600, loss = 1.43246
I0518 16:41:05.291726  4008 solver.cpp:247]     Train net output #0: loss = 1.43246 (* 1 = 1.43246 loss)
I0518 16:41:05.291749  4008 sgd_solver.cpp:106] Iteration 217600, lr = 0.001
I0518 16:41:05.450345  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4656	3.125	79.279	0	89.0174	4.94792	86.5637	0	82.2584	0	81.4078	0	73.0282	0	27.9209	2	
I0518 16:41:05.525353  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.17188	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:41:05.528195  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:41:05.528249  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:41:05.538238  4008 solver.cpp:260]     Total regularization terms: 1.01232 loss+regular. : 2.44479
I0518 16:42:35.729457  4008 solver.cpp:231] Iteration 217800, loss = 1.46646
I0518 16:42:35.730712  4008 solver.cpp:247]     Train net output #0: loss = 1.46646 (* 1 = 1.46646 loss)
I0518 16:42:35.730783  4008 sgd_solver.cpp:106] Iteration 217800, lr = 0.001
I0518 16:42:35.890038  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8444	3.125	79.2741	0	89.0539	4.94792	86.5845	0	82.2824	0	81.4216	0	73.0449	0	27.9281	2	
I0518 16:42:35.965237  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.17188	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:42:35.967990  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:42:35.968049  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:42:35.978444  4008 solver.cpp:260]     Total regularization terms: 1.01208 loss+regular. : 2.47854
I0518 16:44:05.709853  4008 solver.cpp:348] Iteration 218000, Testing net (#0)
I0518 16:44:50.839920  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:45:33.383929  4008 solver.cpp:415]     Test net output #0: accuracy = 0.550559
I0518 16:45:33.384395  4008 solver.cpp:415]     Test net output #1: loss = 1.9362 (* 1 = 1.9362 loss)
I0518 16:45:33.477900  4008 solver.cpp:231] Iteration 218000, loss = 1.41374
I0518 16:45:33.477998  4008 solver.cpp:247]     Train net output #0: loss = 1.41374 (* 1 = 1.41374 loss)
I0518 16:45:33.478029  4008 sgd_solver.cpp:106] Iteration 218000, lr = 0.001
I0518 16:45:33.642036  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6636	3.125	79.054	0	89.0582	4.94792	86.5914	0	82.2969	0	81.4355	0	73.0611	0	27.9346	2	
I0518 16:45:33.717075  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.17188	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:45:33.719768  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:45:33.719826  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:45:33.729964  4008 solver.cpp:260]     Total regularization terms: 1.0119 loss+regular. : 2.42564
I0518 16:47:02.936411  4008 solver.cpp:231] Iteration 218200, loss = 1.44325
I0518 16:47:02.936703  4008 solver.cpp:247]     Train net output #0: loss = 1.44325 (* 1 = 1.44325 loss)
I0518 16:47:02.936724  4008 sgd_solver.cpp:106] Iteration 218200, lr = 0.001
I0518 16:47:03.098469  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6263	3.125	79.1367	0	89.0549	4.94792	86.5964	0	82.251	0	81.4491	0	73.0783	0	27.9414	2	
I0518 16:47:03.173346  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:47:03.175642  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:47:03.175693  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:47:03.189687  4008 solver.cpp:260]     Total regularization terms: 1.0117 loss+regular. : 2.45495
I0518 16:48:27.198894  4008 solver.cpp:231] Iteration 218400, loss = 1.2915
I0518 16:48:27.201679  4008 solver.cpp:247]     Train net output #0: loss = 1.2915 (* 1 = 1.2915 loss)
I0518 16:48:27.201720  4008 sgd_solver.cpp:106] Iteration 218400, lr = 0.001
I0518 16:48:27.358872  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6837	3.125	78.9059	0	89.0594	4.94792	86.5837	0	82.3278	0	81.4629	0	73.0948	0	27.9477	2	
I0518 16:48:27.434105  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:48:27.437091  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:48:27.437146  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:48:27.447475  4008 solver.cpp:260]     Total regularization terms: 1.01157 loss+regular. : 2.30307
I0518 16:49:32.352159  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:49:57.354990  4008 solver.cpp:231] Iteration 218600, loss = 1.28182
I0518 16:49:57.355101  4008 solver.cpp:247]     Train net output #0: loss = 1.28182 (* 1 = 1.28182 loss)
I0518 16:49:57.355120  4008 sgd_solver.cpp:106] Iteration 218600, lr = 0.001
I0518 16:49:57.514361  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4828	3.125	79.0312	0	89.0653	4.94792	86.6133	0	82.331	0	81.4762	0	73.1116	0	27.9552	2	
I0518 16:49:57.590062  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:49:57.592257  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:49:57.592319  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:49:57.607318  4008 solver.cpp:260]     Total regularization terms: 1.01139 loss+regular. : 2.29321
I0518 16:51:24.863674  4008 solver.cpp:231] Iteration 218800, loss = 1.51428
I0518 16:51:24.864023  4008 solver.cpp:247]     Train net output #0: loss = 1.51428 (* 1 = 1.51428 loss)
I0518 16:51:24.864042  4008 sgd_solver.cpp:106] Iteration 218800, lr = 0.001
I0518 16:51:25.023677  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3651	3.125	79.0918	0	89.0823	4.94792	86.5876	0	82.3107	0	81.4897	0	73.1283	0	27.9615	2	
I0518 16:51:25.098752  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:51:25.100548  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:51:25.100595  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:51:25.110458  4008 solver.cpp:260]     Total regularization terms: 1.01126 loss+regular. : 2.52554
I0518 16:53:01.475667  4008 solver.cpp:348] Iteration 219000, Testing net (#0)
I0518 16:53:55.327965  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:54:43.869783  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55528
I0518 16:54:43.870621  4008 solver.cpp:415]     Test net output #1: loss = 1.91673 (* 1 = 1.91673 loss)
I0518 16:54:43.962920  4008 solver.cpp:231] Iteration 219000, loss = 1.6353
I0518 16:54:43.963037  4008 solver.cpp:247]     Train net output #0: loss = 1.6353 (* 1 = 1.6353 loss)
I0518 16:54:43.963063  4008 sgd_solver.cpp:106] Iteration 219000, lr = 0.001
I0518 16:54:44.122993  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6406	3.125	79.18	0	89.0789	4.94792	86.611	0	82.3344	0	81.5036	0	73.1449	0	27.9682	2	
I0518 16:54:44.198007  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:54:44.200718  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:54:44.200765  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:54:44.210652  4008 solver.cpp:260]     Total regularization terms: 1.01102 loss+regular. : 2.64631
I0518 16:56:01.074020  4008 solver.cpp:231] Iteration 219200, loss = 1.30348
I0518 16:56:01.077662  4008 solver.cpp:247]     Train net output #0: loss = 1.30348 (* 1 = 1.30348 loss)
I0518 16:56:01.077693  4008 sgd_solver.cpp:106] Iteration 219200, lr = 0.001
I0518 16:56:01.235147  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7066	3.125	78.9535	0	89.0488	4.94792	86.602	0	82.3437	0	81.5172	0	73.1623	0	27.9753	2	
I0518 16:56:01.310719  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:56:01.312882  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:56:01.312916  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:56:01.327972  4008 solver.cpp:260]     Total regularization terms: 1.01088 loss+regular. : 2.31436
I0518 16:57:17.407817  4008 solver.cpp:231] Iteration 219400, loss = 1.26667
I0518 16:57:17.408013  4008 solver.cpp:247]     Train net output #0: loss = 1.26667 (* 1 = 1.26667 loss)
I0518 16:57:17.408032  4008 sgd_solver.cpp:106] Iteration 219400, lr = 0.001
I0518 16:57:17.567293  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3221	3.125	79.1543	0	89.0853	4.94792	86.6322	0	82.3364	0	81.5306	0	73.1787	0	27.9825	2	
I0518 16:57:17.642148  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:57:17.645012  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:57:17.645073  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:57:17.654786  4008 solver.cpp:260]     Total regularization terms: 1.01071 loss+regular. : 2.27737
I0518 16:58:24.213793  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 16:58:47.417809  4008 solver.cpp:231] Iteration 219600, loss = 1.48359
I0518 16:58:47.417892  4008 solver.cpp:247]     Train net output #0: loss = 1.48359 (* 1 = 1.48359 loss)
I0518 16:58:47.417915  4008 sgd_solver.cpp:106] Iteration 219600, lr = 0.001
I0518 16:58:47.576548  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3565	3.125	79.1497	0	89.1073	4.94792	86.6594	0	82.3502	0	81.5442	0	73.1952	0	27.9893	2	
I0518 16:58:47.651065  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 16:58:47.652984  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 16:58:47.653012  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 16:58:47.662830  4008 solver.cpp:260]     Total regularization terms: 1.01051 loss+regular. : 2.4941
I0518 17:00:07.803948  4008 solver.cpp:231] Iteration 219800, loss = 1.37755
I0518 17:00:07.804241  4008 solver.cpp:247]     Train net output #0: loss = 1.37755 (* 1 = 1.37755 loss)
I0518 17:00:07.804260  4008 sgd_solver.cpp:106] Iteration 219800, lr = 0.001
I0518 17:00:07.964524  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2876	3.125	79.0941	0	89.0712	4.94792	86.6535	0	82.3622	0	81.558	0	73.2122	0	27.9958	2	
I0518 17:00:08.039026  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:00:08.040873  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:00:08.040895  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:00:08.057504  4008 solver.cpp:260]     Total regularization terms: 1.01038 loss+regular. : 2.38794
I0518 17:01:38.002408  4008 solver.cpp:348] Iteration 220000, Testing net (#0)
I0518 17:02:19.635620  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:02:55.267077  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5545
I0518 17:02:55.267372  4008 solver.cpp:415]     Test net output #1: loss = 1.91226 (* 1 = 1.91226 loss)
I0518 17:02:55.355690  4008 solver.cpp:231] Iteration 220000, loss = 1.36881
I0518 17:02:55.355783  4008 solver.cpp:247]     Train net output #0: loss = 1.36881 (* 1 = 1.36881 loss)
I0518 17:02:55.355808  4008 sgd_solver.cpp:106] Iteration 220000, lr = 0.001
I0518 17:02:55.522080  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.698	3.125	78.9645	0	89.0471	4.94792	86.6054	0	82.357	0	81.5714	0	73.229	0	28.0029	2	
I0518 17:02:55.597682  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:02:55.601174  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:02:55.601236  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:02:55.611716  4008 solver.cpp:260]     Total regularization terms: 1.01024 loss+regular. : 2.37905
I0518 17:04:24.954768  4008 solver.cpp:231] Iteration 220200, loss = 1.50075
I0518 17:04:24.955091  4008 solver.cpp:247]     Train net output #0: loss = 1.50075 (* 1 = 1.50075 loss)
I0518 17:04:24.955118  4008 sgd_solver.cpp:106] Iteration 220200, lr = 0.001
I0518 17:04:25.115020  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6463	3.125	79.0742	0	89.0953	4.94792	86.6544	0	82.3755	0	81.5849	0	73.2459	0	28.0098	2	
I0518 17:04:25.191001  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:04:25.194573  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:04:25.194629  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:04:25.204723  4008 solver.cpp:260]     Total regularization terms: 1.01003 loss+regular. : 2.51078
I0518 17:06:00.065058  4008 solver.cpp:231] Iteration 220400, loss = 1.3148
I0518 17:06:00.065440  4008 solver.cpp:247]     Train net output #0: loss = 1.3148 (* 1 = 1.3148 loss)
I0518 17:06:00.065462  4008 sgd_solver.cpp:106] Iteration 220400, lr = 0.001
I0518 17:06:00.226078  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.787	3.125	79.0078	0	89.0738	4.94792	86.6381	0	82.3943	0	81.5983	0	73.2625	0	28.0158	2	
I0518 17:06:00.300734  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:06:00.302808  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:06:00.302852  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:06:00.312645  4008 solver.cpp:260]     Total regularization terms: 1.00989 loss+regular. : 2.32469
I0518 17:07:15.463748  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:07:31.466317  4008 solver.cpp:231] Iteration 220600, loss = 1.39923
I0518 17:07:31.466436  4008 solver.cpp:247]     Train net output #0: loss = 1.39923 (* 1 = 1.39923 loss)
I0518 17:07:31.466459  4008 sgd_solver.cpp:106] Iteration 220600, lr = 0.001
I0518 17:07:31.626693  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4828	3.125	79.0133	0	89.0771	4.94792	86.6392	0	82.3898	0	81.6116	0	73.2789	0	28.023	2	
I0518 17:07:31.702301  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:07:31.704627  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:07:31.704663  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:07:31.718809  4008 solver.cpp:260]     Total regularization terms: 1.00977 loss+regular. : 2.409
I0518 17:08:56.584252  4008 solver.cpp:231] Iteration 220800, loss = 1.19165
I0518 17:08:56.584535  4008 solver.cpp:247]     Train net output #0: loss = 1.19165 (* 1 = 1.19165 loss)
I0518 17:08:56.584561  4008 sgd_solver.cpp:106] Iteration 220800, lr = 0.001
I0518 17:08:56.743139  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.457	3.125	79.0335	0	89.1189	4.94792	86.6633	0	82.4142	0	81.6252	0	73.2961	0	28.029	2	
I0518 17:08:56.818375  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.21528	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:08:56.821115  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:08:56.821157  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:08:56.831142  4008 solver.cpp:260]     Total regularization terms: 1.00946 loss+regular. : 2.20112
I0518 17:10:22.925168  4008 solver.cpp:348] Iteration 221000, Testing net (#0)
I0518 17:11:12.422173  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:11:51.527127  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55542
I0518 17:11:51.527359  4008 solver.cpp:415]     Test net output #1: loss = 1.91247 (* 1 = 1.91247 loss)
I0518 17:11:51.615300  4008 solver.cpp:231] Iteration 221000, loss = 1.222
I0518 17:11:51.615372  4008 solver.cpp:247]     Train net output #0: loss = 1.222 (* 1 = 1.222 loss)
I0518 17:11:51.615391  4008 sgd_solver.cpp:106] Iteration 221000, lr = 0.001
I0518 17:11:51.783748  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7267	3.125	79.3421	0	89.1305	4.94792	86.6669	0	82.4115	0	81.6385	0	73.3126	0	28.0357	2	
I0518 17:11:51.858644  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:11:51.861343  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:11:51.861387  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:11:51.871250  4008 solver.cpp:260]     Total regularization terms: 1.00931 loss+regular. : 2.23131
I0518 17:13:22.776671  4008 solver.cpp:231] Iteration 221200, loss = 1.38325
I0518 17:13:22.777011  4008 solver.cpp:247]     Train net output #0: loss = 1.38325 (* 1 = 1.38325 loss)
I0518 17:13:22.777040  4008 sgd_solver.cpp:106] Iteration 221200, lr = 0.001
I0518 17:13:22.937453  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6865	3.125	79.2467	0	89.1347	4.94792	86.6841	0	82.4131	0	81.6519	0	73.3288	0	28.0428	2	
I0518 17:13:23.013303  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:13:23.017911  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:13:23.017993  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:13:23.028354  4008 solver.cpp:260]     Total regularization terms: 1.00913 loss+regular. : 2.39238
I0518 17:14:43.012627  4008 solver.cpp:231] Iteration 221400, loss = 1.38483
I0518 17:14:43.013099  4008 solver.cpp:247]     Train net output #0: loss = 1.38483 (* 1 = 1.38483 loss)
I0518 17:14:43.013131  4008 sgd_solver.cpp:106] Iteration 221400, lr = 0.001
I0518 17:14:43.172801  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4627	3.125	79.0843	0	89.133	4.94792	86.6815	0	82.4323	0	81.6655	0	73.3448	0	28.0499	2	
I0518 17:14:43.248378  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:14:43.251986  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:14:43.252045  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:14:43.262318  4008 solver.cpp:260]     Total regularization terms: 1.00894 loss+regular. : 2.39377
I0518 17:15:56.835927  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:16:09.487515  4008 solver.cpp:231] Iteration 221600, loss = 1.43419
I0518 17:16:09.487601  4008 solver.cpp:247]     Train net output #0: loss = 1.43419 (* 1 = 1.43419 loss)
I0518 17:16:09.487629  4008 sgd_solver.cpp:106] Iteration 221600, lr = 0.001
I0518 17:16:09.649405  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4828	3.125	79.1849	0	89.1485	4.94792	86.6778	0	82.4461	0	81.6791	0	73.3615	0	28.0565	2	
I0518 17:16:09.723920  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:16:09.726073  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:16:09.726109  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:16:09.743249  4008 solver.cpp:260]     Total regularization terms: 1.00877 loss+regular. : 2.44296
I0518 17:17:36.835603  4008 solver.cpp:231] Iteration 221800, loss = 1.26216
I0518 17:17:36.835865  4008 solver.cpp:247]     Train net output #0: loss = 1.26216 (* 1 = 1.26216 loss)
I0518 17:17:36.835887  4008 sgd_solver.cpp:106] Iteration 221800, lr = 0.001
I0518 17:17:37.001983  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1757	3.125	78.4255	0	89.1284	4.94792	86.7052	0	82.4617	0	81.6923	0	73.3779	0	28.063	2	
I0518 17:17:37.090976  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:17:37.092777  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:17:37.092808  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:17:37.102866  4008 solver.cpp:260]     Total regularization terms: 1.00863 loss+regular. : 2.27079
I0518 17:19:03.257711  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_222000.caffemodel
I0518 17:19:36.012974  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_222000.solverstate
I0518 17:19:36.592751  4008 solver.cpp:348] Iteration 222000, Testing net (#0)
I0518 17:20:27.561059  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:21:04.680932  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55378
I0518 17:21:04.685662  4008 solver.cpp:415]     Test net output #1: loss = 1.92008 (* 1 = 1.92008 loss)
I0518 17:21:04.774776  4008 solver.cpp:231] Iteration 222000, loss = 1.31914
I0518 17:21:04.774868  4008 solver.cpp:247]     Train net output #0: loss = 1.31914 (* 1 = 1.31914 loss)
I0518 17:21:04.774931  4008 sgd_solver.cpp:106] Iteration 222000, lr = 0.001
I0518 17:21:04.940624  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4254	3.125	79.2217	0	89.1544	4.94792	86.7356	0	82.4655	0	81.7059	0	73.3937	0	28.0692	2	
I0518 17:21:04.942493  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:21:04.945228  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:21:04.945271  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:21:04.955163  4008 solver.cpp:260]     Total regularization terms: 1.00839 loss+regular. : 2.32753
I0518 17:22:37.336683  4008 solver.cpp:231] Iteration 222200, loss = 1.43045
I0518 17:22:37.336998  4008 solver.cpp:247]     Train net output #0: loss = 1.43045 (* 1 = 1.43045 loss)
I0518 17:22:37.337028  4008 sgd_solver.cpp:106] Iteration 222200, lr = 0.001
I0518 17:22:37.495088  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1987	3.125	78.9369	0	89.1339	4.94792	86.7191	0	82.4809	0	81.7192	0	73.4095	0	28.0755	2	
I0518 17:22:37.569974  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:22:37.573864  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:22:37.573930  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:22:37.584359  4008 solver.cpp:260]     Total regularization terms: 1.00828 loss+regular. : 2.43873
I0518 17:24:03.477308  4008 solver.cpp:231] Iteration 222400, loss = 1.31121
I0518 17:24:03.477602  4008 solver.cpp:247]     Train net output #0: loss = 1.31121 (* 1 = 1.31121 loss)
I0518 17:24:03.477624  4008 sgd_solver.cpp:106] Iteration 222400, lr = 0.001
I0518 17:24:03.637965  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2762	3.125	79.2646	0	89.1691	4.94792	86.7471	0	82.4868	0	81.7322	0	73.4257	0	28.082	2	
I0518 17:24:03.712551  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:24:03.714704  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:24:03.714752  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:24:03.724570  4008 solver.cpp:260]     Total regularization terms: 1.00808 loss+regular. : 2.3193
I0518 17:25:20.355250  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:25:31.785398  4008 solver.cpp:231] Iteration 222600, loss = 1.29276
I0518 17:25:31.785503  4008 solver.cpp:247]     Train net output #0: loss = 1.29276 (* 1 = 1.29276 loss)
I0518 17:25:31.785522  4008 sgd_solver.cpp:106] Iteration 222600, lr = 0.001
I0518 17:25:31.945708  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6148	3.125	79.1113	0	89.1706	4.94792	86.7294	0	82.4632	0	81.7456	0	73.4416	0	28.0889	2	
I0518 17:25:32.020516  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:25:32.022544  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:25:32.022593  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:25:32.032531  4008 solver.cpp:260]     Total regularization terms: 1.00793 loss+regular. : 2.30069
I0518 17:27:02.912156  4008 solver.cpp:231] Iteration 222800, loss = 1.5068
I0518 17:27:02.912499  4008 solver.cpp:247]     Train net output #0: loss = 1.5068 (* 1 = 1.5068 loss)
I0518 17:27:02.912523  4008 sgd_solver.cpp:106] Iteration 222800, lr = 0.001
I0518 17:27:03.072300  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0351	3.125	79.2314	0	89.1793	4.94792	86.7438	0	82.4908	0	81.7588	0	73.4581	0	28.0955	2	
I0518 17:27:03.147543  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:27:03.150746  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:27:03.150795  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:27:03.160647  4008 solver.cpp:260]     Total regularization terms: 1.00769 loss+regular. : 2.51449
I0518 17:28:26.628216  4008 solver.cpp:348] Iteration 223000, Testing net (#0)
I0518 17:29:14.968273  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:29:50.380585  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55474
I0518 17:29:50.380908  4008 solver.cpp:415]     Test net output #1: loss = 1.92017 (* 1 = 1.92017 loss)
I0518 17:29:50.497051  4008 solver.cpp:231] Iteration 223000, loss = 1.46238
I0518 17:29:50.497159  4008 solver.cpp:247]     Train net output #0: loss = 1.46238 (* 1 = 1.46238 loss)
I0518 17:29:50.497185  4008 sgd_solver.cpp:106] Iteration 223000, lr = 0.001
I0518 17:29:50.656039  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3881	3.125	79.1904	0	89.1987	4.94792	86.7618	0	82.4956	0	81.7719	0	73.4737	0	28.1033	2	
I0518 17:29:50.731878  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:29:50.734678  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:29:50.734729  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:29:50.744864  4008 solver.cpp:260]     Total regularization terms: 1.00752 loss+regular. : 2.46989
I0518 17:31:20.066840  4008 solver.cpp:231] Iteration 223200, loss = 1.37652
I0518 17:31:20.067131  4008 solver.cpp:247]     Train net output #0: loss = 1.37652 (* 1 = 1.37652 loss)
I0518 17:31:20.067149  4008 sgd_solver.cpp:106] Iteration 223200, lr = 0.001
I0518 17:31:20.227303  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3537	3.125	79.3464	0	89.1521	4.94792	86.7602	0	82.4883	0	81.7853	0	73.4894	0	28.11	2	
I0518 17:31:20.302011  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:31:20.303882  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:31:20.303923  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:31:20.313873  4008 solver.cpp:260]     Total regularization terms: 1.00731 loss+regular. : 2.38383
I0518 17:32:46.016913  4008 solver.cpp:231] Iteration 223400, loss = 1.44434
I0518 17:32:46.017248  4008 solver.cpp:247]     Train net output #0: loss = 1.44434 (* 1 = 1.44434 loss)
I0518 17:32:46.017277  4008 sgd_solver.cpp:106] Iteration 223400, lr = 0.001
I0518 17:32:46.177279  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3881	3.125	79.0915	0	89.1736	4.94792	86.7563	0	82.5134	0	81.7986	0	73.5059	0	28.1172	2	
I0518 17:32:46.253365  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:32:46.255272  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:32:46.255318  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:32:46.285434  4008 solver.cpp:260]     Total regularization terms: 1.00716 loss+regular. : 2.4515
I0518 17:34:05.159436  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:34:12.868288  4008 solver.cpp:231] Iteration 223600, loss = 1.34333
I0518 17:34:12.868398  4008 solver.cpp:247]     Train net output #0: loss = 1.34333 (* 1 = 1.34333 loss)
I0518 17:34:12.868418  4008 sgd_solver.cpp:106] Iteration 223600, lr = 0.001
I0518 17:34:13.027344  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4598	3.125	79.0462	0	89.1756	4.94792	86.7952	0	82.5345	0	81.8117	0	73.5226	0	28.1237	2	
I0518 17:34:13.102908  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:34:13.106643  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:34:13.106711  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:34:13.116865  4008 solver.cpp:260]     Total regularization terms: 1.00699 loss+regular. : 2.35032
I0518 17:35:38.130976  4008 solver.cpp:231] Iteration 223800, loss = 1.21358
I0518 17:35:38.131347  4008 solver.cpp:247]     Train net output #0: loss = 1.21358 (* 1 = 1.21358 loss)
I0518 17:35:38.131371  4008 sgd_solver.cpp:106] Iteration 223800, lr = 0.001
I0518 17:35:38.292547  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5803	3.125	79.1182	0	89.1878	4.94792	86.7674	0	82.5378	0	81.8251	0	73.5388	0	28.1304	2	
I0518 17:35:38.370290  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:35:38.373282  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:35:38.373333  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:35:38.383508  4008 solver.cpp:260]     Total regularization terms: 1.00686 loss+regular. : 2.22043
I0518 17:37:09.641855  4008 solver.cpp:348] Iteration 224000, Testing net (#0)
I0518 17:38:00.116519  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:38:34.688799  4008 solver.cpp:415]     Test net output #0: accuracy = 0.550939
I0518 17:38:34.689136  4008 solver.cpp:415]     Test net output #1: loss = 1.92898 (* 1 = 1.92898 loss)
I0518 17:38:34.777725  4008 solver.cpp:231] Iteration 224000, loss = 1.23449
I0518 17:38:34.777801  4008 solver.cpp:247]     Train net output #0: loss = 1.23449 (* 1 = 1.23449 loss)
I0518 17:38:34.777819  4008 sgd_solver.cpp:106] Iteration 224000, lr = 0.001
I0518 17:38:34.943202  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4426	3.125	79.1162	0	89.1747	4.94792	86.7979	0	82.5385	0	81.8379	0	73.5542	0	28.1361	2	
I0518 17:38:35.018371  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:38:35.021466  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:38:35.021514  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:38:35.033993  4008 solver.cpp:260]     Total regularization terms: 1.00668 loss+regular. : 2.24117
I0518 17:40:08.852421  4008 solver.cpp:231] Iteration 224200, loss = 1.41843
I0518 17:40:08.852699  4008 solver.cpp:247]     Train net output #0: loss = 1.41843 (* 1 = 1.41843 loss)
I0518 17:40:08.852720  4008 sgd_solver.cpp:106] Iteration 224200, lr = 0.001
I0518 17:40:09.014047  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3192	3.125	79.2988	0	89.1891	4.94792	86.806	0	82.5516	0	81.851	0	73.5702	0	28.1425	2	
I0518 17:40:09.088596  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:40:09.091051  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:40:09.091081  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:40:09.100764  4008 solver.cpp:260]     Total regularization terms: 1.00646 loss+regular. : 2.42489
I0518 17:41:42.256176  4008 solver.cpp:231] Iteration 224400, loss = 1.4152
I0518 17:41:42.256433  4008 solver.cpp:247]     Train net output #0: loss = 1.4152 (* 1 = 1.4152 loss)
I0518 17:41:42.256453  4008 sgd_solver.cpp:106] Iteration 224400, lr = 0.001
I0518 17:41:42.418546  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3135	3.125	79.2422	0	89.2229	4.94792	86.8075	0	82.5643	0	81.8638	0	73.5859	0	28.1494	2	
I0518 17:41:42.493933  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:41:42.496510  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:41:42.496556  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:41:42.506866  4008 solver.cpp:260]     Total regularization terms: 1.00625 loss+regular. : 2.42145
I0518 17:43:12.234340  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:43:17.881451  4008 solver.cpp:231] Iteration 224600, loss = 1.23047
I0518 17:43:17.881594  4008 solver.cpp:247]     Train net output #0: loss = 1.23047 (* 1 = 1.23047 loss)
I0518 17:43:17.881624  4008 sgd_solver.cpp:106] Iteration 224600, lr = 0.001
I0518 17:43:18.042623  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3537	3.125	79.2109	0	89.1869	4.94792	86.7953	0	82.5675	0	81.8767	0	73.6024	0	28.1557	2	
I0518 17:43:18.118535  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:43:18.121831  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2	
I0518 17:43:18.121896  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:43:18.132055  4008 solver.cpp:260]     Total regularization terms: 1.00606 loss+regular. : 2.23652
I0518 17:44:42.221127  4008 solver.cpp:231] Iteration 224800, loss = 1.33735
I0518 17:44:42.221585  4008 solver.cpp:247]     Train net output #0: loss = 1.33735 (* 1 = 1.33735 loss)
I0518 17:44:42.221622  4008 sgd_solver.cpp:106] Iteration 224800, lr = 0.001
I0518 17:44:42.381280  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.411	3.125	79.3151	0	89.2066	4.94792	86.8423	0	82.593	0	81.89	0	73.6184	0	28.1625	2.1	
I0518 17:44:42.457226  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:44:42.460839  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 17:44:42.460901  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:44:42.471102  4008 solver.cpp:260]     Total regularization terms: 1.00589 loss+regular. : 2.34324
I0518 17:46:07.676434  4008 solver.cpp:348] Iteration 225000, Testing net (#0)
I0518 17:46:57.746464  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:47:29.738978  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55522
I0518 17:47:29.739226  4008 solver.cpp:415]     Test net output #1: loss = 1.91572 (* 1 = 1.91572 loss)
I0518 17:47:29.826956  4008 solver.cpp:231] Iteration 225000, loss = 1.48619
I0518 17:47:29.827095  4008 solver.cpp:247]     Train net output #0: loss = 1.48619 (* 1 = 1.48619 loss)
I0518 17:47:29.827121  4008 sgd_solver.cpp:106] Iteration 225000, lr = 0.001
I0518 17:47:29.990471  4008 sgd_solver.cpp:120]     Element Sparsity %: 
11.8199	3.125	79.3366	0	89.1997	4.94792	86.8086	0	82.5977	0	81.9031	0	73.6338	0	28.1687	2.1	
I0518 17:47:30.065279  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:47:30.067690  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 17:47:30.067769  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:47:30.077728  4008 solver.cpp:260]     Total regularization terms: 1.00562 loss+regular. : 2.49181
I0518 17:49:02.046381  4008 solver.cpp:231] Iteration 225200, loss = 1.41504
I0518 17:49:02.049654  4008 solver.cpp:247]     Train net output #0: loss = 1.41504 (* 1 = 1.41504 loss)
I0518 17:49:02.049688  4008 sgd_solver.cpp:106] Iteration 225200, lr = 0.001
I0518 17:49:02.207676  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2389	3.125	79.3717	0	89.2381	4.94792	86.8354	0	82.5876	0	81.9159	0	73.6503	0	28.1757	2.1	
I0518 17:49:02.283635  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:49:02.287099  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 17:49:02.287169  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:49:02.297227  4008 solver.cpp:260]     Total regularization terms: 1.00543 loss+regular. : 2.42048
I0518 17:50:26.007694  4008 solver.cpp:231] Iteration 225400, loss = 1.56878
I0518 17:50:26.007941  4008 solver.cpp:247]     Train net output #0: loss = 1.56878 (* 1 = 1.56878 loss)
I0518 17:50:26.007958  4008 sgd_solver.cpp:106] Iteration 225400, lr = 0.001
I0518 17:50:26.169294  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3881	3.125	79.474	0	89.2068	4.94792	86.8244	0	82.6154	0	81.9291	0	73.6665	0	28.1822	2.1	
I0518 17:50:26.244185  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:50:26.245950  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 17:50:26.246031  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:50:26.267114  4008 solver.cpp:260]     Total regularization terms: 1.00529 loss+regular. : 2.57407
I0518 17:51:49.559773  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:51:50.897094  4008 solver.cpp:231] Iteration 225600, loss = 1.39648
I0518 17:51:50.897207  4008 solver.cpp:247]     Train net output #0: loss = 1.39648 (* 1 = 1.39648 loss)
I0518 17:51:50.897228  4008 sgd_solver.cpp:106] Iteration 225600, lr = 0.001
I0518 17:51:51.056869  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7353	3.125	79.3988	0	89.2275	4.94792	86.8398	0	82.6292	0	81.942	0	73.6829	0	28.1896	2.1	
I0518 17:51:51.131917  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:51:51.134048  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 17:51:51.134099  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:51:51.147191  4008 solver.cpp:260]     Total regularization terms: 1.00511 loss+regular. : 2.40158
I0518 17:53:19.180112  4008 solver.cpp:231] Iteration 225800, loss = 1.65066
I0518 17:53:19.180443  4008 solver.cpp:247]     Train net output #0: loss = 1.65066 (* 1 = 1.65066 loss)
I0518 17:53:19.180465  4008 sgd_solver.cpp:106] Iteration 225800, lr = 0.001
I0518 17:53:19.347298  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5488	3.125	79.4027	0	89.2344	4.94792	86.852	0	82.6194	0	81.9549	0	73.6984	0	28.1966	2.1	
I0518 17:53:19.422430  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:53:19.425245  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 17:53:19.425292  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:53:19.435225  4008 solver.cpp:260]     Total regularization terms: 1.00492 loss+regular. : 2.65558
I0518 17:54:49.103149  4008 solver.cpp:348] Iteration 226000, Testing net (#0)
I0518 17:55:33.433490  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 17:56:04.461236  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55392
I0518 17:56:04.461923  4008 solver.cpp:415]     Test net output #1: loss = 1.91511 (* 1 = 1.91511 loss)
I0518 17:56:04.548764  4008 solver.cpp:231] Iteration 226000, loss = 1.26631
I0518 17:56:04.548851  4008 solver.cpp:247]     Train net output #0: loss = 1.26631 (* 1 = 1.26631 loss)
I0518 17:56:04.548882  4008 sgd_solver.cpp:106] Iteration 226000, lr = 0.001
I0518 17:56:04.716219  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.566	3.125	79.2754	0	89.2501	4.94792	86.8675	0	82.6122	0	81.9681	0	73.7145	0	28.2031	2.1	
I0518 17:56:04.790751  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:56:04.792533  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 17:56:04.792582  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:56:04.802639  4008 solver.cpp:260]     Total regularization terms: 1.00479 loss+regular. : 2.2711
I0518 17:57:27.720970  4008 solver.cpp:231] Iteration 226200, loss = 1.37821
I0518 17:57:27.721304  4008 solver.cpp:247]     Train net output #0: loss = 1.37821 (* 1 = 1.37821 loss)
I0518 17:57:27.721324  4008 sgd_solver.cpp:106] Iteration 226200, lr = 0.001
I0518 17:57:27.881229  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3106	3.125	79.5098	0	89.2403	4.94792	86.8716	0	82.6466	0	81.9812	0	73.7304	0	28.2097	2.1	
I0518 17:57:27.955701  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:57:27.957752  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 17:57:27.957797  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:57:27.967633  4008 solver.cpp:260]     Total regularization terms: 1.00451 loss+regular. : 2.38272
I0518 17:59:00.243156  4008 solver.cpp:231] Iteration 226400, loss = 1.44363
I0518 17:59:00.243505  4008 solver.cpp:247]     Train net output #0: loss = 1.44363 (* 1 = 1.44363 loss)
I0518 17:59:00.243533  4008 sgd_solver.cpp:106] Iteration 226400, lr = 0.001
I0518 17:59:00.402138  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.589	3.125	79.4189	0	89.2428	4.94792	86.8619	0	82.6389	0	81.9941	0	73.7464	0	28.2165	2.1	
I0518 17:59:00.476943  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 17:59:00.479742  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 17:59:00.479794  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 17:59:00.490000  4008 solver.cpp:260]     Total regularization terms: 1.00436 loss+regular. : 2.44799
I0518 18:00:31.078891  4008 solver.cpp:231] Iteration 226600, loss = 1.44224
I0518 18:00:31.079197  4008 solver.cpp:247]     Train net output #0: loss = 1.44224 (* 1 = 1.44224 loss)
I0518 18:00:31.079218  4008 sgd_solver.cpp:106] Iteration 226600, lr = 0.001
I0518 18:00:31.238055  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5976	3.125	79.3698	0	89.2594	4.94792	86.8802	0	82.635	0	82.0068	0	73.7621	0	28.2229	2.1	
I0518 18:00:31.312687  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:00:31.314368  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:00:31.314410  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:00:31.324245  4008 solver.cpp:260]     Total regularization terms: 1.00421 loss+regular. : 2.44646
I0518 18:00:32.730219  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:02:00.104466  4008 solver.cpp:231] Iteration 226800, loss = 1.35501
I0518 18:02:00.104764  4008 solver.cpp:247]     Train net output #0: loss = 1.35501 (* 1 = 1.35501 loss)
I0518 18:02:00.104784  4008 sgd_solver.cpp:106] Iteration 226800, lr = 0.001
I0518 18:02:00.266217  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5832	3.125	79.3688	0	89.2601	4.94792	86.8818	0	82.6549	0	82.0195	0	73.7785	0	28.229	2.1	
I0518 18:02:00.341310  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:02:00.342818  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:02:00.342851  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:02:00.357844  4008 solver.cpp:260]     Total regularization terms: 1.00406 loss+regular. : 2.35907
I0518 18:03:29.601313  4008 solver.cpp:348] Iteration 227000, Testing net (#0)
I0518 18:04:20.512258  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:04:52.555367  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55384
I0518 18:04:52.557471  4008 solver.cpp:415]     Test net output #1: loss = 1.91932 (* 1 = 1.91932 loss)
I0518 18:04:52.653098  4008 solver.cpp:231] Iteration 227000, loss = 1.28157
I0518 18:04:52.653190  4008 solver.cpp:247]     Train net output #0: loss = 1.28157 (* 1 = 1.28157 loss)
I0518 18:04:52.653209  4008 sgd_solver.cpp:106] Iteration 227000, lr = 0.001
I0518 18:04:52.819607  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7124	3.125	79.3226	0	89.2803	4.94792	86.9088	0	82.6699	0	82.0325	0	73.7945	0	28.2358	2.1	
I0518 18:04:52.894773  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:04:52.897399  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:04:52.897451  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:04:52.907498  4008 solver.cpp:260]     Total regularization terms: 1.00387 loss+regular. : 2.28544
I0518 18:06:27.329113  4008 solver.cpp:231] Iteration 227200, loss = 1.58078
I0518 18:06:27.329445  4008 solver.cpp:247]     Train net output #0: loss = 1.58078 (* 1 = 1.58078 loss)
I0518 18:06:27.329470  4008 sgd_solver.cpp:106] Iteration 227200, lr = 0.001
I0518 18:06:27.489337  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7181	3.125	78.9987	0	89.281	4.94792	86.8874	0	82.6918	0	82.0451	0	73.81	0	28.2425	2.1	
I0518 18:06:27.563971  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:06:27.566104  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:06:27.566148  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:06:27.575898  4008 solver.cpp:260]     Total regularization terms: 1.00377 loss+regular. : 2.58455
I0518 18:07:56.177230  4008 solver.cpp:231] Iteration 227400, loss = 1.3523
I0518 18:07:56.181684  4008 solver.cpp:247]     Train net output #0: loss = 1.3523 (* 1 = 1.3523 loss)
I0518 18:07:56.181716  4008 sgd_solver.cpp:106] Iteration 227400, lr = 0.001
I0518 18:07:56.339515  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7353	3.125	79.3158	0	89.296	4.94792	86.9159	0	82.6859	0	82.0579	0	73.8253	0	28.249	2.1	
I0518 18:07:56.414196  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:07:56.416342  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:07:56.416386  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:07:56.431301  4008 solver.cpp:260]     Total regularization terms: 1.00356 loss+regular. : 2.35587
I0518 18:09:31.416846  4008 solver.cpp:231] Iteration 227600, loss = 1.36644
I0518 18:09:31.417251  4008 solver.cpp:247]     Train net output #0: loss = 1.36644 (* 1 = 1.36644 loss)
I0518 18:09:31.417418  4008 sgd_solver.cpp:106] Iteration 227600, lr = 0.001
I0518 18:09:31.576455  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8817	3.125	79.3913	0	89.3086	4.94792	86.9335	0	82.6898	0	82.0706	0	73.8407	0	28.2553	2.1	
I0518 18:09:31.651368  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:09:31.653383  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:09:31.653436  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:09:31.663424  4008 solver.cpp:260]     Total regularization terms: 1.0034 loss+regular. : 2.36984
I0518 18:09:36.668445  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:10:56.217829  4008 solver.cpp:231] Iteration 227800, loss = 1.4375
I0518 18:10:56.218178  4008 solver.cpp:247]     Train net output #0: loss = 1.4375 (* 1 = 1.4375 loss)
I0518 18:10:56.218199  4008 sgd_solver.cpp:106] Iteration 227800, lr = 0.001
I0518 18:10:56.378892  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8128	3.125	79.1881	0	89.2854	4.94792	86.8928	0	82.7042	0	82.0833	0	73.8563	0	28.262	2.1	
I0518 18:10:56.453639  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:10:56.456064  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:10:56.456123  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:10:56.466327  4008 solver.cpp:260]     Total regularization terms: 1.00318 loss+regular. : 2.44068
I0518 18:12:20.357817  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_228000.caffemodel
I0518 18:13:30.561134  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_228000.solverstate
I0518 18:13:31.144546  4008 solver.cpp:348] Iteration 228000, Testing net (#0)
I0518 18:14:16.295255  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:14:49.472195  4008 solver.cpp:415]     Test net output #0: accuracy = 0.555519
I0518 18:14:49.472406  4008 solver.cpp:415]     Test net output #1: loss = 1.91288 (* 1 = 1.91288 loss)
I0518 18:14:49.561100  4008 solver.cpp:231] Iteration 228000, loss = 1.36708
I0518 18:14:49.561228  4008 solver.cpp:247]     Train net output #0: loss = 1.36708 (* 1 = 1.36708 loss)
I0518 18:14:49.561355  4008 sgd_solver.cpp:106] Iteration 228000, lr = 0.001
I0518 18:14:49.729064  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5201	3.125	79.3522	0	89.3364	4.94792	86.929	0	82.7268	0	82.0959	0	73.8719	0	28.268	2.1	
I0518 18:14:49.730511  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:14:49.732434  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:14:49.732453  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:14:49.742244  4008 solver.cpp:260]     Total regularization terms: 1.00302 loss+regular. : 2.3701
I0518 18:16:15.497382  4008 solver.cpp:231] Iteration 228200, loss = 1.32593
I0518 18:16:15.497880  4008 solver.cpp:247]     Train net output #0: loss = 1.32593 (* 1 = 1.32593 loss)
I0518 18:16:15.497905  4008 sgd_solver.cpp:106] Iteration 228200, lr = 0.001
I0518 18:16:15.657351  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6951	3.125	79.2598	0	89.3043	4.94792	86.8994	0	82.7352	0	82.1085	0	73.8877	0	28.2743	2.1	
I0518 18:16:15.731911  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:16:15.734091  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:16:15.734153  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:16:15.749379  4008 solver.cpp:260]     Total regularization terms: 1.00287 loss+regular. : 2.3288
I0518 18:17:39.790755  4008 solver.cpp:231] Iteration 228400, loss = 1.67324
I0518 18:17:39.791824  4008 solver.cpp:247]     Train net output #0: loss = 1.67324 (* 1 = 1.67324 loss)
I0518 18:17:39.791857  4008 sgd_solver.cpp:106] Iteration 228400, lr = 0.001
I0518 18:17:39.950791  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.589	3.125	79.4388	0	89.3251	4.94792	86.9112	0	82.7458	0	82.1213	0	73.9038	0	28.2805	2.1	
I0518 18:17:40.025224  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:17:40.026734  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:17:40.026763  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:17:40.036372  4008 solver.cpp:260]     Total regularization terms: 1.0027 loss+regular. : 2.67594
I0518 18:19:06.832706  4008 solver.cpp:231] Iteration 228600, loss = 1.45374
I0518 18:19:06.833169  4008 solver.cpp:247]     Train net output #0: loss = 1.45374 (* 1 = 1.45374 loss)
I0518 18:19:06.833196  4008 sgd_solver.cpp:106] Iteration 228600, lr = 0.001
I0518 18:19:06.992501  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.632	3.125	79.2402	0	89.2977	4.94792	86.9248	0	82.7406	0	82.1336	0	73.9191	0	28.2866	2.1	
I0518 18:19:07.067781  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:19:07.070746  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:19:07.070824  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:19:07.081259  4008 solver.cpp:260]     Total regularization terms: 1.0026 loss+regular. : 2.45634
I0518 18:19:14.914966  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:20:28.781790  4008 solver.cpp:231] Iteration 228800, loss = 1.37123
I0518 18:20:28.782162  4008 solver.cpp:247]     Train net output #0: loss = 1.37123 (* 1 = 1.37123 loss)
I0518 18:20:28.782222  4008 sgd_solver.cpp:106] Iteration 228800, lr = 0.001
I0518 18:20:28.940726  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.477	3.125	79.459	0	89.306	4.94792	86.9364	0	82.7302	0	82.1464	0	73.9344	0	28.2936	2.1	
I0518 18:20:29.015866  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:20:29.018414  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:20:29.018530  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:20:29.028311  4008 solver.cpp:260]     Total regularization terms: 1.0024 loss+regular. : 2.37363
I0518 18:21:50.897411  4008 solver.cpp:348] Iteration 229000, Testing net (#0)
I0518 18:22:43.668339  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:23:13.608705  4008 solver.cpp:415]     Test net output #0: accuracy = 0.552959
I0518 18:23:13.608798  4008 solver.cpp:415]     Test net output #1: loss = 1.92233 (* 1 = 1.92233 loss)
I0518 18:23:13.697891  4008 solver.cpp:231] Iteration 229000, loss = 1.40509
I0518 18:23:13.698133  4008 solver.cpp:247]     Train net output #0: loss = 1.40509 (* 1 = 1.40509 loss)
I0518 18:23:13.698154  4008 sgd_solver.cpp:106] Iteration 229000, lr = 0.001
I0518 18:23:13.862830  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6291	3.125	79.2494	0	89.322	4.94792	86.9572	0	82.7628	0	82.159	0	73.9498	0	28.2999	2.1	
I0518 18:23:13.937196  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:23:13.938992  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:23:13.939039  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:23:13.950181  4008 solver.cpp:260]     Total regularization terms: 1.00219 loss+regular. : 2.40729
I0518 18:24:45.305698  4008 solver.cpp:231] Iteration 229200, loss = 1.3692
I0518 18:24:45.305974  4008 solver.cpp:247]     Train net output #0: loss = 1.3692 (* 1 = 1.3692 loss)
I0518 18:24:45.305994  4008 sgd_solver.cpp:106] Iteration 229200, lr = 0.001
I0518 18:24:45.465667  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6177	3.125	79.2887	0	89.3165	4.94792	86.9605	0	82.7621	0	82.1716	0	73.9653	0	28.3062	2.1	
I0518 18:24:45.540545  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:24:45.543035  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:24:45.543082  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:24:45.553059  4008 solver.cpp:260]     Total regularization terms: 1.00201 loss+regular. : 2.37121
I0518 18:26:25.903834  4008 solver.cpp:231] Iteration 229400, loss = 1.42675
I0518 18:26:25.904356  4008 solver.cpp:247]     Train net output #0: loss = 1.42675 (* 1 = 1.42675 loss)
I0518 18:26:25.904386  4008 sgd_solver.cpp:106] Iteration 229400, lr = 0.001
I0518 18:26:26.063577  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7124	3.125	79.5189	0	89.3654	4.94792	86.9671	0	82.7745	0	82.1843	0	73.9808	0	28.3123	2.1	
I0518 18:26:26.138790  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:26:26.141130  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:26:26.141181  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:26:26.151120  4008 solver.cpp:260]     Total regularization terms: 1.00186 loss+regular. : 2.4286
I0518 18:27:49.285969  4008 solver.cpp:231] Iteration 229600, loss = 1.37504
I0518 18:27:49.287314  4008 solver.cpp:247]     Train net output #0: loss = 1.37504 (* 1 = 1.37504 loss)
I0518 18:27:49.287343  4008 sgd_solver.cpp:106] Iteration 229600, lr = 0.001
I0518 18:27:49.446765  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7238	3.125	79.5469	0	89.3308	4.94792	86.9606	0	82.7795	0	82.1964	0	73.9962	0	28.3188	2.1	
I0518 18:27:49.521790  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:27:49.524363  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	4.94792	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:27:49.524423  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:27:49.534654  4008 solver.cpp:260]     Total regularization terms: 1.00156 loss+regular. : 2.37659
I0518 18:28:00.546597  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:29:15.730376  4008 solver.cpp:231] Iteration 229800, loss = 1.40346
I0518 18:29:15.730676  4008 solver.cpp:247]     Train net output #0: loss = 1.40346 (* 1 = 1.40346 loss)
I0518 18:29:15.730700  4008 sgd_solver.cpp:106] Iteration 229800, lr = 0.001
I0518 18:29:15.888787  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.609	3.125	79.3675	0	89.3174	5.20833	86.9599	0	82.7686	0	82.2088	0	74.0118	0	28.3246	2.1	
I0518 18:29:15.964087  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:29:15.966527  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:29:15.966564  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:29:15.976379  4008 solver.cpp:260]     Total regularization terms: 1.00144 loss+regular. : 2.4049
I0518 18:30:41.775637  4008 solver.cpp:348] Iteration 230000, Testing net (#0)
I0518 18:31:33.757279  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:32:02.999217  4008 solver.cpp:415]     Test net output #0: accuracy = 0.54768
I0518 18:32:02.999313  4008 solver.cpp:415]     Test net output #1: loss = 1.93734 (* 1 = 1.93734 loss)
I0518 18:32:03.087272  4008 solver.cpp:231] Iteration 230000, loss = 1.33436
I0518 18:32:03.087365  4008 solver.cpp:247]     Train net output #0: loss = 1.33436 (* 1 = 1.33436 loss)
I0518 18:32:03.087390  4008 sgd_solver.cpp:106] Iteration 230000, lr = 0.001
I0518 18:32:03.252324  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.698	3.125	79.5094	0	89.3447	5.20833	86.9733	0	82.8044	0	82.2213	0	74.0269	0	28.331	2.1	
I0518 18:32:03.326866  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:32:03.329006  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:32:03.329053  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:32:03.339179  4008 solver.cpp:260]     Total regularization terms: 1.00125 loss+regular. : 2.3356
I0518 18:33:36.675957  4008 solver.cpp:231] Iteration 230200, loss = 1.56363
I0518 18:33:36.676245  4008 solver.cpp:247]     Train net output #0: loss = 1.56363 (* 1 = 1.56363 loss)
I0518 18:33:36.676270  4008 sgd_solver.cpp:106] Iteration 230200, lr = 0.001
I0518 18:33:36.837137  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0667	3.125	79.2705	0	89.3664	5.20833	86.993	0	82.7917	0	82.234	0	74.0422	0	28.3375	2.1	
I0518 18:33:36.914703  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:33:36.917081  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:33:36.917125  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:33:36.932348  4008 solver.cpp:260]     Total regularization terms: 1.00111 loss+regular. : 2.56474
I0518 18:35:03.323976  4008 solver.cpp:231] Iteration 230400, loss = 1.30894
I0518 18:35:03.324296  4008 solver.cpp:247]     Train net output #0: loss = 1.30894 (* 1 = 1.30894 loss)
I0518 18:35:03.324317  4008 sgd_solver.cpp:106] Iteration 230400, lr = 0.001
I0518 18:35:03.483481  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7611	3.125	79.429	0	89.3781	5.20833	87.0012	0	82.8274	0	82.2465	0	74.0575	0	28.3433	2.1	
I0518 18:35:03.558079  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:35:03.560190  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:35:03.560237  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:35:03.570039  4008 solver.cpp:260]     Total regularization terms: 1.00091 loss+regular. : 2.30985
I0518 18:36:28.925467  4008 solver.cpp:231] Iteration 230600, loss = 1.44909
I0518 18:36:28.929599  4008 solver.cpp:247]     Train net output #0: loss = 1.44909 (* 1 = 1.44909 loss)
I0518 18:36:28.929641  4008 sgd_solver.cpp:106] Iteration 230600, lr = 0.001
I0518 18:36:29.084635  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6636	3.125	79.4381	0	89.399	5.20833	87.0321	0	82.8374	0	82.2586	0	74.0727	0	28.3497	2.1	
I0518 18:36:29.158831  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:36:29.160300  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:36:29.160331  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:36:29.170065  4008 solver.cpp:260]     Total regularization terms: 1.00075 loss+regular. : 2.44984
I0518 18:36:42.791522  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:38:03.677404  4008 solver.cpp:231] Iteration 230800, loss = 1.49299
I0518 18:38:03.682025  4008 solver.cpp:247]     Train net output #0: loss = 1.49299 (* 1 = 1.49299 loss)
I0518 18:38:03.682060  4008 sgd_solver.cpp:106] Iteration 230800, lr = 0.001
I0518 18:38:03.838223  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7037	3.125	79.2174	0	89.3943	5.20833	87.0015	0	82.8471	0	82.2712	0	74.0882	0	28.3556	2.1	
I0518 18:38:03.913702  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:38:03.915997  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:38:03.916050  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:38:03.926352  4008 solver.cpp:260]     Total regularization terms: 1.00058 loss+regular. : 2.49357
I0518 18:39:31.343185  4008 solver.cpp:348] Iteration 231000, Testing net (#0)
I0518 18:40:23.716300  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:41:00.285291  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55246
I0518 18:41:00.285650  4008 solver.cpp:415]     Test net output #1: loss = 1.92773 (* 1 = 1.92773 loss)
I0518 18:41:00.374670  4008 solver.cpp:231] Iteration 231000, loss = 1.45478
I0518 18:41:00.374771  4008 solver.cpp:247]     Train net output #0: loss = 1.45478 (* 1 = 1.45478 loss)
I0518 18:41:00.374796  4008 sgd_solver.cpp:106] Iteration 231000, lr = 0.001
I0518 18:41:00.538128  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5488	3.125	79.4954	0	89.3803	5.20833	87.0183	0	82.8444	0	82.2838	0	74.1035	0	28.3618	2.1	
I0518 18:41:00.613006  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:41:00.615242  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:41:00.615300  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:41:00.625315  4008 solver.cpp:260]     Total regularization terms: 1.00042 loss+regular. : 2.4552
I0518 18:42:29.664216  4008 solver.cpp:231] Iteration 231200, loss = 1.21857
I0518 18:42:29.664481  4008 solver.cpp:247]     Train net output #0: loss = 1.21857 (* 1 = 1.21857 loss)
I0518 18:42:29.664501  4008 sgd_solver.cpp:106] Iteration 231200, lr = 0.001
I0518 18:42:29.823245  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8845	3.125	79.6214	0	89.398	5.20833	87.0348	0	82.862	0	82.296	0	74.1184	0	28.3686	2.1	
I0518 18:42:29.898102  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:42:29.900897  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:42:29.900962  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:42:29.911201  4008 solver.cpp:260]     Total regularization terms: 1.00023 loss+regular. : 2.2188
I0518 18:43:56.676204  4008 solver.cpp:231] Iteration 231400, loss = 1.5369
I0518 18:43:56.676458  4008 solver.cpp:247]     Train net output #0: loss = 1.5369 (* 1 = 1.5369 loss)
I0518 18:43:56.676476  4008 sgd_solver.cpp:106] Iteration 231400, lr = 0.001
I0518 18:43:56.836710  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8042	3.125	79.4883	0	89.3832	5.20833	87.0586	0	82.8577	0	82.3082	0	74.1341	0	28.375	2.1	
I0518 18:43:56.911078  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:43:56.913173  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:43:56.913246  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:43:56.928185  4008 solver.cpp:260]     Total regularization terms: 1.00003 loss+regular. : 2.53693
I0518 18:45:22.504720  4008 solver.cpp:231] Iteration 231600, loss = 1.34966
I0518 18:45:22.505210  4008 solver.cpp:247]     Train net output #0: loss = 1.34966 (* 1 = 1.34966 loss)
I0518 18:45:22.505247  4008 sgd_solver.cpp:106] Iteration 231600, lr = 0.001
I0518 18:45:22.665221  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7296	3.125	79.5283	0	89.3934	5.20833	87.0274	0	82.8604	0	82.3204	0	74.149	0	28.3821	2.1	
I0518 18:45:22.740114  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.25868	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:45:22.742784  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:45:22.742837  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:45:22.752923  4008 solver.cpp:260]     Total regularization terms: 0.999865 loss+regular. : 2.34952
I0518 18:45:40.435058  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:47:04.789566  4008 solver.cpp:231] Iteration 231800, loss = 1.37304
I0518 18:47:04.789804  4008 solver.cpp:247]     Train net output #0: loss = 1.37304 (* 1 = 1.37304 loss)
I0518 18:47:04.789824  4008 sgd_solver.cpp:106] Iteration 231800, lr = 0.001
I0518 18:47:04.949450  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6894	3.125	79.3776	0	89.4089	5.20833	87.0715	0	82.8744	0	82.3325	0	74.1637	0	28.3887	2.1	
I0518 18:47:05.024102  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:47:05.026020  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:47:05.026067  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:47:05.035874  4008 solver.cpp:260]     Total regularization terms: 0.999681 loss+regular. : 2.37272
I0518 18:48:33.209377  4008 solver.cpp:348] Iteration 232000, Testing net (#0)
I0518 18:49:31.530141  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:50:01.235565  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55458
I0518 18:50:01.235687  4008 solver.cpp:415]     Test net output #1: loss = 1.91795 (* 1 = 1.91795 loss)
I0518 18:50:01.333220  4008 solver.cpp:231] Iteration 232000, loss = 1.40489
I0518 18:50:01.333305  4008 solver.cpp:247]     Train net output #0: loss = 1.40489 (* 1 = 1.40489 loss)
I0518 18:50:01.333324  4008 sgd_solver.cpp:106] Iteration 232000, lr = 0.001
I0518 18:50:01.492151  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4914	3.125	79.474	0	89.4156	5.20833	87.0735	0	82.8767	0	82.3453	0	74.1797	0	28.395	2.1	
I0518 18:50:01.569087  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:50:01.572163  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:50:01.572209  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:50:01.582183  4008 solver.cpp:260]     Total regularization terms: 0.999522 loss+regular. : 2.40442
I0518 18:51:32.402194  4008 solver.cpp:231] Iteration 232200, loss = 1.37856
I0518 18:51:32.402498  4008 solver.cpp:247]     Train net output #0: loss = 1.37856 (* 1 = 1.37856 loss)
I0518 18:51:32.402528  4008 sgd_solver.cpp:106] Iteration 232200, lr = 0.001
I0518 18:51:32.563576  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6406	3.125	79.3704	0	89.3932	5.20833	87.0447	0	82.8559	0	82.3572	0	74.1944	0	28.4013	2.1	
I0518 18:51:32.638788  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:51:32.641324  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:51:32.641366  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:51:32.656380  4008 solver.cpp:260]     Total regularization terms: 0.999415 loss+regular. : 2.37797
I0518 18:52:57.447875  4008 solver.cpp:231] Iteration 232400, loss = 1.34996
I0518 18:52:57.449651  4008 solver.cpp:247]     Train net output #0: loss = 1.34996 (* 1 = 1.34996 loss)
I0518 18:52:57.449687  4008 sgd_solver.cpp:106] Iteration 232400, lr = 0.001
I0518 18:52:57.606674  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5517	3.125	79.3369	0	89.4163	5.20833	87.0836	0	82.8833	0	82.3695	0	74.2096	0	28.407	2.1	
I0518 18:52:57.681582  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:52:57.684306  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:52:57.684350  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:52:57.698213  4008 solver.cpp:260]     Total regularization terms: 0.999216 loss+regular. : 2.34918
I0518 18:54:18.277886  4008 solver.cpp:231] Iteration 232600, loss = 1.25927
I0518 18:54:18.278151  4008 solver.cpp:247]     Train net output #0: loss = 1.25927 (* 1 = 1.25927 loss)
I0518 18:54:18.278173  4008 sgd_solver.cpp:106] Iteration 232600, lr = 0.001
I0518 18:54:18.437680  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.655	3.125	79.5488	0	89.4063	5.20833	87.0654	0	82.8855	0	82.3815	0	74.2245	0	28.4141	2.1	
I0518 18:54:18.512666  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:54:18.515506  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:54:18.515555  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:54:18.525454  4008 solver.cpp:260]     Total regularization terms: 0.999099 loss+regular. : 2.25837
I0518 18:54:38.450711  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:55:45.795022  4008 solver.cpp:231] Iteration 232800, loss = 1.30851
I0518 18:55:45.795280  4008 solver.cpp:247]     Train net output #0: loss = 1.30851 (* 1 = 1.30851 loss)
I0518 18:55:45.795455  4008 sgd_solver.cpp:106] Iteration 232800, lr = 0.001
I0518 18:55:45.955631  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6607	3.125	79.4268	0	89.4202	5.20833	87.074	0	82.8903	0	82.3936	0	74.2402	0	28.4211	2.1	
I0518 18:55:46.030316  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:55:46.031878  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:55:46.031918  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:55:46.041816  4008 solver.cpp:260]     Total regularization terms: 0.998869 loss+regular. : 2.30738
I0518 18:57:07.095829  4008 solver.cpp:348] Iteration 233000, Testing net (#0)
I0518 18:57:57.663388  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 18:58:27.936427  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55304
I0518 18:58:27.936736  4008 solver.cpp:415]     Test net output #1: loss = 1.93225 (* 1 = 1.93225 loss)
I0518 18:58:28.025010  4008 solver.cpp:231] Iteration 233000, loss = 1.45396
I0518 18:58:28.025149  4008 solver.cpp:247]     Train net output #0: loss = 1.45396 (* 1 = 1.45396 loss)
I0518 18:58:28.025171  4008 sgd_solver.cpp:106] Iteration 233000, lr = 0.001
I0518 18:58:28.192108  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0868	3.125	79.4401	0	89.4442	5.20833	87.1074	0	82.8998	0	82.4058	0	74.2549	0	28.4273	2.1	
I0518 18:58:28.266988  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:58:28.269186  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:58:28.269232  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:58:28.279153  4008 solver.cpp:260]     Total regularization terms: 0.99867 loss+regular. : 2.45263
I0518 18:59:53.722260  4008 solver.cpp:231] Iteration 233200, loss = 1.23817
I0518 18:59:53.722654  4008 solver.cpp:247]     Train net output #0: loss = 1.23817 (* 1 = 1.23817 loss)
I0518 18:59:53.722687  4008 sgd_solver.cpp:106] Iteration 233200, lr = 0.001
I0518 18:59:53.882344  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4598	3.125	79.5039	0	89.4275	5.20833	87.0857	0	82.9138	0	82.4177	0	74.2703	0	28.4338	2.1	
I0518 18:59:53.957696  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 18:59:53.960402  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 18:59:53.960449  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 18:59:53.970386  4008 solver.cpp:260]     Total regularization terms: 0.998546 loss+regular. : 2.23671
I0518 19:01:19.114943  4008 solver.cpp:231] Iteration 233400, loss = 1.35877
I0518 19:01:19.115283  4008 solver.cpp:247]     Train net output #0: loss = 1.35877 (* 1 = 1.35877 loss)
I0518 19:01:19.115308  4008 sgd_solver.cpp:106] Iteration 233400, lr = 0.001
I0518 19:01:19.275116  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.675	3.125	79.5049	0	89.4668	5.20833	87.1229	0	82.9185	0	82.4298	0	74.2848	0	28.4397	2.1	
I0518 19:01:19.350642  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:01:19.352478  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:01:19.352525  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:01:19.367935  4008 solver.cpp:260]     Total regularization terms: 0.998371 loss+regular. : 2.35714
I0518 19:02:43.858532  4008 solver.cpp:231] Iteration 233600, loss = 1.43991
I0518 19:02:43.859061  4008 solver.cpp:247]     Train net output #0: loss = 1.43991 (* 1 = 1.43991 loss)
I0518 19:02:43.859087  4008 sgd_solver.cpp:106] Iteration 233600, lr = 0.001
I0518 19:02:44.016827  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.477	3.125	79.556	0	89.4587	5.20833	87.1449	0	82.9196	0	82.4418	0	74.3001	0	28.4462	2.1	
I0518 19:02:44.091500  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:02:44.093636  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:02:44.093693  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:02:44.103900  4008 solver.cpp:260]     Total regularization terms: 0.998186 loss+regular. : 2.4381
I0518 19:03:05.614033  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:04:08.976933  4008 solver.cpp:231] Iteration 233800, loss = 1.44947
I0518 19:04:08.977293  4008 solver.cpp:247]     Train net output #0: loss = 1.44947 (* 1 = 1.44947 loss)
I0518 19:04:08.977320  4008 sgd_solver.cpp:106] Iteration 233800, lr = 0.001
I0518 19:04:09.135756  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5803	3.125	79.5745	0	89.4848	5.20833	87.1584	0	82.9352	0	82.4539	0	74.3154	0	28.4532	2.1	
I0518 19:04:09.210273  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:04:09.212319  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:04:09.212364  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:04:09.223640  4008 solver.cpp:260]     Total regularization terms: 0.998018 loss+regular. : 2.44748
I0518 19:05:32.062988  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_234000.caffemodel
I0518 19:08:38.564434  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_234000.solverstate
I0518 19:08:39.304939  4008 solver.cpp:348] Iteration 234000, Testing net (#0)
I0518 19:09:37.415585  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:10:07.272503  4008 solver.cpp:415]     Test net output #0: accuracy = 0.555979
I0518 19:10:07.272917  4008 solver.cpp:415]     Test net output #1: loss = 1.91167 (* 1 = 1.91167 loss)
I0518 19:10:07.370235  4008 solver.cpp:231] Iteration 234000, loss = 1.28077
I0518 19:10:07.370345  4008 solver.cpp:247]     Train net output #0: loss = 1.28077 (* 1 = 1.28077 loss)
I0518 19:10:07.370369  4008 sgd_solver.cpp:106] Iteration 234000, lr = 0.001
I0518 19:10:07.534229  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.589	3.125	79.359	0	89.4792	5.20833	87.1439	0	82.947	0	82.466	0	74.3303	0	28.4597	2.1	
I0518 19:10:07.535981  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:10:07.537636  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:10:07.537681  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:10:07.550673  4008 solver.cpp:260]     Total regularization terms: 0.997832 loss+regular. : 2.27861
I0518 19:11:34.695778  4008 solver.cpp:231] Iteration 234200, loss = 1.51774
I0518 19:11:34.696529  4008 solver.cpp:247]     Train net output #0: loss = 1.51774 (* 1 = 1.51774 loss)
I0518 19:11:34.696555  4008 sgd_solver.cpp:106] Iteration 234200, lr = 0.001
I0518 19:11:34.855167  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8243	3.125	79.6185	0	89.4731	5.20833	87.1418	0	82.9585	0	82.4783	0	74.3456	0	28.4666	2.1	
I0518 19:11:34.929729  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:11:34.931659  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:11:34.931704  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:11:34.941650  4008 solver.cpp:260]     Total regularization terms: 0.997668 loss+regular. : 2.51541
I0518 19:12:56.511070  4008 solver.cpp:231] Iteration 234400, loss = 1.37657
I0518 19:12:56.517702  4008 solver.cpp:247]     Train net output #0: loss = 1.37657 (* 1 = 1.37657 loss)
I0518 19:12:56.517745  4008 sgd_solver.cpp:106] Iteration 234400, lr = 0.001
I0518 19:12:56.672662  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5258	3.125	79.4225	0	89.4675	5.20833	87.1273	0	82.9594	0	82.4903	0	74.3602	0	28.4728	2.1	
I0518 19:12:56.747292  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:12:56.749130  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:12:56.749173  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:12:56.778832  4008 solver.cpp:260]     Total regularization terms: 0.997499 loss+regular. : 2.37407
I0518 19:14:20.133590  4008 solver.cpp:231] Iteration 234600, loss = 1.38611
I0518 19:14:20.136139  4008 solver.cpp:247]     Train net output #0: loss = 1.38611 (* 1 = 1.38611 loss)
I0518 19:14:20.136168  4008 sgd_solver.cpp:106] Iteration 234600, lr = 0.001
I0518 19:14:20.294030  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4311	3.125	79.291	0	89.4568	5.20833	87.1489	0	82.9536	0	82.502	0	74.3754	0	28.4789	2.1	
I0518 19:14:20.372346  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:14:20.374595  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:14:20.374666  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:14:20.384572  4008 solver.cpp:260]     Total regularization terms: 0.997341 loss+regular. : 2.38346
I0518 19:14:43.212069  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:15:42.521057  4008 solver.cpp:231] Iteration 234800, loss = 1.4289
I0518 19:15:42.521384  4008 solver.cpp:247]     Train net output #0: loss = 1.4289 (* 1 = 1.4289 loss)
I0518 19:15:42.521404  4008 sgd_solver.cpp:106] Iteration 234800, lr = 0.001
I0518 19:15:42.681535  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6492	3.125	79.2171	0	89.4645	5.20833	87.1547	0	82.9683	0	82.5138	0	74.3904	0	28.4855	2.1	
I0518 19:15:42.755980  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:15:42.758050  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:15:42.758097  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:15:42.768028  4008 solver.cpp:260]     Total regularization terms: 0.997188 loss+regular. : 2.42609
I0518 19:17:14.442935  4008 solver.cpp:348] Iteration 235000, Testing net (#0)
I0518 19:18:09.844171  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:18:41.048265  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55238
I0518 19:18:41.048617  4008 solver.cpp:415]     Test net output #1: loss = 1.92744 (* 1 = 1.92744 loss)
I0518 19:18:41.136590  4008 solver.cpp:231] Iteration 235000, loss = 1.39682
I0518 19:18:41.136689  4008 solver.cpp:247]     Train net output #0: loss = 1.39682 (* 1 = 1.39682 loss)
I0518 19:18:41.136709  4008 sgd_solver.cpp:106] Iteration 235000, lr = 0.001
I0518 19:18:41.298818  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3823	3.125	79.2305	0	89.4649	5.20833	87.1552	0	82.9995	0	82.5254	0	74.4057	0	28.4934	2.1	
I0518 19:18:41.374181  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:18:41.376433  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:18:41.376485  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:18:41.386351  4008 solver.cpp:260]     Total regularization terms: 0.997012 loss+regular. : 2.39383
I0518 19:20:04.026096  4008 solver.cpp:231] Iteration 235200, loss = 1.55183
I0518 19:20:04.026412  4008 solver.cpp:247]     Train net output #0: loss = 1.55183 (* 1 = 1.55183 loss)
I0518 19:20:04.026429  4008 sgd_solver.cpp:106] Iteration 235200, lr = 0.001
I0518 19:20:04.186202  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6177	3.125	79.472	0	89.532	5.20833	87.1831	0	82.9879	0	82.5375	0	74.4208	0	28.4997	2.1	
I0518 19:20:04.260732  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:20:04.262728  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:20:04.262790  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:20:04.274375  4008 solver.cpp:260]     Total regularization terms: 0.99684 loss+regular. : 2.54867
I0518 19:21:37.726117  4008 solver.cpp:231] Iteration 235400, loss = 1.40632
I0518 19:21:37.729671  4008 solver.cpp:247]     Train net output #0: loss = 1.40632 (* 1 = 1.40632 loss)
I0518 19:21:37.729702  4008 sgd_solver.cpp:106] Iteration 235400, lr = 0.001
I0518 19:21:37.887468  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5459	3.125	79.4997	0	89.5034	5.20833	87.1671	0	82.9834	0	82.5491	0	74.4355	0	28.5059	2.1	
I0518 19:21:37.961983  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:21:37.963999  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:21:37.964046  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:21:37.973965  4008 solver.cpp:260]     Total regularization terms: 0.996717 loss+regular. : 2.40304
I0518 19:23:09.820488  4008 solver.cpp:231] Iteration 235600, loss = 1.43281
I0518 19:23:09.820822  4008 solver.cpp:247]     Train net output #0: loss = 1.43281 (* 1 = 1.43281 loss)
I0518 19:23:09.820842  4008 sgd_solver.cpp:106] Iteration 235600, lr = 0.001
I0518 19:23:09.981662  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3795	3.125	79.1813	0	89.4326	5.20833	87.1739	0	83.0022	0	82.561	0	74.4505	0	28.513	2.1	
I0518 19:23:10.057013  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:23:10.058892  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:23:10.058938  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:23:10.072589  4008 solver.cpp:260]     Total regularization terms: 0.996603 loss+regular. : 2.42941
I0518 19:23:37.794734  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:24:42.057979  4008 solver.cpp:231] Iteration 235800, loss = 1.336
I0518 19:24:42.058387  4008 solver.cpp:247]     Train net output #0: loss = 1.336 (* 1 = 1.336 loss)
I0518 19:24:42.058408  4008 sgd_solver.cpp:106] Iteration 235800, lr = 0.001
I0518 19:24:42.218194  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3049	3.125	79.3607	0	89.4843	5.20833	87.1484	0	82.9931	0	82.5731	0	74.4658	0	28.5192	2.1	
I0518 19:24:42.293015  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:24:42.295073  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:24:42.295127  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:24:42.310364  4008 solver.cpp:260]     Total regularization terms: 0.99638 loss+regular. : 2.33238
I0518 19:26:08.819887  4008 solver.cpp:348] Iteration 236000, Testing net (#0)
I0518 19:27:10.281384  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:27:46.227896  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5491
I0518 19:27:46.229629  4008 solver.cpp:415]     Test net output #1: loss = 1.93978 (* 1 = 1.93978 loss)
I0518 19:27:46.342768  4008 solver.cpp:231] Iteration 236000, loss = 1.29411
I0518 19:27:46.342876  4008 solver.cpp:247]     Train net output #0: loss = 1.29411 (* 1 = 1.29411 loss)
I0518 19:27:46.342896  4008 sgd_solver.cpp:106] Iteration 236000, lr = 0.001
I0518 19:27:46.507797  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.0093	3.125	79.4938	0	89.518	5.20833	87.1892	0	83.0334	0	82.5852	0	74.4805	0	28.5257	2.1	
I0518 19:27:46.582556  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:27:46.584688  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:27:46.584729  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:27:46.594630  4008 solver.cpp:260]     Total regularization terms: 0.996221 loss+regular. : 2.29033
I0518 19:29:13.583374  4008 solver.cpp:231] Iteration 236200, loss = 1.44393
I0518 19:29:13.583889  4008 solver.cpp:247]     Train net output #0: loss = 1.44393 (* 1 = 1.44393 loss)
I0518 19:29:13.583925  4008 sgd_solver.cpp:106] Iteration 236200, lr = 0.001
I0518 19:29:13.742100  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7382	3.125	79.6071	0	89.4996	5.20833	87.1883	0	83.0404	0	82.5971	0	74.4955	0	28.5318	2.1	
I0518 19:29:13.816907  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:29:13.818850  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:29:13.818904  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:29:13.828883  4008 solver.cpp:260]     Total regularization terms: 0.996073 loss+regular. : 2.44
I0518 19:30:35.415530  4008 solver.cpp:231] Iteration 236400, loss = 1.13898
I0518 19:30:35.415925  4008 solver.cpp:247]     Train net output #0: loss = 1.13898 (* 1 = 1.13898 loss)
I0518 19:30:35.415956  4008 sgd_solver.cpp:106] Iteration 236400, lr = 0.001
I0518 19:30:35.575320  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7669	3.125	79.7083	0	89.5278	5.20833	87.1947	0	83.0311	0	82.6091	0	74.5102	0	28.5382	2.1	
I0518 19:30:35.650486  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:30:35.652843  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:30:35.652896  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:30:35.662972  4008 solver.cpp:260]     Total regularization terms: 0.995934 loss+regular. : 2.13491
I0518 19:32:01.134138  4008 solver.cpp:231] Iteration 236600, loss = 1.36779
I0518 19:32:01.134585  4008 solver.cpp:247]     Train net output #0: loss = 1.36779 (* 1 = 1.36779 loss)
I0518 19:32:01.134613  4008 sgd_solver.cpp:106] Iteration 236600, lr = 0.001
I0518 19:32:01.295492  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8759	3.125	79.5811	0	89.5513	5.20833	87.2248	0	83.0358	0	82.6205	0	74.5248	0	28.5449	2.1	
I0518 19:32:01.370756  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:32:01.373435  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:32:01.373507  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:32:01.383538  4008 solver.cpp:260]     Total regularization terms: 0.995774 loss+regular. : 2.36357
I0518 19:32:35.588670  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:33:29.825356  4008 solver.cpp:231] Iteration 236800, loss = 1.45196
I0518 19:33:29.825763  4008 solver.cpp:247]     Train net output #0: loss = 1.45196 (* 1 = 1.45196 loss)
I0518 19:33:29.825937  4008 sgd_solver.cpp:106] Iteration 236800, lr = 0.001
I0518 19:33:29.985368  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5775	3.125	79.488	0	89.5075	5.20833	87.1989	0	83.0438	0	82.6325	0	74.5394	0	28.5519	2.1	
I0518 19:33:30.062609  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:33:30.064666  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:33:30.064719  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:33:30.075745  4008 solver.cpp:260]     Total regularization terms: 0.995604 loss+regular. : 2.44756
I0518 19:34:57.879076  4008 solver.cpp:348] Iteration 237000, Testing net (#0)
I0518 19:35:54.175534  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:36:22.736693  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55738
I0518 19:36:22.736837  4008 solver.cpp:415]     Test net output #1: loss = 1.90569 (* 1 = 1.90569 loss)
I0518 19:36:22.828802  4008 solver.cpp:231] Iteration 237000, loss = 1.31562
I0518 19:36:22.828943  4008 solver.cpp:247]     Train net output #0: loss = 1.31562 (* 1 = 1.31562 loss)
I0518 19:36:22.828969  4008 sgd_solver.cpp:106] Iteration 237000, lr = 0.001
I0518 19:36:22.988674  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7267	3.125	79.8424	0	89.5443	5.20833	87.2322	0	83.0627	0	82.6447	0	74.5545	0	28.5581	2.1	
I0518 19:36:23.063756  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:36:23.066066  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:36:23.066157  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:36:23.077425  4008 solver.cpp:260]     Total regularization terms: 0.995384 loss+regular. : 2.311
I0518 19:37:48.625406  4008 solver.cpp:231] Iteration 237200, loss = 1.48022
I0518 19:37:48.625702  4008 solver.cpp:247]     Train net output #0: loss = 1.48022 (* 1 = 1.48022 loss)
I0518 19:37:48.625725  4008 sgd_solver.cpp:106] Iteration 237200, lr = 0.001
I0518 19:37:48.785503  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5976	3.125	79.5238	0	89.5133	5.20833	87.1867	0	83.0474	0	82.6561	0	74.5688	0	28.565	2.1	
I0518 19:37:48.860007  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:37:48.862174  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.1	
I0518 19:37:48.862253  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:37:48.877624  4008 solver.cpp:260]     Total regularization terms: 0.995275 loss+regular. : 2.47549
I0518 19:39:21.506003  4008 solver.cpp:231] Iteration 237400, loss = 1.2294
I0518 19:39:21.506368  4008 solver.cpp:247]     Train net output #0: loss = 1.2294 (* 1 = 1.2294 loss)
I0518 19:39:21.506389  4008 sgd_solver.cpp:106] Iteration 237400, lr = 0.001
I0518 19:39:21.665138  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6837	3.125	79.7025	0	89.5503	5.20833	87.2446	0	83.0842	0	82.6679	0	74.5836	0	28.5716	2.2	
I0518 19:39:21.739686  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.30208	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:39:21.741514  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.2	
I0518 19:39:21.741577  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:39:21.751577  4008 solver.cpp:260]     Total regularization terms: 0.995052 loss+regular. : 2.22445
I0518 19:40:49.078464  4008 solver.cpp:231] Iteration 237600, loss = 1.43512
I0518 19:40:49.079104  4008 solver.cpp:247]     Train net output #0: loss = 1.43512 (* 1 = 1.43512 loss)
I0518 19:40:49.079124  4008 sgd_solver.cpp:106] Iteration 237600, lr = 0.001
I0518 19:40:49.238440  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.345	3.125	79.4414	0	89.517	5.20833	87.2348	0	83.0533	0	82.6797	0	74.5983	0	28.5786	2.2	
I0518 19:40:49.315676  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:40:49.317867  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.2	
I0518 19:40:49.317919  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:40:49.332798  4008 solver.cpp:260]     Total regularization terms: 0.994942 loss+regular. : 2.43006
I0518 19:41:23.392911  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:42:11.991479  4008 solver.cpp:231] Iteration 237800, loss = 1.32661
I0518 19:42:11.991777  4008 solver.cpp:247]     Train net output #0: loss = 1.32661 (* 1 = 1.32661 loss)
I0518 19:42:11.991802  4008 sgd_solver.cpp:106] Iteration 237800, lr = 0.001
I0518 19:42:12.152782  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4225	3.125	79.3079	0	89.5293	5.20833	87.2387	0	83.0786	0	82.6912	0	74.6129	0	28.5852	2.3	
I0518 19:42:12.228063  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:42:12.230255  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.3	
I0518 19:42:12.230303  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:42:12.240173  4008 solver.cpp:260]     Total regularization terms: 0.994759 loss+regular. : 2.32137
I0518 19:43:34.713464  4008 solver.cpp:348] Iteration 238000, Testing net (#0)
I0518 19:44:30.472020  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:44:56.108389  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55462
I0518 19:44:56.108486  4008 solver.cpp:415]     Test net output #1: loss = 1.9199 (* 1 = 1.9199 loss)
I0518 19:44:56.199749  4008 solver.cpp:231] Iteration 238000, loss = 1.4448
I0518 19:44:56.199841  4008 solver.cpp:247]     Train net output #0: loss = 1.4448 (* 1 = 1.4448 loss)
I0518 19:44:56.199862  4008 sgd_solver.cpp:106] Iteration 238000, lr = 0.001
I0518 19:44:56.359730  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.589	3.125	79.6198	0	89.5494	5.20833	87.2423	0	83.0915	0	82.7028	0	74.6276	0	28.5923	2.3	
I0518 19:44:56.435834  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:44:56.437969  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.3	
I0518 19:44:56.438024  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:44:56.447902  4008 solver.cpp:260]     Total regularization terms: 0.994584 loss+regular. : 2.43939
I0518 19:46:21.802438  4008 solver.cpp:231] Iteration 238200, loss = 1.38222
I0518 19:46:21.802732  4008 solver.cpp:247]     Train net output #0: loss = 1.38222 (* 1 = 1.38222 loss)
I0518 19:46:21.802762  4008 sgd_solver.cpp:106] Iteration 238200, lr = 0.001
I0518 19:46:21.963223  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8329	3.125	79.5433	0	89.5573	5.20833	87.2663	0	83.093	0	82.7147	0	74.642	0	28.5985	2.3	
I0518 19:46:22.038585  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:46:22.041224  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.20833	0	0	0	0	0	0	0	0	0	2.3	
I0518 19:46:22.041302  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:46:22.051403  4008 solver.cpp:260]     Total regularization terms: 0.994381 loss+regular. : 2.3766
I0518 19:47:43.473299  4008 solver.cpp:231] Iteration 238400, loss = 1.41633
I0518 19:47:43.473685  4008 solver.cpp:247]     Train net output #0: loss = 1.41633 (* 1 = 1.41633 loss)
I0518 19:47:43.473706  4008 sgd_solver.cpp:106] Iteration 238400, lr = 0.001
I0518 19:47:43.634855  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8817	3.125	79.7718	0	89.5833	5.46875	87.2682	0	83.1263	0	82.7262	0	74.6565	0	28.6041	2.3	
I0518 19:47:43.709650  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:47:43.711927  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 19:47:43.711982  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:47:43.721835  4008 solver.cpp:260]     Total regularization terms: 0.99419 loss+regular. : 2.41052
I0518 19:49:08.890837  4008 solver.cpp:231] Iteration 238600, loss = 1.25512
I0518 19:49:08.891187  4008 solver.cpp:247]     Train net output #0: loss = 1.25512 (* 1 = 1.25512 loss)
I0518 19:49:08.891206  4008 sgd_solver.cpp:106] Iteration 238600, lr = 0.001
I0518 19:49:09.050083  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6722	3.125	79.6364	0	89.5501	5.46875	87.2836	0	83.1154	0	82.738	0	74.6709	0	28.6097	2.3	
I0518 19:49:09.124718  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:49:09.126683  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 19:49:09.126740  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:49:09.142956  4008 solver.cpp:260]     Total regularization terms: 0.994074 loss+regular. : 2.2492
I0518 19:49:50.976838  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:50:36.648962  4008 solver.cpp:231] Iteration 238800, loss = 1.37529
I0518 19:50:36.649297  4008 solver.cpp:247]     Train net output #0: loss = 1.37529 (* 1 = 1.37529 loss)
I0518 19:50:36.649318  4008 sgd_solver.cpp:106] Iteration 238800, lr = 0.001
I0518 19:50:36.810952  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.2963	3.125	79.6344	0	89.5693	5.46875	87.2777	0	83.133	0	82.7495	0	74.6858	0	28.6156	2.3	
I0518 19:50:36.885659  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:50:36.887646  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 19:50:36.887696  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:50:36.902230  4008 solver.cpp:260]     Total regularization terms: 0.993922 loss+regular. : 2.36921
I0518 19:51:57.879869  4008 solver.cpp:348] Iteration 239000, Testing net (#0)
I0518 19:52:50.546999  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:53:14.846884  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55272
I0518 19:53:14.846985  4008 solver.cpp:415]     Test net output #1: loss = 1.92347 (* 1 = 1.92347 loss)
I0518 19:53:14.938112  4008 solver.cpp:231] Iteration 239000, loss = 1.34509
I0518 19:53:14.938205  4008 solver.cpp:247]     Train net output #0: loss = 1.34509 (* 1 = 1.34509 loss)
I0518 19:53:14.938225  4008 sgd_solver.cpp:106] Iteration 239000, lr = 0.001
I0518 19:53:15.098582  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5545	3.125	79.6029	0	89.5753	5.46875	87.255	0	83.1161	0	82.7613	0	74.7002	0	28.6217	2.3	
I0518 19:53:15.174777  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:53:15.177000  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 19:53:15.177060  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:53:15.187046  4008 solver.cpp:260]     Total regularization terms: 0.993768 loss+regular. : 2.33886
I0518 19:54:46.782721  4008 solver.cpp:231] Iteration 239200, loss = 1.33049
I0518 19:54:46.783164  4008 solver.cpp:247]     Train net output #0: loss = 1.33049 (* 1 = 1.33049 loss)
I0518 19:54:46.783190  4008 sgd_solver.cpp:106] Iteration 239200, lr = 0.001
I0518 19:54:46.942157  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7611	3.125	79.6696	0	89.5856	5.46875	87.2789	0	83.1269	0	82.7728	0	74.7146	0	28.6283	2.3	
I0518 19:54:47.017299  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:54:47.020084  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 19:54:47.020130  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:54:47.030129  4008 solver.cpp:260]     Total regularization terms: 0.99359 loss+regular. : 2.32408
I0518 19:56:16.886346  4008 solver.cpp:231] Iteration 239400, loss = 1.51473
I0518 19:56:16.886692  4008 solver.cpp:247]     Train net output #0: loss = 1.51473 (* 1 = 1.51473 loss)
I0518 19:56:16.886714  4008 sgd_solver.cpp:106] Iteration 239400, lr = 0.001
I0518 19:56:17.047695  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8587	3.125	79.6842	0	89.5993	5.46875	87.2592	0	83.1222	0	82.7843	0	74.7283	0	28.635	2.3	
I0518 19:56:17.123397  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:56:17.126497  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 19:56:17.126545  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:56:17.136504  4008 solver.cpp:260]     Total regularization terms: 0.993439 loss+regular. : 2.50817
I0518 19:57:43.900923  4008 solver.cpp:231] Iteration 239600, loss = 1.52758
I0518 19:57:43.901326  4008 solver.cpp:247]     Train net output #0: loss = 1.52758 (* 1 = 1.52758 loss)
I0518 19:57:43.901365  4008 sgd_solver.cpp:106] Iteration 239600, lr = 0.001
I0518 19:57:44.061851  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9132	3.125	79.7803	0	89.6288	5.46875	87.3074	0	83.1796	0	82.7957	0	74.7428	0	28.641	2.3	
I0518 19:57:44.137797  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:57:44.140727  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 19:57:44.140785  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:57:44.151212  4008 solver.cpp:260]     Total regularization terms: 0.993255 loss+regular. : 2.52083
I0518 19:58:25.810396  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 19:59:17.640957  4008 solver.cpp:231] Iteration 239800, loss = 1.36061
I0518 19:59:17.641233  4008 solver.cpp:247]     Train net output #0: loss = 1.36061 (* 1 = 1.36061 loss)
I0518 19:59:17.641260  4008 sgd_solver.cpp:106] Iteration 239800, lr = 0.001
I0518 19:59:17.799433  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7382	3.125	79.5778	0	89.6016	5.46875	87.3205	0	83.1941	0	82.8072	0	74.7574	0	28.6471	2.3	
I0518 19:59:17.874848  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 19:59:17.877990  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 19:59:17.878039  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 19:59:17.888129  4008 solver.cpp:260]     Total regularization terms: 0.993129 loss+regular. : 2.35374
I0518 20:00:50.634862  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_240000.caffemodel
I0518 20:02:34.109979  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_240000.solverstate
I0518 20:02:34.660598  4008 solver.cpp:348] Iteration 240000, Testing net (#0)
I0518 20:03:25.760149  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:03:48.556592  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55484
I0518 20:03:48.556747  4008 solver.cpp:415]     Test net output #1: loss = 1.9175 (* 1 = 1.9175 loss)
I0518 20:03:48.645385  4008 solver.cpp:231] Iteration 240000, loss = 1.26904
I0518 20:03:48.645530  4008 solver.cpp:247]     Train net output #0: loss = 1.26904 (* 1 = 1.26904 loss)
I0518 20:03:48.645565  4008 sgd_solver.cpp:106] Iteration 240000, lr = 0.001
I0518 20:03:48.805171  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5517	3.125	79.6406	0	89.5764	5.46875	87.2967	0	83.1948	0	82.8187	0	74.7724	0	28.6533	2.3	
I0518 20:03:48.806244  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:03:48.807662  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:03:48.807677  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:03:48.820788  4008 solver.cpp:260]     Total regularization terms: 0.993004 loss+regular. : 2.26204
I0518 20:05:17.639243  4008 solver.cpp:231] Iteration 240200, loss = 1.33637
I0518 20:05:17.639540  4008 solver.cpp:247]     Train net output #0: loss = 1.33637 (* 1 = 1.33637 loss)
I0518 20:05:17.639564  4008 sgd_solver.cpp:106] Iteration 240200, lr = 0.001
I0518 20:05:17.799417  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6923	3.125	79.8135	0	89.622	5.46875	87.321	0	83.1905	0	82.8301	0	74.7864	0	28.6593	2.3	
I0518 20:05:17.873976  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:05:17.876082  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:05:17.876132  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:05:17.886139  4008 solver.cpp:260]     Total regularization terms: 0.99278 loss+regular. : 2.32915
I0518 20:06:46.637809  4008 solver.cpp:231] Iteration 240400, loss = 1.28549
I0518 20:06:46.641836  4008 solver.cpp:247]     Train net output #0: loss = 1.28549 (* 1 = 1.28549 loss)
I0518 20:06:46.641902  4008 sgd_solver.cpp:106] Iteration 240400, lr = 0.001
I0518 20:06:46.798655  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.741	3.125	79.7581	0	89.6028	5.46875	87.2922	0	83.1898	0	82.8416	0	74.8004	0	28.6653	2.3	
I0518 20:06:46.874619  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:06:46.877310  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:06:46.877357  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:06:46.893477  4008 solver.cpp:260]     Total regularization terms: 0.99263 loss+regular. : 2.27812
I0518 20:08:16.761732  4008 solver.cpp:231] Iteration 240600, loss = 1.30853
I0518 20:08:16.762102  4008 solver.cpp:247]     Train net output #0: loss = 1.30853 (* 1 = 1.30853 loss)
I0518 20:08:16.762130  4008 sgd_solver.cpp:106] Iteration 240600, lr = 0.001
I0518 20:08:16.922142  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5517	3.125	79.4704	0	89.6229	5.46875	87.3097	0	83.1948	0	82.8533	0	74.8153	0	28.6717	2.3	
I0518 20:08:16.996711  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:08:16.998787  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:08:16.998841  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:08:17.008754  4008 solver.cpp:260]     Total regularization terms: 0.992439 loss+regular. : 2.30097
I0518 20:08:58.934674  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:09:45.893295  4008 solver.cpp:231] Iteration 240800, loss = 1.42385
I0518 20:09:45.893677  4008 solver.cpp:247]     Train net output #0: loss = 1.42385 (* 1 = 1.42385 loss)
I0518 20:09:45.893705  4008 sgd_solver.cpp:106] Iteration 240800, lr = 0.001
I0518 20:09:46.054323  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7726	3.125	79.5882	0	89.6492	5.46875	87.3229	0	83.228	0	82.8648	0	74.829	0	28.6785	2.3	
I0518 20:09:46.129472  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:09:46.131965  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:09:46.132015  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:09:46.142192  4008 solver.cpp:260]     Total regularization terms: 0.992275 loss+regular. : 2.41613
I0518 20:11:14.024178  4008 solver.cpp:348] Iteration 241000, Testing net (#0)
I0518 20:12:13.851110  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:12:39.087198  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55366
I0518 20:12:39.087291  4008 solver.cpp:415]     Test net output #1: loss = 1.92159 (* 1 = 1.92159 loss)
I0518 20:12:39.175323  4008 solver.cpp:231] Iteration 241000, loss = 1.55287
I0518 20:12:39.175405  4008 solver.cpp:247]     Train net output #0: loss = 1.55287 (* 1 = 1.55287 loss)
I0518 20:12:39.175422  4008 sgd_solver.cpp:106] Iteration 241000, lr = 0.001
I0518 20:12:39.339704  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6578	3.125	79.6488	0	89.6512	5.46875	87.3115	0	83.2226	0	82.8763	0	74.8428	0	28.6847	2.3	
I0518 20:12:39.415493  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:12:39.418366  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:12:39.418421  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:12:39.428236  4008 solver.cpp:260]     Total regularization terms: 0.992174 loss+regular. : 2.54504
I0518 20:13:59.177824  4008 solver.cpp:231] Iteration 241200, loss = 1.3199
I0518 20:13:59.178131  4008 solver.cpp:247]     Train net output #0: loss = 1.3199 (* 1 = 1.3199 loss)
I0518 20:13:59.178156  4008 sgd_solver.cpp:106] Iteration 241200, lr = 0.001
I0518 20:13:59.336998  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.873	3.125	79.8568	0	89.6483	5.46875	87.3403	0	83.2418	0	82.8875	0	74.857	0	28.6917	2.3	
I0518 20:13:59.411624  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:13:59.413763  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:13:59.413805  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:13:59.423681  4008 solver.cpp:260]     Total regularization terms: 0.991959 loss+regular. : 2.31185
I0518 20:15:23.775801  4008 solver.cpp:231] Iteration 241400, loss = 1.39457
I0518 20:15:23.776152  4008 solver.cpp:247]     Train net output #0: loss = 1.39457 (* 1 = 1.39457 loss)
I0518 20:15:23.776175  4008 sgd_solver.cpp:106] Iteration 241400, lr = 0.001
I0518 20:15:23.934746  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9161	3.125	79.7445	0	89.662	5.46875	87.3636	0	83.2427	0	82.8989	0	74.8713	0	28.6981	2.3	
I0518 20:15:24.010054  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:15:24.013026  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:15:24.013069  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:15:24.023016  4008 solver.cpp:260]     Total regularization terms: 0.991808 loss+regular. : 2.38638
I0518 20:16:54.463409  4008 solver.cpp:231] Iteration 241600, loss = 1.38445
I0518 20:16:54.463753  4008 solver.cpp:247]     Train net output #0: loss = 1.38445 (* 1 = 1.38445 loss)
I0518 20:16:54.463783  4008 sgd_solver.cpp:106] Iteration 241600, lr = 0.001
I0518 20:16:54.621651  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6779	3.125	79.6742	0	89.6404	5.46875	87.3669	0	83.2284	0	82.9102	0	74.8847	0	28.7042	2.3	
I0518 20:16:54.696821  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:16:54.699621  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:16:54.699695  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:16:54.709913  4008 solver.cpp:260]     Total regularization terms: 0.991699 loss+regular. : 2.37614
I0518 20:17:47.143928  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:18:27.055012  4008 solver.cpp:231] Iteration 241800, loss = 1.43877
I0518 20:18:27.055380  4008 solver.cpp:247]     Train net output #0: loss = 1.43877 (* 1 = 1.43877 loss)
I0518 20:18:27.055419  4008 sgd_solver.cpp:106] Iteration 241800, lr = 0.001
I0518 20:18:27.214777  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6779	3.125	79.1497	0	89.627	5.46875	87.3707	0	83.2416	0	82.9213	0	74.8987	0	28.7104	2.3	
I0518 20:18:27.289629  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:18:27.292415  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:18:27.292464  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:18:27.302377  4008 solver.cpp:260]     Total regularization terms: 0.991529 loss+regular. : 2.4303
I0518 20:19:58.947063  4008 solver.cpp:348] Iteration 242000, Testing net (#0)
I0518 20:21:03.480121  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:21:30.479820  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5548
I0518 20:21:30.479904  4008 solver.cpp:415]     Test net output #1: loss = 1.91437 (* 1 = 1.91437 loss)
I0518 20:21:30.568353  4008 solver.cpp:231] Iteration 242000, loss = 1.43864
I0518 20:21:30.568437  4008 solver.cpp:247]     Train net output #0: loss = 1.43864 (* 1 = 1.43864 loss)
I0518 20:21:30.568459  4008 sgd_solver.cpp:106] Iteration 242000, lr = 0.001
I0518 20:21:30.734179  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9936	3.125	79.4629	0	89.6334	5.46875	87.3487	0	83.2296	0	82.9326	0	74.9129	0	28.7165	2.3	
I0518 20:21:30.809204  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:21:30.817994  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:21:30.818055  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:21:30.828147  4008 solver.cpp:260]     Total regularization terms: 0.991409 loss+regular. : 2.43005
I0518 20:23:01.961138  4008 solver.cpp:231] Iteration 242200, loss = 1.49553
I0518 20:23:01.961539  4008 solver.cpp:247]     Train net output #0: loss = 1.49553 (* 1 = 1.49553 loss)
I0518 20:23:01.961599  4008 sgd_solver.cpp:106] Iteration 242200, lr = 0.001
I0518 20:23:02.123435  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7468	3.125	79.4421	0	89.6377	5.46875	87.388	0	83.2495	0	82.9437	0	74.9272	0	28.7226	2.3	
I0518 20:23:02.198572  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:23:02.201526  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:23:02.201591  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:23:02.213956  4008 solver.cpp:260]     Total regularization terms: 0.991274 loss+regular. : 2.48681
I0518 20:24:22.547567  4008 solver.cpp:231] Iteration 242400, loss = 1.28302
I0518 20:24:22.547909  4008 solver.cpp:247]     Train net output #0: loss = 1.28302 (* 1 = 1.28302 loss)
I0518 20:24:22.547932  4008 sgd_solver.cpp:106] Iteration 242400, lr = 0.001
I0518 20:24:22.707453  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.787	3.125	79.5114	0	89.6803	5.46875	87.3941	0	83.2818	0	82.9549	0	74.9408	0	28.729	2.3	
I0518 20:24:22.782469  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:24:22.785248  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:24:22.785291  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:24:22.795383  4008 solver.cpp:260]     Total regularization terms: 0.991142 loss+regular. : 2.27416
I0518 20:25:52.636591  4008 solver.cpp:231] Iteration 242600, loss = 1.24277
I0518 20:25:52.637042  4008 solver.cpp:247]     Train net output #0: loss = 1.24277 (* 1 = 1.24277 loss)
I0518 20:25:52.637073  4008 sgd_solver.cpp:106] Iteration 242600, lr = 0.001
I0518 20:25:52.797092  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9419	3.125	79.5413	0	89.6347	5.46875	87.3502	0	83.2587	0	82.9661	0	74.9551	0	28.7355	2.3	
I0518 20:25:52.872058  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:25:52.874209  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:25:52.874264  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:25:52.884223  4008 solver.cpp:260]     Total regularization terms: 0.990961 loss+regular. : 2.23373
I0518 20:26:45.536361  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:27:19.766824  4008 solver.cpp:231] Iteration 242800, loss = 1.56815
I0518 20:27:19.767168  4008 solver.cpp:247]     Train net output #0: loss = 1.56815 (* 1 = 1.56815 loss)
I0518 20:27:19.767190  4008 sgd_solver.cpp:106] Iteration 242800, lr = 0.001
I0518 20:27:19.926723  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0854	3.125	79.5208	0	89.671	5.46875	87.3719	0	83.2718	0	82.9773	0	74.969	0	28.7423	2.3	
I0518 20:27:20.002367  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:27:20.004767  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:27:20.004822  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:27:20.014897  4008 solver.cpp:260]     Total regularization terms: 0.99082 loss+regular. : 2.55897
I0518 20:28:56.744390  4008 solver.cpp:348] Iteration 243000, Testing net (#0)
I0518 20:29:55.087260  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:30:22.172106  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55232
I0518 20:30:22.172188  4008 solver.cpp:415]     Test net output #1: loss = 1.93298 (* 1 = 1.93298 loss)
I0518 20:30:22.260174  4008 solver.cpp:231] Iteration 243000, loss = 1.45432
I0518 20:30:22.260264  4008 solver.cpp:247]     Train net output #0: loss = 1.45432 (* 1 = 1.45432 loss)
I0518 20:30:22.260284  4008 sgd_solver.cpp:106] Iteration 243000, lr = 0.001
I0518 20:30:22.425429  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9247	3.125	79.6507	0	89.6795	5.46875	87.3769	0	83.2831	0	82.9885	0	74.9827	0	28.748	2.3	
I0518 20:30:22.500922  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:30:22.503866  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:30:22.503916  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:30:22.513864  4008 solver.cpp:260]     Total regularization terms: 0.990678 loss+regular. : 2.445
I0518 20:31:51.389430  4008 solver.cpp:231] Iteration 243200, loss = 1.34607
I0518 20:31:51.389684  4008 solver.cpp:247]     Train net output #0: loss = 1.34607 (* 1 = 1.34607 loss)
I0518 20:31:51.389703  4008 sgd_solver.cpp:106] Iteration 243200, lr = 0.001
I0518 20:31:51.550483  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8759	3.125	79.7441	0	89.675	5.46875	87.398	0	83.3119	0	82.9995	0	74.9966	0	28.7543	2.3	
I0518 20:31:51.625701  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:31:51.627931  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:31:51.627984  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:31:51.637969  4008 solver.cpp:260]     Total regularization terms: 0.990515 loss+regular. : 2.33659
I0518 20:33:19.469468  4008 solver.cpp:231] Iteration 243400, loss = 1.39322
I0518 20:33:19.473685  4008 solver.cpp:247]     Train net output #0: loss = 1.39322 (* 1 = 1.39322 loss)
I0518 20:33:19.473722  4008 sgd_solver.cpp:106] Iteration 243400, lr = 0.001
I0518 20:33:19.629714  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.764	3.125	79.6247	0	89.6768	5.46875	87.439	0	83.3116	0	83.0108	0	75.0106	0	28.76	2.3	
I0518 20:33:19.705242  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:33:19.708236  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:33:19.708288  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:33:19.718607  4008 solver.cpp:260]     Total regularization terms: 0.990301 loss+regular. : 2.38352
I0518 20:34:48.836791  4008 solver.cpp:231] Iteration 243600, loss = 1.40432
I0518 20:34:48.837154  4008 solver.cpp:247]     Train net output #0: loss = 1.40432 (* 1 = 1.40432 loss)
I0518 20:34:48.837183  4008 sgd_solver.cpp:106] Iteration 243600, lr = 0.001
I0518 20:34:48.997120  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9764	3.125	79.8066	0	89.725	5.46875	87.4598	0	83.3354	0	83.0218	0	75.0251	0	28.7663	2.3	
I0518 20:34:49.071682  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.34549	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:34:49.073815  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:34:49.073855  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:34:49.084278  4008 solver.cpp:260]     Total regularization terms: 0.990095 loss+regular. : 2.39442
I0518 20:35:41.771118  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:36:15.465543  4008 solver.cpp:231] Iteration 243800, loss = 1.43851
I0518 20:36:15.465929  4008 solver.cpp:247]     Train net output #0: loss = 1.43851 (* 1 = 1.43851 loss)
I0518 20:36:15.465955  4008 sgd_solver.cpp:106] Iteration 243800, lr = 0.001
I0518 20:36:15.626302  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8157	3.125	79.8675	0	89.7237	5.46875	87.462	0	83.3347	0	83.033	0	75.0388	0	28.7729	2.3	
I0518 20:36:15.701848  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:36:15.704601  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:36:15.704644  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:36:15.714772  4008 solver.cpp:260]     Total regularization terms: 0.989914 loss+regular. : 2.42842
I0518 20:37:47.267259  4008 solver.cpp:348] Iteration 244000, Testing net (#0)
I0518 20:38:45.234793  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:39:09.986697  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55392
I0518 20:39:09.986801  4008 solver.cpp:415]     Test net output #1: loss = 1.91606 (* 1 = 1.91606 loss)
I0518 20:39:10.078996  4008 solver.cpp:231] Iteration 244000, loss = 1.41668
I0518 20:39:10.079073  4008 solver.cpp:247]     Train net output #0: loss = 1.41668 (* 1 = 1.41668 loss)
I0518 20:39:10.079093  4008 sgd_solver.cpp:106] Iteration 244000, lr = 0.001
I0518 20:39:10.238710  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6607	3.125	79.4183	0	89.6592	5.46875	87.4477	0	83.3485	0	83.044	0	75.0524	0	28.78	2.3	
I0518 20:39:10.314748  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:39:10.317755  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:39:10.317800  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:39:10.327668  4008 solver.cpp:260]     Total regularization terms: 0.989839 loss+regular. : 2.40652
I0518 20:40:33.384986  4008 solver.cpp:231] Iteration 244200, loss = 1.40287
I0518 20:40:33.385356  4008 solver.cpp:247]     Train net output #0: loss = 1.40287 (* 1 = 1.40287 loss)
I0518 20:40:33.385388  4008 sgd_solver.cpp:106] Iteration 244200, lr = 0.001
I0518 20:40:33.544507  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.566	3.125	79.6689	0	89.7061	5.46875	87.4679	0	83.3483	0	83.0549	0	75.0671	0	28.7864	2.3	
I0518 20:40:33.620295  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:40:33.623102  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.3	
I0518 20:40:33.623193  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:40:33.633345  4008 solver.cpp:260]     Total regularization terms: 0.989642 loss+regular. : 2.39251
I0518 20:41:52.766105  4008 solver.cpp:231] Iteration 244400, loss = 1.34652
I0518 20:41:52.766408  4008 solver.cpp:247]     Train net output #0: loss = 1.34652 (* 1 = 1.34652 loss)
I0518 20:41:52.766429  4008 sgd_solver.cpp:106] Iteration 244400, lr = 0.001
I0518 20:41:52.927749  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7324	3.125	79.4948	0	89.7204	5.46875	87.4473	0	83.3591	0	83.066	0	75.0806	0	28.7928	2.4	
I0518 20:41:53.003026  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:41:53.005800  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 20:41:53.005848  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:41:53.015647  4008 solver.cpp:260]     Total regularization terms: 0.989521 loss+regular. : 2.33604
I0518 20:43:24.169486  4008 solver.cpp:231] Iteration 244600, loss = 1.28348
I0518 20:43:24.169889  4008 solver.cpp:247]     Train net output #0: loss = 1.28348 (* 1 = 1.28348 loss)
I0518 20:43:24.169919  4008 sgd_solver.cpp:106] Iteration 244600, lr = 0.001
I0518 20:43:24.329841  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4225	3.125	79.6038	0	89.72	5.46875	87.4548	0	83.3336	0	83.077	0	75.0945	0	28.7994	2.4	
I0518 20:43:24.405483  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:43:24.408555  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 20:43:24.408606  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:43:24.419008  4008 solver.cpp:260]     Total regularization terms: 0.989346 loss+regular. : 2.27283
I0518 20:44:16.401975  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:44:44.127377  4008 solver.cpp:231] Iteration 244800, loss = 1.5895
I0518 20:44:44.127465  4008 solver.cpp:247]     Train net output #0: loss = 1.5895 (* 1 = 1.5895 loss)
I0518 20:44:44.127483  4008 sgd_solver.cpp:106] Iteration 244800, lr = 0.001
I0518 20:44:44.289180  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7124	3.125	79.8044	0	89.7156	5.46875	87.4311	0	83.3566	0	83.088	0	75.1085	0	28.8063	2.4	
I0518 20:44:44.364845  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:44:44.367543  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 20:44:44.367594  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:44:44.397663  4008 solver.cpp:260]     Total regularization terms: 0.989154 loss+regular. : 2.57865
I0518 20:46:02.338135  4008 solver.cpp:348] Iteration 245000, Testing net (#0)
I0518 20:46:56.379403  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:47:18.904733  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55562
I0518 20:47:18.904851  4008 solver.cpp:415]     Test net output #1: loss = 1.91462 (* 1 = 1.91462 loss)
I0518 20:47:18.999534  4008 solver.cpp:231] Iteration 245000, loss = 1.31452
I0518 20:47:18.999642  4008 solver.cpp:247]     Train net output #0: loss = 1.31452 (* 1 = 1.31452 loss)
I0518 20:47:18.999672  4008 sgd_solver.cpp:106] Iteration 245000, lr = 0.001
I0518 20:47:19.158586  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5201	3.125	79.7334	0	89.7323	5.46875	87.47	0	83.3602	0	83.0992	0	75.1225	0	28.8132	2.4	
I0518 20:47:19.234313  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:47:19.237177  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 20:47:19.237227  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:47:19.247325  4008 solver.cpp:260]     Total regularization terms: 0.988942 loss+regular. : 2.30346
I0518 20:48:43.460566  4008 solver.cpp:231] Iteration 245200, loss = 1.27989
I0518 20:48:43.460970  4008 solver.cpp:247]     Train net output #0: loss = 1.27989 (* 1 = 1.27989 loss)
I0518 20:48:43.460999  4008 sgd_solver.cpp:106] Iteration 245200, lr = 0.001
I0518 20:48:43.620412  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6664	3.125	79.8509	0	89.7498	5.46875	87.4962	0	83.3758	0	83.1102	0	75.137	0	28.8193	2.4	
I0518 20:48:43.695713  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:48:43.700070  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 20:48:43.700145  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:48:43.710420  4008 solver.cpp:260]     Total regularization terms: 0.988738 loss+regular. : 2.26863
I0518 20:50:11.708649  4008 solver.cpp:231] Iteration 245400, loss = 1.53933
I0518 20:50:11.708811  4008 solver.cpp:247]     Train net output #0: loss = 1.53933 (* 1 = 1.53933 loss)
I0518 20:50:11.708827  4008 sgd_solver.cpp:106] Iteration 245400, lr = 0.001
I0518 20:50:11.869688  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5545	3.125	80.012	0	89.7514	5.46875	87.465	0	83.3611	0	83.1211	0	75.1504	0	28.8253	2.4	
I0518 20:50:11.944465  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:50:11.946748  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 20:50:11.946787  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:50:11.959769  4008 solver.cpp:260]     Total regularization terms: 0.988615 loss+regular. : 2.52794
I0518 20:51:40.024093  4008 solver.cpp:231] Iteration 245600, loss = 1.40511
I0518 20:51:40.024422  4008 solver.cpp:247]     Train net output #0: loss = 1.40511 (* 1 = 1.40511 loss)
I0518 20:51:40.024446  4008 sgd_solver.cpp:106] Iteration 245600, lr = 0.001
I0518 20:51:40.182826  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8989	3.125	79.7139	0	89.7615	5.46875	87.4916	0	83.37	0	83.1319	0	75.1644	0	28.8315	2.4	
I0518 20:51:40.257908  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:51:40.260568  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 20:51:40.260610  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:51:40.270354  4008 solver.cpp:260]     Total regularization terms: 0.98845 loss+regular. : 2.39356
I0518 20:52:41.478953  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:53:08.682250  4008 solver.cpp:231] Iteration 245800, loss = 1.33086
I0518 20:53:08.682337  4008 solver.cpp:247]     Train net output #0: loss = 1.33086 (* 1 = 1.33086 loss)
I0518 20:53:08.682358  4008 sgd_solver.cpp:106] Iteration 245800, lr = 0.001
I0518 20:53:08.842766  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8357	3.125	79.8379	0	89.7748	5.46875	87.495	0	83.3941	0	83.1427	0	75.1781	0	28.8379	2.4	
I0518 20:53:08.917971  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:53:08.920791  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 20:53:08.920842  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:53:08.930806  4008 solver.cpp:260]     Total regularization terms: 0.988235 loss+regular. : 2.3191
I0518 20:54:34.861455  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_246000.caffemodel
I0518 20:57:49.128970  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_246000.solverstate
I0518 20:57:49.770452  4008 solver.cpp:348] Iteration 246000, Testing net (#0)
I0518 20:58:52.631170  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 20:59:15.859544  4008 solver.cpp:415]     Test net output #0: accuracy = 0.551839
I0518 20:59:15.859637  4008 solver.cpp:415]     Test net output #1: loss = 1.93054 (* 1 = 1.93054 loss)
I0518 20:59:15.946949  4008 solver.cpp:231] Iteration 246000, loss = 1.27664
I0518 20:59:15.947026  4008 solver.cpp:247]     Train net output #0: loss = 1.27664 (* 1 = 1.27664 loss)
I0518 20:59:15.947046  4008 sgd_solver.cpp:106] Iteration 246000, lr = 0.001
I0518 20:59:16.113744  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0682	3.125	79.96	0	89.7718	5.46875	87.4928	0	83.3898	0	83.1536	0	75.1916	0	28.8442	2.4	
I0518 20:59:16.115797  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 20:59:16.118698  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 20:59:16.118742  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 20:59:16.128592  4008 solver.cpp:260]     Total regularization terms: 0.988079 loss+regular. : 2.26472
I0518 21:00:48.922709  4008 solver.cpp:231] Iteration 246200, loss = 1.26556
I0518 21:00:48.923022  4008 solver.cpp:247]     Train net output #0: loss = 1.26556 (* 1 = 1.26556 loss)
I0518 21:00:48.923046  4008 sgd_solver.cpp:106] Iteration 246200, lr = 0.001
I0518 21:00:49.083315  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0452	3.125	79.8825	0	89.7635	5.46875	87.5084	0	83.4057	0	83.1649	0	75.2055	0	28.8504	2.4	
I0518 21:00:49.158110  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:00:49.160440  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:00:49.160485  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:00:49.170506  4008 solver.cpp:260]     Total regularization terms: 0.987928 loss+regular. : 2.25349
I0518 21:02:23.980543  4008 solver.cpp:231] Iteration 246400, loss = 1.31895
I0518 21:02:23.980883  4008 solver.cpp:247]     Train net output #0: loss = 1.31895 (* 1 = 1.31895 loss)
I0518 21:02:23.980904  4008 sgd_solver.cpp:106] Iteration 246400, lr = 0.001
I0518 21:02:24.140353  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7353	3.125	79.9971	0	89.7837	5.46875	87.5356	0	83.407	0	83.1758	0	75.2194	0	28.8573	2.4	
I0518 21:02:24.215431  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:02:24.217895  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:02:24.217947  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:02:24.227855  4008 solver.cpp:260]     Total regularization terms: 0.987755 loss+regular. : 2.30671
I0518 21:03:58.316965  4008 solver.cpp:231] Iteration 246600, loss = 1.32739
I0518 21:03:58.317309  4008 solver.cpp:247]     Train net output #0: loss = 1.32739 (* 1 = 1.32739 loss)
I0518 21:03:58.317334  4008 sgd_solver.cpp:106] Iteration 246600, lr = 0.001
I0518 21:03:58.477826  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8157	3.125	79.7708	0	89.7695	5.46875	87.5252	0	83.4222	0	83.1863	0	75.233	0	28.8633	2.4	
I0518 21:03:58.558465  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:03:58.561357  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:03:58.561403  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:03:58.571368  4008 solver.cpp:260]     Total regularization terms: 0.987622 loss+regular. : 2.31501
I0518 21:04:56.738819  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:05:18.482496  4008 solver.cpp:231] Iteration 246800, loss = 1.47329
I0518 21:05:18.482583  4008 solver.cpp:247]     Train net output #0: loss = 1.47329 (* 1 = 1.47329 loss)
I0518 21:05:18.482600  4008 sgd_solver.cpp:106] Iteration 246800, lr = 0.001
I0518 21:05:18.644333  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7238	3.125	79.8451	0	89.748	5.46875	87.5344	0	83.414	0	83.197	0	75.2461	0	28.87	2.4	
I0518 21:05:18.719975  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:05:18.723505  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:05:18.723572  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:05:18.733542  4008 solver.cpp:260]     Total regularization terms: 0.987446 loss+regular. : 2.46074
I0518 21:06:53.624063  4008 solver.cpp:348] Iteration 247000, Testing net (#0)
I0518 21:08:02.179082  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:08:24.662983  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5548
I0518 21:08:24.663079  4008 solver.cpp:415]     Test net output #1: loss = 1.91791 (* 1 = 1.91791 loss)
I0518 21:08:24.752665  4008 solver.cpp:231] Iteration 247000, loss = 1.23229
I0518 21:08:24.752737  4008 solver.cpp:247]     Train net output #0: loss = 1.23229 (* 1 = 1.23229 loss)
I0518 21:08:24.752758  4008 sgd_solver.cpp:106] Iteration 247000, lr = 0.001
I0518 21:08:24.912052  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7956	3.125	79.7744	0	89.7573	5.46875	87.5345	0	83.4231	0	83.2079	0	75.2598	0	28.8759	2.4	
I0518 21:08:24.988889  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:08:24.991379  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:08:24.991436  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:08:25.001569  4008 solver.cpp:260]     Total regularization terms: 0.987298 loss+regular. : 2.21959
I0518 21:10:01.016726  4008 solver.cpp:231] Iteration 247200, loss = 1.45594
I0518 21:10:01.017107  4008 solver.cpp:247]     Train net output #0: loss = 1.45594 (* 1 = 1.45594 loss)
I0518 21:10:01.017146  4008 sgd_solver.cpp:106] Iteration 247200, lr = 0.001
I0518 21:10:01.176367  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6148	3.125	79.5013	0	89.7554	5.46875	87.5265	0	83.4163	0	83.2187	0	75.2737	0	28.8821	2.4	
I0518 21:10:01.251096  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:10:01.252760  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:10:01.252810  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:10:01.262882  4008 solver.cpp:260]     Total regularization terms: 0.98721 loss+regular. : 2.44315
I0518 21:11:34.882784  4008 solver.cpp:231] Iteration 247400, loss = 1.47882
I0518 21:11:34.883203  4008 solver.cpp:247]     Train net output #0: loss = 1.47882 (* 1 = 1.47882 loss)
I0518 21:11:34.883225  4008 sgd_solver.cpp:106] Iteration 247400, lr = 0.001
I0518 21:11:35.043783  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6435	3.125	79.7933	0	89.7986	5.46875	87.5445	0	83.4518	0	83.2292	0	75.2872	0	28.8887	2.4	
I0518 21:11:35.119355  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.38889	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:11:35.122104  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:11:35.122155  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:11:35.132060  4008 solver.cpp:260]     Total regularization terms: 0.987003 loss+regular. : 2.46583
I0518 21:13:05.589653  4008 solver.cpp:231] Iteration 247600, loss = 1.46533
I0518 21:13:05.590983  4008 solver.cpp:247]     Train net output #0: loss = 1.46533 (* 1 = 1.46533 loss)
I0518 21:13:05.591012  4008 sgd_solver.cpp:106] Iteration 247600, lr = 0.001
I0518 21:13:05.750087  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7468	3.125	79.8555	0	89.8194	5.46875	87.5203	0	83.4414	0	83.2396	0	75.3008	0	28.8943	2.4	
I0518 21:13:05.825744  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:13:05.828975  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:13:05.829042  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:13:05.839104  4008 solver.cpp:260]     Total regularization terms: 0.986803 loss+regular. : 2.45213
I0518 21:14:11.958387  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:14:33.844892  4008 solver.cpp:231] Iteration 247800, loss = 1.42501
I0518 21:14:33.844995  4008 solver.cpp:247]     Train net output #0: loss = 1.42501 (* 1 = 1.42501 loss)
I0518 21:14:33.845016  4008 sgd_solver.cpp:106] Iteration 247800, lr = 0.001
I0518 21:14:34.004613  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7353	3.125	79.7562	0	89.7585	5.46875	87.5407	0	83.4439	0	83.2503	0	75.3145	0	28.9007	2.4	
I0518 21:14:34.079898  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:14:34.083236  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:14:34.083288  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:14:34.093276  4008 solver.cpp:260]     Total regularization terms: 0.986636 loss+regular. : 2.41164
I0518 21:15:54.951802  4008 solver.cpp:348] Iteration 248000, Testing net (#0)
I0518 21:16:52.515197  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:17:14.865470  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55358
I0518 21:17:14.865622  4008 solver.cpp:415]     Test net output #1: loss = 1.93197 (* 1 = 1.93197 loss)
I0518 21:17:14.954406  4008 solver.cpp:231] Iteration 248000, loss = 1.51469
I0518 21:17:14.954526  4008 solver.cpp:247]     Train net output #0: loss = 1.51469 (* 1 = 1.51469 loss)
I0518 21:17:14.954551  4008 sgd_solver.cpp:106] Iteration 248000, lr = 0.001
I0518 21:17:15.114787  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4971	3.125	79.8874	0	89.7966	5.46875	87.5424	0	83.4701	0	83.261	0	75.3278	0	28.9065	2.4	
I0518 21:17:15.190098  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:17:15.192301  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:17:15.192349  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:17:15.205231  4008 solver.cpp:260]     Total regularization terms: 0.986493 loss+regular. : 2.50118
I0518 21:18:41.828771  4008 solver.cpp:231] Iteration 248200, loss = 1.52204
I0518 21:18:41.829056  4008 solver.cpp:247]     Train net output #0: loss = 1.52204 (* 1 = 1.52204 loss)
I0518 21:18:41.829082  4008 sgd_solver.cpp:106] Iteration 248200, lr = 0.001
I0518 21:18:41.989522  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8644	3.125	79.8327	0	89.7756	5.46875	87.554	0	83.4633	0	83.272	0	75.3413	0	28.9125	2.4	
I0518 21:18:42.065021  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:18:42.068420  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:18:42.068475  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:18:42.078589  4008 solver.cpp:260]     Total regularization terms: 0.98634 loss+regular. : 2.50838
I0518 21:20:05.234200  4008 solver.cpp:231] Iteration 248400, loss = 1.35908
I0518 21:20:05.234447  4008 solver.cpp:247]     Train net output #0: loss = 1.35908 (* 1 = 1.35908 loss)
I0518 21:20:05.234482  4008 sgd_solver.cpp:106] Iteration 248400, lr = 0.001
I0518 21:20:05.394593  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1141	3.125	80.0745	0	89.8188	5.46875	87.5631	0	83.5103	0	83.2824	0	75.3551	0	28.9194	2.4	
I0518 21:20:05.469235  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:20:05.471506  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:20:05.471544  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:20:05.482765  4008 solver.cpp:260]     Total regularization terms: 0.986163 loss+regular. : 2.34525
I0518 21:21:28.019855  4008 solver.cpp:231] Iteration 248600, loss = 1.30283
I0518 21:21:28.021497  4008 solver.cpp:247]     Train net output #0: loss = 1.30283 (* 1 = 1.30283 loss)
I0518 21:21:28.021530  4008 sgd_solver.cpp:106] Iteration 248600, lr = 0.001
I0518 21:21:28.180795  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9046	3.125	80.0863	0	89.8411	5.46875	87.577	0	83.495	0	83.293	0	75.3687	0	28.9257	2.4	
I0518 21:21:28.256139  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:21:28.259234  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:21:28.259286  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:21:28.269160  4008 solver.cpp:260]     Total regularization terms: 0.986069 loss+regular. : 2.2889
I0518 21:22:35.495872  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:22:53.375867  4008 solver.cpp:231] Iteration 248800, loss = 1.32505
I0518 21:22:53.375962  4008 solver.cpp:247]     Train net output #0: loss = 1.32505 (* 1 = 1.32505 loss)
I0518 21:22:53.376076  4008 sgd_solver.cpp:106] Iteration 248800, lr = 0.001
I0518 21:22:53.535960  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5861	3.125	79.9206	0	89.802	5.46875	87.5835	0	83.4873	0	83.3036	0	75.3821	0	28.9325	2.4	
I0518 21:22:53.611934  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:22:53.614778  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:22:53.614831  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:22:53.629698  4008 solver.cpp:260]     Total regularization terms: 0.985928 loss+regular. : 2.31098
I0518 21:24:29.655060  4008 solver.cpp:348] Iteration 249000, Testing net (#0)
I0518 21:25:36.402917  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:25:57.732205  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55584
I0518 21:25:57.732353  4008 solver.cpp:415]     Test net output #1: loss = 1.91418 (* 1 = 1.91418 loss)
I0518 21:25:57.820760  4008 solver.cpp:231] Iteration 249000, loss = 1.40606
I0518 21:25:57.820870  4008 solver.cpp:247]     Train net output #0: loss = 1.40606 (* 1 = 1.40606 loss)
I0518 21:25:57.820891  4008 sgd_solver.cpp:106] Iteration 249000, lr = 0.001
I0518 21:25:57.986093  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8472	3.125	79.8174	0	89.8042	5.46875	87.5969	0	83.5124	0	83.3143	0	75.3961	0	28.9385	2.4	
I0518 21:25:58.061519  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:25:58.063871  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:25:58.063927  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:25:58.073889  4008 solver.cpp:260]     Total regularization terms: 0.985785 loss+regular. : 2.39184
I0518 21:27:25.292147  4008 solver.cpp:231] Iteration 249200, loss = 1.18355
I0518 21:27:25.292491  4008 solver.cpp:247]     Train net output #0: loss = 1.18355 (* 1 = 1.18355 loss)
I0518 21:27:25.292516  4008 sgd_solver.cpp:106] Iteration 249200, lr = 0.001
I0518 21:27:25.453524  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9046	3.125	79.918	0	89.8364	5.46875	87.6091	0	83.5083	0	83.325	0	75.4096	0	28.9452	2.4	
I0518 21:27:25.529374  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:27:25.532625  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:27:25.532678  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:27:25.542625  4008 solver.cpp:260]     Total regularization terms: 0.985547 loss+regular. : 2.1691
I0518 21:28:53.465855  4008 solver.cpp:231] Iteration 249400, loss = 1.1509
I0518 21:28:53.466255  4008 solver.cpp:247]     Train net output #0: loss = 1.1509 (* 1 = 1.1509 loss)
I0518 21:28:53.466285  4008 sgd_solver.cpp:106] Iteration 249400, lr = 0.001
I0518 21:28:53.624558  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.675	3.125	79.6816	0	89.8049	5.46875	87.574	0	83.5223	0	83.3353	0	75.4233	0	28.9509	2.4	
I0518 21:28:53.699874  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:28:53.702482  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:28:53.702534  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:28:53.712646  4008 solver.cpp:260]     Total regularization terms: 0.985512 loss+regular. : 2.13641
I0518 21:30:30.381753  4008 solver.cpp:231] Iteration 249600, loss = 1.39712
I0518 21:30:30.386193  4008 solver.cpp:247]     Train net output #0: loss = 1.39712 (* 1 = 1.39712 loss)
I0518 21:30:30.386250  4008 sgd_solver.cpp:106] Iteration 249600, lr = 0.001
I0518 21:30:30.541510  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7124	3.125	79.7777	0	89.8449	5.46875	87.5883	0	83.5201	0	83.3456	0	75.4367	0	28.9564	2.4	
I0518 21:30:30.617997  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:30:30.621752  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:30:30.621815  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:30:30.632196  4008 solver.cpp:260]     Total regularization terms: 0.985359 loss+regular. : 2.38248
I0518 21:31:43.427485  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:32:00.472118  4008 solver.cpp:231] Iteration 249800, loss = 1.35661
I0518 21:32:00.472260  4008 solver.cpp:247]     Train net output #0: loss = 1.35661 (* 1 = 1.35661 loss)
I0518 21:32:00.472277  4008 sgd_solver.cpp:106] Iteration 249800, lr = 0.001
I0518 21:32:00.633577  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5717	3.125	79.7721	0	89.8393	5.46875	87.6017	0	83.528	0	83.3562	0	75.4506	0	28.963	2.4	
I0518 21:32:00.711689  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:32:00.713682  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:32:00.713742  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:32:00.723709  4008 solver.cpp:260]     Total regularization terms: 0.98522 loss+regular. : 2.34183
I0518 21:33:30.375160  4008 solver.cpp:348] Iteration 250000, Testing net (#0)
I0518 21:34:38.596441  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:34:58.187090  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55348
I0518 21:34:58.187207  4008 solver.cpp:415]     Test net output #1: loss = 1.91573 (* 1 = 1.91573 loss)
I0518 21:34:58.276428  4008 solver.cpp:231] Iteration 250000, loss = 1.39892
I0518 21:34:58.276506  4008 solver.cpp:247]     Train net output #0: loss = 1.39892 (* 1 = 1.39892 loss)
I0518 21:34:58.276525  4008 sgd_solver.cpp:106] Iteration 250000, lr = 0.001
I0518 21:34:58.441499  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7037	3.125	79.8066	0	89.8064	5.46875	87.5996	0	83.5117	0	83.367	0	75.4648	0	28.9691	2.4	
I0518 21:34:58.516818  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:34:58.520128  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:34:58.520177  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:34:58.530740  4008 solver.cpp:260]     Total regularization terms: 0.985057 loss+regular. : 2.38398
I0518 21:36:26.421946  4008 solver.cpp:231] Iteration 250200, loss = 1.42395
I0518 21:36:26.429966  4008 solver.cpp:247]     Train net output #0: loss = 1.42395 (* 1 = 1.42395 loss)
I0518 21:36:26.430003  4008 sgd_solver.cpp:106] Iteration 250200, lr = 0.001
I0518 21:36:26.580713  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8185	3.125	79.585	0	89.857	5.46875	87.6105	0	83.5323	0	83.3777	0	75.4788	0	28.9754	2.4	
I0518 21:36:26.655933  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:36:26.658880  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:36:26.658936  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:36:26.668913  4008 solver.cpp:260]     Total regularization terms: 0.984844 loss+regular. : 2.4088
I0518 21:37:54.450767  4008 solver.cpp:231] Iteration 250400, loss = 1.43735
I0518 21:37:54.453696  4008 solver.cpp:247]     Train net output #0: loss = 1.43735 (* 1 = 1.43735 loss)
I0518 21:37:54.453737  4008 sgd_solver.cpp:106] Iteration 250400, lr = 0.001
I0518 21:37:54.609664  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9161	3.125	79.7718	0	89.8228	5.46875	87.6064	0	83.5338	0	83.3883	0	75.4928	0	28.9816	2.4	
I0518 21:37:54.684907  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:37:54.687882  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:37:54.687932  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:37:54.703173  4008 solver.cpp:260]     Total regularization terms: 0.984708 loss+regular. : 2.42206
I0518 21:39:20.401824  4008 solver.cpp:231] Iteration 250600, loss = 1.51953
I0518 21:39:20.402180  4008 solver.cpp:247]     Train net output #0: loss = 1.51953 (* 1 = 1.51953 loss)
I0518 21:39:20.402211  4008 sgd_solver.cpp:106] Iteration 250600, lr = 0.001
I0518 21:39:20.562551  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1399	3.125	79.6611	0	89.8651	5.46875	87.6495	0	83.5436	0	83.3989	0	75.5061	0	28.9879	2.4	
I0518 21:39:20.637585  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:39:20.640094  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:39:20.640144  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:39:20.650246  4008 solver.cpp:260]     Total regularization terms: 0.984605 loss+regular. : 2.50413
I0518 21:40:37.513520  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:40:50.464984  4008 solver.cpp:231] Iteration 250800, loss = 1.30866
I0518 21:40:50.465083  4008 solver.cpp:247]     Train net output #0: loss = 1.30866 (* 1 = 1.30866 loss)
I0518 21:40:50.465111  4008 sgd_solver.cpp:106] Iteration 250800, lr = 0.001
I0518 21:40:50.624884  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.5488	3.125	79.7523	0	89.887	5.46875	87.6493	0	83.5433	0	83.4094	0	75.5195	0	28.9943	2.4	
I0518 21:40:50.700276  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:40:50.703281  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:40:50.703332  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:40:50.724576  4008 solver.cpp:260]     Total regularization terms: 0.984419 loss+regular. : 2.29308
I0518 21:42:17.167145  4008 solver.cpp:348] Iteration 251000, Testing net (#0)
I0518 21:43:26.340785  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:43:46.080602  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55496
I0518 21:43:46.080752  4008 solver.cpp:415]     Test net output #1: loss = 1.9152 (* 1 = 1.9152 loss)
I0518 21:43:46.173748  4008 solver.cpp:231] Iteration 251000, loss = 1.38665
I0518 21:43:46.173849  4008 solver.cpp:247]     Train net output #0: loss = 1.38665 (* 1 = 1.38665 loss)
I0518 21:43:46.173877  4008 sgd_solver.cpp:106] Iteration 251000, lr = 0.001
I0518 21:43:46.339977  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4426	3.125	80.0648	0	89.8889	5.46875	87.648	0	83.5666	0	83.4198	0	75.5334	0	29.0001	2.4	
I0518 21:43:46.415053  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:43:46.417157  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:43:46.417229  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:43:46.430392  4008 solver.cpp:260]     Total regularization terms: 0.984245 loss+regular. : 2.37089
I0518 21:45:11.093734  4008 solver.cpp:231] Iteration 251200, loss = 1.21994
I0518 21:45:11.094393  4008 solver.cpp:247]     Train net output #0: loss = 1.21994 (* 1 = 1.21994 loss)
I0518 21:45:11.094431  4008 sgd_solver.cpp:106] Iteration 251200, lr = 0.001
I0518 21:45:11.251180  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8013	3.125	80.1055	0	89.8405	5.46875	87.6373	0	83.5802	0	83.4302	0	75.5462	0	29.0062	2.4	
I0518 21:45:11.326081  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:45:11.328068  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:45:11.328119  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:45:11.338238  4008 solver.cpp:260]     Total regularization terms: 0.984083 loss+regular. : 2.20403
I0518 21:46:27.511622  4008 solver.cpp:231] Iteration 251400, loss = 1.64265
I0518 21:46:27.511962  4008 solver.cpp:247]     Train net output #0: loss = 1.64265 (* 1 = 1.64265 loss)
I0518 21:46:27.511982  4008 sgd_solver.cpp:106] Iteration 251400, lr = 0.001
I0518 21:46:27.671540  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.632	3.125	80.001	0	89.8794	5.46875	87.6421	0	83.5707	0	83.4408	0	75.5593	0	29.0119	2.4	
I0518 21:46:27.746232  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:46:27.748216  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:46:27.748265  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:46:27.758448  4008 solver.cpp:260]     Total regularization terms: 0.983909 loss+regular. : 2.62656
I0518 21:47:45.251991  4008 solver.cpp:231] Iteration 251600, loss = 1.42523
I0518 21:47:45.252321  4008 solver.cpp:247]     Train net output #0: loss = 1.42523 (* 1 = 1.42523 loss)
I0518 21:47:45.252357  4008 sgd_solver.cpp:106] Iteration 251600, lr = 0.001
I0518 21:47:45.412267  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3795	3.125	79.9779	0	89.8815	5.46875	87.645	0	83.5863	0	83.4515	0	75.5724	0	29.0176	2.4	
I0518 21:47:45.486639  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:47:45.488232  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:47:45.488267  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:47:45.499480  4008 solver.cpp:260]     Total regularization terms: 0.983763 loss+regular. : 2.409
I0518 21:49:00.407172  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:49:09.492029  4008 solver.cpp:231] Iteration 251800, loss = 1.54115
I0518 21:49:09.492192  4008 solver.cpp:247]     Train net output #0: loss = 1.54115 (* 1 = 1.54115 loss)
I0518 21:49:09.492214  4008 sgd_solver.cpp:106] Iteration 251800, lr = 0.001
I0518 21:49:09.651494  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.4857	3.125	79.7227	0	89.8336	5.46875	87.6611	0	83.5777	0	83.4619	0	75.5852	0	29.0247	2.4	
I0518 21:49:09.726387  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:49:09.728550  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:49:09.728603  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:49:09.738615  4008 solver.cpp:260]     Total regularization terms: 0.983641 loss+regular. : 2.52479
I0518 21:50:50.793442  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_252000.caffemodel
I0518 21:53:38.507169  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_252000.solverstate
I0518 21:53:39.312300  4008 solver.cpp:348] Iteration 252000, Testing net (#0)
I0518 21:54:47.039319  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 21:55:03.931381  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55646
I0518 21:55:03.931470  4008 solver.cpp:415]     Test net output #1: loss = 1.9138 (* 1 = 1.9138 loss)
I0518 21:55:04.020912  4008 solver.cpp:231] Iteration 252000, loss = 1.54914
I0518 21:55:04.021009  4008 solver.cpp:247]     Train net output #0: loss = 1.54914 (* 1 = 1.54914 loss)
I0518 21:55:04.021035  4008 sgd_solver.cpp:106] Iteration 252000, lr = 0.001
I0518 21:55:04.180940  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7784	3.125	79.9251	0	89.8461	5.46875	87.648	0	83.5698	0	83.4722	0	75.5986	0	29.031	2.4	
I0518 21:55:04.182641  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.43229	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:55:04.184623  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:55:04.184670  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:55:04.197306  4008 solver.cpp:260]     Total regularization terms: 0.983534 loss+regular. : 2.53268
I0518 21:56:27.967528  4008 solver.cpp:231] Iteration 252200, loss = 1.45178
I0518 21:56:27.969707  4008 solver.cpp:247]     Train net output #0: loss = 1.45178 (* 1 = 1.45178 loss)
I0518 21:56:27.969758  4008 sgd_solver.cpp:106] Iteration 252200, lr = 0.001
I0518 21:56:28.128366  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6808	3.125	79.7783	0	89.8627	5.46875	87.665	0	83.5768	0	83.4823	0	75.612	0	29.0371	2.4	
I0518 21:56:28.203522  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.47569	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:56:28.206231  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:56:28.206291  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:56:28.216323  4008 solver.cpp:260]     Total regularization terms: 0.983455 loss+regular. : 2.43523
I0518 21:58:00.678270  4008 solver.cpp:231] Iteration 252400, loss = 1.45267
I0518 21:58:00.681692  4008 solver.cpp:247]     Train net output #0: loss = 1.45267 (* 1 = 1.45267 loss)
I0518 21:58:00.681737  4008 sgd_solver.cpp:106] Iteration 252400, lr = 0.001
I0518 21:58:00.839715  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9419	3.125	79.9753	0	89.8823	5.46875	87.7151	0	83.6141	0	83.4926	0	75.6248	0	29.0428	2.4	
I0518 21:58:00.914599  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.47569	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:58:00.917094  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:58:00.917167  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:58:00.927180  4008 solver.cpp:260]     Total regularization terms: 0.983262 loss+regular. : 2.43593
I0518 21:59:31.762197  4008 solver.cpp:231] Iteration 252600, loss = 1.39147
I0518 21:59:31.762531  4008 solver.cpp:247]     Train net output #0: loss = 1.39147 (* 1 = 1.39147 loss)
I0518 21:59:31.762559  4008 sgd_solver.cpp:106] Iteration 252600, lr = 0.001
I0518 21:59:31.922510  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8874	3.125	79.8669	0	89.8789	5.46875	87.6644	0	83.5763	0	83.5026	0	75.6382	0	29.0486	2.4	
I0518 21:59:31.997313  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.47569	0	0	0	0	0	0	0	0	0	0	0	
I0518 21:59:32.000231  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 21:59:32.000308  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 21:59:32.030370  4008 solver.cpp:260]     Total regularization terms: 0.98313 loss+regular. : 2.3746
I0518 22:00:50.040789  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:00:55.515722  4008 solver.cpp:231] Iteration 252800, loss = 1.2451
I0518 22:00:55.515825  4008 solver.cpp:247]     Train net output #0: loss = 1.2451 (* 1 = 1.2451 loss)
I0518 22:00:55.515884  4008 sgd_solver.cpp:106] Iteration 252800, lr = 0.001
I0518 22:00:55.676242  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6004	3.125	79.7383	0	89.8944	5.46875	87.6834	0	83.6177	0	83.5131	0	75.6517	0	29.0549	2.4	
I0518 22:00:55.753818  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.47569	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:00:55.755668  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:00:55.755710  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:00:55.770084  4008 solver.cpp:260]     Total regularization terms: 0.982935 loss+regular. : 2.22803
I0518 22:02:12.306911  4008 solver.cpp:348] Iteration 253000, Testing net (#0)
I0518 22:03:16.108600  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:03:32.177191  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55294
I0518 22:03:32.177321  4008 solver.cpp:415]     Test net output #1: loss = 1.92071 (* 1 = 1.92071 loss)
I0518 22:03:32.265319  4008 solver.cpp:231] Iteration 253000, loss = 1.63672
I0518 22:03:32.265403  4008 solver.cpp:247]     Train net output #0: loss = 1.63672 (* 1 = 1.63672 loss)
I0518 22:03:32.265419  4008 sgd_solver.cpp:106] Iteration 253000, lr = 0.001
I0518 22:03:32.431586  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.1987	3.125	80.096	0	89.9136	5.46875	87.7025	0	83.613	0	83.5235	0	75.6643	0	29.0607	2.4	
I0518 22:03:32.506145  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.47569	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:03:32.507987  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:03:32.508019  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:03:32.518041  4008 solver.cpp:260]     Total regularization terms: 0.982765 loss+regular. : 2.61948
I0518 22:04:48.430200  4008 solver.cpp:231] Iteration 253200, loss = 1.42048
I0518 22:04:48.430533  4008 solver.cpp:247]     Train net output #0: loss = 1.42048 (* 1 = 1.42048 loss)
I0518 22:04:48.430562  4008 sgd_solver.cpp:106] Iteration 253200, lr = 0.001
I0518 22:04:48.591732  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7812	3.125	79.8643	0	89.9118	5.46875	87.6689	0	83.6005	0	83.534	0	75.6769	0	29.0666	2.4	
I0518 22:04:48.666582  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.47569	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:04:48.668644  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:04:48.668684  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:04:48.678585  4008 solver.cpp:260]     Total regularization terms: 0.982647 loss+regular. : 2.40313
I0518 22:06:16.998459  4008 solver.cpp:231] Iteration 253400, loss = 1.36717
I0518 22:06:16.998756  4008 solver.cpp:247]     Train net output #0: loss = 1.36717 (* 1 = 1.36717 loss)
I0518 22:06:16.998780  4008 sgd_solver.cpp:106] Iteration 253400, lr = 0.001
I0518 22:06:17.157430  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7984	3.125	80.1169	0	89.9439	5.46875	87.69	0	83.6329	0	83.5444	0	75.6898	0	29.0729	2.4	
I0518 22:06:17.233222  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5191	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:06:17.236095  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:06:17.236148  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:06:17.246779  4008 solver.cpp:260]     Total regularization terms: 0.982526 loss+regular. : 2.34969
I0518 22:07:44.000300  4008 solver.cpp:231] Iteration 253600, loss = 1.18897
I0518 22:07:44.000617  4008 solver.cpp:247]     Train net output #0: loss = 1.18897 (* 1 = 1.18897 loss)
I0518 22:07:44.000640  4008 sgd_solver.cpp:106] Iteration 253600, lr = 0.001
I0518 22:07:44.159458  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7554	3.125	79.7767	0	89.9027	5.46875	87.6959	0	83.6218	0	83.5547	0	75.7025	0	29.0789	2.4	
I0518 22:07:44.235049  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5191	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:07:44.237949  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:07:44.238003  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:07:44.247897  4008 solver.cpp:260]     Total regularization terms: 0.982444 loss+regular. : 2.17141
I0518 22:09:13.528647  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:09:16.790771  4008 solver.cpp:231] Iteration 253800, loss = 1.4102
I0518 22:09:16.790859  4008 solver.cpp:247]     Train net output #0: loss = 1.4102 (* 1 = 1.4102 loss)
I0518 22:09:16.790882  4008 sgd_solver.cpp:106] Iteration 253800, lr = 0.001
I0518 22:09:16.951359  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.787	3.125	79.9583	0	89.9139	5.46875	87.6998	0	83.6191	0	83.5652	0	75.7154	0	29.0849	2.4	
I0518 22:09:17.027276  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5191	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:09:17.029573  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:09:17.029620  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:09:17.044987  4008 solver.cpp:260]     Total regularization terms: 0.982278 loss+regular. : 2.39247
I0518 22:10:46.000507  4008 solver.cpp:348] Iteration 254000, Testing net (#0)
I0518 22:11:57.084209  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:12:14.324182  4008 solver.cpp:415]     Test net output #0: accuracy = 0.554099
I0518 22:12:14.324301  4008 solver.cpp:415]     Test net output #1: loss = 1.91725 (* 1 = 1.91725 loss)
I0518 22:12:14.412916  4008 solver.cpp:231] Iteration 254000, loss = 1.55618
I0518 22:12:14.413017  4008 solver.cpp:247]     Train net output #0: loss = 1.55618 (* 1 = 1.55618 loss)
I0518 22:12:14.413038  4008 sgd_solver.cpp:106] Iteration 254000, lr = 0.001
I0518 22:12:14.577782  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9104	3.125	79.7783	0	89.9168	5.46875	87.7129	0	83.6555	0	83.5756	0	75.729	0	29.0908	2.4	
I0518 22:12:14.652817  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5191	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:12:14.655221  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:12:14.655274  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:12:14.665314  4008 solver.cpp:260]     Total regularization terms: 0.982154 loss+regular. : 2.53834
I0518 22:13:51.078526  4008 solver.cpp:231] Iteration 254200, loss = 1.51394
I0518 22:13:51.078994  4008 solver.cpp:247]     Train net output #0: loss = 1.51394 (* 1 = 1.51394 loss)
I0518 22:13:51.079041  4008 sgd_solver.cpp:106] Iteration 254200, lr = 0.001
I0518 22:13:51.236984  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9304	3.125	79.9421	0	89.9347	5.46875	87.7229	0	83.6844	0	83.5858	0	75.7417	0	29.0972	2.4	
I0518 22:13:51.313392  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5625	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:13:51.318990  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:13:51.319048  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:13:51.334115  4008 solver.cpp:260]     Total regularization terms: 0.981946 loss+regular. : 2.49589
I0518 22:15:17.826130  4008 solver.cpp:231] Iteration 254400, loss = 1.50252
I0518 22:15:17.826463  4008 solver.cpp:247]     Train net output #0: loss = 1.50252 (* 1 = 1.50252 loss)
I0518 22:15:17.826493  4008 sgd_solver.cpp:106] Iteration 254400, lr = 0.001
I0518 22:15:17.986186  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.698	3.125	79.6553	0	89.935	5.46875	87.7283	0	83.6837	0	83.5962	0	75.7551	0	29.1028	2.4	
I0518 22:15:18.061184  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5625	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:15:18.063977  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:15:18.064056  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:15:18.074770  4008 solver.cpp:260]     Total regularization terms: 0.981867 loss+regular. : 2.48439
I0518 22:16:48.964031  4008 solver.cpp:231] Iteration 254600, loss = 1.58994
I0518 22:16:48.964462  4008 solver.cpp:247]     Train net output #0: loss = 1.58994 (* 1 = 1.58994 loss)
I0518 22:16:48.964483  4008 sgd_solver.cpp:106] Iteration 254600, lr = 0.001
I0518 22:16:49.125339  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7124	3.125	79.3141	0	89.9338	5.46875	87.7298	0	83.6532	0	83.6065	0	75.7683	0	29.1088	2.4	
I0518 22:16:49.199893  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5625	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:16:49.201611  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:16:49.201668  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:16:49.211515  4008 solver.cpp:260]     Total regularization terms: 0.981718 loss+regular. : 2.57166
I0518 22:18:21.132935  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:18:21.420034  4008 solver.cpp:231] Iteration 254800, loss = 1.48189
I0518 22:18:21.420135  4008 solver.cpp:247]     Train net output #0: loss = 1.48189 (* 1 = 1.48189 loss)
I0518 22:18:21.420153  4008 sgd_solver.cpp:106] Iteration 254800, lr = 0.001
I0518 22:18:21.580276  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.3967	3.125	79.6839	0	89.9446	5.46875	87.7304	0	83.6717	0	83.6167	0	75.7813	0	29.1149	2.4	
I0518 22:18:21.655256  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5625	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:18:21.657341  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:18:21.657390  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:18:21.671448  4008 solver.cpp:260]     Total regularization terms: 0.981577 loss+regular. : 2.46346
I0518 22:19:46.833549  4008 solver.cpp:348] Iteration 255000, Testing net (#0)
I0518 22:20:56.100352  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:21:14.218888  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55232
I0518 22:21:14.218981  4008 solver.cpp:415]     Test net output #1: loss = 1.92487 (* 1 = 1.92487 loss)
I0518 22:21:14.349992  4008 solver.cpp:231] Iteration 255000, loss = 1.26998
I0518 22:21:14.350091  4008 solver.cpp:247]     Train net output #0: loss = 1.26998 (* 1 = 1.26998 loss)
I0518 22:21:14.350109  4008 sgd_solver.cpp:106] Iteration 255000, lr = 0.001
I0518 22:21:14.510920  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.632	3.125	79.9287	0	89.9515	5.46875	87.7512	0	83.6833	0	83.6272	0	75.7945	0	29.1209	2.4	
I0518 22:21:14.586064  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5625	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:21:14.587805  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:21:14.587855  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:21:14.597743  4008 solver.cpp:260]     Total regularization terms: 0.981359 loss+regular. : 2.25133
I0518 22:22:37.013715  4008 solver.cpp:231] Iteration 255200, loss = 1.53551
I0518 22:22:37.014009  4008 solver.cpp:247]     Train net output #0: loss = 1.53551 (* 1 = 1.53551 loss)
I0518 22:22:37.014031  4008 sgd_solver.cpp:106] Iteration 255200, lr = 0.001
I0518 22:22:37.173388  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8817	3.125	80.1051	0	89.9557	5.46875	87.7716	0	83.6697	0	83.6376	0	75.8073	0	29.1269	2.4	
I0518 22:22:37.248147  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5625	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:22:37.250095  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:22:37.250146  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:22:37.261381  4008 solver.cpp:260]     Total regularization terms: 0.981201 loss+regular. : 2.51672
I0518 22:24:03.051203  4008 solver.cpp:231] Iteration 255400, loss = 1.29096
I0518 22:24:03.051625  4008 solver.cpp:247]     Train net output #0: loss = 1.29096 (* 1 = 1.29096 loss)
I0518 22:24:03.051656  4008 sgd_solver.cpp:106] Iteration 255400, lr = 0.001
I0518 22:24:03.211649  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9161	3.125	80.1836	0	89.9332	5.46875	87.7354	0	83.6966	0	83.6476	0	75.8202	0	29.133	2.4	
I0518 22:24:03.287256  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5625	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:24:03.289433  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:24:03.289489  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:24:03.304669  4008 solver.cpp:260]     Total regularization terms: 0.981037 loss+regular. : 2.272
I0518 22:25:22.124665  4008 solver.cpp:231] Iteration 255600, loss = 1.24247
I0518 22:25:22.124979  4008 solver.cpp:247]     Train net output #0: loss = 1.24247 (* 1 = 1.24247 loss)
I0518 22:25:22.125000  4008 sgd_solver.cpp:106] Iteration 255600, lr = 0.001
I0518 22:25:22.285080  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9161	3.125	80.0882	0	89.9706	5.46875	87.7392	0	83.6989	0	83.6579	0	75.8334	0	29.139	2.4	
I0518 22:25:22.359959  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5625	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:25:22.362186  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:25:22.362236  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:25:22.372328  4008 solver.cpp:260]     Total regularization terms: 0.980892 loss+regular. : 2.22336
I0518 22:26:49.689227  4008 solver.cpp:231] Iteration 255800, loss = 1.4999
I0518 22:26:49.689565  4008 solver.cpp:247]     Train net output #0: loss = 1.4999 (* 1 = 1.4999 loss)
I0518 22:26:49.689589  4008 sgd_solver.cpp:106] Iteration 255800, lr = 0.001
I0518 22:26:49.849678  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1571	3.125	80.1686	0	89.9655	5.46875	87.7514	0	83.7156	0	83.6678	0	75.8463	0	29.1457	2.4	
I0518 22:26:49.924924  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5625	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:26:49.926774  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:26:49.926817  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:26:49.936611  4008 solver.cpp:260]     Total regularization terms: 0.980769 loss+regular. : 2.48067
I0518 22:26:53.431251  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:28:14.729876  4008 solver.cpp:348] Iteration 256000, Testing net (#0)
I0518 22:29:24.713198  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:29:42.986124  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55376
I0518 22:29:42.986251  4008 solver.cpp:415]     Test net output #1: loss = 1.92483 (* 1 = 1.92483 loss)
I0518 22:29:43.074429  4008 solver.cpp:231] Iteration 256000, loss = 1.65569
I0518 22:29:43.074532  4008 solver.cpp:247]     Train net output #0: loss = 1.65569 (* 1 = 1.65569 loss)
I0518 22:29:43.074553  4008 sgd_solver.cpp:106] Iteration 256000, lr = 0.001
I0518 22:29:43.234190  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8185	3.125	80.0895	0	89.9887	5.46875	87.7559	0	83.7066	0	83.6778	0	75.8592	0	29.1513	2.4	
I0518 22:29:43.310503  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.5625	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:29:43.312328  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:29:43.312379  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:29:43.322432  4008 solver.cpp:260]     Total regularization terms: 0.980627 loss+regular. : 2.63632
I0518 22:31:06.873711  4008 solver.cpp:231] Iteration 256200, loss = 1.26226
I0518 22:31:06.874034  4008 solver.cpp:247]     Train net output #0: loss = 1.26226 (* 1 = 1.26226 loss)
I0518 22:31:06.874055  4008 sgd_solver.cpp:106] Iteration 256200, lr = 0.001
I0518 22:31:07.034849  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.985	3.125	80.1849	0	89.9984	5.46875	87.7811	0	83.7283	0	83.6882	0	75.8723	0	29.1571	2.4	
I0518 22:31:07.110563  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.6059	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:31:07.113075  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:31:07.113128  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:31:07.124626  4008 solver.cpp:260]     Total regularization terms: 0.980461 loss+regular. : 2.24273
I0518 22:32:33.121690  4008 solver.cpp:231] Iteration 256400, loss = 1.30228
I0518 22:32:33.122145  4008 solver.cpp:247]     Train net output #0: loss = 1.30228 (* 1 = 1.30228 loss)
I0518 22:32:33.122171  4008 sgd_solver.cpp:106] Iteration 256400, lr = 0.001
I0518 22:32:33.281653  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8989	3.125	79.8936	0	89.9936	5.46875	87.7692	0	83.7167	0	83.6983	0	75.885	0	29.1631	2.4	
I0518 22:32:33.357035  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.6059	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:32:33.359298  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:32:33.359355  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:32:33.374706  4008 solver.cpp:260]     Total regularization terms: 0.980293 loss+regular. : 2.28258
I0518 22:34:02.600499  4008 solver.cpp:231] Iteration 256600, loss = 1.5128
I0518 22:34:02.600826  4008 solver.cpp:247]     Train net output #0: loss = 1.5128 (* 1 = 1.5128 loss)
I0518 22:34:02.601016  4008 sgd_solver.cpp:106] Iteration 256600, lr = 0.001
I0518 22:34:02.760963  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9448	3.125	80.153	0	90.0136	5.46875	87.7913	0	83.7258	0	83.7083	0	75.8977	0	29.1688	2.4	
I0518 22:34:02.835583  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.6059	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:34:02.837283  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:34:02.837319  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:34:02.847344  4008 solver.cpp:260]     Total regularization terms: 0.980158 loss+regular. : 2.49296
I0518 22:35:29.732333  4008 solver.cpp:231] Iteration 256800, loss = 1.33124
I0518 22:35:29.732698  4008 solver.cpp:247]     Train net output #0: loss = 1.33124 (* 1 = 1.33124 loss)
I0518 22:35:29.732720  4008 sgd_solver.cpp:106] Iteration 256800, lr = 0.001
I0518 22:35:29.892627  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9276	3.125	80.1064	0	89.9543	5.46875	87.7946	0	83.7242	0	83.7183	0	75.9108	0	29.1741	2.4	
I0518 22:35:29.967579  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.6059	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:35:29.969084  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:35:29.969115  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:35:29.989425  4008 solver.cpp:260]     Total regularization terms: 0.980001 loss+regular. : 2.31124
I0518 22:35:35.893307  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:36:56.759868  4008 solver.cpp:348] Iteration 257000, Testing net (#0)
I0518 22:38:08.919984  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:38:25.443830  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55538
I0518 22:38:25.443928  4008 solver.cpp:415]     Test net output #1: loss = 1.91715 (* 1 = 1.91715 loss)
I0518 22:38:25.556128  4008 solver.cpp:231] Iteration 257000, loss = 1.37458
I0518 22:38:25.556222  4008 solver.cpp:247]     Train net output #0: loss = 1.37458 (* 1 = 1.37458 loss)
I0518 22:38:25.556242  4008 sgd_solver.cpp:106] Iteration 257000, lr = 0.001
I0518 22:38:25.714607  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.051	3.125	80.0599	0	89.993	5.46875	87.7972	0	83.738	0	83.7283	0	75.9241	0	29.18	2.4	
I0518 22:38:25.790843  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:38:25.793110  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:38:25.793187  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:38:25.802994  4008 solver.cpp:260]     Total regularization terms: 0.979813 loss+regular. : 2.3544
I0518 22:39:53.284838  4008 solver.cpp:231] Iteration 257200, loss = 1.48905
I0518 22:39:53.286758  4008 solver.cpp:247]     Train net output #0: loss = 1.48905 (* 1 = 1.48905 loss)
I0518 22:39:53.286790  4008 sgd_solver.cpp:106] Iteration 257200, lr = 0.001
I0518 22:39:53.445271  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.83	3.125	80.0143	0	89.9914	5.46875	87.7773	0	83.7441	0	83.7381	0	75.9364	0	29.1864	2.4	
I0518 22:39:53.520737  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:39:53.523654  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:39:53.523706  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:39:53.533543  4008 solver.cpp:260]     Total regularization terms: 0.979727 loss+regular. : 2.46877
I0518 22:41:18.464483  4008 solver.cpp:231] Iteration 257400, loss = 1.47016
I0518 22:41:18.464782  4008 solver.cpp:247]     Train net output #0: loss = 1.47016 (* 1 = 1.47016 loss)
I0518 22:41:18.464802  4008 sgd_solver.cpp:106] Iteration 257400, lr = 0.001
I0518 22:41:18.625780  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9247	3.125	79.8939	0	90.0033	5.46875	87.8056	0	83.7407	0	83.748	0	75.9493	0	29.192	2.4	
I0518 22:41:18.700471  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:41:18.702512  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:41:18.702563  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:41:18.712409  4008 solver.cpp:260]     Total regularization terms: 0.979578 loss+regular. : 2.44973
I0518 22:42:42.313261  4008 solver.cpp:231] Iteration 257600, loss = 1.36806
I0518 22:42:42.315160  4008 solver.cpp:247]     Train net output #0: loss = 1.36806 (* 1 = 1.36806 loss)
I0518 22:42:42.315191  4008 sgd_solver.cpp:106] Iteration 257600, lr = 0.001
I0518 22:42:42.474429  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9677	3.125	80.0602	0	89.9788	5.46875	87.8106	0	83.7576	0	83.7578	0	75.9622	0	29.1983	2.4	
I0518 22:42:42.550297  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:42:42.552459  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:42:42.552517  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:42:42.573617  4008 solver.cpp:260]     Total regularization terms: 0.979436 loss+regular. : 2.3475
I0518 22:44:08.919329  4008 solver.cpp:231] Iteration 257800, loss = 1.38758
I0518 22:44:08.919595  4008 solver.cpp:247]     Train net output #0: loss = 1.38758 (* 1 = 1.38758 loss)
I0518 22:44:08.919615  4008 sgd_solver.cpp:106] Iteration 257800, lr = 0.001
I0518 22:44:09.079705  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8845	3.125	79.9714	0	89.9646	5.46875	87.8111	0	83.752	0	83.7677	0	75.9749	0	29.2041	2.4	
I0518 22:44:09.154278  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:44:09.156455  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:44:09.156503  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:44:09.166640  4008 solver.cpp:260]     Total regularization terms: 0.979326 loss+regular. : 2.3669
I0518 22:44:17.257264  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:45:35.046093  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_258000.caffemodel
I0518 22:50:04.658002  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_258000.solverstate
I0518 22:50:05.553258  4008 solver.cpp:348] Iteration 258000, Testing net (#0)
I0518 22:51:22.142940  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:51:37.497656  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55556
I0518 22:51:37.497788  4008 solver.cpp:415]     Test net output #1: loss = 1.91775 (* 1 = 1.91775 loss)
I0518 22:51:37.586756  4008 solver.cpp:231] Iteration 258000, loss = 1.3964
I0518 22:51:37.586911  4008 solver.cpp:247]     Train net output #0: loss = 1.3964 (* 1 = 1.3964 loss)
I0518 22:51:37.586935  4008 sgd_solver.cpp:106] Iteration 258000, lr = 0.001
I0518 22:51:37.746130  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8989	3.125	80.2497	0	90.0166	5.46875	87.8141	0	83.7735	0	83.7774	0	75.9873	0	29.2096	2.4	
I0518 22:51:37.748299  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:51:37.750772  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:51:37.750849  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:51:37.764734  4008 solver.cpp:260]     Total regularization terms: 0.979198 loss+regular. : 2.3756
I0518 22:53:06.692087  4008 solver.cpp:231] Iteration 258200, loss = 1.53975
I0518 22:53:06.692579  4008 solver.cpp:247]     Train net output #0: loss = 1.53975 (* 1 = 1.53975 loss)
I0518 22:53:06.692606  4008 sgd_solver.cpp:106] Iteration 258200, lr = 0.001
I0518 22:53:06.851898  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8013	3.125	80.3516	0	90.0009	5.46875	87.8049	0	83.787	0	83.7873	0	75.9997	0	29.2148	2.4	
I0518 22:53:06.927464  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:53:06.929983  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:53:06.930035  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:53:06.940102  4008 solver.cpp:260]     Total regularization terms: 0.978986 loss+regular. : 2.51873
I0518 22:54:39.253713  4008 solver.cpp:231] Iteration 258400, loss = 1.55643
I0518 22:54:39.253983  4008 solver.cpp:247]     Train net output #0: loss = 1.55643 (* 1 = 1.55643 loss)
I0518 22:54:39.254007  4008 sgd_solver.cpp:106] Iteration 258400, lr = 0.001
I0518 22:54:39.415441  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9276	3.125	80.1904	0	90.0212	5.46875	87.8451	0	83.8051	0	83.7976	0	76.0125	0	29.2209	2.4	
I0518 22:54:39.491101  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:54:39.494153  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:54:39.494204  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:54:39.504077  4008 solver.cpp:260]     Total regularization terms: 0.978839 loss+regular. : 2.53526
I0518 22:56:14.189306  4008 solver.cpp:231] Iteration 258600, loss = 1.35104
I0518 22:56:14.193691  4008 solver.cpp:247]     Train net output #0: loss = 1.35104 (* 1 = 1.35104 loss)
I0518 22:56:14.193738  4008 sgd_solver.cpp:106] Iteration 258600, lr = 0.001
I0518 22:56:14.350385  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.853	3.125	80.1442	0	90.0328	5.46875	87.8469	0	83.8071	0	83.8073	0	76.0255	0	29.2263	2.4	
I0518 22:56:14.426519  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:56:14.429189  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:56:14.429255  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:56:14.439347  4008 solver.cpp:260]     Total regularization terms: 0.978685 loss+regular. : 2.32973
I0518 22:57:40.540145  4008 solver.cpp:231] Iteration 258800, loss = 1.43205
I0518 22:57:40.540689  4008 solver.cpp:247]     Train net output #0: loss = 1.43205 (* 1 = 1.43205 loss)
I0518 22:57:40.540730  4008 sgd_solver.cpp:106] Iteration 258800, lr = 0.001
I0518 22:57:40.699379  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6951	3.125	80.0788	0	90.0345	5.46875	87.8608	0	83.8047	0	83.8172	0	76.0379	0	29.2323	2.4	
I0518 22:57:40.774096  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 22:57:40.775774  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 22:57:40.775817  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 22:57:40.785725  4008 solver.cpp:260]     Total regularization terms: 0.978609 loss+regular. : 2.41066
I0518 22:57:54.827456  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 22:59:22.101989  4008 solver.cpp:348] Iteration 259000, Testing net (#0)
I0518 23:00:31.908820  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:00:46.025916  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55436
I0518 23:00:46.026034  4008 solver.cpp:415]     Test net output #1: loss = 1.92048 (* 1 = 1.92048 loss)
I0518 23:00:46.117178  4008 solver.cpp:231] Iteration 259000, loss = 1.32121
I0518 23:00:46.117269  4008 solver.cpp:247]     Train net output #0: loss = 1.32121 (* 1 = 1.32121 loss)
I0518 23:00:46.117287  4008 sgd_solver.cpp:106] Iteration 259000, lr = 0.001
I0518 23:00:46.284440  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7812	3.125	80.0576	0	90.0145	5.46875	87.8383	0	83.8207	0	83.8271	0	76.0503	0	29.238	2.4	
I0518 23:00:46.359321  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:00:46.360958  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:00:46.361001  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:00:46.370805  4008 solver.cpp:260]     Total regularization terms: 0.978443 loss+regular. : 2.29966
I0518 23:02:11.074156  4008 solver.cpp:231] Iteration 259200, loss = 1.38149
I0518 23:02:11.074458  4008 solver.cpp:247]     Train net output #0: loss = 1.38149 (* 1 = 1.38149 loss)
I0518 23:02:11.074481  4008 sgd_solver.cpp:106] Iteration 259200, lr = 0.001
I0518 23:02:11.235117  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8185	3.125	79.8063	0	90.016	5.46875	87.8406	0	83.7986	0	83.837	0	76.0632	0	29.2439	2.4	
I0518 23:02:11.310642  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:02:11.313529  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:02:11.313592  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:02:11.323564  4008 solver.cpp:260]     Total regularization terms: 0.978306 loss+regular. : 2.3598
I0518 23:03:55.045841  4008 solver.cpp:231] Iteration 259400, loss = 1.43195
I0518 23:03:55.046099  4008 solver.cpp:247]     Train net output #0: loss = 1.43195 (* 1 = 1.43195 loss)
I0518 23:03:55.046123  4008 sgd_solver.cpp:106] Iteration 259400, lr = 0.001
I0518 23:03:55.206987  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7152	3.125	80.2178	0	90.042	5.46875	87.8522	0	83.8309	0	83.8469	0	76.0757	0	29.2501	2.4	
I0518 23:03:55.282806  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:03:55.285810  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:03:55.285862  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:03:55.295863  4008 solver.cpp:260]     Total regularization terms: 0.978215 loss+regular. : 2.41017
I0518 23:05:33.349766  4008 solver.cpp:231] Iteration 259600, loss = 1.35492
I0518 23:05:33.350134  4008 solver.cpp:247]     Train net output #0: loss = 1.35492 (* 1 = 1.35492 loss)
I0518 23:05:33.350169  4008 sgd_solver.cpp:106] Iteration 259600, lr = 0.001
I0518 23:05:33.511071  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.962	3.125	79.8656	0	90.0111	5.46875	87.8428	0	83.8288	0	83.8565	0	76.0881	0	29.2559	2.4	
I0518 23:05:33.585899  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:05:33.587599  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:05:33.587644  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:05:33.597587  4008 solver.cpp:260]     Total regularization terms: 0.978038 loss+regular. : 2.33296
I0518 23:07:10.086508  4008 solver.cpp:231] Iteration 259800, loss = 1.35784
I0518 23:07:10.086964  4008 solver.cpp:247]     Train net output #0: loss = 1.35784 (* 1 = 1.35784 loss)
I0518 23:07:10.086989  4008 sgd_solver.cpp:106] Iteration 259800, lr = 0.001
I0518 23:07:10.247294  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9046	3.125	80.1888	0	90.0137	5.46875	87.8718	0	83.8492	0	83.8663	0	76.1006	0	29.2621	2.4	
I0518 23:07:10.322417  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:07:10.324524  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:07:10.324570  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:07:10.334434  4008 solver.cpp:260]     Total regularization terms: 0.977903 loss+regular. : 2.33574
I0518 23:07:28.114262  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:08:43.243047  4008 solver.cpp:348] Iteration 260000, Testing net (#0)
I0518 23:09:57.296309  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:10:10.744108  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5545
I0518 23:10:10.744206  4008 solver.cpp:415]     Test net output #1: loss = 1.92095 (* 1 = 1.92095 loss)
I0518 23:10:10.834946  4008 solver.cpp:231] Iteration 260000, loss = 1.35429
I0518 23:10:10.835032  4008 solver.cpp:247]     Train net output #0: loss = 1.35429 (* 1 = 1.35429 loss)
I0518 23:10:10.835048  4008 sgd_solver.cpp:106] Iteration 260000, lr = 0.001
I0518 23:10:11.003303  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8243	3.125	79.9215	0	90.0029	5.46875	87.8706	0	83.8711	0	83.8767	0	76.1133	0	29.2684	2.4	
I0518 23:10:11.078014  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:10:11.079884  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:10:11.079931  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:10:11.089833  4008 solver.cpp:260]     Total regularization terms: 0.977778 loss+regular. : 2.33207
I0518 23:11:41.482271  4008 solver.cpp:231] Iteration 260200, loss = 1.08577
I0518 23:11:41.483258  4008 solver.cpp:247]     Train net output #0: loss = 1.08577 (* 1 = 1.08577 loss)
I0518 23:11:41.483286  4008 sgd_solver.cpp:106] Iteration 260200, lr = 0.001
I0518 23:11:41.642263  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7066	3.125	80.0026	0	90.0474	5.46875	87.8848	0	83.8793	0	83.8866	0	76.1258	0	29.2742	2.4	
I0518 23:11:41.717157  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:11:41.719565  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:11:41.719629  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:11:41.729562  4008 solver.cpp:260]     Total regularization terms: 0.977588 loss+regular. : 2.06336
I0518 23:13:08.877931  4008 solver.cpp:231] Iteration 260400, loss = 1.32409
I0518 23:13:08.878330  4008 solver.cpp:247]     Train net output #0: loss = 1.32409 (* 1 = 1.32409 loss)
I0518 23:13:08.878446  4008 sgd_solver.cpp:106] Iteration 260400, lr = 0.001
I0518 23:13:09.037451  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.807	3.125	80.195	0	90.0475	5.46875	87.8832	0	83.856	0	83.8966	0	76.1378	0	29.2801	2.4	
I0518 23:13:09.112058  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.64931	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:13:09.117619  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:13:09.117715  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:13:09.127673  4008 solver.cpp:260]     Total regularization terms: 0.977416 loss+regular. : 2.30151
I0518 23:14:41.674434  4008 solver.cpp:231] Iteration 260600, loss = 1.28448
I0518 23:14:41.675117  4008 solver.cpp:247]     Train net output #0: loss = 1.28448 (* 1 = 1.28448 loss)
I0518 23:14:41.675138  4008 sgd_solver.cpp:106] Iteration 260600, lr = 0.001
I0518 23:14:41.838512  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8788	3.125	80.057	0	90.0429	5.46875	87.8685	0	83.849	0	83.9064	0	76.1503	0	29.2863	2.4	
I0518 23:14:41.914140  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:14:41.916405  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:14:41.916461  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:14:41.926811  4008 solver.cpp:260]     Total regularization terms: 0.977327 loss+regular. : 2.2618
I0518 23:16:12.727563  4008 solver.cpp:231] Iteration 260800, loss = 1.42655
I0518 23:16:12.727812  4008 solver.cpp:247]     Train net output #0: loss = 1.42655 (* 1 = 1.42655 loss)
I0518 23:16:12.727829  4008 sgd_solver.cpp:106] Iteration 260800, lr = 0.001
I0518 23:16:12.888423  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.853	3.125	80.1136	0	90.0802	5.46875	87.8866	0	83.8734	0	83.9161	0	76.1627	0	29.2923	2.4	
I0518 23:16:12.963650  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:16:12.965909  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:16:12.965973  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:16:12.981359  4008 solver.cpp:260]     Total regularization terms: 0.977152 loss+regular. : 2.40371
I0518 23:16:30.920310  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:17:42.489063  4008 solver.cpp:348] Iteration 261000, Testing net (#0)
I0518 23:18:56.731092  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:19:10.738190  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55442
I0518 23:19:10.738272  4008 solver.cpp:415]     Test net output #1: loss = 1.91878 (* 1 = 1.91878 loss)
I0518 23:19:10.825264  4008 solver.cpp:231] Iteration 261000, loss = 1.19121
I0518 23:19:10.825346  4008 solver.cpp:247]     Train net output #0: loss = 1.19121 (* 1 = 1.19121 loss)
I0518 23:19:10.825366  4008 sgd_solver.cpp:106] Iteration 261000, lr = 0.001
I0518 23:19:10.990094  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9505	3.125	80.1797	0	90.0638	5.46875	87.8979	0	83.8815	0	83.9258	0	76.1751	0	29.2977	2.4	
I0518 23:19:11.066835  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:19:11.069100  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:19:11.069175  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:19:11.079229  4008 solver.cpp:260]     Total regularization terms: 0.977057 loss+regular. : 2.16827
I0518 23:20:36.571358  4008 solver.cpp:231] Iteration 261200, loss = 1.40533
I0518 23:20:36.571686  4008 solver.cpp:247]     Train net output #0: loss = 1.40533 (* 1 = 1.40533 loss)
I0518 23:20:36.571710  4008 sgd_solver.cpp:106] Iteration 261200, lr = 0.001
I0518 23:20:36.731986  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0079	3.125	80.1523	0	90.0479	5.46875	87.873	0	83.8912	0	83.9356	0	76.1879	0	29.3037	2.4	
I0518 23:20:36.807819  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:20:36.811162  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:20:36.811219  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:20:36.822064  4008 solver.cpp:260]     Total regularization terms: 0.976878 loss+regular. : 2.3822
I0518 23:22:11.748565  4008 solver.cpp:231] Iteration 261400, loss = 1.5183
I0518 23:22:11.749047  4008 solver.cpp:247]     Train net output #0: loss = 1.5183 (* 1 = 1.5183 loss)
I0518 23:22:11.749081  4008 sgd_solver.cpp:106] Iteration 261400, lr = 0.001
I0518 23:22:11.907910  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1055	3.125	80.2549	0	90.1097	5.46875	87.9364	0	83.9152	0	83.945	0	76.2003	0	29.3095	2.4	
I0518 23:22:11.983438  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:22:11.985502  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:22:11.985569  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:22:12.003741  4008 solver.cpp:260]     Total regularization terms: 0.976689 loss+regular. : 2.49499
I0518 23:23:39.055274  4008 solver.cpp:231] Iteration 261600, loss = 1.47746
I0518 23:23:39.055651  4008 solver.cpp:247]     Train net output #0: loss = 1.47746 (* 1 = 1.47746 loss)
I0518 23:23:39.055671  4008 sgd_solver.cpp:106] Iteration 261600, lr = 0.001
I0518 23:23:39.216219  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0251	3.125	80.0436	0	90.0933	5.46875	87.9196	0	83.9161	0	83.9546	0	76.213	0	29.3151	2.4	
I0518 23:23:39.291725  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:23:39.293660  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:23:39.293683  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:23:39.307284  4008 solver.cpp:260]     Total regularization terms: 0.976593 loss+regular. : 2.45405
I0518 23:25:14.300207  4008 solver.cpp:231] Iteration 261800, loss = 1.42278
I0518 23:25:14.300518  4008 solver.cpp:247]     Train net output #0: loss = 1.42278 (* 1 = 1.42278 loss)
I0518 23:25:14.300539  4008 sgd_solver.cpp:106] Iteration 261800, lr = 0.001
I0518 23:25:14.461766  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8644	3.125	80.1569	0	90.0877	5.46875	87.9251	0	83.9292	0	83.9643	0	76.2251	0	29.321	2.4	
I0518 23:25:14.536530  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:25:14.538651  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:25:14.538704  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:25:14.548703  4008 solver.cpp:260]     Total regularization terms: 0.97642 loss+regular. : 2.3992
I0518 23:25:36.172935  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:26:39.412880  4008 solver.cpp:348] Iteration 262000, Testing net (#0)
I0518 23:27:52.024441  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:28:04.123774  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55298
I0518 23:28:04.123862  4008 solver.cpp:415]     Test net output #1: loss = 1.9247 (* 1 = 1.9247 loss)
I0518 23:28:04.213080  4008 solver.cpp:231] Iteration 262000, loss = 1.4343
I0518 23:28:04.213161  4008 solver.cpp:247]     Train net output #0: loss = 1.4343 (* 1 = 1.4343 loss)
I0518 23:28:04.213181  4008 sgd_solver.cpp:106] Iteration 262000, lr = 0.001
I0518 23:28:04.372973  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0395	3.125	80.1276	0	90.0677	5.46875	87.9191	0	83.9215	0	83.974	0	76.2375	0	29.3261	2.4	
I0518 23:28:04.448540  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:28:04.452085  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:28:04.452159  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:28:04.465016  4008 solver.cpp:260]     Total regularization terms: 0.976262 loss+regular. : 2.41056
I0518 23:29:24.152871  4008 solver.cpp:231] Iteration 262200, loss = 1.37194
I0518 23:29:24.153326  4008 solver.cpp:247]     Train net output #0: loss = 1.37194 (* 1 = 1.37194 loss)
I0518 23:29:24.153350  4008 sgd_solver.cpp:106] Iteration 262200, lr = 0.001
I0518 23:29:24.313277  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0481	3.125	79.9717	0	90.0547	5.46875	87.9077	0	83.9394	0	83.9836	0	76.2499	0	29.3312	2.4	
I0518 23:29:24.388483  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:29:24.390664  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:29:24.390713  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:29:24.400554  4008 solver.cpp:260]     Total regularization terms: 0.976175 loss+regular. : 2.34811
I0518 23:30:43.960036  4008 solver.cpp:231] Iteration 262400, loss = 1.39788
I0518 23:30:43.961650  4008 solver.cpp:247]     Train net output #0: loss = 1.39788 (* 1 = 1.39788 loss)
I0518 23:30:43.961680  4008 sgd_solver.cpp:106] Iteration 262400, lr = 0.001
I0518 23:30:44.119946  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3781	3.125	80.1738	0	90.1083	5.46875	87.9395	0	83.9227	0	83.9931	0	76.2618	0	29.3371	2.4	
I0518 23:30:44.195289  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:30:44.198426  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:30:44.198477  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:30:44.228097  4008 solver.cpp:260]     Total regularization terms: 0.976014 loss+regular. : 2.3739
I0518 23:32:13.673804  4008 solver.cpp:231] Iteration 262600, loss = 1.43922
I0518 23:32:13.674160  4008 solver.cpp:247]     Train net output #0: loss = 1.43922 (* 1 = 1.43922 loss)
I0518 23:32:13.674180  4008 sgd_solver.cpp:106] Iteration 262600, lr = 0.001
I0518 23:32:13.835080  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4584	3.125	80.1634	0	90.131	5.46875	87.9523	0	83.9473	0	84.0026	0	76.2741	0	29.3426	2.4	
I0518 23:32:13.909710  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:32:13.911949  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:32:13.911996  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:32:13.921821  4008 solver.cpp:260]     Total regularization terms: 0.975834 loss+regular. : 2.41505
I0518 23:33:45.140877  4008 solver.cpp:231] Iteration 262800, loss = 1.39884
I0518 23:33:45.141154  4008 solver.cpp:247]     Train net output #0: loss = 1.39884 (* 1 = 1.39884 loss)
I0518 23:33:45.141176  4008 sgd_solver.cpp:106] Iteration 262800, lr = 0.001
I0518 23:33:45.300446  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3494	3.125	80.1748	0	90.1307	5.46875	87.9749	0	83.964	0	84.0123	0	76.2864	0	29.3488	2.4	
I0518 23:33:45.375663  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:33:45.378618  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:33:45.378666  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:33:45.388460  4008 solver.cpp:260]     Total regularization terms: 0.975657 loss+regular. : 2.3745
I0518 23:34:10.483465  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:35:07.790015  4008 solver.cpp:348] Iteration 263000, Testing net (#0)
I0518 23:36:18.323211  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:36:29.644273  4008 solver.cpp:415]     Test net output #0: accuracy = 0.554459
I0518 23:36:29.644381  4008 solver.cpp:415]     Test net output #1: loss = 1.91438 (* 1 = 1.91438 loss)
I0518 23:36:29.797389  4008 solver.cpp:231] Iteration 263000, loss = 1.41488
I0518 23:36:29.797477  4008 solver.cpp:247]     Train net output #0: loss = 1.41488 (* 1 = 1.41488 loss)
I0518 23:36:29.797492  4008 sgd_solver.cpp:106] Iteration 263000, lr = 0.001
I0518 23:36:29.964217  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3092	3.125	80.3057	0	90.1384	5.46875	87.9743	0	83.9658	0	84.0221	0	76.2988	0	29.3546	2.4	
I0518 23:36:30.038916  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:36:30.040560  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:36:30.040597  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:36:30.051868  4008 solver.cpp:260]     Total regularization terms: 0.975507 loss+regular. : 2.39038
I0518 23:37:50.782910  4008 solver.cpp:231] Iteration 263200, loss = 1.58785
I0518 23:37:50.783306  4008 solver.cpp:247]     Train net output #0: loss = 1.58785 (* 1 = 1.58785 loss)
I0518 23:37:50.783337  4008 sgd_solver.cpp:106] Iteration 263200, lr = 0.001
I0518 23:37:50.943032  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1026	3.125	80.2406	0	90.1122	5.46875	87.9765	0	83.9735	0	84.0313	0	76.3112	0	29.3606	2.4	
I0518 23:37:51.018501  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:37:51.021064  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:37:51.021116  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:37:51.036509  4008 solver.cpp:260]     Total regularization terms: 0.975339 loss+regular. : 2.56319
I0518 23:39:19.686959  4008 solver.cpp:231] Iteration 263400, loss = 1.44129
I0518 23:39:19.693156  4008 solver.cpp:247]     Train net output #0: loss = 1.44129 (* 1 = 1.44129 loss)
I0518 23:39:19.693192  4008 sgd_solver.cpp:106] Iteration 263400, lr = 0.001
I0518 23:39:19.848603  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9534	3.125	80.2305	0	90.1012	5.46875	87.9688	0	84.0013	0	84.0409	0	76.3233	0	29.3655	2.4	
I0518 23:39:19.924032  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:39:19.926803  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:39:19.926853  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:39:19.936746  4008 solver.cpp:260]     Total regularization terms: 0.975221 loss+regular. : 2.41651
I0518 23:41:00.904716  4008 solver.cpp:231] Iteration 263600, loss = 1.48344
I0518 23:41:00.905015  4008 solver.cpp:247]     Train net output #0: loss = 1.48344 (* 1 = 1.48344 loss)
I0518 23:41:00.905036  4008 sgd_solver.cpp:106] Iteration 263600, lr = 0.001
I0518 23:41:01.065975  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0137	3.125	80.1549	0	90.1194	5.46875	87.9815	0	83.9737	0	84.0504	0	76.3346	0	29.3715	2.4	
I0518 23:41:01.141202  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:41:01.143882  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:41:01.143934  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:41:01.153792  4008 solver.cpp:260]     Total regularization terms: 0.975107 loss+regular. : 2.45854
I0518 23:42:33.442780  4008 solver.cpp:231] Iteration 263800, loss = 1.28606
I0518 23:42:33.443236  4008 solver.cpp:247]     Train net output #0: loss = 1.28606 (* 1 = 1.28606 loss)
I0518 23:42:33.443265  4008 sgd_solver.cpp:106] Iteration 263800, lr = 0.001
I0518 23:42:33.602716  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9477	3.125	80.0518	0	90.103	5.46875	87.9682	0	83.9875	0	84.0599	0	76.3474	0	29.3769	2.4	
I0518 23:42:33.679055  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:42:33.682749  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:42:33.682812  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:42:33.692826  4008 solver.cpp:260]     Total regularization terms: 0.974992 loss+regular. : 2.26105
I0518 23:43:00.037982  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:44:03.789762  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_264000.caffemodel
I0518 23:47:11.591565  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_264000.solverstate
I0518 23:47:12.419564  4008 solver.cpp:348] Iteration 264000, Testing net (#0)
I0518 23:48:28.576544  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:48:39.413024  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55474
I0518 23:48:39.413139  4008 solver.cpp:415]     Test net output #1: loss = 1.9194 (* 1 = 1.9194 loss)
I0518 23:48:39.500916  4008 solver.cpp:231] Iteration 264000, loss = 1.35643
I0518 23:48:39.501003  4008 solver.cpp:247]     Train net output #0: loss = 1.35643 (* 1 = 1.35643 loss)
I0518 23:48:39.501024  4008 sgd_solver.cpp:106] Iteration 264000, lr = 0.001
I0518 23:48:39.659348  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1887	3.125	79.9541	0	90.1045	5.46875	87.9749	0	83.9769	0	84.0695	0	76.3597	0	29.382	2.4	
I0518 23:48:39.660976  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:48:39.662945  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:48:39.662991  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:48:39.676640  4008 solver.cpp:260]     Total regularization terms: 0.974859 loss+regular. : 2.33129
I0518 23:50:06.085608  4008 solver.cpp:231] Iteration 264200, loss = 1.53096
I0518 23:50:06.087482  4008 solver.cpp:247]     Train net output #0: loss = 1.53096 (* 1 = 1.53096 loss)
I0518 23:50:06.087514  4008 sgd_solver.cpp:106] Iteration 264200, lr = 0.001
I0518 23:50:06.247293  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0452	3.125	79.9577	0	90.0922	5.46875	87.9854	0	83.9792	0	84.0789	0	76.3718	0	29.3876	2.4	
I0518 23:50:06.322314  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.69271	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:50:06.325016  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:50:06.325067  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:50:06.335482  4008 solver.cpp:260]     Total regularization terms: 0.974705 loss+regular. : 2.50566
I0518 23:51:33.893286  4008 solver.cpp:231] Iteration 264400, loss = 1.32073
I0518 23:51:33.893723  4008 solver.cpp:247]     Train net output #0: loss = 1.32073 (* 1 = 1.32073 loss)
I0518 23:51:33.893754  4008 sgd_solver.cpp:106] Iteration 264400, lr = 0.001
I0518 23:51:34.052570  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9936	3.125	80.1042	0	90.0881	5.46875	87.9587	0	83.9835	0	84.0882	0	76.384	0	29.3936	2.4	
I0518 23:51:34.128047  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:51:34.131037  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:51:34.131086  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:51:34.141032  4008 solver.cpp:260]     Total regularization terms: 0.974592 loss+regular. : 2.29532
I0518 23:53:02.036945  4008 solver.cpp:231] Iteration 264600, loss = 1.52337
I0518 23:53:02.037325  4008 solver.cpp:247]     Train net output #0: loss = 1.52337 (* 1 = 1.52337 loss)
I0518 23:53:02.037360  4008 sgd_solver.cpp:106] Iteration 264600, lr = 0.001
I0518 23:53:02.197916  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9534	3.125	80.3145	0	90.1286	5.46875	87.9785	0	84.0077	0	84.0976	0	76.397	0	29.3995	2.4	
I0518 23:53:02.272794  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:53:02.274655  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:53:02.274705  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:53:02.285173  4008 solver.cpp:260]     Total regularization terms: 0.974371 loss+regular. : 2.49774
I0518 23:54:32.323555  4008 solver.cpp:231] Iteration 264800, loss = 1.44246
I0518 23:54:32.323923  4008 solver.cpp:247]     Train net output #0: loss = 1.44246 (* 1 = 1.44246 loss)
I0518 23:54:32.323952  4008 sgd_solver.cpp:106] Iteration 264800, lr = 0.001
I0518 23:54:32.483237  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0481	3.125	80.167	0	90.1226	5.46875	87.9919	0	84.0131	0	84.1071	0	76.4089	0	29.4051	2.4	
I0518 23:54:32.558465  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:54:32.561128  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:54:32.561178  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:54:32.571238  4008 solver.cpp:260]     Total regularization terms: 0.974247 loss+regular. : 2.41671
I0518 23:55:04.454524  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:56:04.258316  4008 solver.cpp:348] Iteration 265000, Testing net (#0)
I0518 23:57:13.556102  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0518 23:57:25.078572  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55228
I0518 23:57:25.078663  4008 solver.cpp:415]     Test net output #1: loss = 1.92455 (* 1 = 1.92455 loss)
I0518 23:57:25.171553  4008 solver.cpp:231] Iteration 265000, loss = 1.3389
I0518 23:57:25.171640  4008 solver.cpp:247]     Train net output #0: loss = 1.3389 (* 1 = 1.3389 loss)
I0518 23:57:25.171661  4008 sgd_solver.cpp:106] Iteration 265000, lr = 0.001
I0518 23:57:25.331820  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1973	3.125	79.9544	0	90.1157	5.46875	87.9607	0	83.9912	0	84.1164	0	76.4209	0	29.4105	2.4	
I0518 23:57:25.407748  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:57:25.410584  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:57:25.410667  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:57:25.420688  4008 solver.cpp:260]     Total regularization terms: 0.974181 loss+regular. : 2.31308
I0518 23:58:54.900336  4008 solver.cpp:231] Iteration 265200, loss = 1.50439
I0518 23:58:54.900651  4008 solver.cpp:247]     Train net output #0: loss = 1.50439 (* 1 = 1.50439 loss)
I0518 23:58:54.900672  4008 sgd_solver.cpp:106] Iteration 265200, lr = 0.001
I0518 23:58:55.060770  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1916	3.125	80.2412	0	90.1547	5.46875	88.0056	0	84.0174	0	84.1258	0	76.433	0	29.4164	2.4	
I0518 23:58:55.136148  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0518 23:58:55.139199  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0518 23:58:55.139252  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0518 23:58:55.149315  4008 solver.cpp:260]     Total regularization terms: 0.973962 loss+regular. : 2.47836
I0519 00:00:23.821597  4008 solver.cpp:231] Iteration 265400, loss = 1.28758
I0519 00:00:23.822010  4008 solver.cpp:247]     Train net output #0: loss = 1.28758 (* 1 = 1.28758 loss)
I0519 00:00:23.822028  4008 sgd_solver.cpp:106] Iteration 265400, lr = 0.001
I0519 00:00:23.984573  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2346	3.125	80.3535	0	90.1512	5.46875	87.9887	0	84.0332	0	84.1351	0	76.445	0	29.4227	2.4	
I0519 00:00:24.058997  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:00:24.061089  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:00:24.061118  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:00:24.070942  4008 solver.cpp:260]     Total regularization terms: 0.973857 loss+regular. : 2.26144
I0519 00:01:55.681478  4008 solver.cpp:231] Iteration 265600, loss = 1.57135
I0519 00:01:55.681771  4008 solver.cpp:247]     Train net output #0: loss = 1.57135 (* 1 = 1.57135 loss)
I0519 00:01:55.681800  4008 sgd_solver.cpp:106] Iteration 265600, lr = 0.001
I0519 00:01:55.842238  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0251	3.125	80.3044	0	90.1441	5.46875	87.9923	0	84.0325	0	84.1448	0	76.457	0	29.4285	2.4	
I0519 00:01:55.917614  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:01:55.920579  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:01:55.920629  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:01:55.930503  4008 solver.cpp:260]     Total regularization terms: 0.97376 loss+regular. : 2.54511
I0519 00:03:21.546759  4008 solver.cpp:231] Iteration 265800, loss = 1.37819
I0519 00:03:21.547516  4008 solver.cpp:247]     Train net output #0: loss = 1.37819 (* 1 = 1.37819 loss)
I0519 00:03:21.547544  4008 sgd_solver.cpp:106] Iteration 265800, lr = 0.001
I0519 00:03:21.706060  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8472	3.125	80.0811	0	90.1317	5.46875	88.0091	0	84.04	0	84.1544	0	76.4695	0	29.4344	2.4	
I0519 00:03:21.781539  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:03:21.784591  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:03:21.784639  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:03:21.794440  4008 solver.cpp:260]     Total regularization terms: 0.973634 loss+regular. : 2.35182
I0519 00:03:56.520277  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:04:51.082581  4008 solver.cpp:348] Iteration 266000, Testing net (#0)
I0519 00:06:12.248245  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:06:22.951030  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55266
I0519 00:06:22.951117  4008 solver.cpp:415]     Test net output #1: loss = 1.9206 (* 1 = 1.9206 loss)
I0519 00:06:23.041316  4008 solver.cpp:231] Iteration 266000, loss = 1.4798
I0519 00:06:23.041393  4008 solver.cpp:247]     Train net output #0: loss = 1.4798 (* 1 = 1.4798 loss)
I0519 00:06:23.041412  4008 sgd_solver.cpp:106] Iteration 266000, lr = 0.001
I0519 00:06:23.200737  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0481	3.125	80.2682	0	90.1601	5.46875	88.0338	0	84.0278	0	84.1638	0	76.4817	0	29.4408	2.4	
I0519 00:06:23.276182  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:06:23.279041  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:06:23.279090  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:06:23.288947  4008 solver.cpp:260]     Total regularization terms: 0.973478 loss+regular. : 2.45328
I0519 00:07:48.714511  4008 solver.cpp:231] Iteration 266200, loss = 1.27991
I0519 00:07:48.714892  4008 solver.cpp:247]     Train net output #0: loss = 1.27991 (* 1 = 1.27991 loss)
I0519 00:07:48.714917  4008 sgd_solver.cpp:106] Iteration 266200, lr = 0.001
I0519 00:07:48.873942  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.16	3.125	80.1393	0	90.1592	5.46875	88.0377	0	84.0538	0	84.173	0	76.4938	0	29.4471	2.4	
I0519 00:07:48.949230  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:07:48.952076  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:07:48.952179  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:07:48.962560  4008 solver.cpp:260]     Total regularization terms: 0.973364 loss+regular. : 2.25327
I0519 00:09:14.028447  4008 solver.cpp:231] Iteration 266400, loss = 1.34253
I0519 00:09:14.028849  4008 solver.cpp:247]     Train net output #0: loss = 1.34253 (* 1 = 1.34253 loss)
I0519 00:09:14.028879  4008 sgd_solver.cpp:106] Iteration 266400, lr = 0.001
I0519 00:09:14.188303  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.358	3.125	80.4144	0	90.1869	5.46875	88.0413	0	84.0637	0	84.1825	0	76.5058	0	29.4523	2.4	
I0519 00:09:14.263730  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:09:14.265806  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:09:14.265858  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:09:14.275861  4008 solver.cpp:260]     Total regularization terms: 0.973193 loss+regular. : 2.31573
I0519 00:10:40.948570  4008 solver.cpp:231] Iteration 266600, loss = 1.44062
I0519 00:10:40.948961  4008 solver.cpp:247]     Train net output #0: loss = 1.44062 (* 1 = 1.44062 loss)
I0519 00:10:40.948985  4008 sgd_solver.cpp:106] Iteration 266600, lr = 0.001
I0519 00:10:41.108414  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.873	3.125	80.1087	0	90.1759	5.46875	88.0403	0	84.0606	0	84.1916	0	76.5176	0	29.4586	2.4	
I0519 00:10:41.184671  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:10:41.187039  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:10:41.187095  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:10:41.216568  4008 solver.cpp:260]     Total regularization terms: 0.973148 loss+regular. : 2.41376
I0519 00:12:07.353991  4008 solver.cpp:231] Iteration 266800, loss = 1.32977
I0519 00:12:07.357667  4008 solver.cpp:247]     Train net output #0: loss = 1.32977 (* 1 = 1.32977 loss)
I0519 00:12:07.357695  4008 sgd_solver.cpp:106] Iteration 266800, lr = 0.001
I0519 00:12:07.515738  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0022	3.125	80.151	0	90.1858	5.46875	88.0565	0	84.0843	0	84.2007	0	76.5295	0	29.4638	2.4	
I0519 00:12:07.590596  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:12:07.592437  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:12:07.592475  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:12:07.602406  4008 solver.cpp:260]     Total regularization terms: 0.972994 loss+regular. : 2.30277
I0519 00:12:41.951441  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:13:28.630080  4008 solver.cpp:348] Iteration 267000, Testing net (#0)
I0519 00:15:09.267925  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:15:19.188196  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55408
I0519 00:15:19.188314  4008 solver.cpp:415]     Test net output #1: loss = 1.91327 (* 1 = 1.91327 loss)
I0519 00:15:19.276291  4008 solver.cpp:231] Iteration 267000, loss = 1.19453
I0519 00:15:19.276425  4008 solver.cpp:247]     Train net output #0: loss = 1.19453 (* 1 = 1.19453 loss)
I0519 00:15:19.276445  4008 sgd_solver.cpp:106] Iteration 267000, lr = 0.001
I0519 00:15:19.441748  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3724	3.125	80.2581	0	90.2079	5.46875	88.0871	0	84.063	0	84.2099	0	76.5411	0	29.47	2.4	
I0519 00:15:19.516926  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:15:19.519119  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:15:19.519173  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:15:19.529021  4008 solver.cpp:260]     Total regularization terms: 0.972854 loss+regular. : 2.16738
I0519 00:16:41.258559  4008 solver.cpp:231] Iteration 267200, loss = 1.45277
I0519 00:16:41.258874  4008 solver.cpp:247]     Train net output #0: loss = 1.45277 (* 1 = 1.45277 loss)
I0519 00:16:41.258913  4008 sgd_solver.cpp:106] Iteration 267200, lr = 0.001
I0519 00:16:41.419703  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1141	3.125	79.9691	0	90.1305	5.46875	88.0724	0	84.0685	0	84.219	0	76.553	0	29.4756	2.4	
I0519 00:16:41.495043  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:16:41.497308  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:16:41.497356  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:16:41.511831  4008 solver.cpp:260]     Total regularization terms: 0.972835 loss+regular. : 2.4256
I0519 00:18:09.475973  4008 solver.cpp:231] Iteration 267400, loss = 1.40078
I0519 00:18:09.476485  4008 solver.cpp:247]     Train net output #0: loss = 1.40078 (* 1 = 1.40078 loss)
I0519 00:18:09.476518  4008 sgd_solver.cpp:106] Iteration 267400, lr = 0.001
I0519 00:18:09.636665  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1916	3.125	79.9867	0	90.1666	5.46875	88.1042	0	84.0938	0	84.2281	0	76.5651	0	29.4809	2.4	
I0519 00:18:09.711355  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:18:09.713207  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:18:09.713275  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:18:09.723373  4008 solver.cpp:260]     Total regularization terms: 0.972673 loss+regular. : 2.37346
I0519 00:19:38.871057  4008 solver.cpp:231] Iteration 267600, loss = 1.28637
I0519 00:19:38.871368  4008 solver.cpp:247]     Train net output #0: loss = 1.28637 (* 1 = 1.28637 loss)
I0519 00:19:38.871390  4008 sgd_solver.cpp:106] Iteration 267600, lr = 0.001
I0519 00:19:39.031769  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1944	3.125	80.055	0	90.1831	5.46875	88.0599	0	84.0823	0	84.2372	0	76.577	0	29.4872	2.4	
I0519 00:19:39.107316  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:19:39.109841  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:19:39.109869  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:19:39.119866  4008 solver.cpp:260]     Total regularization terms: 0.972531 loss+regular. : 2.2589
I0519 00:20:59.826043  4008 solver.cpp:231] Iteration 267800, loss = 1.52904
I0519 00:20:59.826506  4008 solver.cpp:247]     Train net output #0: loss = 1.52904 (* 1 = 1.52904 loss)
I0519 00:20:59.826539  4008 sgd_solver.cpp:106] Iteration 267800, lr = 0.001
I0519 00:20:59.986356  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3867	3.125	80.2122	0	90.2193	5.46875	88.0927	0	84.0983	0	84.2464	0	76.5887	0	29.4925	2.4	
I0519 00:21:00.062039  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:21:00.064232  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:21:00.064271  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:21:00.075444  4008 solver.cpp:260]     Total regularization terms: 0.972369 loss+regular. : 2.5014
I0519 00:21:36.537987  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:22:22.996268  4008 solver.cpp:348] Iteration 268000, Testing net (#0)
I0519 00:23:32.074998  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:23:39.844561  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55354
I0519 00:23:39.844667  4008 solver.cpp:415]     Test net output #1: loss = 1.9231 (* 1 = 1.9231 loss)
I0519 00:23:39.932570  4008 solver.cpp:231] Iteration 268000, loss = 1.4846
I0519 00:23:39.932665  4008 solver.cpp:247]     Train net output #0: loss = 1.4846 (* 1 = 1.4846 loss)
I0519 00:23:39.932687  4008 sgd_solver.cpp:106] Iteration 268000, lr = 0.001
I0519 00:23:40.092849  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0051	3.125	80.0586	0	90.1603	5.46875	88.0626	0	84.0872	0	84.2559	0	76.6005	0	29.4989	2.4	
I0519 00:23:40.169821  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:23:40.171581  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:23:40.171622  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:23:40.181637  4008 solver.cpp:260]     Total regularization terms: 0.972222 loss+regular. : 2.45682
I0519 00:25:06.379323  4008 solver.cpp:231] Iteration 268200, loss = 1.35469
I0519 00:25:06.379788  4008 solver.cpp:247]     Train net output #0: loss = 1.35469 (* 1 = 1.35469 loss)
I0519 00:25:06.379822  4008 sgd_solver.cpp:106] Iteration 268200, lr = 0.001
I0519 00:25:06.540021  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.094	3.125	80.3623	0	90.217	5.46875	88.1122	0	84.0999	0	84.2651	0	76.6129	0	29.5051	2.4	
I0519 00:25:06.614920  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:25:06.617002  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:25:06.617100  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:25:06.626912  4008 solver.cpp:260]     Total regularization terms: 0.972039 loss+regular. : 2.32673
I0519 00:26:31.179116  4008 solver.cpp:231] Iteration 268400, loss = 1.13016
I0519 00:26:31.179471  4008 solver.cpp:247]     Train net output #0: loss = 1.13016 (* 1 = 1.13016 loss)
I0519 00:26:31.179493  4008 sgd_solver.cpp:106] Iteration 268400, lr = 0.001
I0519 00:26:31.338762  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1112	3.125	80.3493	0	90.2162	5.46875	88.1177	0	84.1175	0	84.2744	0	76.6247	0	29.5103	2.4	
I0519 00:26:31.414844  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:26:31.416980  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:26:31.417033  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:26:31.427156  4008 solver.cpp:260]     Total regularization terms: 0.971953 loss+regular. : 2.10211
I0519 00:28:01.450608  4008 solver.cpp:231] Iteration 268600, loss = 1.40748
I0519 00:28:01.451032  4008 solver.cpp:247]     Train net output #0: loss = 1.40748 (* 1 = 1.40748 loss)
I0519 00:28:01.451055  4008 sgd_solver.cpp:106] Iteration 268600, lr = 0.001
I0519 00:28:01.609242  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0079	3.125	80.2015	0	90.2034	5.46875	88.1104	0	84.1218	0	84.2838	0	76.6362	0	29.5157	2.4	
I0519 00:28:01.690470  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:28:01.693622  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:28:01.693661  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:28:01.704632  4008 solver.cpp:260]     Total regularization terms: 0.971826 loss+regular. : 2.37931
I0519 00:29:30.691069  4008 solver.cpp:231] Iteration 268800, loss = 1.4346
I0519 00:29:30.691392  4008 solver.cpp:247]     Train net output #0: loss = 1.4346 (* 1 = 1.4346 loss)
I0519 00:29:30.691417  4008 sgd_solver.cpp:106] Iteration 268800, lr = 0.001
I0519 00:29:30.857363  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8042	3.125	80.3066	0	90.1975	5.46875	88.0865	0	84.1058	0	84.2934	0	76.6483	0	29.5211	2.4	
I0519 00:29:30.932821  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:29:30.935222  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:29:30.935271  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:29:30.945397  4008 solver.cpp:260]     Total regularization terms: 0.971718 loss+regular. : 2.40632
I0519 00:30:12.679805  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:30:58.278048  4008 solver.cpp:348] Iteration 269000, Testing net (#0)
I0519 00:32:10.940392  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:32:21.551254  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55142
I0519 00:32:21.551370  4008 solver.cpp:415]     Test net output #1: loss = 1.93354 (* 1 = 1.93354 loss)
I0519 00:32:21.645195  4008 solver.cpp:231] Iteration 269000, loss = 1.48861
I0519 00:32:21.645277  4008 solver.cpp:247]     Train net output #0: loss = 1.48861 (* 1 = 1.48861 loss)
I0519 00:32:21.645297  4008 sgd_solver.cpp:106] Iteration 269000, lr = 0.001
I0519 00:32:21.810534  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.962	3.125	80.2852	0	90.2115	5.46875	88.1233	0	84.1295	0	84.3026	0	76.6597	0	29.5268	2.4	
I0519 00:32:21.886214  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:32:21.888945  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:32:21.888998  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:32:21.899086  4008 solver.cpp:260]     Total regularization terms: 0.971565 loss+regular. : 2.46018
I0519 00:33:52.799226  4008 solver.cpp:231] Iteration 269200, loss = 1.22591
I0519 00:33:52.799790  4008 solver.cpp:247]     Train net output #0: loss = 1.22591 (* 1 = 1.22591 loss)
I0519 00:33:52.799815  4008 sgd_solver.cpp:106] Iteration 269200, lr = 0.001
I0519 00:33:52.958541  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.853	3.125	80.3975	0	90.2353	5.46875	88.1369	0	84.1487	0	84.3117	0	76.6717	0	29.5329	2.4	
I0519 00:33:53.033231  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:33:53.035415  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:33:53.035461  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:33:53.045195  4008 solver.cpp:260]     Total regularization terms: 0.971354 loss+regular. : 2.19726
I0519 00:35:26.820024  4008 solver.cpp:231] Iteration 269400, loss = 1.66128
I0519 00:35:26.821631  4008 solver.cpp:247]     Train net output #0: loss = 1.66128 (* 1 = 1.66128 loss)
I0519 00:35:26.821674  4008 sgd_solver.cpp:106] Iteration 269400, lr = 0.001
I0519 00:35:26.982765  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9132	3.125	80.291	0	90.2292	5.46875	88.1161	0	84.1494	0	84.3207	0	76.6838	0	29.5389	2.4	
I0519 00:35:27.058120  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:35:27.061419  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:35:27.061470  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:35:27.071455  4008 solver.cpp:260]     Total regularization terms: 0.971258 loss+regular. : 2.63254
I0519 00:36:59.998059  4008 solver.cpp:231] Iteration 269600, loss = 1.3385
I0519 00:36:59.998616  4008 solver.cpp:247]     Train net output #0: loss = 1.3385 (* 1 = 1.3385 loss)
I0519 00:36:59.998641  4008 sgd_solver.cpp:106] Iteration 269600, lr = 0.001
I0519 00:37:00.157912  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1772	3.125	80.0785	0	90.2203	5.46875	88.1061	0	84.1564	0	84.3301	0	76.6957	0	29.5449	2.4	
I0519 00:37:00.233077  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:37:00.235025  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:37:00.235085  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:37:00.245064  4008 solver.cpp:260]     Total regularization terms: 0.971151 loss+regular. : 2.30965
I0519 00:38:30.777070  4008 solver.cpp:231] Iteration 269800, loss = 1.33981
I0519 00:38:30.777396  4008 solver.cpp:247]     Train net output #0: loss = 1.33981 (* 1 = 1.33981 loss)
I0519 00:38:30.777420  4008 sgd_solver.cpp:106] Iteration 269800, lr = 0.001
I0519 00:38:30.936027  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.249	3.125	80.3652	0	90.2135	5.46875	88.1137	0	84.1783	0	84.339	0	76.7075	0	29.5509	2.4	
I0519 00:38:31.011512  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:38:31.014680  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:38:31.014734  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:38:31.024626  4008 solver.cpp:260]     Total regularization terms: 0.971044 loss+regular. : 2.31086
I0519 00:39:24.425819  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:40:03.077157  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_270000.caffemodel
I0519 00:44:25.132011  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_270000.solverstate
I0519 00:44:25.749958  4008 solver.cpp:348] Iteration 270000, Testing net (#0)
I0519 00:45:49.778213  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:45:57.992182  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55342
I0519 00:45:57.992280  4008 solver.cpp:415]     Test net output #1: loss = 1.91991 (* 1 = 1.91991 loss)
I0519 00:45:58.083844  4008 solver.cpp:231] Iteration 270000, loss = 1.49337
I0519 00:45:58.083930  4008 solver.cpp:247]     Train net output #0: loss = 1.49337 (* 1 = 1.49337 loss)
I0519 00:45:58.083950  4008 sgd_solver.cpp:106] Iteration 270000, lr = 0.001
I0519 00:45:58.243489  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.117	3.125	80.2467	0	90.2443	5.46875	88.1504	0	84.1876	0	84.3482	0	76.7199	0	29.5565	2.4	
I0519 00:45:58.245167  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:45:58.247313  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:45:58.247360  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:45:58.259531  4008 solver.cpp:260]     Total regularization terms: 0.970868 loss+regular. : 2.46424
I0519 00:47:22.814990  4008 solver.cpp:231] Iteration 270200, loss = 1.40186
I0519 00:47:22.815459  4008 solver.cpp:247]     Train net output #0: loss = 1.40186 (* 1 = 1.40186 loss)
I0519 00:47:22.815490  4008 sgd_solver.cpp:106] Iteration 270200, lr = 0.001
I0519 00:47:22.975075  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0825	3.125	80.2292	0	90.224	5.46875	88.1532	0	84.1763	0	84.3572	0	76.7312	0	29.5618	2.4	
I0519 00:47:23.050070  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:47:23.052117  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.4	
I0519 00:47:23.052268  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:47:23.062180  4008 solver.cpp:260]     Total regularization terms: 0.970724 loss+regular. : 2.37258
I0519 00:48:50.757221  4008 solver.cpp:231] Iteration 270400, loss = 1.2916
I0519 00:48:50.757562  4008 solver.cpp:247]     Train net output #0: loss = 1.2916 (* 1 = 1.2916 loss)
I0519 00:48:50.757583  4008 sgd_solver.cpp:106] Iteration 270400, lr = 0.001
I0519 00:48:50.916179  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2174	3.125	80.36	0	90.2436	5.46875	88.1655	0	84.1729	0	84.3664	0	76.7429	0	29.5675	2.5	
I0519 00:48:50.991027  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:48:50.993191  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 00:48:50.993262  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:48:51.013406  4008 solver.cpp:260]     Total regularization terms: 0.970607 loss+regular. : 2.26221
I0519 00:50:12.365003  4008 solver.cpp:231] Iteration 270600, loss = 1.29265
I0519 00:50:12.365272  4008 solver.cpp:247]     Train net output #0: loss = 1.29265 (* 1 = 1.29265 loss)
I0519 00:50:12.365310  4008 sgd_solver.cpp:106] Iteration 270600, lr = 0.001
I0519 00:50:12.525528  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.315	3.125	80.3096	0	90.2453	5.46875	88.1424	0	84.1844	0	84.3755	0	76.7546	0	29.573	2.5	
I0519 00:50:12.601094  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:50:12.603189  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 00:50:12.603255  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:50:12.618151  4008 solver.cpp:260]     Total regularization terms: 0.970525 loss+regular. : 2.26317
I0519 00:51:37.425014  4008 solver.cpp:231] Iteration 270800, loss = 1.239
I0519 00:51:37.425482  4008 solver.cpp:247]     Train net output #0: loss = 1.239 (* 1 = 1.239 loss)
I0519 00:51:37.425508  4008 sgd_solver.cpp:106] Iteration 270800, lr = 0.001
I0519 00:51:37.585755  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9563	3.125	80.3639	0	90.257	5.46875	88.1541	0	84.1953	0	84.3844	0	76.7664	0	29.5786	2.5	
I0519 00:51:37.660614  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:51:37.663287  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 00:51:37.663353  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:51:37.673590  4008 solver.cpp:260]     Total regularization terms: 0.970398 loss+regular. : 2.20939
I0519 00:52:26.379602  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:53:02.554028  4008 solver.cpp:348] Iteration 271000, Testing net (#0)
I0519 00:54:18.828209  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 00:54:27.767472  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55286
I0519 00:54:27.767662  4008 solver.cpp:415]     Test net output #1: loss = 1.9188 (* 1 = 1.9188 loss)
I0519 00:54:27.856734  4008 solver.cpp:231] Iteration 271000, loss = 1.39304
I0519 00:54:27.856818  4008 solver.cpp:247]     Train net output #0: loss = 1.39304 (* 1 = 1.39304 loss)
I0519 00:54:27.856840  4008 sgd_solver.cpp:106] Iteration 271000, lr = 0.001
I0519 00:54:28.020653  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1801	3.125	80.5638	0	90.2624	5.46875	88.174	0	84.2091	0	84.3937	0	76.7779	0	29.5845	2.5	
I0519 00:54:28.096233  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:54:28.098865  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 00:54:28.098923  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:54:28.109222  4008 solver.cpp:260]     Total regularization terms: 0.970255 loss+regular. : 2.36329
I0519 00:55:55.725989  4008 solver.cpp:231] Iteration 271200, loss = 1.48721
I0519 00:55:55.729720  4008 solver.cpp:247]     Train net output #0: loss = 1.48721 (* 1 = 1.48721 loss)
I0519 00:55:55.729800  4008 sgd_solver.cpp:106] Iteration 271200, lr = 0.001
I0519 00:55:55.884078  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2404	3.125	80.5117	0	90.2887	5.46875	88.1723	0	84.2224	0	84.4029	0	76.7899	0	29.5905	2.5	
I0519 00:55:55.958979  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:55:55.961776  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 00:55:55.961835  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:55:55.971794  4008 solver.cpp:260]     Total regularization terms: 0.97006 loss+regular. : 2.45727
I0519 00:57:22.964596  4008 solver.cpp:231] Iteration 271400, loss = 1.52295
I0519 00:57:22.964939  4008 solver.cpp:247]     Train net output #0: loss = 1.52295 (* 1 = 1.52295 loss)
I0519 00:57:22.964956  4008 sgd_solver.cpp:106] Iteration 271400, lr = 0.001
I0519 00:57:23.124629  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4068	3.125	80.4948	0	90.2768	5.46875	88.1926	0	84.2229	0	84.4121	0	76.8016	0	29.5961	2.5	
I0519 00:57:23.199241  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:57:23.201174  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 00:57:23.201218  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:57:23.211182  4008 solver.cpp:260]     Total regularization terms: 0.969927 loss+regular. : 2.49287
I0519 00:58:42.385427  4008 solver.cpp:231] Iteration 271600, loss = 1.23099
I0519 00:58:42.385993  4008 solver.cpp:247]     Train net output #0: loss = 1.23099 (* 1 = 1.23099 loss)
I0519 00:58:42.386286  4008 sgd_solver.cpp:106] Iteration 271600, lr = 0.001
I0519 00:58:42.545828  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4011	3.125	80.2054	0	90.2885	5.46875	88.1764	0	84.1951	0	84.421	0	76.8129	0	29.602	2.5	
I0519 00:58:42.621860  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 00:58:42.624335  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 00:58:42.624389  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 00:58:42.634516  4008 solver.cpp:260]     Total regularization terms: 0.969849 loss+regular. : 2.20084
I0519 01:00:02.916821  4008 solver.cpp:231] Iteration 271800, loss = 1.21657
I0519 01:00:02.917347  4008 solver.cpp:247]     Train net output #0: loss = 1.21657 (* 1 = 1.21657 loss)
I0519 01:00:02.917369  4008 sgd_solver.cpp:106] Iteration 271800, lr = 0.001
I0519 01:00:03.076854  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1801	3.125	80.3883	0	90.2771	5.46875	88.1652	0	84.2276	0	84.4301	0	76.8245	0	29.608	2.5	
I0519 01:00:03.152395  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:00:03.155529  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:00:03.155578  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:00:03.167104  4008 solver.cpp:260]     Total regularization terms: 0.969678 loss+regular. : 2.18625
I0519 01:00:53.852897  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:01:27.523177  4008 solver.cpp:348] Iteration 272000, Testing net (#0)
I0519 01:02:44.206205  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:02:50.702322  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55232
I0519 01:02:50.702415  4008 solver.cpp:415]     Test net output #1: loss = 1.91796 (* 1 = 1.91796 loss)
I0519 01:02:50.790259  4008 solver.cpp:231] Iteration 272000, loss = 1.42399
I0519 01:02:50.790343  4008 solver.cpp:247]     Train net output #0: loss = 1.42399 (* 1 = 1.42399 loss)
I0519 01:02:50.790367  4008 sgd_solver.cpp:106] Iteration 272000, lr = 0.001
I0519 01:02:50.955641  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0768	3.125	80.375	0	90.2535	5.46875	88.1723	0	84.2437	0	84.4393	0	76.8361	0	29.6142	2.5	
I0519 01:02:51.030995  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:02:51.033252  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:02:51.033303  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:02:51.044075  4008 solver.cpp:260]     Total regularization terms: 0.969575 loss+regular. : 2.39356
I0519 01:04:16.967041  4008 solver.cpp:231] Iteration 272200, loss = 1.30395
I0519 01:04:16.969336  4008 solver.cpp:247]     Train net output #0: loss = 1.30395 (* 1 = 1.30395 loss)
I0519 01:04:16.969368  4008 sgd_solver.cpp:106] Iteration 272200, lr = 0.001
I0519 01:04:17.126763  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8271	3.125	80.3317	0	90.2675	5.46875	88.1432	0	84.2163	0	84.4486	0	76.8475	0	29.6193	2.5	
I0519 01:04:17.201815  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.77951	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:04:17.204195  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:04:17.204246  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:04:17.214388  4008 solver.cpp:260]     Total regularization terms: 0.96948 loss+regular. : 2.27343
I0519 01:05:46.491044  4008 solver.cpp:231] Iteration 272400, loss = 1.40717
I0519 01:05:46.492519  4008 solver.cpp:247]     Train net output #0: loss = 1.40717 (* 1 = 1.40717 loss)
I0519 01:05:46.492547  4008 sgd_solver.cpp:106] Iteration 272400, lr = 0.001
I0519 01:05:46.650586  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8558	3.125	80.2956	0	90.302	5.46875	88.196	0	84.2563	0	84.4576	0	76.8591	0	29.6247	2.5	
I0519 01:05:46.726878  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:05:46.729873  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:05:46.729930  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:05:46.745218  4008 solver.cpp:260]     Total regularization terms: 0.969297 loss+regular. : 2.37647
I0519 01:07:12.354600  4008 solver.cpp:231] Iteration 272600, loss = 1.36161
I0519 01:07:12.355576  4008 solver.cpp:247]     Train net output #0: loss = 1.36161 (* 1 = 1.36161 loss)
I0519 01:07:12.355604  4008 sgd_solver.cpp:106] Iteration 272600, lr = 0.001
I0519 01:07:12.515159  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6521	3.125	80.1244	0	90.2569	5.46875	88.1468	0	84.2285	0	84.4666	0	76.8706	0	29.6306	2.5	
I0519 01:07:12.590499  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:07:12.592869  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:07:12.592919  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:07:12.603166  4008 solver.cpp:260]     Total regularization terms: 0.969168 loss+regular. : 2.33078
I0519 01:08:36.755832  4008 solver.cpp:231] Iteration 272800, loss = 1.395
I0519 01:08:36.756083  4008 solver.cpp:247]     Train net output #0: loss = 1.395 (* 1 = 1.395 loss)
I0519 01:08:36.756103  4008 sgd_solver.cpp:106] Iteration 272800, lr = 0.001
I0519 01:08:36.914994  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2805	3.125	80.4977	0	90.3254	5.46875	88.1985	0	84.2509	0	84.4758	0	76.8823	0	29.6361	2.5	
I0519 01:08:36.990756  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:08:36.993724  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:08:36.993777  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:08:37.003798  4008 solver.cpp:260]     Total regularization terms: 0.968893 loss+regular. : 2.3639
I0519 01:09:29.550145  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:10:01.190536  4008 solver.cpp:348] Iteration 273000, Testing net (#0)
I0519 01:11:12.752264  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:11:18.112376  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5566
I0519 01:11:18.112473  4008 solver.cpp:415]     Test net output #1: loss = 1.90909 (* 1 = 1.90909 loss)
I0519 01:11:18.203616  4008 solver.cpp:231] Iteration 273000, loss = 1.2218
I0519 01:11:18.203701  4008 solver.cpp:247]     Train net output #0: loss = 1.2218 (* 1 = 1.2218 loss)
I0519 01:11:18.203721  4008 sgd_solver.cpp:106] Iteration 273000, lr = 0.001
I0519 01:11:18.368301  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8214	3.125	80.4186	0	90.2967	5.46875	88.1575	0	84.2328	0	84.485	0	76.8938	0	29.6416	2.5	
I0519 01:11:18.448312  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:11:18.450368  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:11:18.450417  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:11:18.460157  4008 solver.cpp:260]     Total regularization terms: 0.968761 loss+regular. : 2.19056
I0519 01:12:51.786664  4008 solver.cpp:231] Iteration 273200, loss = 1.51418
I0519 01:12:51.787092  4008 solver.cpp:247]     Train net output #0: loss = 1.51418 (* 1 = 1.51418 loss)
I0519 01:12:51.787120  4008 sgd_solver.cpp:106] Iteration 273200, lr = 0.001
I0519 01:12:51.946552  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1198	3.125	80.6449	0	90.3375	5.46875	88.196	0	84.2391	0	84.4939	0	76.9051	0	29.6477	2.5	
I0519 01:12:52.021513  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:12:52.023964  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:12:52.024088  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:12:52.034065  4008 solver.cpp:260]     Total regularization terms: 0.968589 loss+regular. : 2.48276
I0519 01:14:20.622589  4008 solver.cpp:231] Iteration 273400, loss = 1.246
I0519 01:14:20.622982  4008 solver.cpp:247]     Train net output #0: loss = 1.246 (* 1 = 1.246 loss)
I0519 01:14:20.623011  4008 sgd_solver.cpp:106] Iteration 273400, lr = 0.001
I0519 01:14:20.781361  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7956	3.125	80.6367	0	90.3382	5.46875	88.2106	0	84.2719	0	84.5031	0	76.9167	0	29.6528	2.5	
I0519 01:14:20.856492  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:14:20.859951  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	0.78125	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:14:20.860033  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:14:20.870020  4008 solver.cpp:260]     Total regularization terms: 0.968513 loss+regular. : 2.21451
I0519 01:15:50.351295  4008 solver.cpp:231] Iteration 273600, loss = 1.41496
I0519 01:15:50.351662  4008 solver.cpp:247]     Train net output #0: loss = 1.41496 (* 1 = 1.41496 loss)
I0519 01:15:50.351692  4008 sgd_solver.cpp:106] Iteration 273600, lr = 0.001
I0519 01:15:50.511927  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0337	3.125	80.2318	0	90.3372	5.46875	88.2256	0	84.2877	0	84.5121	0	76.9287	0	29.6585	2.5	
I0519 01:15:50.587136  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:15:50.589262  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:15:50.589320  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:15:50.599514  4008 solver.cpp:260]     Total regularization terms: 0.968456 loss+regular. : 2.38341
I0519 01:17:19.321517  4008 solver.cpp:231] Iteration 273800, loss = 1.42237
I0519 01:17:19.321897  4008 solver.cpp:247]     Train net output #0: loss = 1.42237 (* 1 = 1.42237 loss)
I0519 01:17:19.321921  4008 sgd_solver.cpp:106] Iteration 273800, lr = 0.001
I0519 01:17:19.480150  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.5216	3.125	80.3945	0	90.3208	5.46875	88.2291	0	84.2828	0	84.5211	0	76.9398	0	29.6644	2.5	
I0519 01:17:19.556556  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:17:19.558761  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:17:19.558816  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:17:19.572576  4008 solver.cpp:260]     Total regularization terms: 0.968298 loss+regular. : 2.39066
I0519 01:18:16.526729  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:18:42.046576  4008 solver.cpp:348] Iteration 274000, Testing net (#0)
I0519 01:20:06.256402  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:20:13.024685  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55506
I0519 01:20:13.024776  4008 solver.cpp:415]     Test net output #1: loss = 1.91581 (* 1 = 1.91581 loss)
I0519 01:20:13.118437  4008 solver.cpp:231] Iteration 274000, loss = 1.31627
I0519 01:20:13.118530  4008 solver.cpp:247]     Train net output #0: loss = 1.31627 (* 1 = 1.31627 loss)
I0519 01:20:13.118546  4008 sgd_solver.cpp:106] Iteration 274000, lr = 0.001
I0519 01:20:13.285722  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0797	3.125	80.224	0	90.3259	5.46875	88.2476	0	84.2986	0	84.53	0	76.9514	0	29.6703	2.5	
I0519 01:20:13.360363  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:20:13.362562  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:20:13.362613  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:20:13.372524  4008 solver.cpp:260]     Total regularization terms: 0.968184 loss+regular. : 2.28446
I0519 01:21:44.332875  4008 solver.cpp:231] Iteration 274200, loss = 1.31047
I0519 01:21:44.333392  4008 solver.cpp:247]     Train net output #0: loss = 1.31047 (* 1 = 1.31047 loss)
I0519 01:21:44.333423  4008 sgd_solver.cpp:106] Iteration 274200, lr = 0.001
I0519 01:21:44.492892  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1457	3.125	80.3236	0	90.315	5.46875	88.2365	0	84.2825	0	84.5389	0	76.9626	0	29.6758	2.5	
I0519 01:21:44.568238  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:21:44.570794  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:21:44.570883  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:21:44.581722  4008 solver.cpp:260]     Total regularization terms: 0.96804 loss+regular. : 2.27851
I0519 01:23:08.097036  4008 solver.cpp:231] Iteration 274400, loss = 1.55981
I0519 01:23:08.097419  4008 solver.cpp:247]     Train net output #0: loss = 1.55981 (* 1 = 1.55981 loss)
I0519 01:23:08.097440  4008 sgd_solver.cpp:106] Iteration 274400, lr = 0.001
I0519 01:23:08.258036  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9046	3.125	80.4079	0	90.285	5.46875	88.21	0	84.2758	0	84.5478	0	76.974	0	29.6814	2.5	
I0519 01:23:08.332886  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:23:08.335100  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:23:08.335161  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:23:08.350986  4008 solver.cpp:260]     Total regularization terms: 0.967959 loss+regular. : 2.52777
I0519 01:24:30.280658  4008 solver.cpp:231] Iteration 274600, loss = 1.4022
I0519 01:24:30.285738  4008 solver.cpp:247]     Train net output #0: loss = 1.4022 (* 1 = 1.4022 loss)
I0519 01:24:30.285786  4008 sgd_solver.cpp:106] Iteration 274600, lr = 0.001
I0519 01:24:30.440826  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7898	3.125	80.4085	0	90.3016	5.46875	88.2161	0	84.2764	0	84.5565	0	76.9855	0	29.687	2.5	
I0519 01:24:30.517145  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:24:30.520769  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:24:30.520848  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:24:30.531277  4008 solver.cpp:260]     Total regularization terms: 0.96785 loss+regular. : 2.37005
I0519 01:25:56.886837  4008 solver.cpp:231] Iteration 274800, loss = 1.41886
I0519 01:25:56.887241  4008 solver.cpp:247]     Train net output #0: loss = 1.41886 (* 1 = 1.41886 loss)
I0519 01:25:56.887275  4008 sgd_solver.cpp:106] Iteration 274800, lr = 0.001
I0519 01:25:57.047293  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8501	3.125	80.418	0	90.2824	5.46875	88.2152	0	84.2934	0	84.5655	0	76.997	0	29.6924	2.5	
I0519 01:25:57.122174  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:25:57.124452  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:25:57.124505  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:25:57.134366  4008 solver.cpp:260]     Total regularization terms: 0.967738 loss+regular. : 2.3866
I0519 01:26:58.418989  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:27:24.193702  4008 solver.cpp:348] Iteration 275000, Testing net (#0)
I0519 01:28:40.089831  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:28:44.784180  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55472
I0519 01:28:44.784292  4008 solver.cpp:415]     Test net output #1: loss = 1.90999 (* 1 = 1.90999 loss)
I0519 01:28:44.873384  4008 solver.cpp:231] Iteration 275000, loss = 1.3177
I0519 01:28:44.873497  4008 solver.cpp:247]     Train net output #0: loss = 1.3177 (* 1 = 1.3177 loss)
I0519 01:28:44.873517  4008 sgd_solver.cpp:106] Iteration 275000, lr = 0.001
I0519 01:28:45.037325  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.698	3.125	80.2464	0	90.3011	5.46875	88.2391	0	84.271	0	84.5744	0	77.0085	0	29.6975	2.5	
I0519 01:28:45.113240  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:28:45.115751  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:28:45.115821  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:28:45.126000  4008 solver.cpp:260]     Total regularization terms: 0.967609 loss+regular. : 2.28531
I0519 01:30:13.592506  4008 solver.cpp:231] Iteration 275200, loss = 1.35632
I0519 01:30:13.593000  4008 solver.cpp:247]     Train net output #0: loss = 1.35632 (* 1 = 1.35632 loss)
I0519 01:30:13.593034  4008 sgd_solver.cpp:106] Iteration 275200, lr = 0.001
I0519 01:30:13.751688  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8444	3.125	80.4736	0	90.3562	5.46875	88.2648	0	84.3101	0	84.5832	0	77.0197	0	29.703	2.5	
I0519 01:30:13.826464  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:30:13.828466  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:30:13.828523  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:30:13.838459  4008 solver.cpp:260]     Total regularization terms: 0.967462 loss+regular. : 2.32378
I0519 01:31:42.544940  4008 solver.cpp:231] Iteration 275400, loss = 1.26328
I0519 01:31:42.545481  4008 solver.cpp:247]     Train net output #0: loss = 1.26328 (* 1 = 1.26328 loss)
I0519 01:31:42.545565  4008 sgd_solver.cpp:106] Iteration 275400, lr = 0.001
I0519 01:31:42.704946  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8501	3.125	80.5251	0	90.3433	5.46875	88.2392	0	84.323	0	84.5917	0	77.0312	0	29.7083	2.5	
I0519 01:31:42.780511  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:31:42.782843  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:31:42.782908  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:31:42.793166  4008 solver.cpp:260]     Total regularization terms: 0.967316 loss+regular. : 2.2306
I0519 01:33:06.265122  4008 solver.cpp:231] Iteration 275600, loss = 1.09488
I0519 01:33:06.265532  4008 solver.cpp:247]     Train net output #0: loss = 1.09488 (* 1 = 1.09488 loss)
I0519 01:33:06.265578  4008 sgd_solver.cpp:106] Iteration 275600, lr = 0.001
I0519 01:33:06.425516  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0366	3.125	80.6292	0	90.3953	5.46875	88.2811	0	84.3244	0	84.6003	0	77.0425	0	29.7134	2.5	
I0519 01:33:06.500562  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:33:06.502717  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:33:06.502770  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:33:06.532927  4008 solver.cpp:260]     Total regularization terms: 0.967215 loss+regular. : 2.06209
I0519 01:34:39.323554  4008 solver.cpp:231] Iteration 275800, loss = 1.42584
I0519 01:34:39.323899  4008 solver.cpp:247]     Train net output #0: loss = 1.42584 (* 1 = 1.42584 loss)
I0519 01:34:39.323922  4008 sgd_solver.cpp:106] Iteration 275800, lr = 0.001
I0519 01:34:39.484030  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.6951	3.125	80.5319	0	90.4027	5.46875	88.2742	0	84.3431	0	84.609	0	77.0534	0	29.7189	2.5	
I0519 01:34:39.558737  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:34:39.560935  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:34:39.560984  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:34:39.570785  4008 solver.cpp:260]     Total regularization terms: 0.967096 loss+regular. : 2.39294
I0519 01:35:50.185271  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:36:13.825925  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_276000.caffemodel
I0519 01:40:29.864105  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_276000.solverstate
I0519 01:40:30.388636  4008 solver.cpp:348] Iteration 276000, Testing net (#0)
I0519 01:41:51.026921  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:41:55.384217  4008 solver.cpp:415]     Test net output #0: accuracy = 0.552959
I0519 01:41:55.384304  4008 solver.cpp:415]     Test net output #1: loss = 1.92603 (* 1 = 1.92603 loss)
I0519 01:41:55.471858  4008 solver.cpp:231] Iteration 276000, loss = 1.65953
I0519 01:41:55.471961  4008 solver.cpp:247]     Train net output #0: loss = 1.65953 (* 1 = 1.65953 loss)
I0519 01:41:55.471978  4008 sgd_solver.cpp:106] Iteration 276000, lr = 0.001
I0519 01:41:55.637730  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9362	3.125	80.6126	0	90.3701	5.46875	88.277	0	84.3291	0	84.6179	0	77.0652	0	29.725	2.5	
I0519 01:41:55.639466  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:41:55.641634  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:41:55.641708  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:41:55.651666  4008 solver.cpp:260]     Total regularization terms: 0.967009 loss+regular. : 2.62654
I0519 01:43:21.484730  4008 solver.cpp:231] Iteration 276200, loss = 1.43295
I0519 01:43:21.485051  4008 solver.cpp:247]     Train net output #0: loss = 1.43295 (* 1 = 1.43295 loss)
I0519 01:43:21.485070  4008 sgd_solver.cpp:106] Iteration 276200, lr = 0.001
I0519 01:43:21.644592  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7525	3.125	80.3171	0	90.3563	5.46875	88.2739	0	84.354	0	84.6266	0	77.0767	0	29.7302	2.5	
I0519 01:43:21.719359  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:43:21.721447  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:43:21.721501  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:43:21.731951  4008 solver.cpp:260]     Total regularization terms: 0.966844 loss+regular. : 2.3998
I0519 01:44:49.330165  4008 solver.cpp:231] Iteration 276400, loss = 1.41988
I0519 01:44:49.330482  4008 solver.cpp:247]     Train net output #0: loss = 1.41988 (* 1 = 1.41988 loss)
I0519 01:44:49.330502  4008 sgd_solver.cpp:106] Iteration 276400, lr = 0.001
I0519 01:44:49.489011  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2375	3.125	80.5068	0	90.3862	5.46875	88.2766	0	84.3456	0	84.6351	0	77.0877	0	29.7353	2.5	
I0519 01:44:49.563637  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:44:49.565693  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:44:49.565757  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:44:49.575966  4008 solver.cpp:260]     Total regularization terms: 0.966748 loss+regular. : 2.38663
I0519 01:46:10.454144  4008 solver.cpp:231] Iteration 276600, loss = 1.27983
I0519 01:46:10.454426  4008 solver.cpp:247]     Train net output #0: loss = 1.27983 (* 1 = 1.27983 loss)
I0519 01:46:10.454454  4008 sgd_solver.cpp:106] Iteration 276600, lr = 0.001
I0519 01:46:10.613595  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.764	3.125	80.3018	0	90.3687	5.46875	88.2517	0	84.3282	0	84.6439	0	77.0988	0	29.7409	2.5	
I0519 01:46:10.688932  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:46:10.691689  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:46:10.691736  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:46:10.701884  4008 solver.cpp:260]     Total regularization terms: 0.966641 loss+regular. : 2.24647
I0519 01:47:28.591501  4008 solver.cpp:231] Iteration 276800, loss = 1.24425
I0519 01:47:28.591948  4008 solver.cpp:247]     Train net output #0: loss = 1.24425 (* 1 = 1.24425 loss)
I0519 01:47:28.591979  4008 sgd_solver.cpp:106] Iteration 276800, lr = 0.001
I0519 01:47:28.752296  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9735	3.125	80.5872	0	90.359	5.46875	88.2835	0	84.363	0	84.6529	0	77.1098	0	29.7457	2.5	
I0519 01:47:28.827788  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:47:28.830724  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:47:28.830773  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:47:28.840607  4008 solver.cpp:260]     Total regularization terms: 0.966505 loss+regular. : 2.21076
I0519 01:48:30.530977  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:48:49.804071  4008 solver.cpp:348] Iteration 277000, Testing net (#0)
I0519 01:50:13.822083  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:50:17.751010  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55282
I0519 01:50:17.751135  4008 solver.cpp:415]     Test net output #1: loss = 1.92496 (* 1 = 1.92496 loss)
I0519 01:50:17.843094  4008 solver.cpp:231] Iteration 277000, loss = 1.41828
I0519 01:50:17.843178  4008 solver.cpp:247]     Train net output #0: loss = 1.41828 (* 1 = 1.41828 loss)
I0519 01:50:17.843199  4008 sgd_solver.cpp:106] Iteration 277000, lr = 0.001
I0519 01:50:18.002903  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9448	3.125	80.5664	0	90.3745	5.46875	88.2874	0	84.361	0	84.6616	0	77.1209	0	29.752	2.5	
I0519 01:50:18.078975  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:50:18.081112  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:50:18.081176  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:50:18.092202  4008 solver.cpp:260]     Total regularization terms: 0.966329 loss+regular. : 2.38461
I0519 01:51:47.297874  4008 solver.cpp:231] Iteration 277200, loss = 1.42871
I0519 01:51:47.298941  4008 solver.cpp:247]     Train net output #0: loss = 1.42871 (* 1 = 1.42871 loss)
I0519 01:51:47.298967  4008 sgd_solver.cpp:106] Iteration 277200, lr = 0.001
I0519 01:51:47.456508  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9677	3.125	80.3848	0	90.3477	5.46875	88.2454	0	84.3632	0	84.6703	0	77.1321	0	29.7573	2.5	
I0519 01:51:47.531592  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:51:47.533419  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:51:47.533466  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:51:47.548324  4008 solver.cpp:260]     Total regularization terms: 0.966288 loss+regular. : 2.39499
I0519 01:53:16.133800  4008 solver.cpp:231] Iteration 277400, loss = 1.32255
I0519 01:53:16.134544  4008 solver.cpp:247]     Train net output #0: loss = 1.32255 (* 1 = 1.32255 loss)
I0519 01:53:16.134567  4008 sgd_solver.cpp:106] Iteration 277400, lr = 0.001
I0519 01:53:16.294381  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9563	3.125	80.029	0	90.3195	5.46875	88.3019	0	84.3802	0	84.6789	0	77.1432	0	29.7633	2.5	
I0519 01:53:16.373687  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:53:16.375694  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:53:16.375747  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:53:16.395961  4008 solver.cpp:260]     Total regularization terms: 0.966104 loss+regular. : 2.28865
I0519 01:54:38.504806  4008 solver.cpp:231] Iteration 277600, loss = 1.20038
I0519 01:54:38.505162  4008 solver.cpp:247]     Train net output #0: loss = 1.20038 (* 1 = 1.20038 loss)
I0519 01:54:38.505179  4008 sgd_solver.cpp:106] Iteration 277600, lr = 0.001
I0519 01:54:38.666867  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1973	3.125	80.4701	0	90.3771	5.46875	88.2638	0	84.3764	0	84.6876	0	77.1548	0	29.7688	2.5	
I0519 01:54:38.741086  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:54:38.742715  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:54:38.742759  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:54:38.752547  4008 solver.cpp:260]     Total regularization terms: 0.965978 loss+regular. : 2.16636
I0519 01:55:52.742790  4008 solver.cpp:231] Iteration 277800, loss = 1.4755
I0519 01:55:52.744657  4008 solver.cpp:247]     Train net output #0: loss = 1.4755 (* 1 = 1.4755 loss)
I0519 01:55:52.744804  4008 sgd_solver.cpp:106] Iteration 277800, lr = 0.001
I0519 01:55:52.902914  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3293	3.125	80.376	0	90.3796	5.46875	88.2757	0	84.3556	0	84.6964	0	77.1663	0	29.7742	2.5	
I0519 01:55:52.977913  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:55:52.980134  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:55:52.980173  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:55:52.994855  4008 solver.cpp:260]     Total regularization terms: 0.965865 loss+regular. : 2.44136
I0519 01:56:55.022433  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:57:09.414727  4008 solver.cpp:348] Iteration 278000, Testing net (#0)
I0519 01:58:27.059053  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 01:58:29.612298  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55644
I0519 01:58:29.612412  4008 solver.cpp:415]     Test net output #1: loss = 1.90874 (* 1 = 1.90874 loss)
I0519 01:58:29.700769  4008 solver.cpp:231] Iteration 278000, loss = 1.48462
I0519 01:58:29.700872  4008 solver.cpp:247]     Train net output #0: loss = 1.48462 (* 1 = 1.48462 loss)
I0519 01:58:29.700901  4008 sgd_solver.cpp:106] Iteration 278000, lr = 0.001
I0519 01:58:29.866385  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.094	3.125	80.2064	0	90.3221	5.46875	88.254	0	84.3671	0	84.7049	0	77.1775	0	29.7797	2.5	
I0519 01:58:29.941874  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:58:29.944561  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:58:29.944602  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:58:29.954448  4008 solver.cpp:260]     Total regularization terms: 0.965827 loss+regular. : 2.45045
I0519 01:59:46.201930  4008 solver.cpp:231] Iteration 278200, loss = 1.30641
I0519 01:59:46.202138  4008 solver.cpp:247]     Train net output #0: loss = 1.30641 (* 1 = 1.30641 loss)
I0519 01:59:46.202160  4008 sgd_solver.cpp:106] Iteration 278200, lr = 0.001
I0519 01:59:46.362617  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1256	3.125	80.4756	0	90.3346	5.46875	88.2565	0	84.3852	0	84.7136	0	77.1886	0	29.7854	2.5	
I0519 01:59:46.438422  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 01:59:46.440896  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 01:59:46.440943  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 01:59:46.456071  4008 solver.cpp:260]     Total regularization terms: 0.965707 loss+regular. : 2.27211
I0519 02:01:10.090075  4008 solver.cpp:231] Iteration 278400, loss = 1.35727
I0519 02:01:10.090364  4008 solver.cpp:247]     Train net output #0: loss = 1.35727 (* 1 = 1.35727 loss)
I0519 02:01:10.090505  4008 sgd_solver.cpp:106] Iteration 278400, lr = 0.001
I0519 02:01:10.249850  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4097	3.125	80.3792	0	90.389	5.46875	88.3139	0	84.4051	0	84.7219	0	77.1995	0	29.7906	2.5	
I0519 02:01:10.324558  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:01:10.326237  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:01:10.326277  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:01:10.336488  4008 solver.cpp:260]     Total regularization terms: 0.965556 loss+regular. : 2.32283
I0519 02:02:33.384564  4008 solver.cpp:231] Iteration 278600, loss = 1.33198
I0519 02:02:33.384891  4008 solver.cpp:247]     Train net output #0: loss = 1.33198 (* 1 = 1.33198 loss)
I0519 02:02:33.384912  4008 sgd_solver.cpp:106] Iteration 278600, lr = 0.001
I0519 02:02:33.544639  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4412	3.125	80.276	0	90.3972	5.46875	88.3183	0	84.4256	0	84.7301	0	77.2108	0	29.7968	2.5	
I0519 02:02:33.619593  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:02:33.621985  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:02:33.622031  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:02:33.631999  4008 solver.cpp:260]     Total regularization terms: 0.965405 loss+regular. : 2.29738
I0519 02:04:00.249723  4008 solver.cpp:231] Iteration 278800, loss = 1.38773
I0519 02:04:00.253671  4008 solver.cpp:247]     Train net output #0: loss = 1.38773 (* 1 = 1.38773 loss)
I0519 02:04:00.253705  4008 sgd_solver.cpp:106] Iteration 278800, lr = 0.001
I0519 02:04:00.409482  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1112	3.125	80.5104	0	90.4083	5.46875	88.3325	0	84.4252	0	84.7388	0	77.2222	0	29.8027	2.5	
I0519 02:04:00.484566  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.82292	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:04:00.487210  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:04:00.487246  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:04:00.517530  4008 solver.cpp:260]     Total regularization terms: 0.96525 loss+regular. : 2.35298
I0519 02:05:07.551723  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:05:21.743268  4008 solver.cpp:348] Iteration 279000, Testing net (#0)
I0519 02:06:38.544894  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:06:40.641973  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55342
I0519 02:06:40.642048  4008 solver.cpp:415]     Test net output #1: loss = 1.92538 (* 1 = 1.92538 loss)
I0519 02:06:40.730247  4008 solver.cpp:231] Iteration 279000, loss = 1.43352
I0519 02:06:40.730320  4008 solver.cpp:247]     Train net output #0: loss = 1.43352 (* 1 = 1.43352 loss)
I0519 02:06:40.730340  4008 sgd_solver.cpp:106] Iteration 279000, lr = 0.001
I0519 02:06:40.896486  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1084	3.125	80.4323	0	90.3681	5.46875	88.3221	0	84.4046	0	84.7473	0	77.2332	0	29.8086	2.5	
I0519 02:06:40.971438  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.86632	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:06:40.973594  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:06:40.973640  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:06:40.983528  4008 solver.cpp:260]     Total regularization terms: 0.965164 loss+regular. : 2.39869
I0519 02:08:05.020141  4008 solver.cpp:231] Iteration 279200, loss = 1.50237
I0519 02:08:05.021620  4008 solver.cpp:247]     Train net output #0: loss = 1.50237 (* 1 = 1.50237 loss)
I0519 02:08:05.021641  4008 sgd_solver.cpp:106] Iteration 279200, lr = 0.001
I0519 02:08:05.180552  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2691	3.125	80.2926	0	90.3943	5.46875	88.3376	0	84.4112	0	84.7558	0	77.2448	0	29.8145	2.5	
I0519 02:08:05.255569  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.86632	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:08:05.258049  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:08:05.258082  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:08:05.267808  4008 solver.cpp:260]     Total regularization terms: 0.965026 loss+regular. : 2.46739
I0519 02:09:24.145686  4008 solver.cpp:231] Iteration 279400, loss = 1.44972
I0519 02:09:24.146035  4008 solver.cpp:247]     Train net output #0: loss = 1.44972 (* 1 = 1.44972 loss)
I0519 02:09:24.146056  4008 sgd_solver.cpp:106] Iteration 279400, lr = 0.001
I0519 02:09:24.305719  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0079	3.125	80.4001	0	90.3949	5.46875	88.31	0	84.4155	0	84.7645	0	77.2563	0	29.8206	2.5	
I0519 02:09:24.381575  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.90972	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:09:24.384167  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:09:24.384201  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:09:24.399271  4008 solver.cpp:260]     Total regularization terms: 0.964943 loss+regular. : 2.41467
I0519 02:10:50.220089  4008 solver.cpp:231] Iteration 279600, loss = 1.25958
I0519 02:10:50.221626  4008 solver.cpp:247]     Train net output #0: loss = 1.25958 (* 1 = 1.25958 loss)
I0519 02:10:50.221650  4008 sgd_solver.cpp:106] Iteration 279600, lr = 0.001
I0519 02:10:50.380136  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1514	3.125	80.2572	0	90.3779	5.46875	88.3337	0	84.4311	0	84.7728	0	77.2673	0	29.8264	2.5	
I0519 02:10:50.455693  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.90972	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:10:50.457762  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:10:50.457800  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:10:50.471333  4008 solver.cpp:260]     Total regularization terms: 0.964786 loss+regular. : 2.22437
I0519 02:12:10.311517  4008 solver.cpp:231] Iteration 279800, loss = 1.42126
I0519 02:12:10.312052  4008 solver.cpp:247]     Train net output #0: loss = 1.42126 (* 1 = 1.42126 loss)
I0519 02:12:10.312080  4008 sgd_solver.cpp:106] Iteration 279800, lr = 0.001
I0519 02:12:10.470479  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2891	3.125	80.5199	0	90.3952	5.46875	88.3433	0	84.4177	0	84.7812	0	77.2778	0	29.8321	2.5	
I0519 02:12:10.546677  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.90972	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:12:10.548929  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:12:10.548977  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:12:10.562878  4008 solver.cpp:260]     Total regularization terms: 0.96465 loss+regular. : 2.38591
I0519 02:13:19.328819  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:13:28.693961  4008 solver.cpp:348] Iteration 280000, Testing net (#0)
I0519 02:14:44.233175  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:14:45.881026  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5555
I0519 02:14:45.881140  4008 solver.cpp:415]     Test net output #1: loss = 1.91016 (* 1 = 1.91016 loss)
I0519 02:14:45.969804  4008 solver.cpp:231] Iteration 280000, loss = 1.446
I0519 02:14:45.969883  4008 solver.cpp:247]     Train net output #0: loss = 1.446 (* 1 = 1.446 loss)
I0519 02:14:45.969902  4008 sgd_solver.cpp:106] Iteration 280000, lr = 0.001
I0519 02:14:46.136193  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1227	3.125	80.2054	0	90.4025	5.46875	88.3347	0	84.4338	0	84.7897	0	77.2887	0	29.8377	2.5	
I0519 02:14:46.211307  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.90972	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:14:46.213487  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:14:46.213533  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:14:46.227157  4008 solver.cpp:260]     Total regularization terms: 0.964534 loss+regular. : 2.41054
I0519 02:16:06.375562  4008 solver.cpp:231] Iteration 280200, loss = 1.42965
I0519 02:16:06.375905  4008 solver.cpp:247]     Train net output #0: loss = 1.42965 (* 1 = 1.42965 loss)
I0519 02:16:06.375928  4008 sgd_solver.cpp:106] Iteration 280200, lr = 0.001
I0519 02:16:06.536317  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8185	3.125	80.5104	0	90.4335	5.46875	88.3669	0	84.4392	0	84.7982	0	77.2994	0	29.843	2.5	
I0519 02:16:06.612323  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.90972	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:16:06.614588  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:16:06.614632  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:16:06.636004  4008 solver.cpp:260]     Total regularization terms: 0.964377 loss+regular. : 2.39402
I0519 02:17:27.098597  4008 solver.cpp:231] Iteration 280400, loss = 1.28467
I0519 02:17:27.098913  4008 solver.cpp:247]     Train net output #0: loss = 1.28467 (* 1 = 1.28467 loss)
I0519 02:17:27.098929  4008 sgd_solver.cpp:106] Iteration 280400, lr = 0.001
I0519 02:17:27.258756  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0452	3.125	80.5472	0	90.441	5.46875	88.3403	0	84.4643	0	84.8068	0	77.3103	0	29.8483	2.5	
I0519 02:17:27.333135  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.90972	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:17:27.335023  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:17:27.335053  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:17:27.349912  4008 solver.cpp:260]     Total regularization terms: 0.96423 loss+regular. : 2.2489
I0519 02:18:46.193799  4008 solver.cpp:231] Iteration 280600, loss = 1.31164
I0519 02:18:46.197664  4008 solver.cpp:247]     Train net output #0: loss = 1.31164 (* 1 = 1.31164 loss)
I0519 02:18:46.197696  4008 sgd_solver.cpp:106] Iteration 280600, lr = 0.001
I0519 02:18:46.353655  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1141	3.125	80.2858	0	90.4387	5.46875	88.3548	0	84.4614	0	84.8152	0	77.3213	0	29.8533	2.5	
I0519 02:18:46.428457  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.90972	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:18:46.430989  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:18:46.431044  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:18:46.449715  4008 solver.cpp:260]     Total regularization terms: 0.96411 loss+regular. : 2.27575
I0519 02:20:08.296311  4008 solver.cpp:231] Iteration 280800, loss = 1.42161
I0519 02:20:08.296571  4008 solver.cpp:247]     Train net output #0: loss = 1.42161 (* 1 = 1.42161 loss)
I0519 02:20:08.296592  4008 sgd_solver.cpp:106] Iteration 280800, lr = 0.001
I0519 02:20:08.456935  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1801	3.125	80.4896	0	90.4694	5.46875	88.3709	0	84.4625	0	84.8235	0	77.3322	0	29.8588	2.5	
I0519 02:20:08.531894  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.90972	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:20:08.534085  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:20:08.534133  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:20:08.544082  4008 solver.cpp:260]     Total regularization terms: 0.963988 loss+regular. : 2.3856
I0519 02:21:23.223506  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:21:30.516309  4008 solver.cpp:348] Iteration 281000, Testing net (#0)
I0519 02:22:52.349165  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:22:53.394408  4008 solver.cpp:415]     Test net output #0: accuracy = 0.554579
I0519 02:22:53.394546  4008 solver.cpp:415]     Test net output #1: loss = 1.91894 (* 1 = 1.91894 loss)
I0519 02:22:53.481947  4008 solver.cpp:231] Iteration 281000, loss = 1.54249
I0519 02:22:53.482055  4008 solver.cpp:247]     Train net output #0: loss = 1.54249 (* 1 = 1.54249 loss)
I0519 02:22:53.482116  4008 sgd_solver.cpp:106] Iteration 281000, lr = 0.001
I0519 02:22:53.650323  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2547	3.125	80.5898	0	90.5003	5.46875	88.3968	0	84.4903	0	84.8321	0	77.3432	0	29.8641	2.5	
I0519 02:22:53.725733  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.90972	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:22:53.728024  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.17188	0	0	5.46875	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:22:53.728070  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:22:53.738013  4008 solver.cpp:260]     Total regularization terms: 0.963807 loss+regular. : 2.5063
I0519 02:24:16.810278  4008 solver.cpp:231] Iteration 281200, loss = 1.36392
I0519 02:24:16.810760  4008 solver.cpp:247]     Train net output #0: loss = 1.36392 (* 1 = 1.36392 loss)
I0519 02:24:16.810782  4008 sgd_solver.cpp:106] Iteration 281200, lr = 0.001
I0519 02:24:16.971175  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8817	3.125	80.1911	0	90.4166	5.72917	88.3195	0	84.4699	0	84.8405	0	77.3543	0	29.8698	2.5	
I0519 02:24:17.046664  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.90972	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:24:17.049367  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.72917	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:24:17.049419  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:24:17.059588  4008 solver.cpp:260]     Total regularization terms: 0.963715 loss+regular. : 2.32763
I0519 02:25:46.421613  4008 solver.cpp:231] Iteration 281400, loss = 1.30514
I0519 02:25:46.421954  4008 solver.cpp:247]     Train net output #0: loss = 1.30514 (* 1 = 1.30514 loss)
I0519 02:25:46.421974  4008 sgd_solver.cpp:106] Iteration 281400, lr = 0.001
I0519 02:25:46.581460  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0883	3.125	80.6536	0	90.446	5.98958	88.3665	0	84.5014	0	84.8491	0	77.3658	0	29.8753	2.5	
I0519 02:25:46.656510  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:25:46.659062  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:25:46.659121  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:25:46.669142  4008 solver.cpp:260]     Total regularization terms: 0.9636 loss+regular. : 2.26874
I0519 02:27:13.936061  4008 solver.cpp:231] Iteration 281600, loss = 1.52775
I0519 02:27:13.936419  4008 solver.cpp:247]     Train net output #0: loss = 1.52775 (* 1 = 1.52775 loss)
I0519 02:27:13.936463  4008 sgd_solver.cpp:106] Iteration 281600, lr = 0.001
I0519 02:27:14.096941  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3437	3.125	80.266	0	90.4417	5.98958	88.3106	0	84.4679	0	84.8574	0	77.3765	0	29.8809	2.5	
I0519 02:27:14.176126  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:27:14.178028  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:27:14.178088  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:27:14.189673  4008 solver.cpp:260]     Total regularization terms: 0.963568 loss+regular. : 2.49132
I0519 02:28:48.855576  4008 solver.cpp:231] Iteration 281800, loss = 1.34285
I0519 02:28:48.861696  4008 solver.cpp:247]     Train net output #0: loss = 1.34285 (* 1 = 1.34285 loss)
I0519 02:28:48.861732  4008 sgd_solver.cpp:106] Iteration 281800, lr = 0.001
I0519 02:28:49.015914  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9677	3.125	80.387	0	90.4248	5.98958	88.3219	0	84.4828	0	84.8659	0	77.3873	0	29.8856	2.5	
I0519 02:28:49.090600  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:28:49.092578  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:28:49.092628  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:28:49.102663  4008 solver.cpp:260]     Total regularization terms: 0.963423 loss+regular. : 2.30628
I0519 02:30:15.780787  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:30:20.301805  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_282000.caffemodel
I0519 02:33:43.081146  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_282000.solverstate
I0519 02:33:44.128509  4008 solver.cpp:348] Iteration 282000, Testing net (#0)
I0519 02:35:11.375203  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:35:11.936076  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55226
I0519 02:35:11.936169  4008 solver.cpp:415]     Test net output #1: loss = 1.92992 (* 1 = 1.92992 loss)
I0519 02:35:12.025259  4008 solver.cpp:231] Iteration 282000, loss = 1.40911
I0519 02:35:12.025353  4008 solver.cpp:247]     Train net output #0: loss = 1.40911 (* 1 = 1.40911 loss)
I0519 02:35:12.025372  4008 sgd_solver.cpp:106] Iteration 282000, lr = 0.001
I0519 02:35:12.183996  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3781	3.125	80.4785	0	90.4408	5.98958	88.3524	0	84.4935	0	84.8744	0	77.3985	0	29.8908	2.5	
I0519 02:35:12.185744  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:35:12.187886  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:35:12.187932  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:35:12.199136  4008 solver.cpp:260]     Total regularization terms: 0.963276 loss+regular. : 2.37238
I0519 02:36:35.962880  4008 solver.cpp:231] Iteration 282200, loss = 1.64515
I0519 02:36:35.963327  4008 solver.cpp:247]     Train net output #0: loss = 1.64515 (* 1 = 1.64515 loss)
I0519 02:36:35.963358  4008 sgd_solver.cpp:106] Iteration 282200, lr = 0.001
I0519 02:36:36.123333  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0969	3.125	80.5241	0	90.4689	5.98958	88.3557	0	84.5197	0	84.8826	0	77.4098	0	29.8959	2.5	
I0519 02:36:36.198124  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:36:36.200095  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:36:36.200152  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:36:36.210067  4008 solver.cpp:260]     Total regularization terms: 0.9632 loss+regular. : 2.60835
I0519 02:38:05.099081  4008 solver.cpp:231] Iteration 282400, loss = 1.33555
I0519 02:38:05.099447  4008 solver.cpp:247]     Train net output #0: loss = 1.33555 (* 1 = 1.33555 loss)
I0519 02:38:05.099470  4008 sgd_solver.cpp:106] Iteration 282400, lr = 0.001
I0519 02:38:05.259809  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0624	3.125	80.6025	0	90.4679	5.98958	88.4127	0	84.5362	0	84.8905	0	77.4205	0	29.9012	2.5	
I0519 02:38:05.334952  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:38:05.337494  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:38:05.337574  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:38:05.347445  4008 solver.cpp:260]     Total regularization terms: 0.963009 loss+regular. : 2.29856
I0519 02:39:34.285434  4008 solver.cpp:231] Iteration 282600, loss = 1.35062
I0519 02:39:34.285670  4008 solver.cpp:247]     Train net output #0: loss = 1.35062 (* 1 = 1.35062 loss)
I0519 02:39:34.285692  4008 sgd_solver.cpp:106] Iteration 282600, lr = 0.001
I0519 02:39:34.446894  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2404	3.125	80.21	0	90.4539	5.98958	88.3937	0	84.5251	0	84.8989	0	77.4312	0	29.9064	2.5	
I0519 02:39:34.521368  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:39:34.523234  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:39:34.523316  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:39:34.533093  4008 solver.cpp:260]     Total regularization terms: 0.962969 loss+regular. : 2.31359
I0519 02:40:57.121726  4008 solver.cpp:231] Iteration 282800, loss = 1.3275
I0519 02:40:57.122146  4008 solver.cpp:247]     Train net output #0: loss = 1.3275 (* 1 = 1.3275 loss)
I0519 02:40:57.122165  4008 sgd_solver.cpp:106] Iteration 282800, lr = 0.001
I0519 02:40:57.281152  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4814	3.125	80.4974	0	90.4895	5.98958	88.4089	0	84.5287	0	84.9073	0	77.4421	0	29.9114	2.5	
I0519 02:40:57.355453  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:40:57.357234  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:40:57.357259  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:40:57.372114  4008 solver.cpp:260]     Total regularization terms: 0.962752 loss+regular. : 2.29025
I0519 02:42:25.661819  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:42:26.464411  4008 solver.cpp:348] Iteration 283000, Testing net (#0)
I0519 02:43:41.747339  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55344
I0519 02:43:41.747653  4008 solver.cpp:415]     Test net output #1: loss = 1.91752 (* 1 = 1.91752 loss)
I0519 02:43:41.871049  4008 solver.cpp:231] Iteration 283000, loss = 1.4294
I0519 02:43:41.871129  4008 solver.cpp:247]     Train net output #0: loss = 1.4294 (* 1 = 1.4294 loss)
I0519 02:43:41.871147  4008 sgd_solver.cpp:106] Iteration 283000, lr = 0.001
I0519 02:43:42.030866  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4613	3.125	80.627	0	90.4683	5.98958	88.3925	0	84.5448	0	84.9155	0	77.4524	0	29.9167	2.5	
I0519 02:43:42.105484  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:43:42.107079  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:43:42.107110  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:43:42.116821  4008 solver.cpp:260]     Total regularization terms: 0.962598 loss+regular. : 2.392
I0519 02:43:43.242724  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:44:59.931290  4008 solver.cpp:231] Iteration 283200, loss = 1.16985
I0519 02:44:59.932122  4008 solver.cpp:247]     Train net output #0: loss = 1.16985 (* 1 = 1.16985 loss)
I0519 02:44:59.932147  4008 sgd_solver.cpp:106] Iteration 283200, lr = 0.001
I0519 02:45:00.091684  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3638	3.125	80.7067	0	90.5266	5.98958	88.4268	0	84.55	0	84.9241	0	77.4629	0	29.9223	2.5	
I0519 02:45:00.167004  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:45:00.170001  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.5	
I0519 02:45:00.170091  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:45:00.180217  4008 solver.cpp:260]     Total regularization terms: 0.962434 loss+regular. : 2.13229
I0519 02:46:45.736639  4008 solver.cpp:231] Iteration 283400, loss = 1.37851
I0519 02:46:45.736943  4008 solver.cpp:247]     Train net output #0: loss = 1.37851 (* 1 = 1.37851 loss)
I0519 02:46:45.736964  4008 sgd_solver.cpp:106] Iteration 283400, lr = 0.001
I0519 02:46:45.897032  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.5675	3.125	80.5928	0	90.5002	5.98958	88.4185	0	84.5366	0	84.9325	0	77.4734	0	29.9283	2.6	
I0519 02:46:45.971813  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:46:45.974055  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 02:46:45.974107  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:46:45.984165  4008 solver.cpp:260]     Total regularization terms: 0.962378 loss+regular. : 2.34089
I0519 02:48:21.105164  4008 solver.cpp:231] Iteration 283600, loss = 1.45189
I0519 02:48:21.105545  4008 solver.cpp:247]     Train net output #0: loss = 1.45189 (* 1 = 1.45189 loss)
I0519 02:48:21.105584  4008 sgd_solver.cpp:106] Iteration 283600, lr = 0.001
I0519 02:48:21.264889  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3064	3.125	80.348	0	90.4298	5.98958	88.424	0	84.5622	0	84.9407	0	77.4837	0	29.9338	2.6	
I0519 02:48:21.340106  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:48:21.342886  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 02:48:21.342932  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:48:21.352726  4008 solver.cpp:260]     Total regularization terms: 0.962256 loss+regular. : 2.41415
I0519 02:49:55.394354  4008 solver.cpp:231] Iteration 283800, loss = 1.41862
I0519 02:49:55.394614  4008 solver.cpp:247]     Train net output #0: loss = 1.41862 (* 1 = 1.41862 loss)
I0519 02:49:55.394637  4008 sgd_solver.cpp:106] Iteration 283800, lr = 0.001
I0519 02:49:55.554126  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4958	3.125	80.7324	0	90.4813	5.98958	88.4408	0	84.5662	0	84.9492	0	77.4948	0	29.9393	2.6	
I0519 02:49:55.631009  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:49:55.634326  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 02:49:55.634377  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:49:55.644384  4008 solver.cpp:260]     Total regularization terms: 0.962083 loss+regular. : 2.3807
I0519 02:51:34.669315  4008 solver.cpp:348] Iteration 284000, Testing net (#0)
I0519 02:51:35.268798  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:52:56.529041  4008 solver.cpp:415]     Test net output #0: accuracy = 0.552139
I0519 02:52:56.529436  4008 solver.cpp:415]     Test net output #1: loss = 1.926 (* 1 = 1.926 loss)
I0519 02:52:56.624220  4008 solver.cpp:231] Iteration 284000, loss = 1.48241
I0519 02:52:56.624322  4008 solver.cpp:247]     Train net output #0: loss = 1.48241 (* 1 = 1.48241 loss)
I0519 02:52:56.624344  4008 sgd_solver.cpp:106] Iteration 284000, lr = 0.001
I0519 02:52:56.783324  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3551	3.125	80.6722	0	90.4877	5.98958	88.4439	0	84.5608	0	84.9575	0	77.5056	0	29.9453	2.6	
I0519 02:52:56.860685  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:52:56.863778  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 02:52:56.863836  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:52:56.873945  4008 solver.cpp:260]     Total regularization terms: 0.961964 loss+regular. : 2.44437
I0519 02:53:01.243775  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 02:54:29.758471  4008 solver.cpp:231] Iteration 284200, loss = 1.52195
I0519 02:54:29.759115  4008 solver.cpp:247]     Train net output #0: loss = 1.52195 (* 1 = 1.52195 loss)
I0519 02:54:29.759143  4008 sgd_solver.cpp:106] Iteration 284200, lr = 0.001
I0519 02:54:29.916947  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1141	3.125	80.6683	0	90.4774	5.98958	88.4665	0	84.5647	0	84.9656	0	77.5163	0	29.9506	2.6	
I0519 02:54:29.992923  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:54:29.996253  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 02:54:29.996301  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:54:30.006150  4008 solver.cpp:260]     Total regularization terms: 0.961794 loss+regular. : 2.48375
I0519 02:55:57.406623  4008 solver.cpp:231] Iteration 284400, loss = 1.41846
I0519 02:55:57.410344  4008 solver.cpp:247]     Train net output #0: loss = 1.41846 (* 1 = 1.41846 loss)
I0519 02:55:57.410401  4008 sgd_solver.cpp:106] Iteration 284400, lr = 0.001
I0519 02:55:57.566081  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.226	3.125	80.8509	0	90.5056	5.98958	88.4889	0	84.5836	0	84.9739	0	77.5271	0	29.9561	2.6	
I0519 02:55:57.642328  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:55:57.646070  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 02:55:57.646122  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:55:57.662530  4008 solver.cpp:260]     Total regularization terms: 0.961688 loss+regular. : 2.38015
I0519 02:57:27.901244  4008 solver.cpp:231] Iteration 284600, loss = 1.12495
I0519 02:57:27.902825  4008 solver.cpp:247]     Train net output #0: loss = 1.12495 (* 1 = 1.12495 loss)
I0519 02:57:27.902861  4008 sgd_solver.cpp:106] Iteration 284600, lr = 0.001
I0519 02:57:28.061450  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.853	3.125	80.5381	0	90.4926	5.98958	88.4641	0	84.5836	0	84.9821	0	77.5382	0	29.9619	2.6	
I0519 02:57:28.137642  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:57:28.141625  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 02:57:28.141695  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:57:28.151916  4008 solver.cpp:260]     Total regularization terms: 0.961582 loss+regular. : 2.08654
I0519 02:59:02.126987  4008 solver.cpp:231] Iteration 284800, loss = 1.36764
I0519 02:59:02.127313  4008 solver.cpp:247]     Train net output #0: loss = 1.36764 (* 1 = 1.36764 loss)
I0519 02:59:02.127333  4008 sgd_solver.cpp:106] Iteration 284800, lr = 0.001
I0519 02:59:02.287071  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.358	3.125	80.5859	0	90.4861	5.98958	88.4377	0	84.5839	0	84.9903	0	77.5486	0	29.9673	2.6	
I0519 02:59:02.361829  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 02:59:02.363636  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 02:59:02.363692  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 02:59:02.373735  4008 solver.cpp:260]     Total regularization terms: 0.961533 loss+regular. : 2.32917
I0519 03:00:44.945523  4008 solver.cpp:348] Iteration 285000, Testing net (#0)
I0519 03:00:46.334986  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:02:08.699071  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55524
I0519 03:02:08.699364  4008 solver.cpp:415]     Test net output #1: loss = 1.90683 (* 1 = 1.90683 loss)
I0519 03:02:08.825464  4008 solver.cpp:231] Iteration 285000, loss = 1.32466
I0519 03:02:08.833662  4008 solver.cpp:247]     Train net output #0: loss = 1.32466 (* 1 = 1.32466 loss)
I0519 03:02:08.833725  4008 sgd_solver.cpp:106] Iteration 285000, lr = 0.001
I0519 03:02:08.978004  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2691	3.125	80.4137	0	90.4941	5.98958	88.4491	0	84.5785	0	84.9984	0	77.5595	0	29.9729	2.6	
I0519 03:02:09.053719  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:02:09.057049  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:02:09.057096  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:02:09.067178  4008 solver.cpp:260]     Total regularization terms: 0.961459 loss+regular. : 2.28612
I0519 03:02:16.960465  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:03:28.406432  4008 solver.cpp:231] Iteration 285200, loss = 1.37506
I0519 03:03:28.406790  4008 solver.cpp:247]     Train net output #0: loss = 1.37506 (* 1 = 1.37506 loss)
I0519 03:03:28.406816  4008 sgd_solver.cpp:106] Iteration 285200, lr = 0.001
I0519 03:03:28.566213  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1112	3.125	80.6191	0	90.5105	5.98958	88.4714	0	84.5898	0	85.0067	0	77.5702	0	29.9783	2.6	
I0519 03:03:28.643836  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:03:28.646006  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:03:28.646044  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:03:28.655913  4008 solver.cpp:260]     Total regularization terms: 0.961345 loss+regular. : 2.33641
I0519 03:04:51.218761  4008 solver.cpp:231] Iteration 285400, loss = 1.5556
I0519 03:04:51.219120  4008 solver.cpp:247]     Train net output #0: loss = 1.5556 (* 1 = 1.5556 loss)
I0519 03:04:51.219146  4008 sgd_solver.cpp:106] Iteration 285400, lr = 0.001
I0519 03:04:51.380390  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1284	3.125	80.556	0	90.4743	5.98958	88.4577	0	84.5968	0	85.0152	0	77.581	0	29.9838	2.6	
I0519 03:04:51.456710  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:04:51.460074  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:04:51.460144  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:04:51.470484  4008 solver.cpp:260]     Total regularization terms: 0.961162 loss+regular. : 2.51676
I0519 03:06:17.272702  4008 solver.cpp:231] Iteration 285600, loss = 1.59007
I0519 03:06:17.273214  4008 solver.cpp:247]     Train net output #0: loss = 1.59007 (* 1 = 1.59007 loss)
I0519 03:06:17.273242  4008 sgd_solver.cpp:106] Iteration 285600, lr = 0.001
I0519 03:06:17.432770  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0711	3.125	80.3744	0	90.4965	5.98958	88.4968	0	84.6072	0	85.0236	0	77.5918	0	29.9891	2.6	
I0519 03:06:17.507721  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:06:17.510390  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:06:17.510450  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:06:17.520377  4008 solver.cpp:260]     Total regularization terms: 0.961084 loss+regular. : 2.55115
I0519 03:07:43.947896  4008 solver.cpp:231] Iteration 285800, loss = 1.42732
I0519 03:07:43.948175  4008 solver.cpp:247]     Train net output #0: loss = 1.42732 (* 1 = 1.42732 loss)
I0519 03:07:43.948329  4008 sgd_solver.cpp:106] Iteration 285800, lr = 0.001
I0519 03:07:44.108376  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2002	3.125	80.7041	0	90.5081	5.98958	88.4978	0	84.6264	0	85.0319	0	77.6024	0	29.9946	2.6	
I0519 03:07:44.184152  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:07:44.187026  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:07:44.187069  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:07:44.196746  4008 solver.cpp:260]     Total regularization terms: 0.96094 loss+regular. : 2.38826
I0519 03:09:27.831003  4008 solver.cpp:348] Iteration 286000, Testing net (#0)
I0519 03:09:29.507789  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:10:36.922886  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55502
I0519 03:10:36.923161  4008 solver.cpp:415]     Test net output #1: loss = 1.92288 (* 1 = 1.92288 loss)
I0519 03:10:37.013031  4008 solver.cpp:231] Iteration 286000, loss = 1.17128
I0519 03:10:37.013109  4008 solver.cpp:247]     Train net output #0: loss = 1.17128 (* 1 = 1.17128 loss)
I0519 03:10:37.013129  4008 sgd_solver.cpp:106] Iteration 286000, lr = 0.001
I0519 03:10:37.181323  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0567	3.125	80.7646	0	90.5388	5.98958	88.5165	0	84.6359	0	85.0401	0	77.6132	0	29.9999	2.6	
I0519 03:10:37.256433  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:10:37.258219  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:10:37.258256  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:10:37.268447  4008 solver.cpp:260]     Total regularization terms: 0.960747 loss+regular. : 2.13203
I0519 03:10:45.973201  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:11:57.411753  4008 solver.cpp:231] Iteration 286200, loss = 1.49926
I0519 03:11:57.412775  4008 solver.cpp:247]     Train net output #0: loss = 1.49926 (* 1 = 1.49926 loss)
I0519 03:11:57.412799  4008 sgd_solver.cpp:106] Iteration 286200, lr = 0.001
I0519 03:11:57.571943  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0969	3.125	80.654	0	90.5454	5.98958	88.5142	0	84.6121	0	85.0483	0	77.6234	0	30.0051	2.6	
I0519 03:11:57.647831  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.95312	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:11:57.649796  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:11:57.649830  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:11:57.659662  4008 solver.cpp:260]     Total regularization terms: 0.960609 loss+regular. : 2.45987
I0519 03:13:23.826982  4008 solver.cpp:231] Iteration 286400, loss = 1.71689
I0519 03:13:23.827642  4008 solver.cpp:247]     Train net output #0: loss = 1.71689 (* 1 = 1.71689 loss)
I0519 03:13:23.827666  4008 sgd_solver.cpp:106] Iteration 286400, lr = 0.001
I0519 03:13:23.987423  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2748	3.125	80.7712	0	90.5428	5.98958	88.4958	0	84.6282	0	85.0565	0	77.6336	0	30.0105	2.6	
I0519 03:13:24.063225  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.99653	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:13:24.065177  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:13:24.065203  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:13:24.079982  4008 solver.cpp:260]     Total regularization terms: 0.960518 loss+regular. : 2.67741
I0519 03:14:43.738968  4008 solver.cpp:231] Iteration 286600, loss = 1.32
I0519 03:14:43.739226  4008 solver.cpp:247]     Train net output #0: loss = 1.32 (* 1 = 1.32 loss)
I0519 03:14:43.739260  4008 sgd_solver.cpp:106] Iteration 286600, lr = 0.001
I0519 03:14:43.899538  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4269	3.125	80.4609	0	90.548	5.98958	88.4898	0	84.6497	0	85.0646	0	77.6442	0	30.0157	2.6	
I0519 03:14:43.974853  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.99653	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:14:43.976508  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:14:43.976532  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:14:43.996553  4008 solver.cpp:260]     Total regularization terms: 0.960436 loss+regular. : 2.28044
I0519 03:16:08.276969  4008 solver.cpp:231] Iteration 286800, loss = 1.47165
I0519 03:16:08.277325  4008 solver.cpp:247]     Train net output #0: loss = 1.47165 (* 1 = 1.47165 loss)
I0519 03:16:08.277356  4008 sgd_solver.cpp:106] Iteration 286800, lr = 0.001
I0519 03:16:08.436524  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4211	3.125	80.6045	0	90.5457	5.98958	88.5163	0	84.6628	0	85.0724	0	77.6551	0	30.0209	2.6	
I0519 03:16:08.521831  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	1.99653	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:16:08.524677  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:16:08.524709  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:16:08.534775  4008 solver.cpp:260]     Total regularization terms: 0.960242 loss+regular. : 2.43189
I0519 03:17:41.306346  4008 solver.cpp:348] Iteration 287000, Testing net (#0)
I0519 03:17:43.418586  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:19:01.340021  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55064
I0519 03:19:01.340301  4008 solver.cpp:415]     Test net output #1: loss = 1.93791 (* 1 = 1.93791 loss)
I0519 03:19:01.430994  4008 solver.cpp:231] Iteration 287000, loss = 1.52676
I0519 03:19:01.431077  4008 solver.cpp:247]     Train net output #0: loss = 1.52676 (* 1 = 1.52676 loss)
I0519 03:19:01.431128  4008 sgd_solver.cpp:106] Iteration 287000, lr = 0.001
I0519 03:19:01.595027  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.5618	3.125	80.5866	0	90.5285	5.98958	88.4925	0	84.6553	0	85.0804	0	77.6657	0	30.0259	2.6	
I0519 03:19:01.676041  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:19:01.677917  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:19:01.677950  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:19:01.688781  4008 solver.cpp:260]     Total regularization terms: 0.960139 loss+regular. : 2.4869
I0519 03:19:16.587136  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:20:23.168334  4008 solver.cpp:231] Iteration 287200, loss = 1.48826
I0519 03:20:23.168725  4008 solver.cpp:247]     Train net output #0: loss = 1.48826 (* 1 = 1.48826 loss)
I0519 03:20:23.168754  4008 sgd_solver.cpp:106] Iteration 287200, lr = 0.001
I0519 03:20:23.330170  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1744	3.125	80.4453	0	90.4935	5.98958	88.5005	0	84.6171	0	85.0885	0	77.6762	0	30.0317	2.6	
I0519 03:20:23.404717  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:20:23.406486  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:20:23.406527  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:20:23.416563  4008 solver.cpp:260]     Total regularization terms: 0.9601 loss+regular. : 2.44836
I0519 03:21:41.300793  4008 solver.cpp:231] Iteration 287400, loss = 1.49574
I0519 03:21:41.301033  4008 solver.cpp:247]     Train net output #0: loss = 1.49574 (* 1 = 1.49574 loss)
I0519 03:21:41.301053  4008 sgd_solver.cpp:106] Iteration 287400, lr = 0.001
I0519 03:21:41.461446  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.16	3.125	80.4984	0	90.5281	5.98958	88.5185	0	84.642	0	85.0965	0	77.6869	0	30.0373	2.6	
I0519 03:21:41.536437  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:21:41.538916  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:21:41.538961  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:21:41.548935  4008 solver.cpp:260]     Total regularization terms: 0.959959 loss+regular. : 2.4557
I0519 03:23:11.095427  4008 solver.cpp:231] Iteration 287600, loss = 1.37137
I0519 03:23:11.095726  4008 solver.cpp:247]     Train net output #0: loss = 1.37137 (* 1 = 1.37137 loss)
I0519 03:23:11.095749  4008 sgd_solver.cpp:106] Iteration 287600, lr = 0.001
I0519 03:23:11.256752  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4326	3.125	80.5114	0	90.5429	5.98958	88.5148	0	84.6402	0	85.1044	0	77.6976	0	30.0427	2.6	
I0519 03:23:11.333084  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:23:11.336030  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:23:11.336084  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:23:11.346030  4008 solver.cpp:260]     Total regularization terms: 0.959867 loss+regular. : 2.33124
I0519 03:24:36.657572  4008 solver.cpp:231] Iteration 287800, loss = 1.52155
I0519 03:24:36.657907  4008 solver.cpp:247]     Train net output #0: loss = 1.52155 (* 1 = 1.52155 loss)
I0519 03:24:36.657934  4008 sgd_solver.cpp:106] Iteration 287800, lr = 0.001
I0519 03:24:36.818809  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.6278	3.125	80.5228	0	90.5277	5.98958	88.5084	0	84.6386	0	85.1126	0	77.7078	0	30.0481	2.6	
I0519 03:24:36.893818  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:24:36.896275  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:24:36.896318  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:24:36.911617  4008 solver.cpp:260]     Total regularization terms: 0.959771 loss+regular. : 2.48132
I0519 03:26:03.382397  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_288000.caffemodel
I0519 03:28:15.036821  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_288000.solverstate
I0519 03:28:15.801025  4008 solver.cpp:348] Iteration 288000, Testing net (#0)
I0519 03:28:19.391835  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:29:57.560240  4008 solver.cpp:415]     Test net output #0: accuracy = 0.553519
I0519 03:29:57.560497  4008 solver.cpp:415]     Test net output #1: loss = 1.92095 (* 1 = 1.92095 loss)
I0519 03:29:57.652161  4008 solver.cpp:231] Iteration 288000, loss = 1.44681
I0519 03:29:57.652253  4008 solver.cpp:247]     Train net output #0: loss = 1.44681 (* 1 = 1.44681 loss)
I0519 03:29:57.652278  4008 sgd_solver.cpp:106] Iteration 288000, lr = 0.001
I0519 03:29:57.812109  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.292	3.125	80.6784	0	90.5457	5.98958	88.5248	0	84.644	0	85.1206	0	77.7183	0	30.0533	2.6	
I0519 03:29:57.814538  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:29:57.817675  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:29:57.817728  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:29:57.829376  4008 solver.cpp:260]     Total regularization terms: 0.959636 loss+regular. : 2.40645
I0519 03:30:14.557299  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:31:22.546983  4008 solver.cpp:231] Iteration 288200, loss = 1.51717
I0519 03:31:22.547243  4008 solver.cpp:247]     Train net output #0: loss = 1.51717 (* 1 = 1.51717 loss)
I0519 03:31:22.547265  4008 sgd_solver.cpp:106] Iteration 288200, lr = 0.001
I0519 03:31:22.707424  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3207	3.125	80.763	0	90.5557	5.98958	88.5304	0	84.6634	0	85.1285	0	77.7283	0	30.0585	2.6	
I0519 03:31:22.782791  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:31:22.785264  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:31:22.785305  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:31:22.797694  4008 solver.cpp:260]     Total regularization terms: 0.959458 loss+regular. : 2.47662
I0519 03:32:46.056315  4008 solver.cpp:231] Iteration 288400, loss = 1.44161
I0519 03:32:46.057633  4008 solver.cpp:247]     Train net output #0: loss = 1.44161 (* 1 = 1.44161 loss)
I0519 03:32:46.057725  4008 sgd_solver.cpp:106] Iteration 288400, lr = 0.001
I0519 03:32:46.217675  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3523	3.125	80.5804	0	90.5296	5.98958	88.5604	0	84.6829	0	85.1366	0	77.7388	0	30.064	2.6	
I0519 03:32:46.293072  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:32:46.296121  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:32:46.296181  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:32:46.305938  4008 solver.cpp:260]     Total regularization terms: 0.959325 loss+regular. : 2.40094
I0519 03:34:19.825300  4008 solver.cpp:231] Iteration 288600, loss = 1.49827
I0519 03:34:19.825597  4008 solver.cpp:247]     Train net output #0: loss = 1.49827 (* 1 = 1.49827 loss)
I0519 03:34:19.825616  4008 sgd_solver.cpp:106] Iteration 288600, lr = 0.001
I0519 03:34:19.985096  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3494	3.125	80.444	0	90.5659	5.98958	88.5754	0	84.6861	0	85.1446	0	77.7496	0	30.0697	2.6	
I0519 03:34:20.059887  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:34:20.061861  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:34:20.061903  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:34:20.071822  4008 solver.cpp:260]     Total regularization terms: 0.959196 loss+regular. : 2.45746
I0519 03:35:50.344753  4008 solver.cpp:231] Iteration 288800, loss = 1.32948
I0519 03:35:50.345299  4008 solver.cpp:247]     Train net output #0: loss = 1.32948 (* 1 = 1.32948 loss)
I0519 03:35:50.345329  4008 sgd_solver.cpp:106] Iteration 288800, lr = 0.001
I0519 03:35:50.502565  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4929	3.125	80.1921	0	90.5639	5.98958	88.5136	0	84.6413	0	85.1526	0	77.7604	0	30.0747	2.6	
I0519 03:35:50.577991  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:35:50.580088  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:35:50.580127  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:35:50.589908  4008 solver.cpp:260]     Total regularization terms: 0.959118 loss+regular. : 2.2886
I0519 03:37:17.447922  4008 solver.cpp:348] Iteration 289000, Testing net (#0)
I0519 03:37:20.824085  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:38:39.811038  4008 solver.cpp:415]     Test net output #0: accuracy = 0.552
I0519 03:38:39.811307  4008 solver.cpp:415]     Test net output #1: loss = 1.92604 (* 1 = 1.92604 loss)
I0519 03:38:39.902633  4008 solver.cpp:231] Iteration 289000, loss = 1.39329
I0519 03:38:39.902712  4008 solver.cpp:247]     Train net output #0: loss = 1.39329 (* 1 = 1.39329 loss)
I0519 03:38:39.902730  4008 sgd_solver.cpp:106] Iteration 289000, lr = 0.001
I0519 03:38:40.062604  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1543	3.125	80.5986	0	90.5814	5.98958	88.5787	0	84.6845	0	85.1605	0	77.7707	0	30.08	2.6	
I0519 03:38:40.138531  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:38:40.141674  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:38:40.141731  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:38:40.151664  4008 solver.cpp:260]     Total regularization terms: 0.958944 loss+regular. : 2.35224
I0519 03:38:57.505650  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:40:08.218127  4008 solver.cpp:231] Iteration 289200, loss = 1.40243
I0519 03:40:08.220012  4008 solver.cpp:247]     Train net output #0: loss = 1.40243 (* 1 = 1.40243 loss)
I0519 03:40:08.220052  4008 sgd_solver.cpp:106] Iteration 289200, lr = 0.001
I0519 03:40:08.379521  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3695	3.125	80.6416	0	90.6005	5.98958	88.6202	0	84.7102	0	85.1684	0	77.7809	0	30.0853	2.6	
I0519 03:40:08.455904  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:40:08.459729  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:40:08.459789  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:40:08.469877  4008 solver.cpp:260]     Total regularization terms: 0.958768 loss+regular. : 2.3612
I0519 03:41:32.257437  4008 solver.cpp:231] Iteration 289400, loss = 1.37019
I0519 03:41:32.260046  4008 solver.cpp:247]     Train net output #0: loss = 1.37019 (* 1 = 1.37019 loss)
I0519 03:41:32.260149  4008 sgd_solver.cpp:106] Iteration 289400, lr = 0.001
I0519 03:41:32.417632  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3437	3.125	80.7614	0	90.5992	5.98958	88.6066	0	84.7209	0	85.1761	0	77.7914	0	30.0909	2.6	
I0519 03:41:32.493698  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:41:32.496791  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:41:32.496830  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:41:32.506639  4008 solver.cpp:260]     Total regularization terms: 0.958668 loss+regular. : 2.32886
I0519 03:43:06.152218  4008 solver.cpp:231] Iteration 289600, loss = 1.42866
I0519 03:43:06.152601  4008 solver.cpp:247]     Train net output #0: loss = 1.42866 (* 1 = 1.42866 loss)
I0519 03:43:06.152623  4008 sgd_solver.cpp:106] Iteration 289600, lr = 0.001
I0519 03:43:06.311230  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0768	3.125	80.611	0	90.5669	5.98958	88.5869	0	84.7331	0	85.184	0	77.8021	0	30.0968	2.6	
I0519 03:43:06.387593  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:43:06.390137  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:43:06.390189  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:43:06.405267  4008 solver.cpp:260]     Total regularization terms: 0.9585 loss+regular. : 2.38716
I0519 03:44:42.231266  4008 solver.cpp:231] Iteration 289800, loss = 1.36708
I0519 03:44:42.231708  4008 solver.cpp:247]     Train net output #0: loss = 1.36708 (* 1 = 1.36708 loss)
I0519 03:44:42.231739  4008 sgd_solver.cpp:106] Iteration 289800, lr = 0.001
I0519 03:44:42.392612  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4498	3.125	80.8818	0	90.5875	5.98958	88.6013	0	84.7272	0	85.1922	0	77.8126	0	30.1021	2.6	
I0519 03:44:42.474478  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:44:42.477270  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:44:42.477331  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:44:42.487205  4008 solver.cpp:260]     Total regularization terms: 0.958339 loss+regular. : 2.32542
I0519 03:46:11.106444  4008 solver.cpp:348] Iteration 290000, Testing net (#0)
I0519 03:46:16.636533  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:47:29.944150  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55608
I0519 03:47:29.944380  4008 solver.cpp:415]     Test net output #1: loss = 1.91597 (* 1 = 1.91597 loss)
I0519 03:47:30.034503  4008 solver.cpp:231] Iteration 290000, loss = 1.53141
I0519 03:47:30.034572  4008 solver.cpp:247]     Train net output #0: loss = 1.53141 (* 1 = 1.53141 loss)
I0519 03:47:30.034589  4008 sgd_solver.cpp:106] Iteration 290000, lr = 0.001
I0519 03:47:30.200703  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0682	3.125	80.6328	0	90.5914	5.98958	88.5762	0	84.7401	0	85.2	0	77.823	0	30.1083	2.6	
I0519 03:47:30.276825  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:47:30.279314  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:47:30.279356  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:47:30.289124  4008 solver.cpp:260]     Total regularization terms: 0.958264 loss+regular. : 2.48968
I0519 03:47:49.507457  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:48:49.014705  4008 solver.cpp:231] Iteration 290200, loss = 1.28695
I0519 03:48:49.014917  4008 solver.cpp:247]     Train net output #0: loss = 1.28695 (* 1 = 1.28695 loss)
I0519 03:48:49.014936  4008 sgd_solver.cpp:106] Iteration 290200, lr = 0.001
I0519 03:48:49.174324  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2317	3.125	80.7673	0	90.5835	5.98958	88.5717	0	84.7227	0	85.2079	0	77.8331	0	30.1128	2.6	
I0519 03:48:49.249797  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:48:49.251807  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:48:49.251832  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:48:49.265285  4008 solver.cpp:260]     Total regularization terms: 0.958184 loss+regular. : 2.24514
I0519 03:50:14.824949  4008 solver.cpp:231] Iteration 290400, loss = 1.39815
I0519 03:50:14.825268  4008 solver.cpp:247]     Train net output #0: loss = 1.39815 (* 1 = 1.39815 loss)
I0519 03:50:14.825299  4008 sgd_solver.cpp:106] Iteration 290400, lr = 0.001
I0519 03:50:14.985337  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3293	3.125	80.7878	0	90.5633	5.98958	88.524	0	84.7378	0	85.2161	0	77.8434	0	30.1179	2.6	
I0519 03:50:15.060353  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:50:15.062896  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:50:15.062932  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:50:15.072654  4008 solver.cpp:260]     Total regularization terms: 0.958054 loss+regular. : 2.35621
I0519 03:51:38.421473  4008 solver.cpp:231] Iteration 290600, loss = 1.4916
I0519 03:51:38.422364  4008 solver.cpp:247]     Train net output #0: loss = 1.4916 (* 1 = 1.4916 loss)
I0519 03:51:38.422387  4008 sgd_solver.cpp:106] Iteration 290600, lr = 0.001
I0519 03:51:38.582331  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3322	3.125	80.5443	0	90.5814	5.98958	88.5712	0	84.7324	0	85.2243	0	77.8534	0	30.1236	2.6	
I0519 03:51:38.657377  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:51:38.660053  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:51:38.660111  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:51:38.669947  4008 solver.cpp:260]     Total regularization terms: 0.957981 loss+regular. : 2.44958
I0519 03:53:01.331790  4008 solver.cpp:231] Iteration 290800, loss = 1.2776
I0519 03:53:01.332057  4008 solver.cpp:247]     Train net output #0: loss = 1.2776 (* 1 = 1.2776 loss)
I0519 03:53:01.332075  4008 sgd_solver.cpp:106] Iteration 290800, lr = 0.001
I0519 03:53:01.492956  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8128	3.125	80.7819	0	90.6311	5.98958	88.603	0	84.7441	0	85.2319	0	77.8636	0	30.1288	2.6	
I0519 03:53:01.567662  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:53:01.569797  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:53:01.569835  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:53:01.579625  4008 solver.cpp:260]     Total regularization terms: 0.957873 loss+regular. : 2.23548
I0519 03:54:21.552793  4008 solver.cpp:348] Iteration 291000, Testing net (#0)
I0519 03:54:25.848454  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:55:40.580452  4008 solver.cpp:415]     Test net output #0: accuracy = 0.553099
I0519 03:55:40.581862  4008 solver.cpp:415]     Test net output #1: loss = 1.92184 (* 1 = 1.92184 loss)
I0519 03:55:40.672235  4008 solver.cpp:231] Iteration 291000, loss = 1.51489
I0519 03:55:40.672305  4008 solver.cpp:247]     Train net output #0: loss = 1.51489 (* 1 = 1.51489 loss)
I0519 03:55:40.672323  4008 sgd_solver.cpp:106] Iteration 291000, lr = 0.001
I0519 03:55:40.843713  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0079	3.125	80.6738	0	90.6101	5.98958	88.6259	0	84.7396	0	85.2396	0	77.8742	0	30.1335	2.6	
I0519 03:55:40.919576  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:55:40.922477  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:55:40.922521  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:55:40.932907  4008 solver.cpp:260]     Total regularization terms: 0.957781 loss+regular. : 2.47267
I0519 03:56:05.259820  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 03:56:58.657531  4008 solver.cpp:231] Iteration 291200, loss = 1.31811
I0519 03:56:58.657861  4008 solver.cpp:247]     Train net output #0: loss = 1.31811 (* 1 = 1.31811 loss)
I0519 03:56:58.657881  4008 sgd_solver.cpp:106] Iteration 291200, lr = 0.001
I0519 03:56:58.818723  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2978	3.125	80.598	0	90.6053	5.98958	88.6075	0	84.7286	0	85.2472	0	77.8841	0	30.1387	2.6	
I0519 03:56:58.894618  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:56:58.896494  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:56:58.896529  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:56:58.911711  4008 solver.cpp:260]     Total regularization terms: 0.957596 loss+regular. : 2.27571
I0519 03:58:25.879508  4008 solver.cpp:231] Iteration 291400, loss = 1.38345
I0519 03:58:25.880064  4008 solver.cpp:247]     Train net output #0: loss = 1.38345 (* 1 = 1.38345 loss)
I0519 03:58:25.880084  4008 sgd_solver.cpp:106] Iteration 291400, lr = 0.001
I0519 03:58:26.039403  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1801	3.125	80.7874	0	90.5669	5.98958	88.6136	0	84.7371	0	85.2553	0	77.8942	0	30.1436	2.6	
I0519 03:58:26.115389  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:58:26.117780  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:58:26.117806  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:58:26.138139  4008 solver.cpp:260]     Total regularization terms: 0.957542 loss+regular. : 2.34099
I0519 03:59:56.172632  4008 solver.cpp:231] Iteration 291600, loss = 1.44107
I0519 03:59:56.177675  4008 solver.cpp:247]     Train net output #0: loss = 1.44107 (* 1 = 1.44107 loss)
I0519 03:59:56.177707  4008 sgd_solver.cpp:106] Iteration 291600, lr = 0.001
I0519 03:59:56.332664  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0452	3.125	80.7933	0	90.6062	5.98958	88.6054	0	84.7107	0	85.2632	0	77.904	0	30.1489	2.6	
I0519 03:59:56.407732  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 03:59:56.410300  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 03:59:56.410346  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 03:59:56.420169  4008 solver.cpp:260]     Total regularization terms: 0.9575 loss+regular. : 2.39857
I0519 04:01:27.772740  4008 solver.cpp:231] Iteration 291800, loss = 1.83811
I0519 04:01:27.773028  4008 solver.cpp:247]     Train net output #0: loss = 1.83811 (* 1 = 1.83811 loss)
I0519 04:01:27.773051  4008 sgd_solver.cpp:106] Iteration 291800, lr = 0.001
I0519 04:01:27.931588  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3408	3.125	80.776	0	90.6108	5.98958	88.6414	0	84.7408	0	85.2709	0	77.9138	0	30.1549	2.6	
I0519 04:01:28.007542  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:01:28.009799  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:01:28.009845  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:01:28.023411  4008 solver.cpp:260]     Total regularization terms: 0.957294 loss+regular. : 2.79541
I0519 04:02:56.905393  4008 solver.cpp:348] Iteration 292000, Testing net (#0)
I0519 04:03:01.621645  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:04:12.740651  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5494
I0519 04:04:12.741034  4008 solver.cpp:415]     Test net output #1: loss = 1.93575 (* 1 = 1.93575 loss)
I0519 04:04:12.828950  4008 solver.cpp:231] Iteration 292000, loss = 1.4527
I0519 04:04:12.829020  4008 solver.cpp:247]     Train net output #0: loss = 1.4527 (* 1 = 1.4527 loss)
I0519 04:04:12.829049  4008 sgd_solver.cpp:106] Iteration 292000, lr = 0.001
I0519 04:04:12.997622  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.49	3.125	80.1077	0	90.5882	5.98958	88.6063	0	84.7613	0	85.2786	0	77.924	0	30.1601	2.6	
I0519 04:04:13.072566  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:04:13.074960  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:04:13.075029  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:04:13.084930  4008 solver.cpp:260]     Total regularization terms: 0.957253 loss+regular. : 2.40995
I0519 04:04:41.774670  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:05:35.457774  4008 solver.cpp:231] Iteration 292200, loss = 1.4209
I0519 04:05:35.458008  4008 solver.cpp:247]     Train net output #0: loss = 1.4209 (* 1 = 1.4209 loss)
I0519 04:05:35.458026  4008 sgd_solver.cpp:106] Iteration 292200, lr = 0.001
I0519 04:05:35.617913  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1801	3.125	80.3571	0	90.5514	5.98958	88.6349	0	84.767	0	85.2862	0	77.9344	0	30.1657	2.6	
I0519 04:05:35.694106  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:05:35.696848  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:05:35.696897  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:05:35.711184  4008 solver.cpp:260]     Total regularization terms: 0.957138 loss+regular. : 2.37804
I0519 04:06:55.118552  4008 solver.cpp:231] Iteration 292400, loss = 1.40272
I0519 04:06:55.120095  4008 solver.cpp:247]     Train net output #0: loss = 1.40272 (* 1 = 1.40272 loss)
I0519 04:06:55.120132  4008 sgd_solver.cpp:106] Iteration 292400, lr = 0.001
I0519 04:06:55.279587  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2088	3.125	80.6667	0	90.6263	5.98958	88.6568	0	84.7971	0	85.2939	0	77.9442	0	30.1715	2.6	
I0519 04:06:55.354671  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:06:55.357377  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:06:55.357417  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:06:55.367342  4008 solver.cpp:260]     Total regularization terms: 0.956972 loss+regular. : 2.35969
I0519 04:08:23.793756  4008 solver.cpp:231] Iteration 292600, loss = 1.49464
I0519 04:08:23.793999  4008 solver.cpp:247]     Train net output #0: loss = 1.49464 (* 1 = 1.49464 loss)
I0519 04:08:23.794020  4008 sgd_solver.cpp:106] Iteration 292600, lr = 0.001
I0519 04:08:23.952627  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2317	3.125	80.2666	0	90.5985	5.98958	88.6604	0	84.7763	0	85.3017	0	77.9545	0	30.1768	2.6	
I0519 04:08:24.027817  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:08:24.030900  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:08:24.030951  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:08:24.041015  4008 solver.cpp:260]     Total regularization terms: 0.956888 loss+regular. : 2.45153
I0519 04:09:42.247130  4008 solver.cpp:231] Iteration 292800, loss = 1.29756
I0519 04:09:42.247362  4008 solver.cpp:247]     Train net output #0: loss = 1.29756 (* 1 = 1.29756 loss)
I0519 04:09:42.247383  4008 sgd_solver.cpp:106] Iteration 292800, lr = 0.001
I0519 04:09:42.406728  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.0538	3.125	80.5957	0	90.6207	5.98958	88.6609	0	84.7846	0	85.3097	0	77.965	0	30.1814	2.6	
I0519 04:09:42.482623  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:09:42.485157  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:09:42.485198  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:09:42.506353  4008 solver.cpp:260]     Total regularization terms: 0.956711 loss+regular. : 2.25427
I0519 04:10:58.783815  4008 solver.cpp:348] Iteration 293000, Testing net (#0)
I0519 04:11:04.676481  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:12:25.140064  4008 solver.cpp:415]     Test net output #0: accuracy = 0.557979
I0519 04:12:25.140362  4008 solver.cpp:415]     Test net output #1: loss = 1.90575 (* 1 = 1.90575 loss)
I0519 04:12:25.231278  4008 solver.cpp:231] Iteration 293000, loss = 1.43589
I0519 04:12:25.231351  4008 solver.cpp:247]     Train net output #0: loss = 1.43589 (* 1 = 1.43589 loss)
I0519 04:12:25.231369  4008 sgd_solver.cpp:106] Iteration 293000, lr = 0.001
I0519 04:12:25.406036  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.16	3.125	80.9235	0	90.6405	5.98958	88.6636	0	84.8041	0	85.3175	0	77.9752	0	30.1868	2.6	
I0519 04:12:25.481021  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:12:25.483209  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:12:25.483253  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:12:25.493140  4008 solver.cpp:260]     Total regularization terms: 0.956588 loss+regular. : 2.39248
I0519 04:12:59.319597  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:13:54.656966  4008 solver.cpp:231] Iteration 293200, loss = 1.41421
I0519 04:13:54.657227  4008 solver.cpp:247]     Train net output #0: loss = 1.41421 (* 1 = 1.41421 loss)
I0519 04:13:54.657248  4008 sgd_solver.cpp:106] Iteration 293200, lr = 0.001
I0519 04:13:54.817345  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3896	3.125	80.8112	0	90.6378	5.98958	88.6687	0	84.8169	0	85.3253	0	77.9855	0	30.1916	2.6	
I0519 04:13:54.892495  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:13:54.895282  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:13:54.895328  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:13:54.910483  4008 solver.cpp:260]     Total regularization terms: 0.956435 loss+regular. : 2.37064
I0519 04:15:16.137454  4008 solver.cpp:231] Iteration 293400, loss = 1.24507
I0519 04:15:16.139390  4008 solver.cpp:247]     Train net output #0: loss = 1.24507 (* 1 = 1.24507 loss)
I0519 04:15:16.139508  4008 sgd_solver.cpp:106] Iteration 293400, lr = 0.001
I0519 04:15:16.298665  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.424	3.125	80.7633	0	90.6365	5.98958	88.6503	0	84.8282	0	85.3331	0	77.9963	0	30.1969	2.6	
I0519 04:15:16.375169  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:15:16.377503  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:15:16.377545  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:15:16.407565  4008 solver.cpp:260]     Total regularization terms: 0.956355 loss+regular. : 2.20142
I0519 04:16:44.337267  4008 solver.cpp:231] Iteration 293600, loss = 1.33737
I0519 04:16:44.337579  4008 solver.cpp:247]     Train net output #0: loss = 1.33737 (* 1 = 1.33737 loss)
I0519 04:16:44.337607  4008 sgd_solver.cpp:106] Iteration 293600, lr = 0.001
I0519 04:16:44.498066  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1428	3.125	80.7669	0	90.6343	5.98958	88.6868	0	84.8262	0	85.3407	0	78.0064	0	30.2016	2.6	
I0519 04:16:44.576967  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:16:44.578922  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:16:44.578979  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:16:44.589067  4008 solver.cpp:260]     Total regularization terms: 0.956277 loss+regular. : 2.29365
I0519 04:18:04.246093  4008 solver.cpp:231] Iteration 293800, loss = 1.30609
I0519 04:18:04.246422  4008 solver.cpp:247]     Train net output #0: loss = 1.30609 (* 1 = 1.30609 loss)
I0519 04:18:04.246443  4008 sgd_solver.cpp:106] Iteration 293800, lr = 0.001
I0519 04:18:04.407568  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.645	3.125	80.902	0	90.6477	5.98958	88.6674	0	84.8407	0	85.3482	0	78.0165	0	30.2072	2.6	
I0519 04:18:04.484843  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:18:04.486621  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:18:04.486685  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:18:04.501806  4008 solver.cpp:260]     Total regularization terms: 0.956141 loss+regular. : 2.26223
I0519 04:19:29.901751  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_294000.caffemodel
I0519 04:21:05.863659  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_294000.solverstate
I0519 04:21:06.634843  4008 solver.cpp:348] Iteration 294000, Testing net (#0)
I0519 04:21:13.056120  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:22:24.710212  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55128
I0519 04:22:24.710512  4008 solver.cpp:415]     Test net output #1: loss = 1.93185 (* 1 = 1.93185 loss)
I0519 04:22:24.798216  4008 solver.cpp:231] Iteration 294000, loss = 1.43943
I0519 04:22:24.798295  4008 solver.cpp:247]     Train net output #0: loss = 1.43943 (* 1 = 1.43943 loss)
I0519 04:22:24.798313  4008 sgd_solver.cpp:106] Iteration 294000, lr = 0.001
I0519 04:22:24.964756  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3695	3.125	80.8249	0	90.6685	5.98958	88.6365	0	84.8088	0	85.356	0	78.0266	0	30.2136	2.6	
I0519 04:22:24.967208  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:22:24.970051  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:22:24.970094  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:22:24.983284  4008 solver.cpp:260]     Total regularization terms: 0.955998 loss+regular. : 2.39543
I0519 04:22:57.513324  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:23:43.721030  4008 solver.cpp:231] Iteration 294200, loss = 1.36885
I0519 04:23:43.725641  4008 solver.cpp:247]     Train net output #0: loss = 1.36885 (* 1 = 1.36885 loss)
I0519 04:23:43.725669  4008 sgd_solver.cpp:106] Iteration 294200, lr = 0.001
I0519 04:23:43.882913  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.5331	3.125	80.874	0	90.658	5.98958	88.6808	0	84.8262	0	85.3639	0	78.0372	0	30.219	2.6	
I0519 04:23:43.958667  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:23:43.960294  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:23:43.960319  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:23:43.981659  4008 solver.cpp:260]     Total regularization terms: 0.955819 loss+regular. : 2.32467
I0519 04:25:06.149081  4008 solver.cpp:231] Iteration 294400, loss = 1.39924
I0519 04:25:06.152271  4008 solver.cpp:247]     Train net output #0: loss = 1.39924 (* 1 = 1.39924 loss)
I0519 04:25:06.152313  4008 sgd_solver.cpp:106] Iteration 294400, lr = 0.001
I0519 04:25:06.310070  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3178	3.125	80.5127	0	90.6462	5.98958	88.6286	0	84.8291	0	85.3717	0	78.0472	0	30.2244	2.6	
I0519 04:25:06.385268  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:25:06.388002  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:25:06.388046  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:25:06.397941  4008 solver.cpp:260]     Total regularization terms: 0.955822 loss+regular. : 2.35507
I0519 04:26:23.932770  4008 solver.cpp:231] Iteration 294600, loss = 1.31105
I0519 04:26:23.937685  4008 solver.cpp:247]     Train net output #0: loss = 1.31105 (* 1 = 1.31105 loss)
I0519 04:26:23.937717  4008 sgd_solver.cpp:106] Iteration 294600, lr = 0.001
I0519 04:26:24.094502  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1944	3.125	80.3184	0	90.608	5.98958	88.6378	0	84.8027	0	85.3794	0	78.0569	0	30.2296	2.6	
I0519 04:26:24.169431  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:26:24.171380  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:26:24.171422  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:26:24.183382  4008 solver.cpp:260]     Total regularization terms: 0.955756 loss+regular. : 2.26681
I0519 04:27:49.650522  4008 solver.cpp:231] Iteration 294800, loss = 1.49095
I0519 04:27:49.650902  4008 solver.cpp:247]     Train net output #0: loss = 1.49095 (* 1 = 1.49095 loss)
I0519 04:27:49.650923  4008 sgd_solver.cpp:106] Iteration 294800, lr = 0.001
I0519 04:27:49.810367  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4671	3.125	80.584	0	90.6479	5.98958	88.6705	0	84.8393	0	85.3872	0	78.0665	0	30.2349	2.6	
I0519 04:27:49.886065  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:27:49.888033  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:27:49.888070  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:27:49.901727  4008 solver.cpp:260]     Total regularization terms: 0.955605 loss+regular. : 2.44655
I0519 04:29:10.525373  4008 solver.cpp:348] Iteration 295000, Testing net (#0)
I0519 04:29:17.859017  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:30:23.282064  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55234
I0519 04:30:23.282299  4008 solver.cpp:415]     Test net output #1: loss = 1.92747 (* 1 = 1.92747 loss)
I0519 04:30:23.369774  4008 solver.cpp:231] Iteration 295000, loss = 1.44728
I0519 04:30:23.369869  4008 solver.cpp:247]     Train net output #0: loss = 1.44728 (* 1 = 1.44728 loss)
I0519 04:30:23.369889  4008 sgd_solver.cpp:106] Iteration 295000, lr = 0.001
I0519 04:30:23.535543  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.249	3.125	80.4079	0	90.6	5.98958	88.6372	0	84.8079	0	85.3948	0	78.0758	0	30.2393	2.6	
I0519 04:30:23.610594  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:30:23.612552  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:30:23.612589  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:30:23.622431  4008 solver.cpp:260]     Total regularization terms: 0.955532 loss+regular. : 2.40282
I0519 04:30:57.424932  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:31:40.528556  4008 solver.cpp:231] Iteration 295200, loss = 1.46255
I0519 04:31:40.528926  4008 solver.cpp:247]     Train net output #0: loss = 1.46255 (* 1 = 1.46255 loss)
I0519 04:31:40.528947  4008 sgd_solver.cpp:106] Iteration 295200, lr = 0.001
I0519 04:31:40.688765  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1141	3.125	80.6058	0	90.6634	5.98958	88.6838	0	84.8549	0	85.4024	0	78.0856	0	30.2454	2.6	
I0519 04:31:40.765223  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:31:40.767957  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:31:40.768007  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:31:40.783141  4008 solver.cpp:260]     Total regularization terms: 0.955426 loss+regular. : 2.41797
I0519 04:33:10.593138  4008 solver.cpp:231] Iteration 295400, loss = 1.60824
I0519 04:33:10.593371  4008 solver.cpp:247]     Train net output #0: loss = 1.60824 (* 1 = 1.60824 loss)
I0519 04:33:10.593387  4008 sgd_solver.cpp:106] Iteration 295400, lr = 0.001
I0519 04:33:10.753181  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.579	3.125	80.8503	0	90.6934	5.98958	88.6814	0	84.8606	0	85.4102	0	78.0953	0	30.2504	2.6	
I0519 04:33:10.828197  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:33:10.830549  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:33:10.830621  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:33:10.840510  4008 solver.cpp:260]     Total regularization terms: 0.955322 loss+regular. : 2.56356
I0519 04:34:32.721249  4008 solver.cpp:231] Iteration 295600, loss = 1.36393
I0519 04:34:32.721613  4008 solver.cpp:247]     Train net output #0: loss = 1.36393 (* 1 = 1.36393 loss)
I0519 04:34:32.721683  4008 sgd_solver.cpp:106] Iteration 295600, lr = 0.001
I0519 04:34:32.880769  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2461	3.125	80.5527	0	90.6651	5.98958	88.6621	0	84.8504	0	85.4182	0	78.105	0	30.2557	2.6	
I0519 04:34:32.956593  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:34:32.958508  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:34:32.958539  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:34:32.973418  4008 solver.cpp:260]     Total regularization terms: 0.955224 loss+regular. : 2.31915
I0519 04:35:55.051283  4008 solver.cpp:231] Iteration 295800, loss = 1.40533
I0519 04:35:55.054134  4008 solver.cpp:247]     Train net output #0: loss = 1.40533 (* 1 = 1.40533 loss)
I0519 04:35:55.054165  4008 sgd_solver.cpp:106] Iteration 295800, lr = 0.001
I0519 04:35:55.211293  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2375	3.125	80.7119	0	90.6893	5.98958	88.657	0	84.8563	0	85.4257	0	78.1145	0	30.2604	2.6	
I0519 04:35:55.287797  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:35:55.290549  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:35:55.290596  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:35:55.305711  4008 solver.cpp:260]     Total regularization terms: 0.955153 loss+regular. : 2.36048
I0519 04:37:23.404330  4008 solver.cpp:348] Iteration 296000, Testing net (#0)
I0519 04:37:32.570945  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:38:43.619990  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55422
I0519 04:38:43.620319  4008 solver.cpp:415]     Test net output #1: loss = 1.91042 (* 1 = 1.91042 loss)
I0519 04:38:43.708658  4008 solver.cpp:231] Iteration 296000, loss = 1.38669
I0519 04:38:43.708748  4008 solver.cpp:247]     Train net output #0: loss = 1.38669 (* 1 = 1.38669 loss)
I0519 04:38:43.708768  4008 sgd_solver.cpp:106] Iteration 296000, lr = 0.001
I0519 04:38:43.876170  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2518	3.125	80.8008	0	90.6817	5.98958	88.68	0	84.8504	0	85.4337	0	78.1245	0	30.2657	2.6	
I0519 04:38:43.951351  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.03993	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:38:43.953071  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:38:43.953119  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:38:43.963523  4008 solver.cpp:260]     Total regularization terms: 0.954982 loss+regular. : 2.34167
I0519 04:39:24.976457  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:40:06.854123  4008 solver.cpp:231] Iteration 296200, loss = 1.3119
I0519 04:40:06.854390  4008 solver.cpp:247]     Train net output #0: loss = 1.3119 (* 1 = 1.3119 loss)
I0519 04:40:06.854409  4008 sgd_solver.cpp:106] Iteration 296200, lr = 0.001
I0519 04:40:07.014974  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.8587	3.125	80.4619	0	90.6628	5.98958	88.7068	0	84.852	0	85.4414	0	78.1345	0	30.2701	2.6	
I0519 04:40:07.090680  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.08333	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:40:07.093133  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:40:07.093180  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:40:07.113759  4008 solver.cpp:260]     Total regularization terms: 0.954821 loss+regular. : 2.26673
I0519 04:41:26.345181  4008 solver.cpp:231] Iteration 296400, loss = 1.48322
I0519 04:41:26.345623  4008 solver.cpp:247]     Train net output #0: loss = 1.48322 (* 1 = 1.48322 loss)
I0519 04:41:26.345645  4008 sgd_solver.cpp:106] Iteration 296400, lr = 0.001
I0519 04:41:26.505350  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2748	3.125	80.8568	0	90.6701	5.98958	88.7047	0	84.8773	0	85.4491	0	78.1443	0	30.2759	2.6	
I0519 04:41:26.581130  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.08333	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:41:26.583686  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:41:26.583734  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:41:26.613762  4008 solver.cpp:260]     Total regularization terms: 0.954642 loss+regular. : 2.43786
I0519 04:42:42.101357  4008 solver.cpp:231] Iteration 296600, loss = 1.45297
I0519 04:42:42.101639  4008 solver.cpp:247]     Train net output #0: loss = 1.45297 (* 1 = 1.45297 loss)
I0519 04:42:42.101661  4008 sgd_solver.cpp:106] Iteration 296600, lr = 0.001
I0519 04:42:42.261979  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.5273	3.125	80.4977	0	90.6406	5.98958	88.6862	0	84.8493	0	85.4564	0	78.154	0	30.2806	2.6	
I0519 04:42:42.336341  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.08333	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:42:42.338347  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:42:42.338374  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:42:42.347966  4008 solver.cpp:260]     Total regularization terms: 0.954635 loss+regular. : 2.40761
I0519 04:44:11.805910  4008 solver.cpp:231] Iteration 296800, loss = 1.32563
I0519 04:44:11.806143  4008 solver.cpp:247]     Train net output #0: loss = 1.32563 (* 1 = 1.32563 loss)
I0519 04:44:11.806159  4008 sgd_solver.cpp:106] Iteration 296800, lr = 0.001
I0519 04:44:11.966536  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.5359	3.125	80.5215	0	90.6448	5.98958	88.6913	0	84.8913	0	85.4641	0	78.1643	0	30.2856	2.6	
I0519 04:44:12.042060  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.08333	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:44:12.044203  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:44:12.044221  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:44:12.059118  4008 solver.cpp:260]     Total regularization terms: 0.954499 loss+regular. : 2.28013
I0519 04:45:33.798617  4008 solver.cpp:348] Iteration 297000, Testing net (#0)
I0519 04:45:41.684514  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:46:51.231696  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55052
I0519 04:46:51.231901  4008 solver.cpp:415]     Test net output #1: loss = 1.92989 (* 1 = 1.92989 loss)
I0519 04:46:51.319537  4008 solver.cpp:231] Iteration 297000, loss = 1.42179
I0519 04:46:51.319612  4008 solver.cpp:247]     Train net output #0: loss = 1.42179 (* 1 = 1.42179 loss)
I0519 04:46:51.319629  4008 sgd_solver.cpp:106] Iteration 297000, lr = 0.001
I0519 04:46:51.485579  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2145	3.125	80.2656	0	90.6795	5.98958	88.7094	0	84.8995	0	85.4714	0	78.1741	0	30.2906	2.6	
I0519 04:46:51.560528  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.08333	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:46:51.562894  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:46:51.562942  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:46:51.572832  4008 solver.cpp:260]     Total regularization terms: 0.954421 loss+regular. : 2.37621
I0519 04:47:32.992758  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:48:13.248791  4008 solver.cpp:231] Iteration 297200, loss = 1.29876
I0519 04:48:13.249161  4008 solver.cpp:247]     Train net output #0: loss = 1.29876 (* 1 = 1.29876 loss)
I0519 04:48:13.249181  4008 sgd_solver.cpp:106] Iteration 297200, lr = 0.001
I0519 04:48:13.407394  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.7898	3.125	80.4997	0	90.6556	5.98958	88.7041	0	84.8807	0	85.4788	0	78.1838	0	30.2961	2.6	
I0519 04:48:13.482909  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:48:13.484879  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:48:13.484923  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:48:13.506193  4008 solver.cpp:260]     Total regularization terms: 0.954271 loss+regular. : 2.25303
I0519 04:49:41.373330  4008 solver.cpp:231] Iteration 297400, loss = 1.44531
I0519 04:49:41.373795  4008 solver.cpp:247]     Train net output #0: loss = 1.44531 (* 1 = 1.44531 loss)
I0519 04:49:41.373817  4008 sgd_solver.cpp:106] Iteration 297400, lr = 0.001
I0519 04:49:41.533781  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.381	3.125	80.9329	0	90.7228	5.98958	88.7772	0	84.9234	0	85.4863	0	78.1935	0	30.3007	2.6	
I0519 04:49:41.608502  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:49:41.610281  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:49:41.610321  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:49:41.620198  4008 solver.cpp:260]     Total regularization terms: 0.954066 loss+regular. : 2.39937
I0519 04:51:12.520606  4008 solver.cpp:231] Iteration 297600, loss = 1.44801
I0519 04:51:12.520905  4008 solver.cpp:247]     Train net output #0: loss = 1.44801 (* 1 = 1.44801 loss)
I0519 04:51:12.520925  4008 sgd_solver.cpp:106] Iteration 297600, lr = 0.001
I0519 04:51:12.681419  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.5531	3.125	80.5918	0	90.6971	5.98958	88.7686	0	84.9354	0	85.494	0	78.2031	0	30.3066	2.6	
I0519 04:51:12.756691  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:51:12.759174  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:51:12.759222  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:51:12.769011  4008 solver.cpp:260]     Total regularization terms: 0.95397 loss+regular. : 2.40198
I0519 04:52:32.922070  4008 solver.cpp:231] Iteration 297800, loss = 1.42747
I0519 04:52:32.922353  4008 solver.cpp:247]     Train net output #0: loss = 1.42747 (* 1 = 1.42747 loss)
I0519 04:52:32.922442  4008 sgd_solver.cpp:106] Iteration 297800, lr = 0.001
I0519 04:52:33.081233  4008 sgd_solver.cpp:120]     Element Sparsity %: 
12.9907	3.125	80.9674	0	90.738	5.98958	88.7572	0	84.9141	0	85.5017	0	78.2133	0	30.3113	2.6	
I0519 04:52:33.156791  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:52:33.159734  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:52:33.159785  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:52:33.169636  4008 solver.cpp:260]     Total regularization terms: 0.953806 loss+regular. : 2.38128
I0519 04:53:55.164609  4008 solver.cpp:348] Iteration 298000, Testing net (#0)
I0519 04:54:03.028555  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:55:11.448196  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55482
I0519 04:55:11.448470  4008 solver.cpp:415]     Test net output #1: loss = 1.91559 (* 1 = 1.91559 loss)
I0519 04:55:11.536084  4008 solver.cpp:231] Iteration 298000, loss = 1.35386
I0519 04:55:11.536156  4008 solver.cpp:247]     Train net output #0: loss = 1.35386 (* 1 = 1.35386 loss)
I0519 04:55:11.536180  4008 sgd_solver.cpp:106] Iteration 298000, lr = 0.001
I0519 04:55:11.704499  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2604	3.125	80.679	0	90.7142	5.98958	88.7346	0	84.9413	0	85.5091	0	78.2234	0	30.316	2.6	
I0519 04:55:11.780421  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:55:11.782752  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:55:11.782788  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:55:11.793596  4008 solver.cpp:260]     Total regularization terms: 0.953656 loss+regular. : 2.30752
I0519 04:55:53.707937  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 04:56:30.331064  4008 solver.cpp:231] Iteration 298200, loss = 1.4045
I0519 04:56:30.331444  4008 solver.cpp:247]     Train net output #0: loss = 1.4045 (* 1 = 1.4045 loss)
I0519 04:56:30.331486  4008 sgd_solver.cpp:106] Iteration 298200, lr = 0.001
I0519 04:56:30.491034  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4412	3.125	80.9098	0	90.7089	5.98958	88.7466	0	84.9368	0	85.5165	0	78.2334	0	30.3215	2.6	
I0519 04:56:30.566319  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:56:30.567778  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:56:30.567800  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:56:30.583055  4008 solver.cpp:260]     Total regularization terms: 0.953577 loss+regular. : 2.35807
I0519 04:57:48.835386  4008 solver.cpp:231] Iteration 298400, loss = 1.55614
I0519 04:57:48.836333  4008 solver.cpp:247]     Train net output #0: loss = 1.55614 (* 1 = 1.55614 loss)
I0519 04:57:48.836356  4008 sgd_solver.cpp:106] Iteration 298400, lr = 0.001
I0519 04:57:48.995312  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3638	3.125	80.8415	0	90.7352	5.98958	88.7523	0	84.9234	0	85.5238	0	78.2434	0	30.327	2.6	
I0519 04:57:49.070624  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:57:49.073158  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:57:49.073201  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:57:49.083739  4008 solver.cpp:260]     Total regularization terms: 0.95342 loss+regular. : 2.50956
I0519 04:59:08.188534  4008 solver.cpp:231] Iteration 298600, loss = 1.35141
I0519 04:59:08.188789  4008 solver.cpp:247]     Train net output #0: loss = 1.35141 (* 1 = 1.35141 loss)
I0519 04:59:08.188808  4008 sgd_solver.cpp:106] Iteration 298600, lr = 0.001
I0519 04:59:08.349421  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.1256	3.125	80.3519	0	90.691	5.98958	88.7341	0	84.9227	0	85.5314	0	78.2533	0	30.3319	2.6	
I0519 04:59:08.425462  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 04:59:08.428164  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.6	
I0519 04:59:08.428212  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 04:59:08.443286  4008 solver.cpp:260]     Total regularization terms: 0.953331 loss+regular. : 2.30474
I0519 05:00:31.715890  4008 solver.cpp:231] Iteration 298800, loss = 1.46899
I0519 05:00:31.716151  4008 solver.cpp:247]     Train net output #0: loss = 1.46899 (* 1 = 1.46899 loss)
I0519 05:00:31.716168  4008 sgd_solver.cpp:106] Iteration 298800, lr = 0.001
I0519 05:00:31.874996  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.5618	3.125	80.8682	0	90.7194	5.98958	88.7641	0	84.8981	0	85.5389	0	78.2633	0	30.3377	2.7	
I0519 05:00:31.949580  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:00:31.951539  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:00:31.951583  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:00:31.971724  4008 solver.cpp:260]     Total regularization terms: 0.953175 loss+regular. : 2.42217
I0519 05:01:52.157605  4008 solver.cpp:348] Iteration 299000, Testing net (#0)
I0519 05:02:00.176302  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:03:11.264528  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55256
I0519 05:03:11.264930  4008 solver.cpp:415]     Test net output #1: loss = 1.91725 (* 1 = 1.91725 loss)
I0519 05:03:11.352329  4008 solver.cpp:231] Iteration 299000, loss = 1.35678
I0519 05:03:11.352407  4008 solver.cpp:247]     Train net output #0: loss = 1.35678 (* 1 = 1.35678 loss)
I0519 05:03:11.352424  4008 sgd_solver.cpp:106] Iteration 299000, lr = 0.001
I0519 05:03:11.515676  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.315	3.125	80.266	0	90.7477	5.98958	88.7795	0	84.93	0	85.5463	0	78.2731	0	30.3427	2.7	
I0519 05:03:11.591286  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:03:11.594121  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:03:11.594171  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:03:11.604080  4008 solver.cpp:260]     Total regularization terms: 0.953064 loss+regular. : 2.30984
I0519 05:03:59.837316  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:04:32.217187  4008 solver.cpp:231] Iteration 299200, loss = 1.42885
I0519 05:04:32.217525  4008 solver.cpp:247]     Train net output #0: loss = 1.42885 (* 1 = 1.42885 loss)
I0519 05:04:32.217545  4008 sgd_solver.cpp:106] Iteration 299200, lr = 0.001
I0519 05:04:32.378237  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.3896	3.125	80.7158	0	90.7637	5.98958	88.7956	0	84.9508	0	85.5535	0	78.2827	0	30.3484	2.7	
I0519 05:04:32.454625  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:04:32.457219  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:04:32.457260  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:04:32.471401  4008 solver.cpp:260]     Total regularization terms: 0.95291 loss+regular. : 2.38176
I0519 05:05:51.894891  4008 solver.cpp:231] Iteration 299400, loss = 1.22333
I0519 05:05:51.895278  4008 solver.cpp:247]     Train net output #0: loss = 1.22333 (* 1 = 1.22333 loss)
I0519 05:05:51.895316  4008 sgd_solver.cpp:106] Iteration 299400, lr = 0.001
I0519 05:05:52.054816  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2375	3.125	80.6273	0	90.7122	5.98958	88.7502	0	84.9557	0	85.5613	0	78.2925	0	30.3534	2.7	
I0519 05:05:52.129508  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:05:52.131352  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:05:52.131398  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:05:52.145984  4008 solver.cpp:260]     Total regularization terms: 0.95286 loss+regular. : 2.17619
I0519 05:07:15.905673  4008 solver.cpp:231] Iteration 299600, loss = 1.3048
I0519 05:07:15.906035  4008 solver.cpp:247]     Train net output #0: loss = 1.3048 (* 1 = 1.3048 loss)
I0519 05:07:15.906065  4008 sgd_solver.cpp:106] Iteration 299600, lr = 0.001
I0519 05:07:16.065786  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4757	3.125	80.667	0	90.7439	5.98958	88.7751	0	84.9456	0	85.5685	0	78.3025	0	30.3587	2.7	
I0519 05:07:16.141504  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:07:16.144547  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:07:16.144595  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:07:16.154562  4008 solver.cpp:260]     Total regularization terms: 0.95271 loss+regular. : 2.25751
I0519 05:08:45.975374  4008 solver.cpp:231] Iteration 299800, loss = 1.31314
I0519 05:08:45.975761  4008 solver.cpp:247]     Train net output #0: loss = 1.31314 (* 1 = 1.31314 loss)
I0519 05:08:45.975957  4008 sgd_solver.cpp:106] Iteration 299800, lr = 0.001
I0519 05:08:46.135519  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.2289	3.125	80.8105	0	90.7412	5.98958	88.7745	0	84.9356	0	85.5759	0	78.3123	0	30.3646	2.7	
I0519 05:08:46.210607  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:08:46.213277  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:08:46.213341  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:08:46.223425  4008 solver.cpp:260]     Total regularization terms: 0.952645 loss+regular. : 2.26578
I0519 05:10:17.493496  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_300000.caffemodel
I0519 05:13:41.307842  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_300000.solverstate
I0519 05:13:41.872257  4008 solver.cpp:348] Iteration 300000, Testing net (#0)
I0519 05:13:50.912132  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:15:02.488306  4008 solver.cpp:415]     Test net output #0: accuracy = 0.55402
I0519 05:15:02.488626  4008 solver.cpp:415]     Test net output #1: loss = 1.92188 (* 1 = 1.92188 loss)
I0519 05:15:02.579679  4008 solver.cpp:231] Iteration 300000, loss = 1.28631
I0519 05:15:02.579771  4008 solver.cpp:247]     Train net output #0: loss = 1.28631 (* 1 = 1.28631 loss)
I0519 05:15:02.579795  4008 sgd_solver.cpp:46] MultiStep Status: Iteration 300000, step = 1
I0519 05:15:02.579808  4008 sgd_solver.cpp:106] Iteration 300000, lr = 0.0001
I0519 05:15:02.746592  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.4326	3.125	80.4372	0	90.7374	5.98958	88.7974	0	84.9763	0	85.5834	0	78.3221	0	30.3702	2.7	
I0519 05:15:02.748932  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:15:02.751549  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:15:02.751602  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:15:02.761528  4008 solver.cpp:260]     Total regularization terms: 0.952534 loss+regular. : 2.23884
I0519 05:16:00.864356  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:16:33.073043  4008 solver.cpp:231] Iteration 300200, loss = 1.48434
I0519 05:16:33.073668  4008 solver.cpp:247]     Train net output #0: loss = 1.48434 (* 1 = 1.48434 loss)
I0519 05:16:33.073694  4008 sgd_solver.cpp:106] Iteration 300200, lr = 0.0001
I0519 05:16:33.232923  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.5761	3.125	80.7611	0	90.7806	5.98958	88.8263	0	84.9985	0	85.5841	0	78.3229	0	30.3706	2.7	
I0519 05:16:33.308756  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:16:33.311877  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:16:33.311933  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:16:33.322240  4008 solver.cpp:260]     Total regularization terms: 0.952431 loss+regular. : 2.43677
I0519 05:18:04.730089  4008 solver.cpp:231] Iteration 300400, loss = 1.42169
I0519 05:18:04.730451  4008 solver.cpp:247]     Train net output #0: loss = 1.42169 (* 1 = 1.42169 loss)
I0519 05:18:04.730489  4008 sgd_solver.cpp:106] Iteration 300400, lr = 0.0001
I0519 05:18:04.890514  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.6278	3.125	80.8555	0	90.7957	5.98958	88.836	0	85.0039	0	85.5843	0	78.3231	0	30.3707	2.7	
I0519 05:18:04.966555  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:18:04.970737  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:18:04.970793  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:18:04.981048  4008 solver.cpp:260]     Total regularization terms: 0.952358 loss+regular. : 2.37405
I0519 05:19:33.736946  4008 solver.cpp:231] Iteration 300600, loss = 1.22011
I0519 05:19:33.742429  4008 solver.cpp:247]     Train net output #0: loss = 1.22011 (* 1 = 1.22011 loss)
I0519 05:19:33.742463  4008 sgd_solver.cpp:106] Iteration 300600, lr = 0.0001
I0519 05:19:33.897701  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.6536	3.125	80.9238	0	90.8041	5.98958	88.8467	0	85.0129	0	85.5844	0	78.3233	0	30.3708	2.7	
I0519 05:19:33.972647  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:19:33.974719  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:19:33.974762  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:19:33.986986  4008 solver.cpp:260]     Total regularization terms: 0.952298 loss+regular. : 2.17241
I0519 05:20:59.747709  4008 solver.cpp:231] Iteration 300800, loss = 1.48595
I0519 05:20:59.748236  4008 solver.cpp:247]     Train net output #0: loss = 1.48595 (* 1 = 1.48595 loss)
I0519 05:20:59.748291  4008 sgd_solver.cpp:106] Iteration 300800, lr = 0.0001
I0519 05:20:59.909104  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.6679	3.125	80.9775	0	90.8118	5.98958	88.8524	0	85.0172	0	85.5845	0	78.3234	0	30.3708	2.7	
I0519 05:20:59.985105  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:20:59.988394  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:20:59.988478  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:20:59.998790  4008 solver.cpp:260]     Total regularization terms: 0.952243 loss+regular. : 2.43819
I0519 05:22:17.899842  4008 solver.cpp:348] Iteration 301000, Testing net (#0)
I0519 05:22:27.074813  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:23:32.350862  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56306
I0519 05:23:32.351073  4008 solver.cpp:415]     Test net output #1: loss = 1.87399 (* 1 = 1.87399 loss)
I0519 05:23:32.440297  4008 solver.cpp:231] Iteration 301000, loss = 1.35
I0519 05:23:32.440378  4008 solver.cpp:247]     Train net output #0: loss = 1.35 (* 1 = 1.35 loss)
I0519 05:23:32.440395  4008 sgd_solver.cpp:106] Iteration 301000, lr = 0.0001
I0519 05:23:32.599514  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.6995	3.125	81.0127	0	90.8191	5.98958	88.8565	0	85.0213	0	85.5846	0	78.3235	0	30.3708	2.7	
I0519 05:23:32.675742  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:23:32.677683  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:23:32.677729  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:23:32.687501  4008 solver.cpp:260]     Total regularization terms: 0.95219 loss+regular. : 2.30219
I0519 05:24:26.292834  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:24:50.270562  4008 solver.cpp:231] Iteration 301200, loss = 1.18847
I0519 05:24:50.270651  4008 solver.cpp:247]     Train net output #0: loss = 1.18847 (* 1 = 1.18847 loss)
I0519 05:24:50.270668  4008 sgd_solver.cpp:106] Iteration 301200, lr = 0.0001
I0519 05:24:50.431365  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.7167	3.125	81.0417	0	90.8247	5.98958	88.8616	0	85.0265	0	85.5847	0	78.3236	0	30.3709	2.7	
I0519 05:24:50.506835  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:24:50.508685  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:24:50.508718  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:24:50.523710  4008 solver.cpp:260]     Total regularization terms: 0.952145 loss+regular. : 2.14062
I0519 05:26:12.803524  4008 solver.cpp:231] Iteration 301400, loss = 1.35901
I0519 05:26:12.803835  4008 solver.cpp:247]     Train net output #0: loss = 1.35901 (* 1 = 1.35901 loss)
I0519 05:26:12.803869  4008 sgd_solver.cpp:106] Iteration 301400, lr = 0.0001
I0519 05:26:12.962735  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.7397	3.125	81.0771	0	90.8292	5.98958	88.8672	0	85.0292	0	85.5848	0	78.3238	0	30.3709	2.7	
I0519 05:26:13.037214  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:26:13.039125  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:26:13.039172  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:26:13.048949  4008 solver.cpp:260]     Total regularization terms: 0.952089 loss+regular. : 2.3111
I0519 05:27:32.272441  4008 solver.cpp:231] Iteration 301600, loss = 1.43804
I0519 05:27:32.272775  4008 solver.cpp:247]     Train net output #0: loss = 1.43804 (* 1 = 1.43804 loss)
I0519 05:27:32.272797  4008 sgd_solver.cpp:106] Iteration 301600, lr = 0.0001
I0519 05:27:32.432075  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.754	3.125	81.1035	0	90.8346	5.98958	88.87	0	85.0326	0	85.5849	0	78.324	0	30.3709	2.7	
I0519 05:27:32.506741  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:27:32.508867  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:27:32.508903  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:27:32.518666  4008 solver.cpp:260]     Total regularization terms: 0.952041 loss+regular. : 2.39008
I0519 05:28:56.206037  4008 solver.cpp:231] Iteration 301800, loss = 1.34296
I0519 05:28:56.206329  4008 solver.cpp:247]     Train net output #0: loss = 1.34296 (* 1 = 1.34296 loss)
I0519 05:28:56.206347  4008 sgd_solver.cpp:106] Iteration 301800, lr = 0.0001
I0519 05:28:56.382886  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.7741	3.125	81.1244	0	90.8417	5.98958	88.8746	0	85.036	0	85.585	0	78.3241	0	30.3711	2.7	
I0519 05:28:56.457516  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:28:56.459231  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:28:56.459256  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:28:56.469012  4008 solver.cpp:260]     Total regularization terms: 0.951989 loss+regular. : 2.29495
I0519 05:30:24.308708  4008 solver.cpp:348] Iteration 302000, Testing net (#0)
I0519 05:30:34.456491  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:31:39.560138  4008 solver.cpp:415]     Test net output #0: accuracy = 0.563539
I0519 05:31:39.560457  4008 solver.cpp:415]     Test net output #1: loss = 1.87127 (* 1 = 1.87127 loss)
I0519 05:31:39.654404  4008 solver.cpp:231] Iteration 302000, loss = 1.31868
I0519 05:31:39.654485  4008 solver.cpp:247]     Train net output #0: loss = 1.31868 (* 1 = 1.31868 loss)
I0519 05:31:39.654503  4008 sgd_solver.cpp:106] Iteration 302000, lr = 0.0001
I0519 05:31:39.814052  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.7885	3.125	81.1442	0	90.8479	5.98958	88.8797	0	85.0389	0	85.5851	0	78.3243	0	30.3711	2.7	
I0519 05:31:39.889124  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:31:39.891156  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:31:39.891203  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:31:39.903617  4008 solver.cpp:260]     Total regularization terms: 0.951925 loss+regular. : 2.2706
I0519 05:32:30.812012  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:32:52.349534  4008 solver.cpp:231] Iteration 302200, loss = 1.09447
I0519 05:32:52.349647  4008 solver.cpp:247]     Train net output #0: loss = 1.09447 (* 1 = 1.09447 loss)
I0519 05:32:52.349664  4008 sgd_solver.cpp:106] Iteration 302200, lr = 0.0001
I0519 05:32:52.511912  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.7971	3.125	81.1758	0	90.8542	5.98958	88.8826	0	85.0425	0	85.5852	0	78.3244	0	30.3712	2.7	
I0519 05:32:52.587153  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:32:52.588762  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:32:52.588835  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:32:52.603029  4008 solver.cpp:260]     Total regularization terms: 0.951882 loss+regular. : 2.04635
I0519 05:34:12.212282  4008 solver.cpp:231] Iteration 302400, loss = 1.17867
I0519 05:34:12.212652  4008 solver.cpp:247]     Train net output #0: loss = 1.17867 (* 1 = 1.17867 loss)
I0519 05:34:12.212684  4008 sgd_solver.cpp:106] Iteration 302400, lr = 0.0001
I0519 05:34:12.372290  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8085	3.125	81.1875	0	90.8588	5.98958	88.8859	0	85.0446	0	85.5853	0	78.3246	0	30.3714	2.7	
I0519 05:34:12.447808  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:34:12.449455  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:34:12.449496  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:34:12.470829  4008 solver.cpp:260]     Total regularization terms: 0.951833 loss+regular. : 2.1305
I0519 05:35:28.897510  4008 solver.cpp:231] Iteration 302600, loss = 1.3661
I0519 05:35:28.897936  4008 solver.cpp:247]     Train net output #0: loss = 1.3661 (* 1 = 1.3661 loss)
I0519 05:35:28.897958  4008 sgd_solver.cpp:106] Iteration 302600, lr = 0.0001
I0519 05:35:29.058181  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8114	3.125	81.2083	0	90.8628	5.98958	88.8892	0	85.0484	0	85.5853	0	78.3247	0	30.3714	2.7	
I0519 05:35:29.132800  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:35:29.134876  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:35:29.134919  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:35:29.144819  4008 solver.cpp:260]     Total regularization terms: 0.951778 loss+regular. : 2.31788
I0519 05:36:50.152827  4008 solver.cpp:231] Iteration 302800, loss = 1.51393
I0519 05:36:50.153093  4008 solver.cpp:247]     Train net output #0: loss = 1.51393 (* 1 = 1.51393 loss)
I0519 05:36:50.153125  4008 sgd_solver.cpp:106] Iteration 302800, lr = 0.0001
I0519 05:36:50.311830  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8143	3.125	81.2334	0	90.8678	5.98958	88.8925	0	85.0511	0	85.5854	0	78.3248	0	30.3715	2.7	
I0519 05:36:50.387341  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:36:50.390399  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:36:50.390456  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:36:50.400879  4008 solver.cpp:260]     Total regularization terms: 0.951733 loss+regular. : 2.46567
I0519 05:38:19.651541  4008 solver.cpp:348] Iteration 303000, Testing net (#0)
I0519 05:38:32.484153  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:39:50.187628  4008 solver.cpp:415]     Test net output #0: accuracy = 0.564579
I0519 05:39:50.188056  4008 solver.cpp:415]     Test net output #1: loss = 1.86728 (* 1 = 1.86728 loss)
I0519 05:39:50.275950  4008 solver.cpp:231] Iteration 303000, loss = 1.36332
I0519 05:39:50.276044  4008 solver.cpp:247]     Train net output #0: loss = 1.36332 (* 1 = 1.36332 loss)
I0519 05:39:50.276062  4008 sgd_solver.cpp:106] Iteration 303000, lr = 0.0001
I0519 05:39:50.441035  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8229	3.125	81.2503	0	90.8714	5.98958	88.8972	0	85.0532	0	85.5855	0	78.3249	0	30.3715	2.7	
I0519 05:39:50.519822  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:39:50.522490  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:39:50.522546  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:39:50.532809  4008 solver.cpp:260]     Total regularization terms: 0.951685 loss+regular. : 2.31501
I0519 05:40:55.944516  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:41:19.265399  4008 solver.cpp:231] Iteration 303200, loss = 1.29672
I0519 05:41:19.265609  4008 solver.cpp:247]     Train net output #0: loss = 1.29672 (* 1 = 1.29672 loss)
I0519 05:41:19.265632  4008 sgd_solver.cpp:106] Iteration 303200, lr = 0.0001
I0519 05:41:19.425251  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8315	3.125	81.2646	0	90.8749	5.98958	88.9016	0	85.0572	0	85.5856	0	78.325	0	30.3716	2.7	
I0519 05:41:19.500051  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:41:19.502266  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:41:19.502321  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:41:19.517354  4008 solver.cpp:260]     Total regularization terms: 0.95164 loss+regular. : 2.24835
I0519 05:42:42.618523  4008 solver.cpp:231] Iteration 303400, loss = 1.27082
I0519 05:42:42.618896  4008 solver.cpp:247]     Train net output #0: loss = 1.27082 (* 1 = 1.27082 loss)
I0519 05:42:42.618929  4008 sgd_solver.cpp:106] Iteration 303400, lr = 0.0001
I0519 05:42:42.778650  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8315	3.125	81.2786	0	90.8799	5.98958	88.9052	0	85.059	0	85.5857	0	78.3251	0	30.3716	2.7	
I0519 05:42:42.854171  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:42:42.856854  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:42:42.856927  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:42:42.866894  4008 solver.cpp:260]     Total regularization terms: 0.951603 loss+regular. : 2.22242
I0519 05:44:37.230242  4008 solver.cpp:231] Iteration 303600, loss = 1.27439
I0519 05:44:37.231199  4008 solver.cpp:247]     Train net output #0: loss = 1.27439 (* 1 = 1.27439 loss)
I0519 05:44:37.231232  4008 sgd_solver.cpp:106] Iteration 303600, lr = 0.0001
I0519 05:44:37.390463  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8344	3.125	81.2933	0	90.8836	5.98958	88.9079	0	85.0606	0	85.5857	0	78.3252	0	30.3717	2.7	
I0519 05:44:37.466018  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:44:37.468291  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:44:37.468345  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:44:37.478698  4008 solver.cpp:260]     Total regularization terms: 0.951553 loss+regular. : 2.22594
I0519 05:46:05.604921  4008 solver.cpp:231] Iteration 303800, loss = 1.24891
I0519 05:46:05.605226  4008 solver.cpp:247]     Train net output #0: loss = 1.24891 (* 1 = 1.24891 loss)
I0519 05:46:05.605252  4008 sgd_solver.cpp:106] Iteration 303800, lr = 0.0001
I0519 05:46:05.765213  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8344	3.125	81.3122	0	90.8875	5.98958	88.9101	0	85.0627	0	85.5858	0	78.3253	0	30.3717	2.7	
I0519 05:46:05.840682  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:46:05.843435  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:46:05.843484  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:46:05.856130  4008 solver.cpp:260]     Total regularization terms: 0.951506 loss+regular. : 2.20042
I0519 05:47:29.110908  4008 solver.cpp:348] Iteration 304000, Testing net (#0)
I0519 05:47:41.787358  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:48:56.280342  4008 solver.cpp:415]     Test net output #0: accuracy = 0.564459
I0519 05:48:56.280854  4008 solver.cpp:415]     Test net output #1: loss = 1.87069 (* 1 = 1.87069 loss)
I0519 05:48:56.371268  4008 solver.cpp:231] Iteration 304000, loss = 1.31016
I0519 05:48:56.371356  4008 solver.cpp:247]     Train net output #0: loss = 1.31016 (* 1 = 1.31016 loss)
I0519 05:48:56.371377  4008 sgd_solver.cpp:106] Iteration 304000, lr = 0.0001
I0519 05:48:56.538362  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8487	3.125	81.3285	0	90.891	5.98958	88.9132	0	85.0649	0	85.5859	0	78.3253	0	30.3717	2.7	
I0519 05:48:56.614187  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:48:56.617079  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:48:56.617127  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:48:56.627075  4008 solver.cpp:260]     Total regularization terms: 0.951466 loss+regular. : 2.26162
I0519 05:50:01.164664  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:50:19.666319  4008 solver.cpp:231] Iteration 304200, loss = 1.13992
I0519 05:50:19.666402  4008 solver.cpp:247]     Train net output #0: loss = 1.13992 (* 1 = 1.13992 loss)
I0519 05:50:19.666421  4008 sgd_solver.cpp:106] Iteration 304200, lr = 0.0001
I0519 05:50:19.826752  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8487	3.125	81.3457	0	90.8941	5.98958	88.9154	0	85.067	0	85.5859	0	78.3255	0	30.3718	2.7	
I0519 05:50:19.901990  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:50:19.904026  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:50:19.904057  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:50:19.915242  4008 solver.cpp:260]     Total regularization terms: 0.951415 loss+regular. : 2.09134
I0519 05:51:42.936857  4008 solver.cpp:231] Iteration 304400, loss = 1.28773
I0519 05:51:42.937124  4008 solver.cpp:247]     Train net output #0: loss = 1.28773 (* 1 = 1.28773 loss)
I0519 05:51:42.937158  4008 sgd_solver.cpp:106] Iteration 304400, lr = 0.0001
I0519 05:51:43.096985  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8573	3.125	81.3617	0	90.896	5.98958	88.9177	0	85.0692	0	85.586	0	78.3256	0	30.3719	2.7	
I0519 05:51:43.172307  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:51:43.175143  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:51:43.175199  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:51:43.185150  4008 solver.cpp:260]     Total regularization terms: 0.951374 loss+regular. : 2.2391
I0519 05:53:09.885221  4008 solver.cpp:231] Iteration 304600, loss = 1.38374
I0519 05:53:09.885538  4008 solver.cpp:247]     Train net output #0: loss = 1.38374 (* 1 = 1.38374 loss)
I0519 05:53:09.885587  4008 sgd_solver.cpp:106] Iteration 304600, lr = 0.0001
I0519 05:53:10.045040  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8602	3.125	81.3756	0	90.8999	5.98958	88.9202	0	85.0719	0	85.5861	0	78.3257	0	30.372	2.7	
I0519 05:53:10.120642  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:53:10.123878  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:53:10.123937  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:53:10.133931  4008 solver.cpp:260]     Total regularization terms: 0.951328 loss+regular. : 2.33507
I0519 05:54:39.870698  4008 solver.cpp:231] Iteration 304800, loss = 1.41113
I0519 05:54:39.871927  4008 solver.cpp:247]     Train net output #0: loss = 1.41113 (* 1 = 1.41113 loss)
I0519 05:54:39.871954  4008 sgd_solver.cpp:106] Iteration 304800, lr = 0.0001
I0519 05:54:40.029464  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8745	3.125	81.39	0	90.9025	5.98958	88.9228	0	85.0744	0	85.5862	0	78.3258	0	30.3721	2.7	
I0519 05:54:40.104545  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:54:40.106768  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:54:40.106806  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:54:40.123988  4008 solver.cpp:260]     Total regularization terms: 0.951281 loss+regular. : 2.36241
I0519 05:56:07.752141  4008 solver.cpp:348] Iteration 305000, Testing net (#0)
I0519 05:56:23.618358  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:57:44.919545  4008 solver.cpp:415]     Test net output #0: accuracy = 0.564479
I0519 05:57:44.921669  4008 solver.cpp:415]     Test net output #1: loss = 1.86936 (* 1 = 1.86936 loss)
I0519 05:57:45.011893  4008 solver.cpp:231] Iteration 305000, loss = 1.19071
I0519 05:57:45.011988  4008 solver.cpp:247]     Train net output #0: loss = 1.19071 (* 1 = 1.19071 loss)
I0519 05:57:45.012008  4008 sgd_solver.cpp:106] Iteration 305000, lr = 0.0001
I0519 05:57:45.174937  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8803	3.125	81.401	0	90.9055	5.98958	88.9252	0	85.0753	0	85.5862	0	78.3259	0	30.3721	2.7	
I0519 05:57:45.251163  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:57:45.254253  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:57:45.254310  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:57:45.264384  4008 solver.cpp:260]     Total regularization terms: 0.951234 loss+regular. : 2.14195
I0519 05:58:57.268012  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 05:59:13.697314  4008 solver.cpp:231] Iteration 305200, loss = 1.251
I0519 05:59:13.697422  4008 solver.cpp:247]     Train net output #0: loss = 1.251 (* 1 = 1.251 loss)
I0519 05:59:13.697445  4008 sgd_solver.cpp:106] Iteration 305200, lr = 0.0001
I0519 05:59:13.857986  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8803	3.125	81.4173	0	90.9073	5.98958	88.9281	0	85.0785	0	85.5863	0	78.326	0	30.3723	2.7	
I0519 05:59:13.933997  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 05:59:13.937499  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 05:59:13.937568  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 05:59:13.947772  4008 solver.cpp:260]     Total regularization terms: 0.951183 loss+regular. : 2.20218
I0519 06:00:42.005851  4008 solver.cpp:231] Iteration 305400, loss = 1.07143
I0519 06:00:42.006162  4008 solver.cpp:247]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0519 06:00:42.006184  4008 sgd_solver.cpp:106] Iteration 305400, lr = 0.0001
I0519 06:00:42.166829  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8803	3.125	81.4268	0	90.9097	5.98958	88.9309	0	85.0805	0	85.5864	0	78.3261	0	30.3723	2.7	
I0519 06:00:42.242904  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:00:42.246276  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:00:42.246342  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:00:42.256436  4008 solver.cpp:260]     Total regularization terms: 0.95113 loss+regular. : 2.02256
I0519 06:02:04.470172  4008 solver.cpp:231] Iteration 305600, loss = 1.0261
I0519 06:02:04.470466  4008 solver.cpp:247]     Train net output #0: loss = 1.0261 (* 1 = 1.0261 loss)
I0519 06:02:04.470490  4008 sgd_solver.cpp:106] Iteration 305600, lr = 0.0001
I0519 06:02:04.629941  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8889	3.125	81.4401	0	90.9136	5.98958	88.9341	0	85.0819	0	85.5865	0	78.3262	0	30.3724	2.7	
I0519 06:02:04.706037  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:02:04.708214  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:02:04.708253  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:02:04.718396  4008 solver.cpp:260]     Total regularization terms: 0.951085 loss+regular. : 1.97718
I0519 06:03:32.225208  4008 solver.cpp:231] Iteration 305800, loss = 1.32963
I0519 06:03:32.225474  4008 solver.cpp:247]     Train net output #0: loss = 1.32963 (* 1 = 1.32963 loss)
I0519 06:03:32.225494  4008 sgd_solver.cpp:106] Iteration 305800, lr = 0.0001
I0519 06:03:32.385273  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.8889	3.125	81.4535	0	90.9163	5.98958	88.9353	0	85.0823	0	85.5865	0	78.3263	0	30.3724	2.7	
I0519 06:03:32.459625  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:03:32.461448  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:03:32.461467  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:03:32.475822  4008 solver.cpp:260]     Total regularization terms: 0.951038 loss+regular. : 2.28067
I0519 06:04:50.656340  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_306000.caffemodel
I0519 06:05:36.863570  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_306000.solverstate
I0519 06:05:37.387042  4008 solver.cpp:348] Iteration 306000, Testing net (#0)
I0519 06:05:52.965246  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:06:59.584477  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56416
I0519 06:06:59.587332  4008 solver.cpp:415]     Test net output #1: loss = 1.8682 (* 1 = 1.8682 loss)
I0519 06:06:59.691952  4008 solver.cpp:231] Iteration 306000, loss = 1.51452
I0519 06:06:59.692033  4008 solver.cpp:247]     Train net output #0: loss = 1.51452 (* 1 = 1.51452 loss)
I0519 06:06:59.692055  4008 sgd_solver.cpp:106] Iteration 306000, lr = 0.0001
I0519 06:06:59.857748  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9032	3.125	81.4652	0	90.9182	5.98958	88.9368	0	85.0841	0	85.5866	0	78.3264	0	30.3725	2.7	
I0519 06:06:59.860004  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:06:59.862738  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:06:59.862783  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:06:59.872810  4008 solver.cpp:260]     Total regularization terms: 0.950986 loss+regular. : 2.46551
I0519 06:08:13.669240  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:08:29.556895  4008 solver.cpp:231] Iteration 306200, loss = 1.38885
I0519 06:08:29.556999  4008 solver.cpp:247]     Train net output #0: loss = 1.38885 (* 1 = 1.38885 loss)
I0519 06:08:29.557019  4008 sgd_solver.cpp:106] Iteration 306200, lr = 0.0001
I0519 06:08:29.717262  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9176	3.125	81.4743	0	90.92	5.98958	88.9385	0	85.0862	0	85.5867	0	78.3265	0	30.3726	2.7	
I0519 06:08:29.792172  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:08:29.794235  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:08:29.794289  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:08:29.804579  4008 solver.cpp:260]     Total regularization terms: 0.950943 loss+regular. : 2.3398
I0519 06:10:04.756359  4008 solver.cpp:231] Iteration 306400, loss = 1.23923
I0519 06:10:04.756726  4008 solver.cpp:247]     Train net output #0: loss = 1.23923 (* 1 = 1.23923 loss)
I0519 06:10:04.756748  4008 sgd_solver.cpp:106] Iteration 306400, lr = 0.0001
I0519 06:10:04.917105  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9291	3.125	81.485	0	90.9223	5.98958	88.9403	0	85.0873	0	85.5867	0	78.3266	0	30.3727	2.7	
I0519 06:10:04.992516  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:10:04.994511  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:10:04.994557  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:10:05.014788  4008 solver.cpp:260]     Total regularization terms: 0.950893 loss+regular. : 2.19012
I0519 06:11:40.458549  4008 solver.cpp:231] Iteration 306600, loss = 1.15264
I0519 06:11:40.463241  4008 solver.cpp:247]     Train net output #0: loss = 1.15264 (* 1 = 1.15264 loss)
I0519 06:11:40.463279  4008 sgd_solver.cpp:106] Iteration 306600, lr = 0.0001
I0519 06:11:40.618237  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9348	3.125	81.4961	0	90.924	5.98958	88.943	0	85.0889	0	85.5868	0	78.3267	0	30.3728	2.7	
I0519 06:11:40.693774  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:11:40.696976  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:11:40.697038  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:11:40.706903  4008 solver.cpp:260]     Total regularization terms: 0.950852 loss+regular. : 2.10349
I0519 06:13:20.157531  4008 solver.cpp:231] Iteration 306800, loss = 1.21894
I0519 06:13:20.157846  4008 solver.cpp:247]     Train net output #0: loss = 1.21894 (* 1 = 1.21894 loss)
I0519 06:13:20.157869  4008 sgd_solver.cpp:106] Iteration 306800, lr = 0.0001
I0519 06:13:20.316954  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9434	3.125	81.5091	0	90.9268	5.98958	88.9459	0	85.0905	0	85.5869	0	78.3268	0	30.3728	2.7	
I0519 06:13:20.392683  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:13:20.395508  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:13:20.395553  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:13:20.405424  4008 solver.cpp:260]     Total regularization terms: 0.9508 loss+regular. : 2.16974
I0519 06:14:47.384471  4008 solver.cpp:348] Iteration 307000, Testing net (#0)
I0519 06:15:01.465816  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:16:16.848484  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56586
I0519 06:16:16.848729  4008 solver.cpp:415]     Test net output #1: loss = 1.86451 (* 1 = 1.86451 loss)
I0519 06:16:16.937676  4008 solver.cpp:231] Iteration 307000, loss = 1.48041
I0519 06:16:16.937772  4008 solver.cpp:247]     Train net output #0: loss = 1.48041 (* 1 = 1.48041 loss)
I0519 06:16:16.937791  4008 sgd_solver.cpp:106] Iteration 307000, lr = 0.0001
I0519 06:16:17.097718  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9434	3.125	81.5179	0	90.9286	5.98958	88.9481	0	85.0918	0	85.587	0	78.3269	0	30.3728	2.7	
I0519 06:16:17.173341  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:16:17.175642  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:16:17.175698  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:16:17.189076  4008 solver.cpp:260]     Total regularization terms: 0.950755 loss+regular. : 2.43116
I0519 06:17:36.621654  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:17:48.380472  4008 solver.cpp:231] Iteration 307200, loss = 1.22139
I0519 06:17:48.380574  4008 solver.cpp:247]     Train net output #0: loss = 1.22139 (* 1 = 1.22139 loss)
I0519 06:17:48.380602  4008 sgd_solver.cpp:106] Iteration 307200, lr = 0.0001
I0519 06:17:48.540524  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9549	3.125	81.5322	0	90.9305	5.98958	88.9508	0	85.0943	0	85.587	0	78.327	0	30.3729	2.7	
I0519 06:17:48.615941  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:17:48.618667  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:17:48.618721  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:17:48.628612  4008 solver.cpp:260]     Total regularization terms: 0.950707 loss+regular. : 2.1721
I0519 06:19:11.931953  4008 solver.cpp:231] Iteration 307400, loss = 1.32976
I0519 06:19:11.932160  4008 solver.cpp:247]     Train net output #0: loss = 1.32976 (* 1 = 1.32976 loss)
I0519 06:19:11.932179  4008 sgd_solver.cpp:106] Iteration 307400, lr = 0.0001
I0519 06:19:12.092983  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9578	3.125	81.5443	0	90.9318	5.98958	88.9532	0	85.0954	0	85.5871	0	78.327	0	30.3729	2.7	
I0519 06:19:12.168355  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:19:12.171252  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:19:12.171289  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:19:12.181282  4008 solver.cpp:260]     Total regularization terms: 0.950669 loss+regular. : 2.28043
I0519 06:20:42.387451  4008 solver.cpp:231] Iteration 307600, loss = 1.44531
I0519 06:20:42.387835  4008 solver.cpp:247]     Train net output #0: loss = 1.44531 (* 1 = 1.44531 loss)
I0519 06:20:42.387866  4008 sgd_solver.cpp:106] Iteration 307600, lr = 0.0001
I0519 06:20:42.546795  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9635	3.125	81.5557	0	90.9334	5.98958	88.955	0	85.0973	0	85.5871	0	78.3272	0	30.3729	2.7	
I0519 06:20:42.622401  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:20:42.625314  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:20:42.625375  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:20:42.635457  4008 solver.cpp:260]     Total regularization terms: 0.950621 loss+regular. : 2.39593
I0519 06:22:15.099807  4008 solver.cpp:231] Iteration 307800, loss = 1.38247
I0519 06:22:15.100116  4008 solver.cpp:247]     Train net output #0: loss = 1.38247 (* 1 = 1.38247 loss)
I0519 06:22:15.100136  4008 sgd_solver.cpp:106] Iteration 307800, lr = 0.0001
I0519 06:22:15.261185  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9664	3.125	81.5677	0	90.9357	5.98958	88.9581	0	85.0975	0	85.5872	0	78.3273	0	30.373	2.7	
I0519 06:22:15.336320  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:22:15.338526  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:22:15.338706  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:22:15.351639  4008 solver.cpp:260]     Total regularization terms: 0.950572 loss+regular. : 2.33304
I0519 06:23:44.412192  4008 solver.cpp:348] Iteration 308000, Testing net (#0)
I0519 06:24:00.583267  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:25:06.505820  4008 solver.cpp:415]     Test net output #0: accuracy = 0.564879
I0519 06:25:06.506120  4008 solver.cpp:415]     Test net output #1: loss = 1.86476 (* 1 = 1.86476 loss)
I0519 06:25:06.594102  4008 solver.cpp:231] Iteration 308000, loss = 1.37714
I0519 06:25:06.594192  4008 solver.cpp:247]     Train net output #0: loss = 1.37714 (* 1 = 1.37714 loss)
I0519 06:25:06.594218  4008 sgd_solver.cpp:106] Iteration 308000, lr = 0.0001
I0519 06:25:06.761804  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9692	3.125	81.5768	0	90.9378	5.98958	88.9603	0	85.1	0	85.5873	0	78.3274	0	30.373	2.7	
I0519 06:25:06.837329  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:25:06.840325  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:25:06.840368  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:25:06.850250  4008 solver.cpp:260]     Total regularization terms: 0.950526 loss+regular. : 2.32767
I0519 06:26:21.352346  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:26:28.974189  4008 solver.cpp:231] Iteration 308200, loss = 1.33513
I0519 06:26:28.974293  4008 solver.cpp:247]     Train net output #0: loss = 1.33513 (* 1 = 1.33513 loss)
I0519 06:26:28.974315  4008 sgd_solver.cpp:106] Iteration 308200, lr = 0.0001
I0519 06:26:29.134063  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9692	3.125	81.5879	0	90.9396	5.98958	88.9617	0	85.1006	0	85.5873	0	78.3275	0	30.3731	2.7	
I0519 06:26:29.209874  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:26:29.212996  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:26:29.213047  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:26:29.223042  4008 solver.cpp:260]     Total regularization terms: 0.950483 loss+regular. : 2.28561
I0519 06:27:51.915221  4008 solver.cpp:231] Iteration 308400, loss = 1.33919
I0519 06:27:51.915581  4008 solver.cpp:247]     Train net output #0: loss = 1.33919 (* 1 = 1.33919 loss)
I0519 06:27:51.915606  4008 sgd_solver.cpp:106] Iteration 308400, lr = 0.0001
I0519 06:27:52.075165  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.975	3.125	81.5996	0	90.9415	5.98958	88.9633	0	85.1022	0	85.5874	0	78.3276	0	30.3732	2.7	
I0519 06:27:52.150637  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:27:52.153834  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:27:52.153884  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:27:52.163827  4008 solver.cpp:260]     Total regularization terms: 0.950436 loss+regular. : 2.28963
I0519 06:29:21.506227  4008 solver.cpp:231] Iteration 308600, loss = 1.15358
I0519 06:29:21.506594  4008 solver.cpp:247]     Train net output #0: loss = 1.15358 (* 1 = 1.15358 loss)
I0519 06:29:21.506628  4008 sgd_solver.cpp:106] Iteration 308600, lr = 0.0001
I0519 06:29:21.664700  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9807	3.125	81.6087	0	90.9436	5.98958	88.9654	0	85.1029	0	85.5875	0	78.3277	0	30.3732	2.7	
I0519 06:29:21.740836  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:29:21.743917  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:29:21.743975  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:29:21.754081  4008 solver.cpp:260]     Total regularization terms: 0.950402 loss+regular. : 2.10399
I0519 06:30:45.156427  4008 solver.cpp:231] Iteration 308800, loss = 1.21846
I0519 06:30:45.156752  4008 solver.cpp:247]     Train net output #0: loss = 1.21846 (* 1 = 1.21846 loss)
I0519 06:30:45.156779  4008 sgd_solver.cpp:106] Iteration 308800, lr = 0.0001
I0519 06:30:45.317306  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9865	3.125	81.6198	0	90.9453	5.98958	88.9673	0	85.1047	0	85.5876	0	78.3278	0	30.3733	2.7	
I0519 06:30:45.392078  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:30:45.394248  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:30:45.394296  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:30:45.404067  4008 solver.cpp:260]     Total regularization terms: 0.950358 loss+regular. : 2.16882
I0519 06:32:11.955907  4008 solver.cpp:348] Iteration 309000, Testing net (#0)
I0519 06:32:26.272246  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:33:34.727058  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56478
I0519 06:33:34.727367  4008 solver.cpp:415]     Test net output #1: loss = 1.86701 (* 1 = 1.86701 loss)
I0519 06:33:34.817265  4008 solver.cpp:231] Iteration 309000, loss = 1.0674
I0519 06:33:34.817347  4008 solver.cpp:247]     Train net output #0: loss = 1.0674 (* 1 = 1.0674 loss)
I0519 06:33:34.817378  4008 sgd_solver.cpp:106] Iteration 309000, lr = 0.0001
I0519 06:33:34.983737  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9865	3.125	81.6315	0	90.9469	5.98958	88.9692	0	85.1056	0	85.5876	0	78.3279	0	30.3734	2.7	
I0519 06:33:35.059764  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:33:35.062983  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:33:35.063042  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:33:35.073101  4008 solver.cpp:260]     Total regularization terms: 0.950322 loss+regular. : 2.01772
I0519 06:34:58.749267  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:35:03.343508  4008 solver.cpp:231] Iteration 309200, loss = 1.17313
I0519 06:35:03.343587  4008 solver.cpp:247]     Train net output #0: loss = 1.17313 (* 1 = 1.17313 loss)
I0519 06:35:03.343605  4008 sgd_solver.cpp:106] Iteration 309200, lr = 0.0001
I0519 06:35:03.505439  4008 sgd_solver.cpp:120]     Element Sparsity %: 
13.9979	3.125	81.6426	0	90.9498	5.98958	88.9718	0	85.1067	0	85.5877	0	78.3279	0	30.3734	2.7	
I0519 06:35:03.580931  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:35:03.583958  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:35:03.583997  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:35:03.593768  4008 solver.cpp:260]     Total regularization terms: 0.950268 loss+regular. : 2.1234
I0519 06:36:19.009467  4008 solver.cpp:231] Iteration 309400, loss = 1.3376
I0519 06:36:19.010016  4008 solver.cpp:247]     Train net output #0: loss = 1.3376 (* 1 = 1.3376 loss)
I0519 06:36:19.010036  4008 sgd_solver.cpp:106] Iteration 309400, lr = 0.0001
I0519 06:36:19.172577  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0008	3.125	81.6501	0	90.9517	5.98958	88.973	0	85.107	0	85.5877	0	78.3281	0	30.3734	2.7	
I0519 06:36:19.248267  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:36:19.250627  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:36:19.250660  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:36:19.264381  4008 solver.cpp:260]     Total regularization terms: 0.95023 loss+regular. : 2.28783
I0519 06:37:37.532991  4008 solver.cpp:231] Iteration 309600, loss = 1.1831
I0519 06:37:37.533200  4008 solver.cpp:247]     Train net output #0: loss = 1.1831 (* 1 = 1.1831 loss)
I0519 06:37:37.533220  4008 sgd_solver.cpp:106] Iteration 309600, lr = 0.0001
I0519 06:37:37.694527  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0065	3.125	81.6585	0	90.954	5.98958	88.9746	0	85.1081	0	85.5878	0	78.3282	0	30.3734	2.7	
I0519 06:37:37.769495  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:37:37.771113  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:37:37.771142  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:37:37.786137  4008 solver.cpp:260]     Total regularization terms: 0.950179 loss+regular. : 2.13328
I0519 06:38:57.247997  4008 solver.cpp:231] Iteration 309800, loss = 1.39911
I0519 06:38:57.248288  4008 solver.cpp:247]     Train net output #0: loss = 1.39911 (* 1 = 1.39911 loss)
I0519 06:38:57.248320  4008 sgd_solver.cpp:106] Iteration 309800, lr = 0.0001
I0519 06:38:57.408665  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0094	3.125	81.6631	0	90.9562	5.98958	88.9761	0	85.1092	0	85.5878	0	78.3283	0	30.3735	2.7	
I0519 06:38:57.484311  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:38:57.485875  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:38:57.485905  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:38:57.500821  4008 solver.cpp:260]     Total regularization terms: 0.950141 loss+regular. : 2.34925
I0519 06:40:13.391881  4008 solver.cpp:348] Iteration 310000, Testing net (#0)
I0519 06:40:27.218818  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:41:25.207763  4008 solver.cpp:415]     Test net output #0: accuracy = 0.564099
I0519 06:41:25.211169  4008 solver.cpp:415]     Test net output #1: loss = 1.86612 (* 1 = 1.86612 loss)
I0519 06:41:25.302317  4008 solver.cpp:231] Iteration 310000, loss = 1.2023
I0519 06:41:25.302412  4008 solver.cpp:247]     Train net output #0: loss = 1.2023 (* 1 = 1.2023 loss)
I0519 06:41:25.302433  4008 sgd_solver.cpp:106] Iteration 310000, lr = 0.0001
I0519 06:41:25.464829  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0152	3.125	81.6722	0	90.9572	5.98958	88.9778	0	85.1099	0	85.5879	0	78.3284	0	30.3735	2.7	
I0519 06:41:25.540539  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:41:25.542841  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:41:25.542903  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:41:25.552804  4008 solver.cpp:260]     Total regularization terms: 0.950098 loss+regular. : 2.1524
I0519 06:42:39.676101  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:42:40.954586  4008 solver.cpp:231] Iteration 310200, loss = 1.27852
I0519 06:42:40.954670  4008 solver.cpp:247]     Train net output #0: loss = 1.27852 (* 1 = 1.27852 loss)
I0519 06:42:40.954689  4008 sgd_solver.cpp:106] Iteration 310200, lr = 0.0001
I0519 06:42:41.114137  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0152	3.125	81.6787	0	90.9598	5.98958	88.9784	0	85.1113	0	85.588	0	78.3284	0	30.3736	2.7	
I0519 06:42:41.191880  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:42:41.194248  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:42:41.194298  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:42:41.209280  4008 solver.cpp:260]     Total regularization terms: 0.950052 loss+regular. : 2.22857
I0519 06:43:53.545219  4008 solver.cpp:231] Iteration 310400, loss = 1.43377
I0519 06:43:53.545425  4008 solver.cpp:247]     Train net output #0: loss = 1.43377 (* 1 = 1.43377 loss)
I0519 06:43:53.545442  4008 sgd_solver.cpp:106] Iteration 310400, lr = 0.0001
I0519 06:43:53.706312  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0152	3.125	81.6859	0	90.9607	5.98958	88.981	0	85.1128	0	85.5881	0	78.3285	0	30.3737	2.7	
I0519 06:43:53.781575  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:43:53.783491  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:43:53.783521  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:43:53.798319  4008 solver.cpp:260]     Total regularization terms: 0.950007 loss+regular. : 2.38377
I0519 06:45:06.350404  4008 solver.cpp:231] Iteration 310600, loss = 1.43431
I0519 06:45:06.353658  4008 solver.cpp:247]     Train net output #0: loss = 1.43431 (* 1 = 1.43431 loss)
I0519 06:45:06.353689  4008 sgd_solver.cpp:106] Iteration 310600, lr = 0.0001
I0519 06:45:06.512676  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.018	3.125	81.694	0	90.963	5.98958	88.9823	0	85.1142	0	85.5882	0	78.3286	0	30.3737	2.7	
I0519 06:45:06.588372  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:45:06.590617  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:45:06.590683  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:45:06.605023  4008 solver.cpp:260]     Total regularization terms: 0.949957 loss+regular. : 2.38427
I0519 06:46:26.813396  4008 solver.cpp:231] Iteration 310800, loss = 1.12944
I0519 06:46:26.813720  4008 solver.cpp:247]     Train net output #0: loss = 1.12944 (* 1 = 1.12944 loss)
I0519 06:46:26.813745  4008 sgd_solver.cpp:106] Iteration 310800, lr = 0.0001
I0519 06:46:26.973331  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0266	3.125	81.7005	0	90.9644	5.98958	88.9838	0	85.1156	0	85.5882	0	78.3287	0	30.3738	2.7	
I0519 06:46:27.048281  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:46:27.050292  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:46:27.050317  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:46:27.059979  4008 solver.cpp:260]     Total regularization terms: 0.94992 loss+regular. : 2.07936
I0519 06:47:47.823098  4008 solver.cpp:348] Iteration 311000, Testing net (#0)
I0519 06:48:05.560387  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:49:04.955889  4008 solver.cpp:415]     Test net output #0: accuracy = 0.564839
I0519 06:49:04.956044  4008 solver.cpp:415]     Test net output #1: loss = 1.86382 (* 1 = 1.86382 loss)
I0519 06:49:05.043596  4008 solver.cpp:231] Iteration 311000, loss = 1.22893
I0519 06:49:05.043663  4008 solver.cpp:247]     Train net output #0: loss = 1.22893 (* 1 = 1.22893 loss)
I0519 06:49:05.043681  4008 sgd_solver.cpp:106] Iteration 311000, lr = 0.0001
I0519 06:49:05.210991  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0324	3.125	81.707	0	90.9674	5.98958	88.9865	0	85.1167	0	85.5883	0	78.3288	0	30.3738	2.7	
I0519 06:49:05.285869  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:49:05.288218  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:49:05.288257  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:49:05.299511  4008 solver.cpp:260]     Total regularization terms: 0.949878 loss+regular. : 2.17881
I0519 06:50:19.172297  4008 solver.cpp:231] Iteration 311200, loss = 1.39199
I0519 06:50:19.172574  4008 solver.cpp:247]     Train net output #0: loss = 1.39199 (* 1 = 1.39199 loss)
I0519 06:50:19.172595  4008 sgd_solver.cpp:106] Iteration 311200, lr = 0.0001
I0519 06:50:19.335587  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0381	3.125	81.7171	0	90.9687	5.98958	88.9891	0	85.1185	0	85.5884	0	78.3289	0	30.3738	2.7	
I0519 06:50:19.411104  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:50:19.412816  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:50:19.412855  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:50:19.434048  4008 solver.cpp:260]     Total regularization terms: 0.949838 loss+regular. : 2.34183
I0519 06:50:20.470036  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:51:35.921844  4008 solver.cpp:231] Iteration 311400, loss = 1.34853
I0519 06:51:35.922158  4008 solver.cpp:247]     Train net output #0: loss = 1.34853 (* 1 = 1.34853 loss)
I0519 06:51:35.922180  4008 sgd_solver.cpp:106] Iteration 311400, lr = 0.0001
I0519 06:51:36.083844  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0438	3.125	81.7253	0	90.9702	5.98958	88.99	0	85.1199	0	85.5884	0	78.329	0	30.374	2.7	
I0519 06:51:36.159819  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:51:36.161501  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:51:36.161535  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:51:36.182375  4008 solver.cpp:260]     Total regularization terms: 0.949789 loss+regular. : 2.29832
I0519 06:53:04.351593  4008 solver.cpp:231] Iteration 311600, loss = 1.20769
I0519 06:53:04.351781  4008 solver.cpp:247]     Train net output #0: loss = 1.20769 (* 1 = 1.20769 loss)
I0519 06:53:04.351809  4008 sgd_solver.cpp:106] Iteration 311600, lr = 0.0001
I0519 06:53:04.511914  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0496	3.125	81.7337	0	90.9721	5.98958	88.9912	0	85.121	0	85.5885	0	78.3291	0	30.3741	2.7	
I0519 06:53:04.588891  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:53:04.591028  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:53:04.591065  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:53:04.600880  4008 solver.cpp:260]     Total regularization terms: 0.949751 loss+regular. : 2.15744
I0519 06:54:23.840204  4008 solver.cpp:231] Iteration 311800, loss = 1.38283
I0519 06:54:23.840523  4008 solver.cpp:247]     Train net output #0: loss = 1.38283 (* 1 = 1.38283 loss)
I0519 06:54:23.840554  4008 sgd_solver.cpp:106] Iteration 311800, lr = 0.0001
I0519 06:54:24.000779  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0582	3.125	81.7406	0	90.9735	5.98958	88.9921	0	85.1228	0	85.5886	0	78.3292	0	30.3742	2.7	
I0519 06:54:24.077304  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:54:24.080006  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:54:24.080047  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:54:24.094988  4008 solver.cpp:260]     Total regularization terms: 0.949708 loss+regular. : 2.33253
I0519 06:55:47.029544  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_312000.caffemodel
I0519 06:56:15.438549  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_312000.solverstate
I0519 06:56:15.952029  4008 solver.cpp:348] Iteration 312000, Testing net (#0)
I0519 06:56:33.417456  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 06:57:36.747318  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56502
I0519 06:57:36.749611  4008 solver.cpp:415]     Test net output #1: loss = 1.86519 (* 1 = 1.86519 loss)
I0519 06:57:36.838642  4008 solver.cpp:231] Iteration 312000, loss = 1.31703
I0519 06:57:36.838711  4008 solver.cpp:247]     Train net output #0: loss = 1.31703 (* 1 = 1.31703 loss)
I0519 06:57:36.838726  4008 sgd_solver.cpp:106] Iteration 312000, lr = 0.0001
I0519 06:57:37.010857  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0611	3.125	81.7464	0	90.9744	5.98958	88.9938	0	85.1244	0	85.5886	0	78.3293	0	30.3742	2.7	
I0519 06:57:37.012943  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:57:37.015637  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:57:37.015669  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:57:37.025462  4008 solver.cpp:260]     Total regularization terms: 0.94966 loss+regular. : 2.26669
I0519 06:58:52.516263  4008 solver.cpp:231] Iteration 312200, loss = 1.30656
I0519 06:58:52.516585  4008 solver.cpp:247]     Train net output #0: loss = 1.30656 (* 1 = 1.30656 loss)
I0519 06:58:52.516609  4008 sgd_solver.cpp:106] Iteration 312200, lr = 0.0001
I0519 06:58:52.676427  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0725	3.125	81.7581	0	90.9758	5.98958	88.9953	0	85.1251	0	85.5887	0	78.3293	0	30.3742	2.7	
I0519 06:58:52.756237  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 06:58:52.758527  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 06:58:52.758580  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 06:58:52.772415  4008 solver.cpp:260]     Total regularization terms: 0.949625 loss+regular. : 2.25619
I0519 06:58:56.281524  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:00:11.822330  4008 solver.cpp:231] Iteration 312400, loss = 1.26073
I0519 07:00:11.825978  4008 solver.cpp:247]     Train net output #0: loss = 1.26073 (* 1 = 1.26073 loss)
I0519 07:00:11.826012  4008 sgd_solver.cpp:106] Iteration 312400, lr = 0.0001
I0519 07:00:11.984295  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0812	3.125	81.7656	0	90.9778	5.98958	88.9966	0	85.1262	0	85.5888	0	78.3294	0	30.3743	2.7	
I0519 07:00:12.059784  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:00:12.062765  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:00:12.062916  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:00:12.073087  4008 solver.cpp:260]     Total regularization terms: 0.949581 loss+regular. : 2.21031
I0519 07:01:28.866910  4008 solver.cpp:231] Iteration 312600, loss = 1.16066
I0519 07:01:28.867300  4008 solver.cpp:247]     Train net output #0: loss = 1.16066 (* 1 = 1.16066 loss)
I0519 07:01:28.867319  4008 sgd_solver.cpp:106] Iteration 312600, lr = 0.0001
I0519 07:01:29.028061  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.084	3.125	81.7731	0	90.9798	5.98958	88.998	0	85.1287	0	85.5888	0	78.3295	0	30.3743	2.7	
I0519 07:01:29.103471  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:01:29.105307  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:01:29.105337  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:01:29.125591  4008 solver.cpp:260]     Total regularization terms: 0.949537 loss+regular. : 2.11019
I0519 07:02:50.693295  4008 solver.cpp:231] Iteration 312800, loss = 1.43815
I0519 07:02:50.695201  4008 solver.cpp:247]     Train net output #0: loss = 1.43815 (* 1 = 1.43815 loss)
I0519 07:02:50.695236  4008 sgd_solver.cpp:106] Iteration 312800, lr = 0.0001
I0519 07:02:50.852578  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.084	3.125	81.7809	0	90.9823	5.98958	88.9995	0	85.1289	0	85.5889	0	78.3295	0	30.3743	2.7	
I0519 07:02:50.927573  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:02:50.930335  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:02:50.930382  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:02:50.944814  4008 solver.cpp:260]     Total regularization terms: 0.949493 loss+regular. : 2.38765
I0519 07:04:16.105037  4008 solver.cpp:348] Iteration 313000, Testing net (#0)
I0519 07:04:33.531256  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:05:42.844153  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56562
I0519 07:05:42.845342  4008 solver.cpp:415]     Test net output #1: loss = 1.86189 (* 1 = 1.86189 loss)
I0519 07:05:42.936699  4008 solver.cpp:231] Iteration 313000, loss = 1.22495
I0519 07:05:42.936772  4008 solver.cpp:247]     Train net output #0: loss = 1.22495 (* 1 = 1.22495 loss)
I0519 07:05:42.936791  4008 sgd_solver.cpp:106] Iteration 313000, lr = 0.0001
I0519 07:05:43.097980  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.084	3.125	81.7878	0	90.9842	5.98958	89.0013	0	85.1291	0	85.589	0	78.3296	0	30.3744	2.7	
I0519 07:05:43.174649  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:05:43.177079  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:05:43.177119  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:05:43.186908  4008 solver.cpp:260]     Total regularization terms: 0.949447 loss+regular. : 2.1744
I0519 07:06:58.939952  4008 solver.cpp:231] Iteration 313200, loss = 1.26891
I0519 07:06:58.940227  4008 solver.cpp:247]     Train net output #0: loss = 1.26891 (* 1 = 1.26891 loss)
I0519 07:06:58.940248  4008 sgd_solver.cpp:106] Iteration 313200, lr = 0.0001
I0519 07:06:59.101168  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.084	3.125	81.7956	0	90.9867	5.98958	89.0028	0	85.1305	0	85.589	0	78.3296	0	30.3745	2.7	
I0519 07:06:59.176226  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:06:59.178892  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:06:59.178939  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:06:59.208544  4008 solver.cpp:260]     Total regularization terms: 0.949406 loss+regular. : 2.21832
I0519 07:07:05.567275  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:08:20.912699  4008 solver.cpp:231] Iteration 313400, loss = 1.31254
I0519 07:08:20.917646  4008 solver.cpp:247]     Train net output #0: loss = 1.31254 (* 1 = 1.31254 loss)
I0519 07:08:20.917675  4008 sgd_solver.cpp:106] Iteration 313400, lr = 0.0001
I0519 07:08:21.073395  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.084	3.125	81.8044	0	90.9883	5.98958	89.0043	0	85.1309	0	85.5891	0	78.3298	0	30.3745	2.7	
I0519 07:08:21.149173  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:08:21.151247  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:08:21.151279  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:08:21.166034  4008 solver.cpp:260]     Total regularization terms: 0.949366 loss+regular. : 2.2619
I0519 07:09:48.405131  4008 solver.cpp:231] Iteration 313600, loss = 1.36804
I0519 07:09:48.409693  4008 solver.cpp:247]     Train net output #0: loss = 1.36804 (* 1 = 1.36804 loss)
I0519 07:09:48.409725  4008 sgd_solver.cpp:106] Iteration 313600, lr = 0.0001
I0519 07:09:48.564232  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0898	3.125	81.8096	0	90.9902	5.98958	89.0064	0	85.133	0	85.5892	0	78.3298	0	30.3745	2.7	
I0519 07:09:48.642635  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:09:48.644696  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:09:48.644743  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:09:48.654533  4008 solver.cpp:260]     Total regularization terms: 0.949327 loss+regular. : 2.31736
I0519 07:11:18.640394  4008 solver.cpp:231] Iteration 313800, loss = 1.34261
I0519 07:11:18.640667  4008 solver.cpp:247]     Train net output #0: loss = 1.34261 (* 1 = 1.34261 loss)
I0519 07:11:18.640825  4008 sgd_solver.cpp:106] Iteration 313800, lr = 0.0001
I0519 07:11:18.801245  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0955	3.125	81.8161	0	90.9927	5.98958	89.0081	0	85.1341	0	85.5893	0	78.3299	0	30.3745	2.7	
I0519 07:11:18.876317  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:11:18.878546  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:11:18.878597  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:11:18.888597  4008 solver.cpp:260]     Total regularization terms: 0.949281 loss+regular. : 2.29189
I0519 07:12:34.820725  4008 solver.cpp:348] Iteration 314000, Testing net (#0)
I0519 07:12:52.348072  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:13:53.696760  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56574
I0519 07:13:53.697011  4008 solver.cpp:415]     Test net output #1: loss = 1.86463 (* 1 = 1.86463 loss)
I0519 07:13:53.788836  4008 solver.cpp:231] Iteration 314000, loss = 1.35547
I0519 07:13:53.788910  4008 solver.cpp:247]     Train net output #0: loss = 1.35547 (* 1 = 1.35547 loss)
I0519 07:13:53.788929  4008 sgd_solver.cpp:106] Iteration 314000, lr = 0.0001
I0519 07:13:53.948961  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0955	3.125	81.8216	0	90.9936	5.98958	89.0098	0	85.135	0	85.5893	0	78.33	0	30.3745	2.7	
I0519 07:13:54.024432  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:13:54.027170  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:13:54.027215  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:13:54.042134  4008 solver.cpp:260]     Total regularization terms: 0.949245 loss+regular. : 2.30472
I0519 07:15:16.141149  4008 solver.cpp:231] Iteration 314200, loss = 1.22222
I0519 07:15:16.141408  4008 solver.cpp:247]     Train net output #0: loss = 1.22222 (* 1 = 1.22222 loss)
I0519 07:15:16.141438  4008 sgd_solver.cpp:106] Iteration 314200, lr = 0.0001
I0519 07:15:16.300345  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.0984	3.125	81.8278	0	90.9943	5.98958	89.0117	0	85.135	0	85.5894	0	78.3301	0	30.3746	2.7	
I0519 07:15:16.376415  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:15:16.379106  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:15:16.379155  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:15:16.389251  4008 solver.cpp:260]     Total regularization terms: 0.949203 loss+regular. : 2.17142
I0519 07:15:25.555989  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:16:37.105824  4008 solver.cpp:231] Iteration 314400, loss = 1.08974
I0519 07:16:37.106294  4008 solver.cpp:247]     Train net output #0: loss = 1.08974 (* 1 = 1.08974 loss)
I0519 07:16:37.106426  4008 sgd_solver.cpp:106] Iteration 314400, lr = 0.0001
I0519 07:16:37.265231  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1012	3.125	81.8337	0	90.9952	5.98958	89.0131	0	85.1366	0	85.5895	0	78.3302	0	30.3747	2.7	
I0519 07:16:37.340028  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:16:37.341893  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:16:37.341946  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:16:37.355767  4008 solver.cpp:260]     Total regularization terms: 0.949172 loss+regular. : 2.03891
I0519 07:18:03.776098  4008 solver.cpp:231] Iteration 314600, loss = 1.44985
I0519 07:18:03.776355  4008 solver.cpp:247]     Train net output #0: loss = 1.44985 (* 1 = 1.44985 loss)
I0519 07:18:03.776376  4008 sgd_solver.cpp:106] Iteration 314600, lr = 0.0001
I0519 07:18:03.936707  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1012	3.125	81.8408	0	90.9972	5.98958	89.0146	0	85.1373	0	85.5895	0	78.3303	0	30.3747	2.7	
I0519 07:18:04.011742  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:18:04.014688  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:18:04.014735  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:18:04.024590  4008 solver.cpp:260]     Total regularization terms: 0.949126 loss+regular. : 2.39898
I0519 07:19:24.658403  4008 solver.cpp:231] Iteration 314800, loss = 1.28212
I0519 07:19:24.658658  4008 solver.cpp:247]     Train net output #0: loss = 1.28212 (* 1 = 1.28212 loss)
I0519 07:19:24.658891  4008 sgd_solver.cpp:106] Iteration 314800, lr = 0.0001
I0519 07:19:24.819769  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1012	3.125	81.846	0	90.9981	5.98958	89.0156	0	85.1379	0	85.5896	0	78.3303	0	30.3747	2.7	
I0519 07:19:24.894474  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:19:24.896291  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:19:24.896352  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:19:24.906245  4008 solver.cpp:260]     Total regularization terms: 0.949084 loss+regular. : 2.2312
I0519 07:20:48.725986  4008 solver.cpp:348] Iteration 315000, Testing net (#0)
I0519 07:21:05.476097  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:22:05.098799  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56538
I0519 07:22:05.100409  4008 solver.cpp:415]     Test net output #1: loss = 1.86498 (* 1 = 1.86498 loss)
I0519 07:22:05.191262  4008 solver.cpp:231] Iteration 315000, loss = 1.40413
I0519 07:22:05.191371  4008 solver.cpp:247]     Train net output #0: loss = 1.40413 (* 1 = 1.40413 loss)
I0519 07:22:05.191390  4008 sgd_solver.cpp:106] Iteration 315000, lr = 0.0001
I0519 07:22:05.362057  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1012	3.125	81.8535	0	90.9991	5.98958	89.0168	0	85.1384	0	85.5896	0	78.3304	0	30.3747	2.7	
I0519 07:22:05.436902  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:22:05.438756  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:22:05.438801  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:22:05.448658  4008 solver.cpp:260]     Total regularization terms: 0.949042 loss+regular. : 2.35317
I0519 07:23:28.251111  4008 solver.cpp:231] Iteration 315200, loss = 1.3438
I0519 07:23:28.251451  4008 solver.cpp:247]     Train net output #0: loss = 1.3438 (* 1 = 1.3438 loss)
I0519 07:23:28.251472  4008 sgd_solver.cpp:106] Iteration 315200, lr = 0.0001
I0519 07:23:28.414273  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1098	3.125	81.8584	0	91.0004	5.98958	89.0179	0	85.1386	0	85.5897	0	78.3305	0	30.3748	2.7	
I0519 07:23:28.489622  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:23:28.492581  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:23:28.492630  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:23:28.502480  4008 solver.cpp:260]     Total regularization terms: 0.948997 loss+regular. : 2.29279
I0519 07:23:41.763758  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:24:53.233505  4008 solver.cpp:231] Iteration 315400, loss = 1.17062
I0519 07:24:53.233829  4008 solver.cpp:247]     Train net output #0: loss = 1.17062 (* 1 = 1.17062 loss)
I0519 07:24:53.233850  4008 sgd_solver.cpp:106] Iteration 315400, lr = 0.0001
I0519 07:24:53.394836  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1156	3.125	81.8646	0	91.0016	5.98958	89.0188	0	85.1409	0	85.5898	0	78.3306	0	30.3749	2.7	
I0519 07:24:53.470278  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:24:53.472822  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:24:53.472862  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:24:53.482767  4008 solver.cpp:260]     Total regularization terms: 0.94895 loss+regular. : 2.11957
I0519 07:26:17.847656  4008 solver.cpp:231] Iteration 315600, loss = 1.29069
I0519 07:26:17.847898  4008 solver.cpp:247]     Train net output #0: loss = 1.29069 (* 1 = 1.29069 loss)
I0519 07:26:17.847916  4008 sgd_solver.cpp:106] Iteration 315600, lr = 0.0001
I0519 07:26:18.008482  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1185	3.125	81.8685	0	91.0023	5.98958	89.0197	0	85.142	0	85.5898	0	78.3307	0	30.3749	2.7	
I0519 07:26:18.084007  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:26:18.087067  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:26:18.087121  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:26:18.097630  4008 solver.cpp:260]     Total regularization terms: 0.948911 loss+regular. : 2.2396
I0519 07:27:38.747948  4008 solver.cpp:231] Iteration 315800, loss = 1.38618
I0519 07:27:38.748369  4008 solver.cpp:247]     Train net output #0: loss = 1.38618 (* 1 = 1.38618 loss)
I0519 07:27:38.748396  4008 sgd_solver.cpp:106] Iteration 315800, lr = 0.0001
I0519 07:27:38.907258  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1271	3.125	81.8724	0	91.0034	5.98958	89.0211	0	85.1427	0	85.5899	0	78.3308	0	30.375	2.7	
I0519 07:27:38.982893  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:27:38.984691  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:27:38.984727  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:27:38.999619  4008 solver.cpp:260]     Total regularization terms: 0.94887 loss+regular. : 2.33505
I0519 07:29:05.057494  4008 solver.cpp:348] Iteration 316000, Testing net (#0)
I0519 07:29:24.530797  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:30:22.339174  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56546
I0519 07:30:22.339449  4008 solver.cpp:415]     Test net output #1: loss = 1.86404 (* 1 = 1.86404 loss)
I0519 07:30:22.426944  4008 solver.cpp:231] Iteration 316000, loss = 1.11991
I0519 07:30:22.427067  4008 solver.cpp:247]     Train net output #0: loss = 1.11991 (* 1 = 1.11991 loss)
I0519 07:30:22.427132  4008 sgd_solver.cpp:106] Iteration 316000, lr = 0.0001
I0519 07:30:22.588032  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1328	3.125	81.8766	0	91.0043	5.98958	89.0224	0	85.1431	0	85.59	0	78.3309	0	30.3751	2.7	
I0519 07:30:22.664597  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:30:22.666295  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:30:22.666338  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:30:22.676163  4008 solver.cpp:260]     Total regularization terms: 0.948834 loss+regular. : 2.06874
I0519 07:31:50.407341  4008 solver.cpp:231] Iteration 316200, loss = 1.47823
I0519 07:31:50.407718  4008 solver.cpp:247]     Train net output #0: loss = 1.47823 (* 1 = 1.47823 loss)
I0519 07:31:50.407737  4008 sgd_solver.cpp:106] Iteration 316200, lr = 0.0001
I0519 07:31:50.569317  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1328	3.125	81.8812	0	91.005	5.98958	89.0239	0	85.1445	0	85.59	0	78.3309	0	30.3751	2.7	
I0519 07:31:50.645596  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:31:50.648229  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:31:50.648273  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:31:50.663381  4008 solver.cpp:260]     Total regularization terms: 0.948793 loss+regular. : 2.42702
I0519 07:32:05.568981  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:33:11.034795  4008 solver.cpp:231] Iteration 316400, loss = 1.17659
I0519 07:33:11.037657  4008 solver.cpp:247]     Train net output #0: loss = 1.17659 (* 1 = 1.17659 loss)
I0519 07:33:11.037689  4008 sgd_solver.cpp:106] Iteration 316400, lr = 0.0001
I0519 07:33:11.195811  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1385	3.125	81.8864	0	91.0065	5.98958	89.025	0	85.145	0	85.5901	0	78.3311	0	30.3752	2.7	
I0519 07:33:11.271528  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:33:11.273674  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:33:11.273708  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:33:11.294401  4008 solver.cpp:260]     Total regularization terms: 0.948742 loss+regular. : 2.12534
I0519 07:34:31.484483  4008 solver.cpp:231] Iteration 316600, loss = 1.09656
I0519 07:34:31.484846  4008 solver.cpp:247]     Train net output #0: loss = 1.09656 (* 1 = 1.09656 loss)
I0519 07:34:31.484876  4008 sgd_solver.cpp:106] Iteration 316600, lr = 0.0001
I0519 07:34:31.645395  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1443	3.125	81.8896	0	91.0078	5.98958	89.0263	0	85.1459	0	85.5901	0	78.3312	0	30.3753	2.7	
I0519 07:34:31.721376  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:34:31.724345  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:34:31.724398  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:34:31.739557  4008 solver.cpp:260]     Total regularization terms: 0.948702 loss+regular. : 2.04526
I0519 07:35:54.380476  4008 solver.cpp:231] Iteration 316800, loss = 1.188
I0519 07:35:54.380921  4008 solver.cpp:247]     Train net output #0: loss = 1.188 (* 1 = 1.188 loss)
I0519 07:35:54.380944  4008 sgd_solver.cpp:106] Iteration 316800, lr = 0.0001
I0519 07:35:54.541528  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1443	3.125	81.8936	0	91.0083	5.98958	89.0278	0	85.1477	0	85.5902	0	78.3312	0	30.3754	2.7	
I0519 07:35:54.617522  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:35:54.620632  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:35:54.620682  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:35:54.630661  4008 solver.cpp:260]     Total regularization terms: 0.948656 loss+regular. : 2.13666
I0519 07:37:14.607815  4008 solver.cpp:348] Iteration 317000, Testing net (#0)
I0519 07:37:34.452138  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:38:36.656141  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56632
I0519 07:38:36.656467  4008 solver.cpp:415]     Test net output #1: loss = 1.86336 (* 1 = 1.86336 loss)
I0519 07:38:36.839994  4008 solver.cpp:231] Iteration 317000, loss = 1.5033
I0519 07:38:36.840077  4008 solver.cpp:247]     Train net output #0: loss = 1.5033 (* 1 = 1.5033 loss)
I0519 07:38:36.840096  4008 sgd_solver.cpp:106] Iteration 317000, lr = 0.0001
I0519 07:38:36.998992  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.15	3.125	81.8978	0	91.0093	5.98958	89.029	0	85.1483	0	85.5903	0	78.3313	0	30.3754	2.7	
I0519 07:38:37.074278  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:38:37.076902  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:38:37.076949  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:38:37.086801  4008 solver.cpp:260]     Total regularization terms: 0.948619 loss+regular. : 2.45191
I0519 07:39:53.535972  4008 solver.cpp:231] Iteration 317200, loss = 1.22582
I0519 07:39:53.536211  4008 solver.cpp:247]     Train net output #0: loss = 1.22582 (* 1 = 1.22582 loss)
I0519 07:39:53.536264  4008 sgd_solver.cpp:106] Iteration 317200, lr = 0.0001
I0519 07:39:53.695580  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.15	3.125	81.903	0	91.0111	5.98958	89.0305	0	85.1486	0	85.5903	0	78.3313	0	30.3755	2.7	
I0519 07:39:53.769987  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:39:53.771878  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:39:53.771895  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:39:53.781489  4008 solver.cpp:260]     Total regularization terms: 0.948578 loss+regular. : 2.1744
I0519 07:40:15.156517  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:41:15.834537  4008 solver.cpp:231] Iteration 317400, loss = 1.27434
I0519 07:41:15.834897  4008 solver.cpp:247]     Train net output #0: loss = 1.27434 (* 1 = 1.27434 loss)
I0519 07:41:15.834935  4008 sgd_solver.cpp:106] Iteration 317400, lr = 0.0001
I0519 07:41:15.996534  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.15	3.125	81.9062	0	91.0122	5.98958	89.0315	0	85.1495	0	85.5904	0	78.3315	0	30.3755	2.7	
I0519 07:41:16.079006  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:41:16.080888  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:41:16.080931  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:41:16.102071  4008 solver.cpp:260]     Total regularization terms: 0.948535 loss+regular. : 2.22288
I0519 07:42:41.215463  4008 solver.cpp:231] Iteration 317600, loss = 1.26177
I0519 07:42:41.215927  4008 solver.cpp:247]     Train net output #0: loss = 1.26177 (* 1 = 1.26177 loss)
I0519 07:42:41.215956  4008 sgd_solver.cpp:106] Iteration 317600, lr = 0.0001
I0519 07:42:41.375300  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.15	3.125	81.9082	0	91.0136	5.98958	89.0331	0	85.1513	0	85.5904	0	78.3315	0	30.3755	2.7	
I0519 07:42:41.452080  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:42:41.456195  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:42:41.456256  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:42:41.466766  4008 solver.cpp:260]     Total regularization terms: 0.948496 loss+regular. : 2.21027
I0519 07:44:10.789773  4008 solver.cpp:231] Iteration 317800, loss = 1.19311
I0519 07:44:10.793704  4008 solver.cpp:247]     Train net output #0: loss = 1.19311 (* 1 = 1.19311 loss)
I0519 07:44:10.793745  4008 sgd_solver.cpp:106] Iteration 317800, lr = 0.0001
I0519 07:44:10.951328  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1529	3.125	81.9118	0	91.0144	5.98958	89.0352	0	85.1531	0	85.5905	0	78.3316	0	30.3756	2.7	
I0519 07:44:11.027853  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:44:11.031522  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:44:11.031586  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:44:11.041640  4008 solver.cpp:260]     Total regularization terms: 0.94846 loss+regular. : 2.14157
I0519 07:45:45.122685  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_318000.caffemodel
I0519 07:47:28.770706  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_318000.solverstate
I0519 07:47:29.486456  4008 solver.cpp:348] Iteration 318000, Testing net (#0)
I0519 07:47:50.068276  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:49:00.976331  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56644
I0519 07:49:00.976630  4008 solver.cpp:415]     Test net output #1: loss = 1.86254 (* 1 = 1.86254 loss)
I0519 07:49:01.068565  4008 solver.cpp:231] Iteration 318000, loss = 1.24732
I0519 07:49:01.068639  4008 solver.cpp:247]     Train net output #0: loss = 1.24732 (* 1 = 1.24732 loss)
I0519 07:49:01.068658  4008 sgd_solver.cpp:106] Iteration 318000, lr = 0.0001
I0519 07:49:01.227690  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1615	3.125	81.917	0	91.0148	5.98958	89.0358	0	85.1531	0	85.5906	0	78.3316	0	30.3757	2.7	
I0519 07:49:01.230150  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:49:01.233083  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:49:01.233129  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:49:01.243086  4008 solver.cpp:260]     Total regularization terms: 0.948415 loss+regular. : 2.19573
I0519 07:50:30.630297  4008 solver.cpp:231] Iteration 318200, loss = 1.25662
I0519 07:50:30.630630  4008 solver.cpp:247]     Train net output #0: loss = 1.25662 (* 1 = 1.25662 loss)
I0519 07:50:30.630650  4008 sgd_solver.cpp:106] Iteration 318200, lr = 0.0001
I0519 07:50:30.792346  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1644	3.125	81.9206	0	91.0157	5.98958	89.0361	0	85.1538	0	85.5907	0	78.3317	0	30.3757	2.7	
I0519 07:50:30.866950  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:50:30.869040  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:50:30.869097  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:50:30.878994  4008 solver.cpp:260]     Total regularization terms: 0.94838 loss+regular. : 2.205
I0519 07:50:55.197751  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:51:54.608834  4008 solver.cpp:231] Iteration 318400, loss = 1.14244
I0519 07:51:54.609117  4008 solver.cpp:247]     Train net output #0: loss = 1.14244 (* 1 = 1.14244 loss)
I0519 07:51:54.609139  4008 sgd_solver.cpp:106] Iteration 318400, lr = 0.0001
I0519 07:51:54.770961  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1644	3.125	81.9258	0	91.0164	5.98958	89.0369	0	85.1547	0	85.5907	0	78.3318	0	30.3758	2.7	
I0519 07:51:54.847549  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:51:54.849678  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:51:54.849728  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:51:54.864718  4008 solver.cpp:260]     Total regularization terms: 0.94834 loss+regular. : 2.09078
I0519 07:53:21.737952  4008 solver.cpp:231] Iteration 318600, loss = 1.20528
I0519 07:53:21.738425  4008 solver.cpp:247]     Train net output #0: loss = 1.20528 (* 1 = 1.20528 loss)
I0519 07:53:21.738450  4008 sgd_solver.cpp:106] Iteration 318600, lr = 0.0001
I0519 07:53:21.898072  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1672	3.125	81.9297	0	91.0174	5.98958	89.0376	0	85.1556	0	85.5908	0	78.3319	0	30.3758	2.7	
I0519 07:53:21.972820  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:53:21.974972  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:53:21.975213  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:53:21.985220  4008 solver.cpp:260]     Total regularization terms: 0.948306 loss+regular. : 2.15359
I0519 07:54:46.583431  4008 solver.cpp:231] Iteration 318800, loss = 1.29291
I0519 07:54:46.586441  4008 solver.cpp:247]     Train net output #0: loss = 1.29291 (* 1 = 1.29291 loss)
I0519 07:54:46.586498  4008 sgd_solver.cpp:106] Iteration 318800, lr = 0.0001
I0519 07:54:46.743171  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1701	3.125	81.9398	0	91.0184	5.98958	89.0391	0	85.1569	0	85.5909	0	78.3319	0	30.3759	2.7	
I0519 07:54:46.819053  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:54:46.821238  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:54:46.821279  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:54:46.836218  4008 solver.cpp:260]     Total regularization terms: 0.948269 loss+regular. : 2.24118
I0519 07:56:09.284919  4008 solver.cpp:348] Iteration 319000, Testing net (#0)
I0519 07:56:32.273311  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 07:57:48.539396  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56636
I0519 07:57:48.539808  4008 solver.cpp:415]     Test net output #1: loss = 1.86491 (* 1 = 1.86491 loss)
I0519 07:57:48.629408  4008 solver.cpp:231] Iteration 319000, loss = 1.12482
I0519 07:57:48.629534  4008 solver.cpp:247]     Train net output #0: loss = 1.12482 (* 1 = 1.12482 loss)
I0519 07:57:48.629580  4008 sgd_solver.cpp:106] Iteration 319000, lr = 0.0001
I0519 07:57:48.788033  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1758	3.125	81.943	0	91.0196	5.98958	89.0406	0	85.1583	0	85.5909	0	78.332	0	30.3759	2.7	
I0519 07:57:48.864816  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:57:48.866961  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:57:48.867020  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:57:48.882031  4008 solver.cpp:260]     Total regularization terms: 0.948233 loss+regular. : 2.07306
I0519 07:59:19.373917  4008 solver.cpp:231] Iteration 319200, loss = 1.1403
I0519 07:59:19.378191  4008 solver.cpp:247]     Train net output #0: loss = 1.1403 (* 1 = 1.1403 loss)
I0519 07:59:19.378248  4008 sgd_solver.cpp:106] Iteration 319200, lr = 0.0001
I0519 07:59:19.533241  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1787	3.125	81.9489	0	91.0203	5.98958	89.0413	0	85.159	0	85.591	0	78.3321	0	30.376	2.7	
I0519 07:59:19.607775  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 07:59:19.612004  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 07:59:19.612061  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 07:59:19.621898  4008 solver.cpp:260]     Total regularization terms: 0.948189 loss+regular. : 2.08849
I0519 07:59:54.481830  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:00:57.157032  4008 solver.cpp:231] Iteration 319400, loss = 1.3061
I0519 08:00:57.158275  4008 solver.cpp:247]     Train net output #0: loss = 1.3061 (* 1 = 1.3061 loss)
I0519 08:00:57.158310  4008 sgd_solver.cpp:106] Iteration 319400, lr = 0.0001
I0519 08:00:57.317328  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1787	3.125	81.9541	0	91.0209	5.98958	89.0434	0	85.1601	0	85.5911	0	78.3322	0	30.3761	2.7	
I0519 08:00:57.392686  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:00:57.394979  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:00:57.395025  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:00:57.404765  4008 solver.cpp:260]     Total regularization terms: 0.948159 loss+regular. : 2.25426
I0519 08:02:36.832008  4008 solver.cpp:231] Iteration 319600, loss = 1.281
I0519 08:02:36.832356  4008 solver.cpp:247]     Train net output #0: loss = 1.281 (* 1 = 1.281 loss)
I0519 08:02:36.832379  4008 sgd_solver.cpp:106] Iteration 319600, lr = 0.0001
I0519 08:02:36.993315  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1816	3.125	81.9587	0	91.022	5.98958	89.0441	0	85.1612	0	85.5912	0	78.3323	0	30.3761	2.7	
I0519 08:02:37.068253  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:02:37.070413  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:02:37.070467  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:02:37.080469  4008 solver.cpp:260]     Total regularization terms: 0.948119 loss+regular. : 2.22912
I0519 08:04:08.065871  4008 solver.cpp:231] Iteration 319800, loss = 1.49181
I0519 08:04:08.066191  4008 solver.cpp:247]     Train net output #0: loss = 1.49181 (* 1 = 1.49181 loss)
I0519 08:04:08.066211  4008 sgd_solver.cpp:106] Iteration 319800, lr = 0.0001
I0519 08:04:08.227118  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1845	3.125	81.9632	0	91.023	5.98958	89.0447	0	85.1621	0	85.5912	0	78.3323	0	30.3761	2.7	
I0519 08:04:08.302402  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:04:08.304600  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:04:08.304651  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:04:08.314522  4008 solver.cpp:260]     Total regularization terms: 0.948083 loss+regular. : 2.4399
I0519 08:05:44.533340  4008 solver.cpp:348] Iteration 320000, Testing net (#0)
I0519 08:06:10.206393  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:07:15.982406  4008 solver.cpp:415]     Test net output #0: accuracy = 0.565499
I0519 08:07:15.982727  4008 solver.cpp:415]     Test net output #1: loss = 1.86339 (* 1 = 1.86339 loss)
I0519 08:07:16.086302  4008 solver.cpp:231] Iteration 320000, loss = 1.20607
I0519 08:07:16.086431  4008 solver.cpp:247]     Train net output #0: loss = 1.20607 (* 1 = 1.20607 loss)
I0519 08:07:16.086458  4008 sgd_solver.cpp:106] Iteration 320000, lr = 0.0001
I0519 08:07:16.250406  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1902	3.125	81.9681	0	91.0235	5.98958	89.0455	0	85.1624	0	85.5913	0	78.3324	0	30.3762	2.7	
I0519 08:07:16.326267  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:07:16.330046  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:07:16.330096  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:07:16.339941  4008 solver.cpp:260]     Total regularization terms: 0.948037 loss+regular. : 2.15411
I0519 08:08:48.186558  4008 solver.cpp:231] Iteration 320200, loss = 1.20148
I0519 08:08:48.186836  4008 solver.cpp:247]     Train net output #0: loss = 1.20148 (* 1 = 1.20148 loss)
I0519 08:08:48.186862  4008 sgd_solver.cpp:106] Iteration 320200, lr = 0.0001
I0519 08:08:48.347115  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1902	3.125	81.9714	0	91.0246	5.98958	89.0465	0	85.1626	0	85.5914	0	78.3325	0	30.3763	2.7	
I0519 08:08:48.423705  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:08:48.426584  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:08:48.426627  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:08:48.436504  4008 solver.cpp:260]     Total regularization terms: 0.947994 loss+regular. : 2.14948
I0519 08:09:17.873467  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:10:19.873738  4008 solver.cpp:231] Iteration 320400, loss = 1.15103
I0519 08:10:19.874146  4008 solver.cpp:247]     Train net output #0: loss = 1.15103 (* 1 = 1.15103 loss)
I0519 08:10:19.874178  4008 sgd_solver.cpp:106] Iteration 320400, lr = 0.0001
I0519 08:10:20.033000  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1959	3.125	81.9772	0	91.025	5.98958	89.0471	0	85.1637	0	85.5914	0	78.3326	0	30.3764	2.7	
I0519 08:10:20.108536  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:10:20.111629  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:10:20.111678  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:10:20.123072  4008 solver.cpp:260]     Total regularization terms: 0.947947 loss+regular. : 2.09898
I0519 08:11:52.631551  4008 solver.cpp:231] Iteration 320600, loss = 1.3746
I0519 08:11:52.631935  4008 solver.cpp:247]     Train net output #0: loss = 1.3746 (* 1 = 1.3746 loss)
I0519 08:11:52.631968  4008 sgd_solver.cpp:106] Iteration 320600, lr = 0.0001
I0519 08:11:52.791326  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.1959	3.125	81.9808	0	91.0258	5.98958	89.0486	0	85.1642	0	85.5915	0	78.3326	0	30.3765	2.7	
I0519 08:11:52.867754  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:11:52.871912  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:11:52.872005  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:11:52.883574  4008 solver.cpp:260]     Total regularization terms: 0.947909 loss+regular. : 2.3225
I0519 08:13:25.933886  4008 solver.cpp:231] Iteration 320800, loss = 1.26315
I0519 08:13:25.934154  4008 solver.cpp:247]     Train net output #0: loss = 1.26315 (* 1 = 1.26315 loss)
I0519 08:13:25.934175  4008 sgd_solver.cpp:106] Iteration 320800, lr = 0.0001
I0519 08:13:26.094898  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2017	3.125	81.9854	0	91.0266	5.98958	89.0501	0	85.1648	0	85.5916	0	78.3327	0	30.3766	2.7	
I0519 08:13:26.169908  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:13:26.171903  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:13:26.171954  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:13:26.182009  4008 solver.cpp:260]     Total regularization terms: 0.947872 loss+regular. : 2.21102
I0519 08:14:59.795788  4008 solver.cpp:348] Iteration 321000, Testing net (#0)
I0519 08:15:25.412432  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:16:25.880456  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56594
I0519 08:16:25.881989  4008 solver.cpp:415]     Test net output #1: loss = 1.86296 (* 1 = 1.86296 loss)
I0519 08:16:25.970618  4008 solver.cpp:231] Iteration 321000, loss = 1.36989
I0519 08:16:25.970693  4008 solver.cpp:247]     Train net output #0: loss = 1.36989 (* 1 = 1.36989 loss)
I0519 08:16:25.970711  4008 sgd_solver.cpp:106] Iteration 321000, lr = 0.0001
I0519 08:16:26.134685  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2045	3.125	81.9906	0	91.0274	5.98958	89.051	0	85.1655	0	85.5916	0	78.3329	0	30.3766	2.7	
I0519 08:16:26.210149  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:16:26.212919  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:16:26.212993  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:16:26.222888  4008 solver.cpp:260]     Total regularization terms: 0.947828 loss+regular. : 2.31772
I0519 08:17:56.126101  4008 solver.cpp:231] Iteration 321200, loss = 1.07658
I0519 08:17:56.126478  4008 solver.cpp:247]     Train net output #0: loss = 1.07658 (* 1 = 1.07658 loss)
I0519 08:17:56.126497  4008 sgd_solver.cpp:106] Iteration 321200, lr = 0.0001
I0519 08:17:56.287252  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2045	3.125	81.9938	0	91.0286	5.98958	89.0517	0	85.1664	0	85.5917	0	78.3329	0	30.3767	2.7	
I0519 08:17:56.362296  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:17:56.364909  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:17:56.364965  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:17:56.374948  4008 solver.cpp:260]     Total regularization terms: 0.947786 loss+regular. : 2.02437
I0519 08:18:27.890807  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:19:22.443907  4008 solver.cpp:231] Iteration 321400, loss = 1.33997
I0519 08:19:22.444716  4008 solver.cpp:247]     Train net output #0: loss = 1.33997 (* 1 = 1.33997 loss)
I0519 08:19:22.444739  4008 sgd_solver.cpp:106] Iteration 321400, lr = 0.0001
I0519 08:19:22.605054  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2045	3.125	82.0003	0	91.0293	5.98958	89.0527	0	85.1675	0	85.5918	0	78.333	0	30.3768	2.7	
I0519 08:19:22.680660  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:19:22.683528  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:19:22.683581  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:19:22.698894  4008 solver.cpp:260]     Total regularization terms: 0.947745 loss+regular. : 2.28772
I0519 08:20:52.751382  4008 solver.cpp:231] Iteration 321600, loss = 1.29362
I0519 08:20:52.751744  4008 solver.cpp:247]     Train net output #0: loss = 1.29362 (* 1 = 1.29362 loss)
I0519 08:20:52.751780  4008 sgd_solver.cpp:106] Iteration 321600, lr = 0.0001
I0519 08:20:52.910737  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2045	3.125	82.0039	0	91.0303	5.98958	89.0532	0	85.1682	0	85.5918	0	78.3331	0	30.3768	2.7	
I0519 08:20:52.984915  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:20:52.986577  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:20:52.986609  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:20:52.996397  4008 solver.cpp:260]     Total regularization terms: 0.947714 loss+regular. : 2.24133
I0519 08:22:20.376567  4008 solver.cpp:231] Iteration 321800, loss = 1.53327
I0519 08:22:20.376979  4008 solver.cpp:247]     Train net output #0: loss = 1.53327 (* 1 = 1.53327 loss)
I0519 08:22:20.377012  4008 sgd_solver.cpp:106] Iteration 321800, lr = 0.0001
I0519 08:22:20.537140  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2045	3.125	82.0078	0	91.0309	5.98958	89.0538	0	85.1696	0	85.5919	0	78.3332	0	30.3769	2.7	
I0519 08:22:20.612943  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:22:20.615329  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:22:20.615401  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:22:20.625417  4008 solver.cpp:260]     Total regularization terms: 0.947671 loss+regular. : 2.48094
I0519 08:23:45.826320  4008 solver.cpp:348] Iteration 322000, Testing net (#0)
I0519 08:24:08.146031  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:25:10.090773  4008 solver.cpp:415]     Test net output #0: accuracy = 0.566819
I0519 08:25:10.091161  4008 solver.cpp:415]     Test net output #1: loss = 1.86179 (* 1 = 1.86179 loss)
I0519 08:25:10.179975  4008 solver.cpp:231] Iteration 322000, loss = 1.27854
I0519 08:25:10.180086  4008 solver.cpp:247]     Train net output #0: loss = 1.27854 (* 1 = 1.27854 loss)
I0519 08:25:10.180107  4008 sgd_solver.cpp:106] Iteration 322000, lr = 0.0001
I0519 08:25:10.346503  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2045	3.125	82.0104	0	91.0321	5.98958	89.0545	0	85.17	0	85.592	0	78.3332	0	30.3769	2.7	
I0519 08:25:10.421677  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:25:10.423985  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:25:10.424018  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:25:10.433979  4008 solver.cpp:260]     Total regularization terms: 0.94762 loss+regular. : 2.22616
I0519 08:26:31.540462  4008 solver.cpp:231] Iteration 322200, loss = 1.10655
I0519 08:26:31.540784  4008 solver.cpp:247]     Train net output #0: loss = 1.10655 (* 1 = 1.10655 loss)
I0519 08:26:31.540814  4008 sgd_solver.cpp:106] Iteration 322200, lr = 0.0001
I0519 08:26:31.699730  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2074	3.125	82.0133	0	91.0327	5.98958	89.0559	0	85.1705	0	85.5921	0	78.3333	0	30.377	2.7	
I0519 08:26:31.774689  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:26:31.776681  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:26:31.776726  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:26:31.786692  4008 solver.cpp:260]     Total regularization terms: 0.94758 loss+regular. : 2.05414
I0519 08:27:09.035634  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:28:15.816923  4008 solver.cpp:231] Iteration 322400, loss = 1.3532
I0519 08:28:15.817240  4008 solver.cpp:247]     Train net output #0: loss = 1.3532 (* 1 = 1.3532 loss)
I0519 08:28:15.817270  4008 sgd_solver.cpp:106] Iteration 322400, lr = 0.0001
I0519 08:28:15.977929  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2074	3.125	82.0182	0	91.034	5.98958	89.0563	0	85.1718	0	85.5921	0	78.3333	0	30.3771	2.7	
I0519 08:28:16.053570  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:28:16.056334  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:28:16.056381  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:28:16.066442  4008 solver.cpp:260]     Total regularization terms: 0.947546 loss+regular. : 2.30074
I0519 08:29:46.880842  4008 solver.cpp:231] Iteration 322600, loss = 1.36735
I0519 08:29:46.881079  4008 solver.cpp:247]     Train net output #0: loss = 1.36735 (* 1 = 1.36735 loss)
I0519 08:29:46.881096  4008 sgd_solver.cpp:106] Iteration 322600, lr = 0.0001
I0519 08:29:47.039937  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2074	3.125	82.0225	0	91.035	5.98958	89.0572	0	85.1734	0	85.5922	0	78.3334	0	30.3771	2.7	
I0519 08:29:47.116876  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:29:47.119338  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:29:47.119387  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:29:47.134912  4008 solver.cpp:260]     Total regularization terms: 0.947506 loss+regular. : 2.31485
I0519 08:31:12.787828  4008 solver.cpp:231] Iteration 322800, loss = 1.2634
I0519 08:31:12.788177  4008 solver.cpp:247]     Train net output #0: loss = 1.2634 (* 1 = 1.2634 loss)
I0519 08:31:12.788226  4008 sgd_solver.cpp:106] Iteration 322800, lr = 0.0001
I0519 08:31:12.948148  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2132	3.125	82.0264	0	91.0362	5.98958	89.0577	0	85.1741	0	85.5923	0	78.3335	0	30.3772	2.7	
I0519 08:31:13.024124  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:31:13.027663  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:31:13.027782  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:31:13.042901  4008 solver.cpp:260]     Total regularization terms: 0.94746 loss+regular. : 2.21086
I0519 08:32:42.531572  4008 solver.cpp:348] Iteration 323000, Testing net (#0)
I0519 08:33:05.748399  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:34:05.872972  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567339
I0519 08:34:05.873194  4008 solver.cpp:415]     Test net output #1: loss = 1.86159 (* 1 = 1.86159 loss)
I0519 08:34:05.963444  4008 solver.cpp:231] Iteration 323000, loss = 1.04532
I0519 08:34:05.963593  4008 solver.cpp:247]     Train net output #0: loss = 1.04532 (* 1 = 1.04532 loss)
I0519 08:34:05.963615  4008 sgd_solver.cpp:106] Iteration 323000, lr = 0.0001
I0519 08:34:06.130609  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2132	3.125	82.0322	0	91.0368	5.98958	89.0584	0	85.175	0	85.5923	0	78.3336	0	30.3773	2.7	
I0519 08:34:06.206028  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:34:06.208199  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:34:06.208247  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:34:06.218191  4008 solver.cpp:260]     Total regularization terms: 0.947428 loss+regular. : 1.99275
I0519 08:35:25.940814  4008 solver.cpp:231] Iteration 323200, loss = 1.29126
I0519 08:35:25.941264  4008 solver.cpp:247]     Train net output #0: loss = 1.29126 (* 1 = 1.29126 loss)
I0519 08:35:25.941292  4008 sgd_solver.cpp:106] Iteration 323200, lr = 0.0001
I0519 08:35:26.102037  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2132	3.125	82.0352	0	91.0374	5.98958	89.0589	0	85.1759	0	85.5924	0	78.3337	0	30.3774	2.7	
I0519 08:35:26.178907  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:35:26.182340  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:35:26.182407  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:35:26.193183  4008 solver.cpp:260]     Total regularization terms: 0.947385 loss+regular. : 2.23864
I0519 08:36:06.156003  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:36:59.080826  4008 solver.cpp:231] Iteration 323400, loss = 1.33748
I0519 08:36:59.081142  4008 solver.cpp:247]     Train net output #0: loss = 1.33748 (* 1 = 1.33748 loss)
I0519 08:36:59.081161  4008 sgd_solver.cpp:106] Iteration 323400, lr = 0.0001
I0519 08:36:59.240118  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2132	3.125	82.043	0	91.0379	5.98958	89.0599	0	85.177	0	85.5925	0	78.3338	0	30.3775	2.7	
I0519 08:36:59.315112  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:36:59.317373  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:36:59.317417  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:36:59.327368  4008 solver.cpp:260]     Total regularization terms: 0.947345 loss+regular. : 2.28482
I0519 08:38:40.653723  4008 solver.cpp:231] Iteration 323600, loss = 1.35941
I0519 08:38:40.654008  4008 solver.cpp:247]     Train net output #0: loss = 1.35941 (* 1 = 1.35941 loss)
I0519 08:38:40.654032  4008 sgd_solver.cpp:106] Iteration 323600, lr = 0.0001
I0519 08:38:40.813024  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.216	3.125	82.0452	0	91.0391	5.98958	89.0613	0	85.1779	0	85.5926	0	78.3338	0	30.3776	2.7	
I0519 08:38:40.888502  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:38:40.891218  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:38:40.891274  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:38:40.901248  4008 solver.cpp:260]     Total regularization terms: 0.947305 loss+regular. : 2.30672
I0519 08:40:11.174652  4008 solver.cpp:231] Iteration 323800, loss = 1.38944
I0519 08:40:11.174986  4008 solver.cpp:247]     Train net output #0: loss = 1.38944 (* 1 = 1.38944 loss)
I0519 08:40:11.175004  4008 sgd_solver.cpp:106] Iteration 323800, lr = 0.0001
I0519 08:40:11.335647  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.216	3.125	82.0492	0	91.0407	5.98958	89.0627	0	85.18	0	85.5926	0	78.334	0	30.3776	2.7	
I0519 08:40:11.410418  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:40:11.412880  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:40:11.412935  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:40:11.423069  4008 solver.cpp:260]     Total regularization terms: 0.947267 loss+regular. : 2.33671
I0519 08:41:35.420590  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_324000.caffemodel
I0519 08:44:59.773481  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_324000.solverstate
I0519 08:45:00.389544  4008 solver.cpp:348] Iteration 324000, Testing net (#0)
I0519 08:45:24.800673  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:46:18.999490  4008 solver.cpp:415]     Test net output #0: accuracy = 0.566059
I0519 08:46:18.999765  4008 solver.cpp:415]     Test net output #1: loss = 1.86435 (* 1 = 1.86435 loss)
I0519 08:46:19.094244  4008 solver.cpp:231] Iteration 324000, loss = 1.39004
I0519 08:46:19.094321  4008 solver.cpp:247]     Train net output #0: loss = 1.39004 (* 1 = 1.39004 loss)
I0519 08:46:19.094338  4008 sgd_solver.cpp:106] Iteration 324000, lr = 0.0001
I0519 08:46:19.259968  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2218	3.125	82.057	0	91.0414	5.98958	89.064	0	85.1804	0	85.5927	0	78.334	0	30.3777	2.7	
I0519 08:46:19.262305  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:46:19.265223  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:46:19.265265  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:46:19.275383  4008 solver.cpp:260]     Total regularization terms: 0.947228 loss+regular. : 2.33727
I0519 08:47:44.234839  4008 solver.cpp:231] Iteration 324200, loss = 1.24587
I0519 08:47:44.237679  4008 solver.cpp:247]     Train net output #0: loss = 1.24587 (* 1 = 1.24587 loss)
I0519 08:47:44.237715  4008 sgd_solver.cpp:106] Iteration 324200, lr = 0.0001
I0519 08:47:44.395709  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2246	3.125	82.0615	0	91.0425	5.98958	89.0651	0	85.1818	0	85.5928	0	78.3341	0	30.3778	2.7	
I0519 08:47:44.471418  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:47:44.474339  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:47:44.474387  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:47:44.484249  4008 solver.cpp:260]     Total regularization terms: 0.947188 loss+regular. : 2.19306
I0519 08:48:23.798802  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:49:08.879858  4008 solver.cpp:231] Iteration 324400, loss = 1.45657
I0519 08:49:08.880359  4008 solver.cpp:247]     Train net output #0: loss = 1.45657 (* 1 = 1.45657 loss)
I0519 08:49:08.880403  4008 sgd_solver.cpp:106] Iteration 324400, lr = 0.0001
I0519 08:49:09.039752  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2246	3.125	82.0654	0	91.0435	5.98958	89.0655	0	85.1832	0	85.5928	0	78.3342	0	30.3779	2.7	
I0519 08:49:09.115499  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:49:09.118357  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:49:09.118427  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:49:09.128465  4008 solver.cpp:260]     Total regularization terms: 0.947149 loss+regular. : 2.40372
I0519 08:50:34.504560  4008 solver.cpp:231] Iteration 324600, loss = 1.28001
I0519 08:50:34.504848  4008 solver.cpp:247]     Train net output #0: loss = 1.28001 (* 1 = 1.28001 loss)
I0519 08:50:34.504866  4008 sgd_solver.cpp:106] Iteration 324600, lr = 0.0001
I0519 08:50:34.666718  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2275	3.125	82.068	0	91.0447	5.98958	89.0657	0	85.1832	0	85.5929	0	78.3343	0	30.378	2.7	
I0519 08:50:34.741561  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:50:34.743806  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:50:34.743840  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:50:34.753610  4008 solver.cpp:260]     Total regularization terms: 0.947105 loss+regular. : 2.22711
I0519 08:52:02.127727  4008 solver.cpp:231] Iteration 324800, loss = 1.24831
I0519 08:52:02.128140  4008 solver.cpp:247]     Train net output #0: loss = 1.24831 (* 1 = 1.24831 loss)
I0519 08:52:02.128183  4008 sgd_solver.cpp:106] Iteration 324800, lr = 0.0001
I0519 08:52:02.286329  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2275	3.125	82.071	0	91.0456	5.98958	89.0669	0	85.1838	0	85.593	0	78.3344	0	30.3781	2.7	
I0519 08:52:02.361721  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:52:02.364461  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:52:02.364513  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:52:02.374536  4008 solver.cpp:260]     Total regularization terms: 0.947076 loss+regular. : 2.19539
I0519 08:53:27.977512  4008 solver.cpp:348] Iteration 325000, Testing net (#0)
I0519 08:53:55.492955  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:54:51.452141  4008 solver.cpp:415]     Test net output #0: accuracy = 0.564659
I0519 08:54:51.452461  4008 solver.cpp:415]     Test net output #1: loss = 1.86297 (* 1 = 1.86297 loss)
I0519 08:54:51.541205  4008 solver.cpp:231] Iteration 325000, loss = 1.22115
I0519 08:54:51.541288  4008 solver.cpp:247]     Train net output #0: loss = 1.22115 (* 1 = 1.22115 loss)
I0519 08:54:51.541308  4008 sgd_solver.cpp:106] Iteration 325000, lr = 0.0001
I0519 08:54:51.701660  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2332	3.125	82.0755	0	91.0461	5.98958	89.0672	0	85.1843	0	85.5931	0	78.3344	0	30.3782	2.7	
I0519 08:54:51.777478  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:54:51.781116  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:54:51.781188  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:54:51.793496  4008 solver.cpp:260]     Total regularization terms: 0.947031 loss+regular. : 2.16818
I0519 08:56:17.969748  4008 solver.cpp:231] Iteration 325200, loss = 1.1731
I0519 08:56:17.970068  4008 solver.cpp:247]     Train net output #0: loss = 1.1731 (* 1 = 1.1731 loss)
I0519 08:56:17.970098  4008 sgd_solver.cpp:106] Iteration 325200, lr = 0.0001
I0519 08:56:18.129961  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2361	3.125	82.0798	0	91.0467	5.98958	89.0678	0	85.1845	0	85.5931	0	78.3345	0	30.3783	2.7	
I0519 08:56:18.205087  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:56:18.207415  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:56:18.207456  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:56:18.222422  4008 solver.cpp:260]     Total regularization terms: 0.946994 loss+regular. : 2.12009
I0519 08:57:01.711999  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 08:57:45.782572  4008 solver.cpp:231] Iteration 325400, loss = 1.10722
I0519 08:57:45.782977  4008 solver.cpp:247]     Train net output #0: loss = 1.10722 (* 1 = 1.10722 loss)
I0519 08:57:45.783015  4008 sgd_solver.cpp:106] Iteration 325400, lr = 0.0001
I0519 08:57:45.942322  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.239	3.125	82.083	0	91.0476	5.98958	89.0685	0	85.1865	0	85.5932	0	78.3345	0	30.3784	2.7	
I0519 08:57:46.017730  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:57:46.020521  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:57:46.020617  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:57:46.030964  4008 solver.cpp:260]     Total regularization terms: 0.946958 loss+regular. : 2.05418
I0519 08:59:09.705684  4008 solver.cpp:231] Iteration 325600, loss = 1.21751
I0519 08:59:09.706145  4008 solver.cpp:247]     Train net output #0: loss = 1.21751 (* 1 = 1.21751 loss)
I0519 08:59:09.706187  4008 sgd_solver.cpp:106] Iteration 325600, lr = 0.0001
I0519 08:59:09.866744  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2447	3.125	82.0872	0	91.0483	5.98958	89.0696	0	85.1879	0	85.5933	0	78.3346	0	30.3785	2.7	
I0519 08:59:09.943003  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 08:59:09.945760  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 08:59:09.945827  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 08:59:09.956305  4008 solver.cpp:260]     Total regularization terms: 0.946915 loss+regular. : 2.16443
I0519 09:00:39.654613  4008 solver.cpp:231] Iteration 325800, loss = 1.4103
I0519 09:00:39.654927  4008 solver.cpp:247]     Train net output #0: loss = 1.4103 (* 1 = 1.4103 loss)
I0519 09:00:39.654948  4008 sgd_solver.cpp:106] Iteration 325800, lr = 0.0001
I0519 09:00:39.815676  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2447	3.125	82.0908	0	91.0486	5.98958	89.0702	0	85.1886	0	85.5933	0	78.3347	0	30.3785	2.7	
I0519 09:00:39.891162  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:00:39.893895  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:00:39.893946  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:00:39.904013  4008 solver.cpp:260]     Total regularization terms: 0.946876 loss+regular. : 2.35717
I0519 09:02:15.020278  4008 solver.cpp:348] Iteration 326000, Testing net (#0)
I0519 09:02:40.387358  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:03:44.775985  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5647
I0519 09:03:44.776284  4008 solver.cpp:415]     Test net output #1: loss = 1.86468 (* 1 = 1.86468 loss)
I0519 09:03:44.864002  4008 solver.cpp:231] Iteration 326000, loss = 1.2061
I0519 09:03:44.864114  4008 solver.cpp:247]     Train net output #0: loss = 1.2061 (* 1 = 1.2061 loss)
I0519 09:03:44.864135  4008 sgd_solver.cpp:106] Iteration 326000, lr = 0.0001
I0519 09:03:45.029801  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2447	3.125	82.0944	0	91.0492	5.98958	89.0705	0	85.1902	0	85.5934	0	78.3348	0	30.3786	2.7	
I0519 09:03:45.105077  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:03:45.107226  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:03:45.107280  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:03:45.117292  4008 solver.cpp:260]     Total regularization terms: 0.946832 loss+regular. : 2.15293
I0519 09:05:14.425858  4008 solver.cpp:231] Iteration 326200, loss = 1.34776
I0519 09:05:14.426333  4008 solver.cpp:247]     Train net output #0: loss = 1.34776 (* 1 = 1.34776 loss)
I0519 09:05:14.426360  4008 sgd_solver.cpp:106] Iteration 326200, lr = 0.0001
I0519 09:05:14.584560  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2447	3.125	82.0977	0	91.05	5.98958	89.0712	0	85.1911	0	85.5934	0	78.3349	0	30.3788	2.7	
I0519 09:05:14.659474  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:05:14.661408  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:05:14.661463  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:05:14.671380  4008 solver.cpp:260]     Total regularization terms: 0.946795 loss+regular. : 2.29456
I0519 09:06:06.074329  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:06:41.979857  4008 solver.cpp:231] Iteration 326400, loss = 1.43262
I0519 09:06:41.980159  4008 solver.cpp:247]     Train net output #0: loss = 1.43262 (* 1 = 1.43262 loss)
I0519 09:06:41.980175  4008 sgd_solver.cpp:106] Iteration 326400, lr = 0.0001
I0519 09:06:42.140589  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2447	3.125	82.1022	0	91.0509	5.98958	89.0721	0	85.1917	0	85.5935	0	78.3349	0	30.3789	2.7	
I0519 09:06:42.215667  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:06:42.218185  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:06:42.218248  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:06:42.228113  4008 solver.cpp:260]     Total regularization terms: 0.946751 loss+regular. : 2.37937
I0519 09:08:12.456843  4008 solver.cpp:231] Iteration 326600, loss = 1.22497
I0519 09:08:12.461765  4008 solver.cpp:247]     Train net output #0: loss = 1.22497 (* 1 = 1.22497 loss)
I0519 09:08:12.461815  4008 sgd_solver.cpp:106] Iteration 326600, lr = 0.0001
I0519 09:08:12.616845  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2447	3.125	82.1048	0	91.0518	5.98958	89.0731	0	85.192	0	85.5936	0	78.335	0	30.379	2.7	
I0519 09:08:12.693543  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:08:12.696413  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:08:12.696470  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:08:12.706471  4008 solver.cpp:260]     Total regularization terms: 0.946719 loss+regular. : 2.17168
I0519 09:09:42.462404  4008 solver.cpp:231] Iteration 326800, loss = 1.27794
I0519 09:09:42.462771  4008 solver.cpp:247]     Train net output #0: loss = 1.27794 (* 1 = 1.27794 loss)
I0519 09:09:42.462855  4008 sgd_solver.cpp:106] Iteration 326800, lr = 0.0001
I0519 09:09:42.622395  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2476	3.125	82.1077	0	91.0529	5.98958	89.0738	0	85.1931	0	85.5937	0	78.3351	0	30.379	2.7	
I0519 09:09:42.697649  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:09:42.699951  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:09:42.700001  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:09:42.710101  4008 solver.cpp:260]     Total regularization terms: 0.946684 loss+regular. : 2.22462
I0519 09:11:14.852742  4008 solver.cpp:348] Iteration 327000, Testing net (#0)
I0519 09:11:40.810842  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:12:37.623244  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56578
I0519 09:12:37.623608  4008 solver.cpp:415]     Test net output #1: loss = 1.86148 (* 1 = 1.86148 loss)
I0519 09:12:37.714107  4008 solver.cpp:231] Iteration 327000, loss = 1.30646
I0519 09:12:37.714186  4008 solver.cpp:247]     Train net output #0: loss = 1.30646 (* 1 = 1.30646 loss)
I0519 09:12:37.714206  4008 sgd_solver.cpp:106] Iteration 327000, lr = 0.0001
I0519 09:12:37.876091  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2476	3.125	82.1113	0	91.0537	5.98958	89.0753	0	85.1938	0	85.5937	0	78.3352	0	30.379	2.7	
I0519 09:12:37.952466  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:12:37.954988  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:12:37.955049  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:12:37.964953  4008 solver.cpp:260]     Total regularization terms: 0.946639 loss+regular. : 2.2531
I0519 09:14:01.318259  4008 solver.cpp:231] Iteration 327200, loss = 1.24275
I0519 09:14:01.319249  4008 solver.cpp:247]     Train net output #0: loss = 1.24275 (* 1 = 1.24275 loss)
I0519 09:14:01.319283  4008 sgd_solver.cpp:106] Iteration 327200, lr = 0.0001
I0519 09:14:01.478693  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2505	3.125	82.1143	0	91.0543	5.98958	89.0762	0	85.194	0	85.5938	0	78.3353	0	30.3791	2.7	
I0519 09:14:01.554435  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:14:01.557883  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:14:01.557943  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:14:01.570844  4008 solver.cpp:260]     Total regularization terms: 0.946601 loss+regular. : 2.18935
I0519 09:14:53.682505  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:15:30.509817  4008 solver.cpp:231] Iteration 327400, loss = 1.17767
I0519 09:15:30.510087  4008 solver.cpp:247]     Train net output #0: loss = 1.17767 (* 1 = 1.17767 loss)
I0519 09:15:30.510109  4008 sgd_solver.cpp:106] Iteration 327400, lr = 0.0001
I0519 09:15:30.672070  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2562	3.125	82.1159	0	91.0548	5.98958	89.0768	0	85.1951	0	85.5939	0	78.3353	0	30.3792	2.7	
I0519 09:15:30.747349  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:15:30.749863  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:15:30.749939  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:15:30.760057  4008 solver.cpp:260]     Total regularization terms: 0.946557 loss+regular. : 2.12422
I0519 09:17:01.533713  4008 solver.cpp:231] Iteration 327600, loss = 1.31275
I0519 09:17:01.534081  4008 solver.cpp:247]     Train net output #0: loss = 1.31275 (* 1 = 1.31275 loss)
I0519 09:17:01.534104  4008 sgd_solver.cpp:106] Iteration 327600, lr = 0.0001
I0519 09:17:01.694206  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2591	3.125	82.1175	0	91.0552	5.98958	89.0779	0	85.1951	0	85.5939	0	78.3354	0	30.3792	2.7	
I0519 09:17:01.772584  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:17:01.775970  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:17:01.776034  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:17:01.785972  4008 solver.cpp:260]     Total regularization terms: 0.946522 loss+regular. : 2.25927
I0519 09:18:29.388241  4008 solver.cpp:231] Iteration 327800, loss = 1.26553
I0519 09:18:29.389607  4008 solver.cpp:247]     Train net output #0: loss = 1.26553 (* 1 = 1.26553 loss)
I0519 09:18:29.389626  4008 sgd_solver.cpp:106] Iteration 327800, lr = 0.0001
I0519 09:18:29.550189  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2619	3.125	82.1208	0	91.056	5.98958	89.0786	0	85.196	0	85.594	0	78.3355	0	30.3793	2.7	
I0519 09:18:29.627218  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:18:29.629154  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:18:29.629174  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:18:29.644109  4008 solver.cpp:260]     Total regularization terms: 0.946477 loss+regular. : 2.21201
I0519 09:19:45.033113  4008 solver.cpp:348] Iteration 328000, Testing net (#0)
I0519 09:20:08.143023  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:21:08.216414  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56592
I0519 09:21:08.217663  4008 solver.cpp:415]     Test net output #1: loss = 1.86268 (* 1 = 1.86268 loss)
I0519 09:21:08.304859  4008 solver.cpp:231] Iteration 328000, loss = 1.3006
I0519 09:21:08.304934  4008 solver.cpp:247]     Train net output #0: loss = 1.3006 (* 1 = 1.3006 loss)
I0519 09:21:08.304951  4008 sgd_solver.cpp:106] Iteration 328000, lr = 0.0001
I0519 09:21:08.465374  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2648	3.125	82.124	0	91.0568	5.98958	89.0801	0	85.1969	0	85.594	0	78.3356	0	30.3793	2.7	
I0519 09:21:08.542423  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:21:08.545104  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:21:08.545147  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:21:08.555021  4008 solver.cpp:260]     Total regularization terms: 0.94644 loss+regular. : 2.24704
I0519 09:22:29.022125  4008 solver.cpp:231] Iteration 328200, loss = 1.44058
I0519 09:22:29.025748  4008 solver.cpp:247]     Train net output #0: loss = 1.44058 (* 1 = 1.44058 loss)
I0519 09:22:29.025785  4008 sgd_solver.cpp:106] Iteration 328200, lr = 0.0001
I0519 09:22:29.184284  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2705	3.125	82.1289	0	91.0576	5.98958	89.0809	0	85.1981	0	85.5941	0	78.3357	0	30.3794	2.7	
I0519 09:22:29.260514  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:22:29.263314  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:22:29.263361  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:22:29.278633  4008 solver.cpp:260]     Total regularization terms: 0.946406 loss+regular. : 2.38698
I0519 09:23:21.112272  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:23:52.907534  4008 solver.cpp:231] Iteration 328400, loss = 1.08465
I0519 09:23:52.907842  4008 solver.cpp:247]     Train net output #0: loss = 1.08465 (* 1 = 1.08465 loss)
I0519 09:23:52.907862  4008 sgd_solver.cpp:106] Iteration 328400, lr = 0.0001
I0519 09:23:53.068462  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2763	3.125	82.1312	0	91.058	5.98958	89.0813	0	85.1987	0	85.5942	0	78.3357	0	30.3794	2.7	
I0519 09:23:53.144080  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:23:53.145936  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:23:53.145998  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:23:53.159633  4008 solver.cpp:260]     Total regularization terms: 0.946366 loss+regular. : 2.03101
I0519 09:25:10.984280  4008 solver.cpp:231] Iteration 328600, loss = 1.51863
I0519 09:25:10.984591  4008 solver.cpp:247]     Train net output #0: loss = 1.51863 (* 1 = 1.51863 loss)
I0519 09:25:10.984612  4008 sgd_solver.cpp:106] Iteration 328600, lr = 0.0001
I0519 09:25:11.146352  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2763	3.125	82.1364	0	91.0587	5.98958	89.0821	0	85.1999	0	85.5942	0	78.3358	0	30.3796	2.7	
I0519 09:25:11.221462  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:25:11.223489  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:25:11.223526  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:25:11.233286  4008 solver.cpp:260]     Total regularization terms: 0.946332 loss+regular. : 2.46496
I0519 09:26:30.736016  4008 solver.cpp:231] Iteration 328800, loss = 1.23364
I0519 09:26:30.736263  4008 solver.cpp:247]     Train net output #0: loss = 1.23364 (* 1 = 1.23364 loss)
I0519 09:26:30.736284  4008 sgd_solver.cpp:106] Iteration 328800, lr = 0.0001
I0519 09:26:30.896368  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.282	3.125	82.138	0	91.0595	5.98958	89.0824	0	85.1999	0	85.5943	0	78.3359	0	30.3797	2.7	
I0519 09:26:30.970896  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:26:30.972707  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:26:30.972741  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:26:30.982576  4008 solver.cpp:260]     Total regularization terms: 0.946295 loss+regular. : 2.17993
I0519 09:27:50.786995  4008 solver.cpp:348] Iteration 329000, Testing net (#0)
I0519 09:28:19.205281  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:29:15.639230  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5657
I0519 09:29:15.639552  4008 solver.cpp:415]     Test net output #1: loss = 1.86382 (* 1 = 1.86382 loss)
I0519 09:29:15.729079  4008 solver.cpp:231] Iteration 329000, loss = 1.37075
I0519 09:29:15.729154  4008 solver.cpp:247]     Train net output #0: loss = 1.37075 (* 1 = 1.37075 loss)
I0519 09:29:15.729173  4008 sgd_solver.cpp:106] Iteration 329000, lr = 0.0001
I0519 09:29:15.893652  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.282	3.125	82.1432	0	91.0605	5.98958	89.0841	0	85.2008	0	85.5944	0	78.336	0	30.3797	2.7	
I0519 09:29:15.969113  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:29:15.971346  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:29:15.971392  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:29:15.981394  4008 solver.cpp:260]     Total regularization terms: 0.94626 loss+regular. : 2.31701
I0519 09:30:37.587883  4008 solver.cpp:231] Iteration 329200, loss = 1.27291
I0519 09:30:37.588176  4008 solver.cpp:247]     Train net output #0: loss = 1.27291 (* 1 = 1.27291 loss)
I0519 09:30:37.588197  4008 sgd_solver.cpp:106] Iteration 329200, lr = 0.0001
I0519 09:30:37.749147  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.282	3.125	82.1452	0	91.0611	5.98958	89.0847	0	85.201	0	85.5944	0	78.3361	0	30.3797	2.7	
I0519 09:30:37.823977  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:30:37.826452  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:30:37.826493  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:30:37.839612  4008 solver.cpp:260]     Total regularization terms: 0.946221 loss+regular. : 2.21913
I0519 09:31:33.392663  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:32:05.996783  4008 solver.cpp:231] Iteration 329400, loss = 1.24593
I0519 09:32:05.997377  4008 solver.cpp:247]     Train net output #0: loss = 1.24593 (* 1 = 1.24593 loss)
I0519 09:32:05.997401  4008 sgd_solver.cpp:106] Iteration 329400, lr = 0.0001
I0519 09:32:06.156527  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2849	3.125	82.1491	0	91.0615	5.98958	89.0856	0	85.201	0	85.5945	0	78.3362	0	30.3798	2.7	
I0519 09:32:06.230612  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:32:06.232075  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:32:06.232100  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:32:06.241690  4008 solver.cpp:260]     Total regularization terms: 0.946184 loss+regular. : 2.19211
I0519 09:33:41.975698  4008 solver.cpp:231] Iteration 329600, loss = 1.25716
I0519 09:33:41.976037  4008 solver.cpp:247]     Train net output #0: loss = 1.25716 (* 1 = 1.25716 loss)
I0519 09:33:41.976058  4008 sgd_solver.cpp:106] Iteration 329600, lr = 0.0001
I0519 09:33:42.138116  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2849	3.125	82.1533	0	91.0617	5.98958	89.0863	0	85.2017	0	85.5946	0	78.3363	0	30.3798	2.7	
I0519 09:33:42.214354  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:33:42.216421  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:33:42.216452  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:33:42.231367  4008 solver.cpp:260]     Total regularization terms: 0.946146 loss+regular. : 2.20331
I0519 09:35:00.761687  4008 solver.cpp:231] Iteration 329800, loss = 1.31825
I0519 09:35:00.765702  4008 solver.cpp:247]     Train net output #0: loss = 1.31825 (* 1 = 1.31825 loss)
I0519 09:35:00.765736  4008 sgd_solver.cpp:106] Iteration 329800, lr = 0.0001
I0519 09:35:00.921298  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2906	3.125	82.1562	0	91.0626	5.98958	89.0871	0	85.2024	0	85.5947	0	78.3364	0	30.3799	2.7	
I0519 09:35:00.996213  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:35:00.998579  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:35:00.998626  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:35:01.008476  4008 solver.cpp:260]     Total regularization terms: 0.946109 loss+regular. : 2.26436
I0519 09:36:22.249938  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_330000.caffemodel
I0519 09:38:14.481966  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_330000.solverstate
I0519 09:38:14.975973  4008 solver.cpp:348] Iteration 330000, Testing net (#0)
I0519 09:38:40.920650  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:39:32.960433  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56466
I0519 09:39:32.960736  4008 solver.cpp:415]     Test net output #1: loss = 1.86344 (* 1 = 1.86344 loss)
I0519 09:39:33.086424  4008 solver.cpp:231] Iteration 330000, loss = 1.3946
I0519 09:39:33.086501  4008 solver.cpp:247]     Train net output #0: loss = 1.3946 (* 1 = 1.3946 loss)
I0519 09:39:33.086519  4008 sgd_solver.cpp:106] Iteration 330000, lr = 0.0001
I0519 09:39:33.245970  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2906	3.125	82.1615	0	91.0637	5.98958	89.0877	0	85.203	0	85.5948	0	78.3365	0	30.3801	2.7	
I0519 09:39:33.248049  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:39:33.250759  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:39:33.250802  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:39:33.260756  4008 solver.cpp:260]     Total regularization terms: 0.946071 loss+regular. : 2.34067
I0519 09:40:50.534648  4008 solver.cpp:231] Iteration 330200, loss = 1.15096
I0519 09:40:50.535956  4008 solver.cpp:247]     Train net output #0: loss = 1.15096 (* 1 = 1.15096 loss)
I0519 09:40:50.535989  4008 sgd_solver.cpp:106] Iteration 330200, lr = 0.0001
I0519 09:40:50.695302  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2935	3.125	82.1631	0	91.0646	5.98958	89.0886	0	85.2039	0	85.5948	0	78.3366	0	30.3802	2.7	
I0519 09:40:50.771183  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:40:50.773088  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:40:50.773133  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:40:50.788440  4008 solver.cpp:260]     Total regularization terms: 0.946033 loss+regular. : 2.09699
I0519 09:41:50.556813  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:42:17.812974  4008 solver.cpp:231] Iteration 330400, loss = 1.1507
I0519 09:42:17.813072  4008 solver.cpp:247]     Train net output #0: loss = 1.1507 (* 1 = 1.1507 loss)
I0519 09:42:17.813091  4008 sgd_solver.cpp:106] Iteration 330400, lr = 0.0001
I0519 09:42:17.972358  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2964	3.125	82.166	0	91.065	5.98958	89.089	0	85.2048	0	85.5949	0	78.3367	0	30.3802	2.7	
I0519 09:42:18.047461  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:42:18.049623  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:42:18.049679  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:42:18.059589  4008 solver.cpp:260]     Total regularization terms: 0.945993 loss+regular. : 2.09669
I0519 09:43:35.329874  4008 solver.cpp:231] Iteration 330600, loss = 1.21818
I0519 09:43:35.330296  4008 solver.cpp:247]     Train net output #0: loss = 1.21818 (* 1 = 1.21818 loss)
I0519 09:43:35.330315  4008 sgd_solver.cpp:106] Iteration 330600, lr = 0.0001
I0519 09:43:35.490970  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2964	3.125	82.1676	0	91.0657	5.98958	89.0895	0	85.2048	0	85.595	0	78.3368	0	30.3803	2.7	
I0519 09:43:35.565601  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:43:35.567652  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:43:35.567694  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:43:35.577442  4008 solver.cpp:260]     Total regularization terms: 0.945951 loss+regular. : 2.16413
I0519 09:44:51.252962  4008 solver.cpp:231] Iteration 330800, loss = 1.31474
I0519 09:44:51.253286  4008 solver.cpp:247]     Train net output #0: loss = 1.31474 (* 1 = 1.31474 loss)
I0519 09:44:51.253306  4008 sgd_solver.cpp:106] Iteration 330800, lr = 0.0001
I0519 09:44:51.414800  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.2992	3.125	82.1706	0	91.0664	5.98958	89.0898	0	85.2055	0	85.5951	0	78.3369	0	30.3804	2.7	
I0519 09:44:51.489531  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:44:51.491674  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:44:51.491734  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:44:51.512475  4008 solver.cpp:260]     Total regularization terms: 0.94592 loss+regular. : 2.26066
I0519 09:46:10.973742  4008 solver.cpp:348] Iteration 331000, Testing net (#0)
I0519 09:46:36.958721  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:47:32.687978  4008 solver.cpp:415]     Test net output #0: accuracy = 0.566479
I0519 09:47:32.689757  4008 solver.cpp:415]     Test net output #1: loss = 1.85988 (* 1 = 1.85988 loss)
I0519 09:47:32.780366  4008 solver.cpp:231] Iteration 331000, loss = 1.26183
I0519 09:47:32.780455  4008 solver.cpp:247]     Train net output #0: loss = 1.26183 (* 1 = 1.26183 loss)
I0519 09:47:32.780475  4008 sgd_solver.cpp:106] Iteration 331000, lr = 0.0001
I0519 09:47:32.945888  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3021	3.125	82.1748	0	91.0667	5.98958	89.0907	0	85.2055	0	85.5951	0	78.337	0	30.3805	2.7	
I0519 09:47:33.020478  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:47:33.022353  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:47:33.022384  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:47:33.039573  4008 solver.cpp:260]     Total regularization terms: 0.945876 loss+regular. : 2.20771
I0519 09:48:48.782450  4008 solver.cpp:231] Iteration 331200, loss = 1.27246
I0519 09:48:48.782737  4008 solver.cpp:247]     Train net output #0: loss = 1.27246 (* 1 = 1.27246 loss)
I0519 09:48:48.782755  4008 sgd_solver.cpp:106] Iteration 331200, lr = 0.0001
I0519 09:48:48.944350  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3021	3.125	82.1755	0	91.0671	5.98958	89.0914	0	85.206	0	85.5952	0	78.3371	0	30.3805	2.7	
I0519 09:48:49.020388  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:48:49.022967  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:48:49.023005  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:48:49.044044  4008 solver.cpp:260]     Total regularization terms: 0.945841 loss+regular. : 2.21831
I0519 09:49:46.967773  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:50:08.340988  4008 solver.cpp:231] Iteration 331400, loss = 1.3707
I0519 09:50:08.341078  4008 solver.cpp:247]     Train net output #0: loss = 1.3707 (* 1 = 1.3707 loss)
I0519 09:50:08.341096  4008 sgd_solver.cpp:106] Iteration 331400, lr = 0.0001
I0519 09:50:08.501921  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3021	3.125	82.1781	0	91.0677	5.98958	89.0919	0	85.2069	0	85.5953	0	78.3372	0	30.3806	2.7	
I0519 09:50:08.577296  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:50:08.579172  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:50:08.579210  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:50:08.594046  4008 solver.cpp:260]     Total regularization terms: 0.945797 loss+regular. : 2.31649
I0519 09:51:29.199573  4008 solver.cpp:231] Iteration 331600, loss = 1.3016
I0519 09:51:29.200268  4008 solver.cpp:247]     Train net output #0: loss = 1.3016 (* 1 = 1.3016 loss)
I0519 09:51:29.200291  4008 sgd_solver.cpp:106] Iteration 331600, lr = 0.0001
I0519 09:51:29.360131  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3079	3.125	82.182	0	91.0689	5.98958	89.0928	0	85.2078	0	85.5953	0	78.3373	0	30.3807	2.7	
I0519 09:51:29.436295  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:51:29.439110  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:51:29.439172  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:51:29.454494  4008 solver.cpp:260]     Total regularization terms: 0.94577 loss+regular. : 2.24737
I0519 09:52:58.034082  4008 solver.cpp:231] Iteration 331800, loss = 1.42557
I0519 09:52:58.034394  4008 solver.cpp:247]     Train net output #0: loss = 1.42557 (* 1 = 1.42557 loss)
I0519 09:52:58.034417  4008 sgd_solver.cpp:106] Iteration 331800, lr = 0.0001
I0519 09:52:58.193567  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3136	3.125	82.1846	0	91.0698	5.98958	89.0938	0	85.2085	0	85.5954	0	78.3373	0	30.3808	2.7	
I0519 09:52:58.268268  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:52:58.269968  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:52:58.270005  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:52:58.279834  4008 solver.cpp:260]     Total regularization terms: 0.945726 loss+regular. : 2.3713
I0519 09:54:15.949522  4008 solver.cpp:348] Iteration 332000, Testing net (#0)
I0519 09:54:47.359218  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:55:45.515009  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56484
I0519 09:55:45.515270  4008 solver.cpp:415]     Test net output #1: loss = 1.86333 (* 1 = 1.86333 loss)
I0519 09:55:45.603454  4008 solver.cpp:231] Iteration 332000, loss = 1.33273
I0519 09:55:45.603530  4008 solver.cpp:247]     Train net output #0: loss = 1.33273 (* 1 = 1.33273 loss)
I0519 09:55:45.603549  4008 sgd_solver.cpp:106] Iteration 332000, lr = 0.0001
I0519 09:55:45.769615  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3136	3.125	82.1888	0	91.0704	5.98958	89.0943	0	85.2094	0	85.5955	0	78.3374	0	30.3809	2.7	
I0519 09:55:45.845813  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:55:45.848925  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:55:45.848970  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:55:45.859071  4008 solver.cpp:260]     Total regularization terms: 0.945684 loss+regular. : 2.27842
I0519 09:57:13.740583  4008 solver.cpp:231] Iteration 332200, loss = 1.26182
I0519 09:57:13.741061  4008 solver.cpp:247]     Train net output #0: loss = 1.26182 (* 1 = 1.26182 loss)
I0519 09:57:13.741093  4008 sgd_solver.cpp:106] Iteration 332200, lr = 0.0001
I0519 09:57:13.901191  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3165	3.125	82.1914	0	91.0708	5.98958	89.0952	0	85.2098	0	85.5956	0	78.3375	0	30.381	2.7	
I0519 09:57:13.977206  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:57:13.979650  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:57:13.979682  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:57:13.989445  4008 solver.cpp:260]     Total regularization terms: 0.945643 loss+regular. : 2.20747
I0519 09:58:17.829735  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 09:58:39.587452  4008 solver.cpp:231] Iteration 332400, loss = 1.24967
I0519 09:58:39.587570  4008 solver.cpp:247]     Train net output #0: loss = 1.24967 (* 1 = 1.24967 loss)
I0519 09:58:39.587589  4008 sgd_solver.cpp:106] Iteration 332400, lr = 0.0001
I0519 09:58:39.749327  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3193	3.125	82.194	0	91.0717	5.98958	89.0961	0	85.2107	0	85.5957	0	78.3376	0	30.381	2.7	
I0519 09:58:39.824247  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 09:58:39.826705  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 09:58:39.826774  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 09:58:39.837009  4008 solver.cpp:260]     Total regularization terms: 0.945604 loss+regular. : 2.19527
I0519 10:00:01.687381  4008 solver.cpp:231] Iteration 332600, loss = 1.25746
I0519 10:00:01.689010  4008 solver.cpp:247]     Train net output #0: loss = 1.25746 (* 1 = 1.25746 loss)
I0519 10:00:01.689054  4008 sgd_solver.cpp:106] Iteration 332600, lr = 0.0001
I0519 10:00:01.847396  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3222	3.125	82.1963	0	91.0725	5.98958	89.0972	0	85.2121	0	85.5957	0	78.3376	0	30.3812	2.7	
I0519 10:00:01.922376  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:00:01.924568  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:00:01.924625  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:00:01.934480  4008 solver.cpp:260]     Total regularization terms: 0.945572 loss+regular. : 2.20303
I0519 10:01:32.407997  4008 solver.cpp:231] Iteration 332800, loss = 1.287
I0519 10:01:32.408282  4008 solver.cpp:247]     Train net output #0: loss = 1.287 (* 1 = 1.287 loss)
I0519 10:01:32.408342  4008 sgd_solver.cpp:106] Iteration 332800, lr = 0.0001
I0519 10:01:32.568322  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3222	3.125	82.1986	0	91.0732	5.98958	89.0979	0	85.2128	0	85.5958	0	78.3377	0	30.3812	2.7	
I0519 10:01:32.643741  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:01:32.646688  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:01:32.646734  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:01:32.656544  4008 solver.cpp:260]     Total regularization terms: 0.945535 loss+regular. : 2.23253
I0519 10:03:03.845981  4008 solver.cpp:348] Iteration 333000, Testing net (#0)
I0519 10:03:32.134189  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:04:31.702406  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56576
I0519 10:04:31.702802  4008 solver.cpp:415]     Test net output #1: loss = 1.86097 (* 1 = 1.86097 loss)
I0519 10:04:31.791548  4008 solver.cpp:231] Iteration 333000, loss = 1.24312
I0519 10:04:31.791623  4008 solver.cpp:247]     Train net output #0: loss = 1.24312 (* 1 = 1.24312 loss)
I0519 10:04:31.791641  4008 sgd_solver.cpp:106] Iteration 333000, lr = 0.0001
I0519 10:04:31.957049  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3251	3.125	82.2002	0	91.0739	5.98958	89.0987	0	85.213	0	85.5959	0	78.3378	0	30.3813	2.7	
I0519 10:04:32.033617  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:04:32.036829  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:04:32.036870  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:04:32.047153  4008 solver.cpp:260]     Total regularization terms: 0.945498 loss+regular. : 2.18862
I0519 10:05:53.370919  4008 solver.cpp:231] Iteration 333200, loss = 0.99231
I0519 10:05:53.371343  4008 solver.cpp:247]     Train net output #0: loss = 0.99231 (* 1 = 0.99231 loss)
I0519 10:05:53.371372  4008 sgd_solver.cpp:106] Iteration 333200, lr = 0.0001
I0519 10:05:53.529940  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3308	3.125	82.2008	0	91.0743	5.98958	89.0993	0	85.2137	0	85.5959	0	78.3379	0	30.3813	2.7	
I0519 10:05:53.605443  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:05:53.608603  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:05:53.608655  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:05:53.618616  4008 solver.cpp:260]     Total regularization terms: 0.945459 loss+regular. : 1.93777
I0519 10:06:59.304503  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:07:18.202677  4008 solver.cpp:231] Iteration 333400, loss = 1.3863
I0519 10:07:18.202785  4008 solver.cpp:247]     Train net output #0: loss = 1.3863 (* 1 = 1.3863 loss)
I0519 10:07:18.202807  4008 sgd_solver.cpp:106] Iteration 333400, lr = 0.0001
I0519 10:07:18.361722  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3337	3.125	82.2028	0	91.0747	5.98958	89.0996	0	85.2139	0	85.596	0	78.338	0	30.3814	2.7	
I0519 10:07:18.437104  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:07:18.440058  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:07:18.440112  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:07:18.450218  4008 solver.cpp:260]     Total regularization terms: 0.945429 loss+regular. : 2.33173
I0519 10:08:45.332355  4008 solver.cpp:231] Iteration 333600, loss = 1.21724
I0519 10:08:45.333606  4008 solver.cpp:247]     Train net output #0: loss = 1.21724 (* 1 = 1.21724 loss)
I0519 10:08:45.333631  4008 sgd_solver.cpp:106] Iteration 333600, lr = 0.0001
I0519 10:08:45.491294  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3337	3.125	82.2054	0	91.0754	5.98958	89.1002	0	85.2146	0	85.5961	0	78.338	0	30.3814	2.7	
I0519 10:08:45.566848  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:08:45.570482  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:08:45.570546  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:08:45.580548  4008 solver.cpp:260]     Total regularization terms: 0.945395 loss+regular. : 2.16263
I0519 10:10:16.841711  4008 solver.cpp:231] Iteration 333800, loss = 1.26308
I0519 10:10:16.845208  4008 solver.cpp:247]     Train net output #0: loss = 1.26308 (* 1 = 1.26308 loss)
I0519 10:10:16.845237  4008 sgd_solver.cpp:106] Iteration 333800, lr = 0.0001
I0519 10:10:17.001723  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3365	3.125	82.2083	0	91.0762	5.98958	89.1009	0	85.215	0	85.5961	0	78.3381	0	30.3815	2.7	
I0519 10:10:17.076104  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:10:17.077745  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:10:17.077776  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:10:17.098028  4008 solver.cpp:260]     Total regularization terms: 0.945357 loss+regular. : 2.20844
I0519 10:11:48.232292  4008 solver.cpp:348] Iteration 334000, Testing net (#0)
I0519 10:12:17.404953  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:13:13.699784  4008 solver.cpp:415]     Test net output #0: accuracy = 0.565759
I0519 10:13:13.700039  4008 solver.cpp:415]     Test net output #1: loss = 1.86409 (* 1 = 1.86409 loss)
I0519 10:13:13.791414  4008 solver.cpp:231] Iteration 334000, loss = 1.31165
I0519 10:13:13.791513  4008 solver.cpp:247]     Train net output #0: loss = 1.31165 (* 1 = 1.31165 loss)
I0519 10:13:13.791532  4008 sgd_solver.cpp:106] Iteration 334000, lr = 0.0001
I0519 10:13:13.959342  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3365	3.125	82.2109	0	91.0764	5.98958	89.1014	0	85.2155	0	85.5962	0	78.3382	0	30.3817	2.7	
I0519 10:13:14.042675  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:13:14.045482  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:13:14.045536  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:13:14.055487  4008 solver.cpp:260]     Total regularization terms: 0.945324 loss+regular. : 2.25697
I0519 10:14:50.868268  4008 solver.cpp:231] Iteration 334200, loss = 1.2668
I0519 10:14:50.868613  4008 solver.cpp:247]     Train net output #0: loss = 1.2668 (* 1 = 1.2668 loss)
I0519 10:14:50.881582  4008 sgd_solver.cpp:106] Iteration 334200, lr = 0.0001
I0519 10:14:51.027670  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3394	3.125	82.2139	0	91.0771	5.98958	89.1018	0	85.2166	0	85.5963	0	78.3383	0	30.3817	2.7	
I0519 10:14:51.102905  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:14:51.105851  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:14:51.105895  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:14:51.115664  4008 solver.cpp:260]     Total regularization terms: 0.945281 loss+regular. : 2.21208
I0519 10:16:00.158324  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:16:18.810402  4008 solver.cpp:231] Iteration 334400, loss = 1.23882
I0519 10:16:18.810489  4008 solver.cpp:247]     Train net output #0: loss = 1.23882 (* 1 = 1.23882 loss)
I0519 10:16:18.810514  4008 sgd_solver.cpp:106] Iteration 334400, lr = 0.0001
I0519 10:16:18.970366  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3394	3.125	82.2168	0	91.078	5.98958	89.1023	0	85.2171	0	85.5963	0	78.3383	0	30.3817	2.7	
I0519 10:16:19.046064  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:16:19.049609  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:16:19.049662  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:16:19.059598  4008 solver.cpp:260]     Total regularization terms: 0.945247 loss+regular. : 2.18406
I0519 10:17:57.831423  4008 solver.cpp:231] Iteration 334600, loss = 1.43662
I0519 10:17:57.833108  4008 solver.cpp:247]     Train net output #0: loss = 1.43662 (* 1 = 1.43662 loss)
I0519 10:17:57.833137  4008 sgd_solver.cpp:106] Iteration 334600, lr = 0.0001
I0519 10:17:57.991777  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3394	3.125	82.2191	0	91.0788	5.98958	89.1029	0	85.2182	0	85.5964	0	78.3384	0	30.3818	2.7	
I0519 10:17:58.067257  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:17:58.070089  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:17:58.070137  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:17:58.091331  4008 solver.cpp:260]     Total regularization terms: 0.945212 loss+regular. : 2.38183
I0519 10:19:26.711575  4008 solver.cpp:231] Iteration 334800, loss = 1.19113
I0519 10:19:26.711838  4008 solver.cpp:247]     Train net output #0: loss = 1.19113 (* 1 = 1.19113 loss)
I0519 10:19:26.711863  4008 sgd_solver.cpp:106] Iteration 334800, lr = 0.0001
I0519 10:19:26.873221  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3423	3.125	82.2207	0	91.0791	5.98958	89.1035	0	85.2191	0	85.5965	0	78.3385	0	30.3819	2.7	
I0519 10:19:26.949013  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:19:26.951772  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:19:26.951815  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:19:26.981808  4008 solver.cpp:260]     Total regularization terms: 0.945175 loss+regular. : 2.13631
I0519 10:20:49.375614  4008 solver.cpp:348] Iteration 335000, Testing net (#0)
I0519 10:21:23.260037  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:22:14.862977  4008 solver.cpp:415]     Test net output #0: accuracy = 0.565279
I0519 10:22:14.863234  4008 solver.cpp:415]     Test net output #1: loss = 1.86197 (* 1 = 1.86197 loss)
I0519 10:22:14.951869  4008 solver.cpp:231] Iteration 335000, loss = 1.27539
I0519 10:22:14.951959  4008 solver.cpp:247]     Train net output #0: loss = 1.27539 (* 1 = 1.27539 loss)
I0519 10:22:14.951979  4008 sgd_solver.cpp:106] Iteration 335000, lr = 0.0001
I0519 10:22:15.116580  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3423	3.125	82.2223	0	91.0794	5.98958	89.1045	0	85.2195	0	85.5966	0	78.3386	0	30.3819	2.7	
I0519 10:22:15.191972  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:22:15.194169  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:22:15.194234  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:22:15.204496  4008 solver.cpp:260]     Total regularization terms: 0.945137 loss+regular. : 2.22053
I0519 10:23:41.784906  4008 solver.cpp:231] Iteration 335200, loss = 1.1649
I0519 10:23:41.785192  4008 solver.cpp:247]     Train net output #0: loss = 1.1649 (* 1 = 1.1649 loss)
I0519 10:23:41.785215  4008 sgd_solver.cpp:106] Iteration 335200, lr = 0.0001
I0519 10:23:41.946624  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3423	3.125	82.2266	0	91.0796	5.98958	89.1055	0	85.2195	0	85.5966	0	78.3387	0	30.382	2.7	
I0519 10:23:42.021574  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:23:42.023821  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:23:42.023864  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:23:42.033663  4008 solver.cpp:260]     Total regularization terms: 0.945094 loss+regular. : 2.11
I0519 10:24:54.439113  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:25:06.374073  4008 solver.cpp:231] Iteration 335400, loss = 1.39043
I0519 10:25:06.374168  4008 solver.cpp:247]     Train net output #0: loss = 1.39043 (* 1 = 1.39043 loss)
I0519 10:25:06.374188  4008 sgd_solver.cpp:106] Iteration 335400, lr = 0.0001
I0519 10:25:06.534600  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3423	3.125	82.2298	0	91.0803	5.98958	89.1058	0	85.2205	0	85.5967	0	78.3387	0	30.382	2.7	
I0519 10:25:06.609647  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:25:06.611752  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:25:06.611781  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:25:06.621536  4008 solver.cpp:260]     Total regularization terms: 0.945063 loss+regular. : 2.33549
I0519 10:26:22.636754  4008 solver.cpp:231] Iteration 335600, loss = 1.39468
I0519 10:26:22.637171  4008 solver.cpp:247]     Train net output #0: loss = 1.39468 (* 1 = 1.39468 loss)
I0519 10:26:22.637194  4008 sgd_solver.cpp:106] Iteration 335600, lr = 0.0001
I0519 10:26:22.798463  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3452	3.125	82.2318	0	91.0812	5.98958	89.1058	0	85.2209	0	85.5968	0	78.3388	0	30.3821	2.7	
I0519 10:26:22.875511  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:26:22.877673  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:26:22.877758  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:26:22.887581  4008 solver.cpp:260]     Total regularization terms: 0.945023 loss+regular. : 2.33971
I0519 10:27:40.702900  4008 solver.cpp:231] Iteration 335800, loss = 1.30047
I0519 10:27:40.705664  4008 solver.cpp:247]     Train net output #0: loss = 1.30047 (* 1 = 1.30047 loss)
I0519 10:27:40.705693  4008 sgd_solver.cpp:106] Iteration 335800, lr = 0.0001
I0519 10:27:40.862294  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.348	3.125	82.2337	0	91.0816	5.98958	89.1064	0	85.2214	0	85.5969	0	78.3388	0	30.3822	2.7	
I0519 10:27:40.939127  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:27:40.941391  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:27:40.941437  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:27:40.951289  4008 solver.cpp:260]     Total regularization terms: 0.944992 loss+regular. : 2.24546
I0519 10:29:04.498191  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_336000.caffemodel
I0519 10:32:41.779587  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_336000.solverstate
I0519 10:32:42.415909  4008 solver.cpp:348] Iteration 336000, Testing net (#0)
I0519 10:33:11.848557  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:34:04.698657  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56486
I0519 10:34:04.698930  4008 solver.cpp:415]     Test net output #1: loss = 1.86333 (* 1 = 1.86333 loss)
I0519 10:34:04.791146  4008 solver.cpp:231] Iteration 336000, loss = 1.18507
I0519 10:34:04.791249  4008 solver.cpp:247]     Train net output #0: loss = 1.18507 (* 1 = 1.18507 loss)
I0519 10:34:04.791273  4008 sgd_solver.cpp:106] Iteration 336000, lr = 0.0001
I0519 10:34:04.949793  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3509	3.125	82.2347	0	91.082	5.98958	89.1073	0	85.222	0	85.597	0	78.3389	0	30.3822	2.7	
I0519 10:34:04.952869  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:34:04.956696  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:34:04.956746  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:34:04.970712  4008 solver.cpp:260]     Total regularization terms: 0.944947 loss+regular. : 2.13001
I0519 10:35:34.011780  4008 solver.cpp:231] Iteration 336200, loss = 1.25925
I0519 10:35:34.012203  4008 solver.cpp:247]     Train net output #0: loss = 1.25925 (* 1 = 1.25925 loss)
I0519 10:35:34.012226  4008 sgd_solver.cpp:106] Iteration 336200, lr = 0.0001
I0519 10:35:34.173483  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3538	3.125	82.236	0	91.0822	5.98958	89.1076	0	85.222	0	85.5971	0	78.339	0	30.3823	2.7	
I0519 10:35:34.248903  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:35:34.252020  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:35:34.252063  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:35:34.262367  4008 solver.cpp:260]     Total regularization terms: 0.944915 loss+regular. : 2.20417
I0519 10:36:51.587771  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:36:59.289420  4008 solver.cpp:231] Iteration 336400, loss = 1.36897
I0519 10:36:59.289499  4008 solver.cpp:247]     Train net output #0: loss = 1.36897 (* 1 = 1.36897 loss)
I0519 10:36:59.289517  4008 sgd_solver.cpp:106] Iteration 336400, lr = 0.0001
I0519 10:36:59.449225  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3566	3.125	82.238	0	91.0825	5.98958	89.108	0	85.2227	0	85.5971	0	78.3391	0	30.3825	2.7	
I0519 10:36:59.524777  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:36:59.526496  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:36:59.526525  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:36:59.547552  4008 solver.cpp:260]     Total regularization terms: 0.944872 loss+regular. : 2.31385
I0519 10:38:23.975796  4008 solver.cpp:231] Iteration 336600, loss = 1.24274
I0519 10:38:23.977639  4008 solver.cpp:247]     Train net output #0: loss = 1.24274 (* 1 = 1.24274 loss)
I0519 10:38:23.977665  4008 sgd_solver.cpp:106] Iteration 336600, lr = 0.0001
I0519 10:38:24.135782  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3566	3.125	82.2402	0	91.0828	5.98958	89.1086	0	85.2234	0	85.5972	0	78.3392	0	30.3825	2.7	
I0519 10:38:24.210883  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:38:24.212807  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:38:24.212841  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:38:24.222682  4008 solver.cpp:260]     Total regularization terms: 0.944843 loss+regular. : 2.18759
I0519 10:39:53.974767  4008 solver.cpp:231] Iteration 336800, loss = 1.14377
I0519 10:39:53.975040  4008 solver.cpp:247]     Train net output #0: loss = 1.14377 (* 1 = 1.14377 loss)
I0519 10:39:53.975060  4008 sgd_solver.cpp:106] Iteration 336800, lr = 0.0001
I0519 10:39:54.134898  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3595	3.125	82.2419	0	91.0834	5.98958	89.11	0	85.2241	0	85.5973	0	78.3393	0	30.3826	2.7	
I0519 10:39:54.209564  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:39:54.211472  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:39:54.211498  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:39:54.221170  4008 solver.cpp:260]     Total regularization terms: 0.944805 loss+regular. : 2.08857
I0519 10:41:16.122895  4008 solver.cpp:348] Iteration 337000, Testing net (#0)
I0519 10:41:44.728011  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:42:31.677220  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56574
I0519 10:42:31.677508  4008 solver.cpp:415]     Test net output #1: loss = 1.86264 (* 1 = 1.86264 loss)
I0519 10:42:31.765674  4008 solver.cpp:231] Iteration 337000, loss = 1.14148
I0519 10:42:31.765787  4008 solver.cpp:247]     Train net output #0: loss = 1.14148 (* 1 = 1.14148 loss)
I0519 10:42:31.765807  4008 sgd_solver.cpp:106] Iteration 337000, lr = 0.0001
I0519 10:42:31.925839  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3652	3.125	82.2441	0	91.0837	5.98958	89.11	0	85.2247	0	85.5974	0	78.3393	0	30.3827	2.7	
I0519 10:42:32.002522  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:42:32.004650  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:42:32.004676  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:42:32.014443  4008 solver.cpp:260]     Total regularization terms: 0.944762 loss+regular. : 2.08625
I0519 10:43:52.730897  4008 solver.cpp:231] Iteration 337200, loss = 1.30157
I0519 10:43:52.731154  4008 solver.cpp:247]     Train net output #0: loss = 1.30157 (* 1 = 1.30157 loss)
I0519 10:43:52.731174  4008 sgd_solver.cpp:106] Iteration 337200, lr = 0.0001
I0519 10:43:52.890220  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3652	3.125	82.2474	0	91.0843	5.98958	89.1119	0	85.2252	0	85.5975	0	78.3394	0	30.3828	2.7	
I0519 10:43:52.965709  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:43:52.968694  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:43:52.968739  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:43:52.978821  4008 solver.cpp:260]     Total regularization terms: 0.944727 loss+regular. : 2.2463
I0519 10:45:12.636018  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:45:17.728389  4008 solver.cpp:231] Iteration 337400, loss = 1.25039
I0519 10:45:17.728472  4008 solver.cpp:247]     Train net output #0: loss = 1.25039 (* 1 = 1.25039 loss)
I0519 10:45:17.728616  4008 sgd_solver.cpp:106] Iteration 337400, lr = 0.0001
I0519 10:45:17.888538  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3652	3.125	82.2487	0	91.0848	5.98958	89.1131	0	85.2252	0	85.5975	0	78.3395	0	30.3828	2.7	
I0519 10:45:17.963466  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:45:17.965711  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:45:17.965759  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:45:17.975587  4008 solver.cpp:260]     Total regularization terms: 0.944692 loss+regular. : 2.19509
I0519 10:46:39.478310  4008 solver.cpp:231] Iteration 337600, loss = 1.25078
I0519 10:46:39.478626  4008 solver.cpp:247]     Train net output #0: loss = 1.25078 (* 1 = 1.25078 loss)
I0519 10:46:39.478660  4008 sgd_solver.cpp:106] Iteration 337600, lr = 0.0001
I0519 10:46:39.640715  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3652	3.125	82.2513	0	91.0853	5.98958	89.1134	0	85.2261	0	85.5976	0	78.3396	0	30.3829	2.7	
I0519 10:46:39.715319  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:46:39.716969  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:46:39.717010  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:46:39.727000  4008 solver.cpp:260]     Total regularization terms: 0.944658 loss+regular. : 2.19544
I0519 10:48:11.434854  4008 solver.cpp:231] Iteration 337800, loss = 1.31203
I0519 10:48:11.435240  4008 solver.cpp:247]     Train net output #0: loss = 1.31203 (* 1 = 1.31203 loss)
I0519 10:48:11.435397  4008 sgd_solver.cpp:106] Iteration 337800, lr = 0.0001
I0519 10:48:11.594336  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3652	3.125	82.2529	0	91.0854	5.98958	89.1137	0	85.2263	0	85.5977	0	78.3397	0	30.3829	2.7	
I0519 10:48:11.670698  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:48:11.672484  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:48:11.672521  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:48:11.687845  4008 solver.cpp:260]     Total regularization terms: 0.944624 loss+regular. : 2.25666
I0519 10:49:33.947383  4008 solver.cpp:348] Iteration 338000, Testing net (#0)
I0519 10:50:03.932335  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:50:48.582216  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56592
I0519 10:50:48.585641  4008 solver.cpp:415]     Test net output #1: loss = 1.86178 (* 1 = 1.86178 loss)
I0519 10:50:48.673431  4008 solver.cpp:231] Iteration 338000, loss = 1.3163
I0519 10:50:48.673533  4008 solver.cpp:247]     Train net output #0: loss = 1.3163 (* 1 = 1.3163 loss)
I0519 10:50:48.673565  4008 sgd_solver.cpp:106] Iteration 338000, lr = 0.0001
I0519 10:50:48.840981  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3681	3.125	82.2542	0	91.0859	5.98958	89.1146	0	85.2263	0	85.5977	0	78.3398	0	30.383	2.7	
I0519 10:50:48.916148  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:50:48.918915  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:50:48.918957  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:50:48.932772  4008 solver.cpp:260]     Total regularization terms: 0.944583 loss+regular. : 2.26088
I0519 10:52:07.572428  4008 solver.cpp:231] Iteration 338200, loss = 1.06438
I0519 10:52:07.572808  4008 solver.cpp:247]     Train net output #0: loss = 1.06438 (* 1 = 1.06438 loss)
I0519 10:52:07.572829  4008 sgd_solver.cpp:106] Iteration 338200, lr = 0.0001
I0519 10:52:07.733921  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3739	3.125	82.2559	0	91.0863	5.98958	89.1151	0	85.227	0	85.5978	0	78.3399	0	30.383	2.7	
I0519 10:52:07.809310  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:52:07.812146  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:52:07.812199  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:52:07.822051  4008 solver.cpp:260]     Total regularization terms: 0.944547 loss+regular. : 2.00892
I0519 10:53:24.538373  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:53:26.941308  4008 solver.cpp:231] Iteration 338400, loss = 1.19409
I0519 10:53:26.941388  4008 solver.cpp:247]     Train net output #0: loss = 1.19409 (* 1 = 1.19409 loss)
I0519 10:53:26.941406  4008 sgd_solver.cpp:106] Iteration 338400, lr = 0.0001
I0519 10:53:27.101305  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3739	3.125	82.2594	0	91.0868	5.98958	89.1159	0	85.2277	0	85.5979	0	78.3399	0	30.3831	2.7	
I0519 10:53:27.176538  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:53:27.179162  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:53:27.179214  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:53:27.189201  4008 solver.cpp:260]     Total regularization terms: 0.944511 loss+regular. : 2.1386
I0519 10:54:47.686506  4008 solver.cpp:231] Iteration 338600, loss = 1.48541
I0519 10:54:47.686817  4008 solver.cpp:247]     Train net output #0: loss = 1.48541 (* 1 = 1.48541 loss)
I0519 10:54:47.686837  4008 sgd_solver.cpp:106] Iteration 338600, lr = 0.0001
I0519 10:54:47.849366  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3739	3.125	82.262	0	91.0872	5.98958	89.1166	0	85.2279	0	85.598	0	78.34	0	30.3832	2.7	
I0519 10:54:47.925398  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:54:47.928103  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:54:47.928134  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:54:47.941598  4008 solver.cpp:260]     Total regularization terms: 0.94448 loss+regular. : 2.42989
I0519 10:56:09.683061  4008 solver.cpp:231] Iteration 338800, loss = 1.22105
I0519 10:56:09.683287  4008 solver.cpp:247]     Train net output #0: loss = 1.22105 (* 1 = 1.22105 loss)
I0519 10:56:09.683307  4008 sgd_solver.cpp:106] Iteration 338800, lr = 0.0001
I0519 10:56:09.843627  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3739	3.125	82.264	0	91.0875	5.98958	89.1174	0	85.2284	0	85.5981	0	78.3401	0	30.3833	2.7	
I0519 10:56:09.921610  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:56:09.923588  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:56:09.923635  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:56:09.935271  4008 solver.cpp:260]     Total regularization terms: 0.944446 loss+regular. : 2.16549
I0519 10:57:32.810793  4008 solver.cpp:348] Iteration 339000, Testing net (#0)
I0519 10:58:00.708197  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 10:58:47.411787  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56572
I0519 10:58:47.412086  4008 solver.cpp:415]     Test net output #1: loss = 1.86198 (* 1 = 1.86198 loss)
I0519 10:58:47.500030  4008 solver.cpp:231] Iteration 339000, loss = 1.38548
I0519 10:58:47.500108  4008 solver.cpp:247]     Train net output #0: loss = 1.38548 (* 1 = 1.38548 loss)
I0519 10:58:47.500126  4008 sgd_solver.cpp:106] Iteration 339000, lr = 0.0001
I0519 10:58:47.665602  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3739	3.125	82.266	0	91.0885	5.98958	89.118	0	85.2284	0	85.5981	0	78.3401	0	30.3833	2.7	
I0519 10:58:47.742326  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 10:58:47.744498  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 10:58:47.744542  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 10:58:47.754525  4008 solver.cpp:260]     Total regularization terms: 0.944413 loss+regular. : 2.3299
I0519 11:00:08.061187  4008 solver.cpp:231] Iteration 339200, loss = 1.46587
I0519 11:00:08.061494  4008 solver.cpp:247]     Train net output #0: loss = 1.46587 (* 1 = 1.46587 loss)
I0519 11:00:08.061514  4008 sgd_solver.cpp:106] Iteration 339200, lr = 0.0001
I0519 11:00:08.220491  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3739	3.125	82.2692	0	91.0886	5.98958	89.1183	0	85.2286	0	85.5982	0	78.3402	0	30.3833	2.7	
I0519 11:00:08.295325  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:00:08.297749  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:00:08.297776  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:00:08.307484  4008 solver.cpp:260]     Total regularization terms: 0.944374 loss+regular. : 2.41025
I0519 11:01:31.542475  4008 solver.cpp:231] Iteration 339400, loss = 1.26397
I0519 11:01:31.542701  4008 solver.cpp:247]     Train net output #0: loss = 1.26397 (* 1 = 1.26397 loss)
I0519 11:01:31.542721  4008 sgd_solver.cpp:106] Iteration 339400, lr = 0.0001
I0519 11:01:31.701895  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3739	3.125	82.2718	0	91.0894	5.98958	89.1196	0	85.229	0	85.5983	0	78.3403	0	30.3833	2.7	
I0519 11:01:31.776845  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:01:31.778934  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:01:31.778978  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:01:31.788902  4008 solver.cpp:260]     Total regularization terms: 0.944343 loss+regular. : 2.20831
I0519 11:01:31.789121  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:02:56.677379  4008 solver.cpp:231] Iteration 339600, loss = 1.40631
I0519 11:02:56.678069  4008 solver.cpp:247]     Train net output #0: loss = 1.40631 (* 1 = 1.40631 loss)
I0519 11:02:56.678091  4008 sgd_solver.cpp:106] Iteration 339600, lr = 0.0001
I0519 11:02:56.839620  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3739	3.125	82.2734	0	91.0901	5.98958	89.1196	0	85.229	0	85.5983	0	78.3404	0	30.3834	2.7	
I0519 11:02:56.915602  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:02:56.918431  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:02:56.918476  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:02:56.938473  4008 solver.cpp:260]     Total regularization terms: 0.944307 loss+regular. : 2.35061
I0519 11:04:25.367902  4008 solver.cpp:231] Iteration 339800, loss = 1.21488
I0519 11:04:25.368188  4008 solver.cpp:247]     Train net output #0: loss = 1.21488 (* 1 = 1.21488 loss)
I0519 11:04:25.368208  4008 sgd_solver.cpp:106] Iteration 339800, lr = 0.0001
I0519 11:04:25.528910  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3767	3.125	82.2757	0	91.0902	5.98958	89.1204	0	85.2299	0	85.5984	0	78.3405	0	30.3834	2.7	
I0519 11:04:25.603801  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:04:25.606300  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:04:25.606328  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:04:25.615972  4008 solver.cpp:260]     Total regularization terms: 0.944276 loss+regular. : 2.15916
I0519 11:05:46.408931  4008 solver.cpp:348] Iteration 340000, Testing net (#0)
I0519 11:06:17.592823  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:07:08.132222  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56566
I0519 11:07:08.132588  4008 solver.cpp:415]     Test net output #1: loss = 1.85912 (* 1 = 1.85912 loss)
I0519 11:07:08.225695  4008 solver.cpp:231] Iteration 340000, loss = 1.4047
I0519 11:07:08.225778  4008 solver.cpp:247]     Train net output #0: loss = 1.4047 (* 1 = 1.4047 loss)
I0519 11:07:08.225797  4008 sgd_solver.cpp:106] Iteration 340000, lr = 0.0001
I0519 11:07:08.389240  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3767	3.125	82.2783	0	91.0906	5.98958	89.1211	0	85.2299	0	85.5985	0	78.3406	0	30.3834	2.7	
I0519 11:07:08.465220  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:07:08.467813  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:07:08.467854  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:07:08.478569  4008 solver.cpp:260]     Total regularization terms: 0.944243 loss+regular. : 2.34895
I0519 11:08:32.112704  4008 solver.cpp:231] Iteration 340200, loss = 1.37404
I0519 11:08:32.113607  4008 solver.cpp:247]     Train net output #0: loss = 1.37404 (* 1 = 1.37404 loss)
I0519 11:08:32.113628  4008 sgd_solver.cpp:106] Iteration 340200, lr = 0.0001
I0519 11:08:32.271136  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3767	3.125	82.2816	0	91.0914	5.98958	89.1213	0	85.2302	0	85.5986	0	78.3406	0	30.3835	2.7	
I0519 11:08:32.346735  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:08:32.349548  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:08:32.349601  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:08:32.359468  4008 solver.cpp:260]     Total regularization terms: 0.9442 loss+regular. : 2.31824
I0519 11:09:54.910755  4008 solver.cpp:231] Iteration 340400, loss = 1.27864
I0519 11:09:54.911305  4008 solver.cpp:247]     Train net output #0: loss = 1.27864 (* 1 = 1.27864 loss)
I0519 11:09:54.911324  4008 sgd_solver.cpp:106] Iteration 340400, lr = 0.0001
I0519 11:09:55.070806  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3767	3.125	82.2855	0	91.0919	5.98958	89.1216	0	85.2304	0	85.5986	0	78.3407	0	30.3836	2.7	
I0519 11:09:55.145414  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:09:55.147253  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:09:55.147284  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:09:55.157366  4008 solver.cpp:260]     Total regularization terms: 0.944165 loss+regular. : 2.22281
I0519 11:09:57.808956  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:11:20.472612  4008 solver.cpp:231] Iteration 340600, loss = 1.32098
I0519 11:11:20.472836  4008 solver.cpp:247]     Train net output #0: loss = 1.32098 (* 1 = 1.32098 loss)
I0519 11:11:20.472857  4008 sgd_solver.cpp:106] Iteration 340600, lr = 0.0001
I0519 11:11:20.632613  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3796	3.125	82.2868	0	91.0926	5.98958	89.122	0	85.2311	0	85.5987	0	78.3408	0	30.3836	2.7	
I0519 11:11:20.707504  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:11:20.709579  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:11:20.709628  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:11:20.719528  4008 solver.cpp:260]     Total regularization terms: 0.944129 loss+regular. : 2.26511
I0519 11:12:48.595953  4008 solver.cpp:231] Iteration 340800, loss = 1.47439
I0519 11:12:48.596338  4008 solver.cpp:247]     Train net output #0: loss = 1.47439 (* 1 = 1.47439 loss)
I0519 11:12:48.596359  4008 sgd_solver.cpp:106] Iteration 340800, lr = 0.0001
I0519 11:12:48.756858  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3853	3.125	82.2881	0	91.0929	5.98958	89.1222	0	85.2311	0	85.5988	0	78.3409	0	30.3838	2.7	
I0519 11:12:48.831748  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:12:48.833842  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:12:48.833884  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:12:48.843745  4008 solver.cpp:260]     Total regularization terms: 0.944096 loss+regular. : 2.41849
I0519 11:14:13.838214  4008 solver.cpp:348] Iteration 341000, Testing net (#0)
I0519 11:14:45.360846  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:15:34.520072  4008 solver.cpp:415]     Test net output #0: accuracy = 0.565739
I0519 11:15:34.520472  4008 solver.cpp:415]     Test net output #1: loss = 1.86197 (* 1 = 1.86197 loss)
I0519 11:15:34.612762  4008 solver.cpp:231] Iteration 341000, loss = 1.2201
I0519 11:15:34.612846  4008 solver.cpp:247]     Train net output #0: loss = 1.2201 (* 1 = 1.2201 loss)
I0519 11:15:34.612869  4008 sgd_solver.cpp:106] Iteration 341000, lr = 0.0001
I0519 11:15:34.782035  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3882	3.125	82.2907	0	91.0933	5.98958	89.1226	0	85.2322	0	85.5989	0	78.341	0	30.3839	2.7	
I0519 11:15:34.871757  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:15:34.873628  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:15:34.873661  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:15:34.883515  4008 solver.cpp:260]     Total regularization terms: 0.944052 loss+regular. : 2.16415
I0519 11:16:55.098263  4008 solver.cpp:231] Iteration 341200, loss = 1.24259
I0519 11:16:55.098629  4008 solver.cpp:247]     Train net output #0: loss = 1.24259 (* 1 = 1.24259 loss)
I0519 11:16:55.098657  4008 sgd_solver.cpp:106] Iteration 341200, lr = 0.0001
I0519 11:16:55.258404  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3882	3.125	82.2926	0	91.0939	5.98958	89.1228	0	85.2329	0	85.5989	0	78.3411	0	30.384	2.7	
I0519 11:16:55.333611  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:16:55.336273  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:16:55.336321  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:16:55.346240  4008 solver.cpp:260]     Total regularization terms: 0.944026 loss+regular. : 2.18661
I0519 11:18:15.811866  4008 solver.cpp:231] Iteration 341400, loss = 1.27461
I0519 11:18:15.812180  4008 solver.cpp:247]     Train net output #0: loss = 1.27461 (* 1 = 1.27461 loss)
I0519 11:18:15.812201  4008 sgd_solver.cpp:106] Iteration 341400, lr = 0.0001
I0519 11:18:15.972260  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3911	3.125	82.2949	0	91.0943	5.98958	89.1229	0	85.2331	0	85.599	0	78.3412	0	30.384	2.7	
I0519 11:18:16.047533  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:18:16.050248  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:18:16.050290  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:18:16.060068  4008 solver.cpp:260]     Total regularization terms: 0.94398 loss+regular. : 2.21859
I0519 11:18:21.928484  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:19:38.517021  4008 solver.cpp:231] Iteration 341600, loss = 1.20071
I0519 11:19:38.517312  4008 solver.cpp:247]     Train net output #0: loss = 1.20071 (* 1 = 1.20071 loss)
I0519 11:19:38.517333  4008 sgd_solver.cpp:106] Iteration 341600, lr = 0.0001
I0519 11:19:38.676599  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3911	3.125	82.2956	0	91.0946	5.98958	89.1235	0	85.2333	0	85.5991	0	78.3412	0	30.3841	2.7	
I0519 11:19:38.751708  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:19:38.754415  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:19:38.754458  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:19:38.767488  4008 solver.cpp:260]     Total regularization terms: 0.94395 loss+regular. : 2.14466
I0519 11:21:00.784240  4008 solver.cpp:231] Iteration 341800, loss = 1.15502
I0519 11:21:00.784636  4008 solver.cpp:247]     Train net output #0: loss = 1.15502 (* 1 = 1.15502 loss)
I0519 11:21:00.784657  4008 sgd_solver.cpp:106] Iteration 341800, lr = 0.0001
I0519 11:21:00.943892  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3911	3.125	82.2975	0	91.0949	5.98958	89.124	0	85.2333	0	85.5992	0	78.3413	0	30.3841	2.7	
I0519 11:21:01.019073  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:21:01.021610  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:21:01.021654  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:21:01.031545  4008 solver.cpp:260]     Total regularization terms: 0.943909 loss+regular. : 2.09893
I0519 11:22:22.594781  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_342000.caffemodel
I0519 11:23:44.548408  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_342000.solverstate
I0519 11:23:45.050236  4008 solver.cpp:348] Iteration 342000, Testing net (#0)
I0519 11:24:15.671387  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:25:00.384145  4008 solver.cpp:415]     Test net output #0: accuracy = 0.565799
I0519 11:25:00.384377  4008 solver.cpp:415]     Test net output #1: loss = 1.85916 (* 1 = 1.85916 loss)
I0519 11:25:00.472311  4008 solver.cpp:231] Iteration 342000, loss = 1.36891
I0519 11:25:00.472388  4008 solver.cpp:247]     Train net output #0: loss = 1.36891 (* 1 = 1.36891 loss)
I0519 11:25:00.472405  4008 sgd_solver.cpp:106] Iteration 342000, lr = 0.0001
I0519 11:25:00.639068  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3911	3.125	82.2995	0	91.0951	5.98958	89.1247	0	85.2338	0	85.5993	0	78.3414	0	30.3842	2.7	
I0519 11:25:00.641191  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:25:00.643690  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:25:00.643738  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:25:00.653492  4008 solver.cpp:260]     Total regularization terms: 0.943865 loss+regular. : 2.31277
I0519 11:26:26.135609  4008 solver.cpp:231] Iteration 342200, loss = 1.12625
I0519 11:26:26.135848  4008 solver.cpp:247]     Train net output #0: loss = 1.12625 (* 1 = 1.12625 loss)
I0519 11:26:26.135867  4008 sgd_solver.cpp:106] Iteration 342200, lr = 0.0001
I0519 11:26:26.296653  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3939	3.125	82.3021	0	91.0955	5.98958	89.1255	0	85.2342	0	85.5993	0	78.3414	0	30.3842	2.7	
I0519 11:26:26.372743  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:26:26.375517  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:26:26.375565  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:26:26.390727  4008 solver.cpp:260]     Total regularization terms: 0.943833 loss+regular. : 2.07009
I0519 11:27:47.258708  4008 solver.cpp:231] Iteration 342400, loss = 1.31257
I0519 11:27:47.258965  4008 solver.cpp:247]     Train net output #0: loss = 1.31257 (* 1 = 1.31257 loss)
I0519 11:27:47.258985  4008 sgd_solver.cpp:106] Iteration 342400, lr = 0.0001
I0519 11:27:47.420994  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3939	3.125	82.3037	0	91.0958	5.98958	89.1259	0	85.2349	0	85.5994	0	78.3415	0	30.3843	2.7	
I0519 11:27:47.497177  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:27:47.499969  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:27:47.500021  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:27:47.513919  4008 solver.cpp:260]     Total regularization terms: 0.943793 loss+regular. : 2.25636
I0519 11:27:55.269842  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:29:02.483435  4008 solver.cpp:231] Iteration 342600, loss = 1.22834
I0519 11:29:02.484428  4008 solver.cpp:247]     Train net output #0: loss = 1.22834 (* 1 = 1.22834 loss)
I0519 11:29:02.484457  4008 sgd_solver.cpp:106] Iteration 342600, lr = 0.0001
I0519 11:29:02.653475  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3968	3.125	82.306	0	91.0961	5.98958	89.1265	0	85.2358	0	85.5995	0	78.3417	0	30.3843	2.7	
I0519 11:29:02.735772  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:29:02.737471  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:29:02.737494  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:29:02.757616  4008 solver.cpp:260]     Total regularization terms: 0.94376 loss+regular. : 2.1721
I0519 11:30:29.424433  4008 solver.cpp:231] Iteration 342800, loss = 1.3296
I0519 11:30:29.424890  4008 solver.cpp:247]     Train net output #0: loss = 1.3296 (* 1 = 1.3296 loss)
I0519 11:30:29.424914  4008 sgd_solver.cpp:106] Iteration 342800, lr = 0.0001
I0519 11:30:29.583034  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3968	3.125	82.3096	0	91.0964	5.98958	89.1275	0	85.236	0	85.5995	0	78.3417	0	30.3844	2.7	
I0519 11:30:29.658167  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:30:29.660086  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:30:29.660133  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:30:29.670186  4008 solver.cpp:260]     Total regularization terms: 0.943727 loss+regular. : 2.27332
I0519 11:31:54.991092  4008 solver.cpp:348] Iteration 343000, Testing net (#0)
I0519 11:32:26.741760  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:33:10.674878  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56602
I0519 11:33:10.675123  4008 solver.cpp:415]     Test net output #1: loss = 1.86047 (* 1 = 1.86047 loss)
I0519 11:33:10.762080  4008 solver.cpp:231] Iteration 343000, loss = 1.08948
I0519 11:33:10.762162  4008 solver.cpp:247]     Train net output #0: loss = 1.08948 (* 1 = 1.08948 loss)
I0519 11:33:10.762179  4008 sgd_solver.cpp:106] Iteration 343000, lr = 0.0001
I0519 11:33:10.930631  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3968	3.125	82.3119	0	91.097	5.98958	89.1278	0	85.2365	0	85.5996	0	78.3418	0	30.3844	2.7	
I0519 11:33:11.005136  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:33:11.007256  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:33:11.007307  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:33:11.019290  4008 solver.cpp:260]     Total regularization terms: 0.943689 loss+regular. : 2.03317
I0519 11:34:28.380393  4008 solver.cpp:231] Iteration 343200, loss = 1.25919
I0519 11:34:28.380676  4008 solver.cpp:247]     Train net output #0: loss = 1.25919 (* 1 = 1.25919 loss)
I0519 11:34:28.380697  4008 sgd_solver.cpp:106] Iteration 343200, lr = 0.0001
I0519 11:34:28.540659  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.3997	3.125	82.3125	0	91.0975	5.98958	89.1281	0	85.2374	0	85.5996	0	78.3419	0	30.3846	2.7	
I0519 11:34:28.615207  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:34:28.617120  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:34:28.617177  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:34:28.626941  4008 solver.cpp:260]     Total regularization terms: 0.943663 loss+regular. : 2.20286
I0519 11:35:42.918041  4008 solver.cpp:231] Iteration 343400, loss = 1.54226
I0519 11:35:42.918315  4008 solver.cpp:247]     Train net output #0: loss = 1.54226 (* 1 = 1.54226 loss)
I0519 11:35:42.918335  4008 sgd_solver.cpp:106] Iteration 343400, lr = 0.0001
I0519 11:35:43.080091  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4054	3.125	82.3135	0	91.0986	5.98958	89.1282	0	85.2379	0	85.5997	0	78.3421	0	30.3847	2.7	
I0519 11:35:43.155763  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:35:43.158076  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:35:43.158100  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:35:43.172950  4008 solver.cpp:260]     Total regularization terms: 0.943622 loss+regular. : 2.48588
I0519 11:35:54.974076  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:37:03.934046  4008 solver.cpp:231] Iteration 343600, loss = 1.27229
I0519 11:37:03.934301  4008 solver.cpp:247]     Train net output #0: loss = 1.27229 (* 1 = 1.27229 loss)
I0519 11:37:03.934321  4008 sgd_solver.cpp:106] Iteration 343600, lr = 0.0001
I0519 11:37:04.094041  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4083	3.125	82.3148	0	91.0989	5.98958	89.1297	0	85.2381	0	85.5998	0	78.3421	0	30.3848	2.7	
I0519 11:37:04.169675  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:37:04.172065  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:37:04.172091  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:37:04.181823  4008 solver.cpp:260]     Total regularization terms: 0.943601 loss+regular. : 2.21589
I0519 11:38:22.404400  4008 solver.cpp:231] Iteration 343800, loss = 1.27502
I0519 11:38:22.404656  4008 solver.cpp:247]     Train net output #0: loss = 1.27502 (* 1 = 1.27502 loss)
I0519 11:38:22.404685  4008 sgd_solver.cpp:106] Iteration 343800, lr = 0.0001
I0519 11:38:22.564941  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4083	3.125	82.3184	0	91.0989	5.98958	89.1308	0	85.2383	0	85.5999	0	78.3423	0	30.3848	2.7	
I0519 11:38:22.639775  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:38:22.641444  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:38:22.641480  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:38:22.651365  4008 solver.cpp:260]     Total regularization terms: 0.943562 loss+regular. : 2.21858
I0519 11:39:42.888195  4008 solver.cpp:348] Iteration 344000, Testing net (#0)
I0519 11:40:13.612035  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:40:54.902407  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56672
I0519 11:40:54.902698  4008 solver.cpp:415]     Test net output #1: loss = 1.85968 (* 1 = 1.85968 loss)
I0519 11:40:54.990335  4008 solver.cpp:231] Iteration 344000, loss = 1.21045
I0519 11:40:54.990417  4008 solver.cpp:247]     Train net output #0: loss = 1.21045 (* 1 = 1.21045 loss)
I0519 11:40:54.990432  4008 sgd_solver.cpp:106] Iteration 344000, lr = 0.0001
I0519 11:40:55.151336  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4112	3.125	82.319	0	91.0995	5.98958	89.1314	0	85.2388	0	85.6	0	78.3423	0	30.3849	2.7	
I0519 11:40:55.226400  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:40:55.228493  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:40:55.228528  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:40:55.238287  4008 solver.cpp:260]     Total regularization terms: 0.943531 loss+regular. : 2.15398
I0519 11:42:18.517071  4008 solver.cpp:231] Iteration 344200, loss = 1.22987
I0519 11:42:18.517421  4008 solver.cpp:247]     Train net output #0: loss = 1.22987 (* 1 = 1.22987 loss)
I0519 11:42:18.517452  4008 sgd_solver.cpp:106] Iteration 344200, lr = 0.0001
I0519 11:42:18.677639  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4112	3.125	82.3219	0	91.1002	5.98958	89.132	0	85.2388	0	85.6001	0	78.3424	0	30.3849	2.7	
I0519 11:42:18.753936  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:42:18.757269  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:42:18.757324  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:42:18.767510  4008 solver.cpp:260]     Total regularization terms: 0.943497 loss+regular. : 2.17337
I0519 11:43:53.715415  4008 solver.cpp:231] Iteration 344400, loss = 1.53572
I0519 11:43:53.718950  4008 solver.cpp:247]     Train net output #0: loss = 1.53572 (* 1 = 1.53572 loss)
I0519 11:43:53.718991  4008 sgd_solver.cpp:106] Iteration 344400, lr = 0.0001
I0519 11:43:53.876022  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4112	3.125	82.3226	0	91.1008	5.98958	89.1326	0	85.2392	0	85.6001	0	78.3425	0	30.3849	2.7	
I0519 11:43:53.953022  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:43:53.956871  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:43:53.956931  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:43:53.967051  4008 solver.cpp:260]     Total regularization terms: 0.943462 loss+regular. : 2.47918
I0519 11:44:09.714592  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:45:25.166002  4008 solver.cpp:231] Iteration 344600, loss = 1.2383
I0519 11:45:25.166647  4008 solver.cpp:247]     Train net output #0: loss = 1.2383 (* 1 = 1.2383 loss)
I0519 11:45:25.166671  4008 sgd_solver.cpp:106] Iteration 344600, lr = 0.0001
I0519 11:45:25.325819  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4112	3.125	82.3232	0	91.1015	5.98958	89.1329	0	85.2394	0	85.6002	0	78.3425	0	30.3851	2.7	
I0519 11:45:25.401437  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:45:25.403904  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:45:25.403959  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:45:25.414037  4008 solver.cpp:260]     Total regularization terms: 0.94343 loss+regular. : 2.18173
I0519 11:46:51.914865  4008 solver.cpp:231] Iteration 344800, loss = 1.19369
I0519 11:46:51.916055  4008 solver.cpp:247]     Train net output #0: loss = 1.19369 (* 1 = 1.19369 loss)
I0519 11:46:51.916090  4008 sgd_solver.cpp:106] Iteration 344800, lr = 0.0001
I0519 11:46:52.074800  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4112	3.125	82.3236	0	91.1019	5.98958	89.1338	0	85.2394	0	85.6003	0	78.3426	0	30.3852	2.7	
I0519 11:46:52.150375  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:46:52.153116  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:46:52.153167  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:46:52.163130  4008 solver.cpp:260]     Total regularization terms: 0.943397 loss+regular. : 2.13709
I0519 11:48:20.184270  4008 solver.cpp:348] Iteration 345000, Testing net (#0)
I0519 11:48:58.096447  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:49:52.120271  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56682
I0519 11:49:52.120982  4008 solver.cpp:415]     Test net output #1: loss = 1.85744 (* 1 = 1.85744 loss)
I0519 11:49:52.211974  4008 solver.cpp:231] Iteration 345000, loss = 1.23299
I0519 11:49:52.212060  4008 solver.cpp:247]     Train net output #0: loss = 1.23299 (* 1 = 1.23299 loss)
I0519 11:49:52.212110  4008 sgd_solver.cpp:106] Iteration 345000, lr = 0.0001
I0519 11:49:52.372637  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.414	3.125	82.3242	0	91.1021	5.98958	89.1353	0	85.2406	0	85.6004	0	78.3427	0	30.3853	2.7	
I0519 11:49:52.448528  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:49:52.451781  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:49:52.451843  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:49:52.465083  4008 solver.cpp:260]     Total regularization terms: 0.943361 loss+regular. : 2.17635
I0519 11:51:12.217875  4008 solver.cpp:231] Iteration 345200, loss = 1.1446
I0519 11:51:12.218224  4008 solver.cpp:247]     Train net output #0: loss = 1.1446 (* 1 = 1.1446 loss)
I0519 11:51:12.218245  4008 sgd_solver.cpp:106] Iteration 345200, lr = 0.0001
I0519 11:51:12.378423  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4169	3.125	82.3268	0	91.1025	5.98958	89.1356	0	85.241	0	85.6004	0	78.3428	0	30.3853	2.7	
I0519 11:51:12.453904  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:51:12.456961  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:51:12.457008  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:51:12.466986  4008 solver.cpp:260]     Total regularization terms: 0.943319 loss+regular. : 2.08792
I0519 11:52:45.085505  4008 solver.cpp:231] Iteration 345400, loss = 1.23522
I0519 11:52:45.089709  4008 solver.cpp:247]     Train net output #0: loss = 1.23522 (* 1 = 1.23522 loss)
I0519 11:52:45.089746  4008 sgd_solver.cpp:106] Iteration 345400, lr = 0.0001
I0519 11:52:45.245298  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4169	3.125	82.3285	0	91.103	5.98958	89.1357	0	85.2412	0	85.6005	0	78.3429	0	30.3854	2.7	
I0519 11:52:45.320979  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:52:45.323882  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:52:45.323958  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:52:45.334180  4008 solver.cpp:260]     Total regularization terms: 0.943288 loss+regular. : 2.17851
I0519 11:53:04.696996  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:54:06.489497  4008 solver.cpp:231] Iteration 345600, loss = 1.51874
I0519 11:54:06.489837  4008 solver.cpp:247]     Train net output #0: loss = 1.51874 (* 1 = 1.51874 loss)
I0519 11:54:06.489864  4008 sgd_solver.cpp:106] Iteration 345600, lr = 0.0001
I0519 11:54:06.650754  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4169	3.125	82.3311	0	91.1034	5.98958	89.1363	0	85.2415	0	85.6006	0	78.3429	0	30.3854	2.7	
I0519 11:54:06.727195  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:54:06.730865  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:54:06.730947  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:54:06.741539  4008 solver.cpp:260]     Total regularization terms: 0.94325 loss+regular. : 2.46199
I0519 11:55:34.708397  4008 solver.cpp:231] Iteration 345800, loss = 1.28778
I0519 11:55:34.708753  4008 solver.cpp:247]     Train net output #0: loss = 1.28778 (* 1 = 1.28778 loss)
I0519 11:55:34.708781  4008 sgd_solver.cpp:106] Iteration 345800, lr = 0.0001
I0519 11:55:34.866801  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4226	3.125	82.334	0	91.104	5.98958	89.1368	0	85.2424	0	85.6007	0	78.343	0	30.3855	2.7	
I0519 11:55:34.942174  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:55:34.944913  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:55:34.944962  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:55:34.955258  4008 solver.cpp:260]     Total regularization terms: 0.943214 loss+regular. : 2.23099
I0519 11:56:55.114567  4008 solver.cpp:348] Iteration 346000, Testing net (#0)
I0519 11:57:30.853806  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 11:58:19.186000  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56608
I0519 11:58:19.186460  4008 solver.cpp:415]     Test net output #1: loss = 1.86017 (* 1 = 1.86017 loss)
I0519 11:58:19.274468  4008 solver.cpp:231] Iteration 346000, loss = 1.37613
I0519 11:58:19.274580  4008 solver.cpp:247]     Train net output #0: loss = 1.37613 (* 1 = 1.37613 loss)
I0519 11:58:19.274605  4008 sgd_solver.cpp:106] Iteration 346000, lr = 0.0001
I0519 11:58:19.439759  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4226	3.125	82.3346	0	91.1043	5.98958	89.1371	0	85.2431	0	85.6007	0	78.3431	0	30.3856	2.7	
I0519 11:58:19.515117  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:58:19.517372  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:58:19.517410  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:58:19.527133  4008 solver.cpp:260]     Total regularization terms: 0.943179 loss+regular. : 2.31931
I0519 11:59:39.092744  4008 solver.cpp:231] Iteration 346200, loss = 1.21262
I0519 11:59:39.093061  4008 solver.cpp:247]     Train net output #0: loss = 1.21262 (* 1 = 1.21262 loss)
I0519 11:59:39.093082  4008 sgd_solver.cpp:106] Iteration 346200, lr = 0.0001
I0519 11:59:39.251775  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4255	3.125	82.3363	0	91.105	5.98958	89.1376	0	85.244	0	85.6008	0	78.3432	0	30.3857	2.7	
I0519 11:59:39.326201  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 11:59:39.328253  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 11:59:39.328305  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 11:59:39.340127  4008 solver.cpp:260]     Total regularization terms: 0.943143 loss+regular. : 2.15577
I0519 12:01:13.753813  4008 solver.cpp:231] Iteration 346400, loss = 1.20299
I0519 12:01:13.754387  4008 solver.cpp:247]     Train net output #0: loss = 1.20299 (* 1 = 1.20299 loss)
I0519 12:01:13.754416  4008 sgd_solver.cpp:106] Iteration 346400, lr = 0.0001
I0519 12:01:13.912211  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4284	3.125	82.3379	0	91.1057	5.98958	89.1379	0	85.2444	0	85.6009	0	78.3433	0	30.3859	2.7	
I0519 12:01:13.987202  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:01:13.989508  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:01:13.989578  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:01:13.999568  4008 solver.cpp:260]     Total regularization terms: 0.943106 loss+regular. : 2.14609
I0519 12:01:37.006767  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:02:44.255970  4008 solver.cpp:231] Iteration 346600, loss = 1.29806
I0519 12:02:44.256783  4008 solver.cpp:247]     Train net output #0: loss = 1.29806 (* 1 = 1.29806 loss)
I0519 12:02:44.256831  4008 sgd_solver.cpp:106] Iteration 346600, lr = 0.0001
I0519 12:02:44.417495  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4284	3.125	82.3398	0	91.1063	5.98958	89.138	0	85.2451	0	85.601	0	78.3434	0	30.386	2.7	
I0519 12:02:44.493849  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:02:44.497098  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:02:44.497164  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:02:44.513495  4008 solver.cpp:260]     Total regularization terms: 0.943077 loss+regular. : 2.24114
I0519 12:04:16.362035  4008 solver.cpp:231] Iteration 346800, loss = 1.31512
I0519 12:04:16.362483  4008 solver.cpp:247]     Train net output #0: loss = 1.31512 (* 1 = 1.31512 loss)
I0519 12:04:16.362522  4008 sgd_solver.cpp:106] Iteration 346800, lr = 0.0001
I0519 12:04:16.522752  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4284	3.125	82.3421	0	91.1069	5.98958	89.1385	0	85.2458	0	85.6011	0	78.3435	0	30.3861	2.7	
I0519 12:04:16.598929  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:04:16.601816  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:04:16.601866  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:04:16.616183  4008 solver.cpp:260]     Total regularization terms: 0.94304 loss+regular. : 2.25816
I0519 12:05:38.843617  4008 solver.cpp:348] Iteration 347000, Testing net (#0)
I0519 12:06:16.937430  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:07:01.184367  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56674
I0519 12:07:01.184698  4008 solver.cpp:415]     Test net output #1: loss = 1.8601 (* 1 = 1.8601 loss)
I0519 12:07:01.275712  4008 solver.cpp:231] Iteration 347000, loss = 1.20355
I0519 12:07:01.275822  4008 solver.cpp:247]     Train net output #0: loss = 1.20355 (* 1 = 1.20355 loss)
I0519 12:07:01.275874  4008 sgd_solver.cpp:106] Iteration 347000, lr = 0.0001
I0519 12:07:01.443897  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4312	3.125	82.3444	0	91.1076	5.98958	89.1386	0	85.2458	0	85.6012	0	78.3435	0	30.3861	2.7	
I0519 12:07:01.520201  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:07:01.524184  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:07:01.524255  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:07:01.534353  4008 solver.cpp:260]     Total regularization terms: 0.942995 loss+regular. : 2.14654
I0519 12:08:30.632283  4008 solver.cpp:231] Iteration 347200, loss = 1.25163
I0519 12:08:30.633626  4008 solver.cpp:247]     Train net output #0: loss = 1.25163 (* 1 = 1.25163 loss)
I0519 12:08:30.633653  4008 sgd_solver.cpp:106] Iteration 347200, lr = 0.0001
I0519 12:08:30.794322  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4312	3.125	82.3464	0	91.108	5.98958	89.1397	0	85.246	0	85.6013	0	78.3436	0	30.3863	2.7	
I0519 12:08:30.869956  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:08:30.873055  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:08:30.873106  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:08:30.883041  4008 solver.cpp:260]     Total regularization terms: 0.942961 loss+regular. : 2.19459
I0519 12:09:48.851480  4008 solver.cpp:231] Iteration 347400, loss = 1.37963
I0519 12:09:48.852094  4008 solver.cpp:247]     Train net output #0: loss = 1.37963 (* 1 = 1.37963 loss)
I0519 12:09:48.852121  4008 sgd_solver.cpp:106] Iteration 347400, lr = 0.0001
I0519 12:09:49.010448  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4341	3.125	82.3486	0	91.1082	5.98958	89.1409	0	85.2467	0	85.6013	0	78.3437	0	30.3864	2.7	
I0519 12:09:49.085875  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:09:49.088481  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:09:49.088510  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:09:49.102802  4008 solver.cpp:260]     Total regularization terms: 0.942926 loss+regular. : 2.32255
I0519 12:10:15.887887  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:11:18.801748  4008 solver.cpp:231] Iteration 347600, loss = 1.30397
I0519 12:11:18.802085  4008 solver.cpp:247]     Train net output #0: loss = 1.30397 (* 1 = 1.30397 loss)
I0519 12:11:18.802106  4008 sgd_solver.cpp:106] Iteration 347600, lr = 0.0001
I0519 12:11:18.963323  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4341	3.125	82.3496	0	91.1082	5.98958	89.1415	0	85.2471	0	85.6014	0	78.3437	0	30.3865	2.7	
I0519 12:11:19.038271  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:11:19.040662  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:11:19.040720  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:11:19.050812  4008 solver.cpp:260]     Total regularization terms: 0.942884 loss+regular. : 2.24686
I0519 12:12:55.462491  4008 solver.cpp:231] Iteration 347800, loss = 1.21886
I0519 12:12:55.463387  4008 solver.cpp:247]     Train net output #0: loss = 1.21886 (* 1 = 1.21886 loss)
I0519 12:12:55.463546  4008 sgd_solver.cpp:106] Iteration 347800, lr = 0.0001
I0519 12:12:55.622323  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.437	3.125	82.3512	0	91.1083	5.98958	89.1418	0	85.2474	0	85.6015	0	78.3438	0	30.3866	2.7	
I0519 12:12:55.697923  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:12:55.700181  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:12:55.700230  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:12:55.710165  4008 solver.cpp:260]     Total regularization terms: 0.942859 loss+regular. : 2.16172
I0519 12:14:39.377590  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_348000.caffemodel
I0519 12:17:32.676601  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_348000.solverstate
I0519 12:17:33.193547  4008 solver.cpp:348] Iteration 348000, Testing net (#0)
I0519 12:18:13.252360  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:18:59.679111  4008 solver.cpp:415]     Test net output #0: accuracy = 0.566939
I0519 12:18:59.679594  4008 solver.cpp:415]     Test net output #1: loss = 1.85961 (* 1 = 1.85961 loss)
I0519 12:18:59.772733  4008 solver.cpp:231] Iteration 348000, loss = 1.09767
I0519 12:18:59.772809  4008 solver.cpp:247]     Train net output #0: loss = 1.09767 (* 1 = 1.09767 loss)
I0519 12:18:59.772827  4008 sgd_solver.cpp:106] Iteration 348000, lr = 0.0001
I0519 12:18:59.940277  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.437	3.125	82.3525	0	91.1085	5.98958	89.1419	0	85.2476	0	85.6015	0	78.3439	0	30.3867	2.7	
I0519 12:18:59.942368  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:18:59.944648  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:18:59.944669  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:18:59.954412  4008 solver.cpp:260]     Total regularization terms: 0.942822 loss+regular. : 2.04049
I0519 12:20:23.174850  4008 solver.cpp:231] Iteration 348200, loss = 1.33646
I0519 12:20:23.175179  4008 solver.cpp:247]     Train net output #0: loss = 1.33646 (* 1 = 1.33646 loss)
I0519 12:20:23.175200  4008 sgd_solver.cpp:106] Iteration 348200, lr = 0.0001
I0519 12:20:23.335517  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.437	3.125	82.3532	0	91.1091	5.98958	89.1424	0	85.2483	0	85.6016	0	78.344	0	30.3868	2.7	
I0519 12:20:23.410337  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:20:23.412588  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:20:23.412636  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:20:23.422456  4008 solver.cpp:260]     Total regularization terms: 0.942788 loss+regular. : 2.27925
I0519 12:21:51.483428  4008 solver.cpp:231] Iteration 348400, loss = 1.3536
I0519 12:21:51.483973  4008 solver.cpp:247]     Train net output #0: loss = 1.3536 (* 1 = 1.3536 loss)
I0519 12:21:51.483999  4008 sgd_solver.cpp:106] Iteration 348400, lr = 0.0001
I0519 12:21:51.643556  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.437	3.125	82.3548	0	91.1093	5.98958	89.1431	0	85.2489	0	85.6017	0	78.344	0	30.3869	2.7	
I0519 12:21:51.718791  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:21:51.721046  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:21:51.721098  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:21:51.736243  4008 solver.cpp:260]     Total regularization terms: 0.942756 loss+regular. : 2.29636
I0519 12:22:19.499163  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:23:15.678560  4008 solver.cpp:231] Iteration 348600, loss = 1.28361
I0519 12:23:15.685727  4008 solver.cpp:247]     Train net output #0: loss = 1.28361 (* 1 = 1.28361 loss)
I0519 12:23:15.685783  4008 sgd_solver.cpp:106] Iteration 348600, lr = 0.0001
I0519 12:23:15.838078  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.437	3.125	82.3561	0	91.1099	5.98958	89.1437	0	85.2494	0	85.6018	0	78.3441	0	30.387	2.7	
I0519 12:23:15.912987  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:23:15.915205  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:23:15.915257  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:23:15.925109  4008 solver.cpp:260]     Total regularization terms: 0.94273 loss+regular. : 2.22634
I0519 12:24:50.727917  4008 solver.cpp:231] Iteration 348800, loss = 1.27335
I0519 12:24:50.728739  4008 solver.cpp:247]     Train net output #0: loss = 1.27335 (* 1 = 1.27335 loss)
I0519 12:24:50.728775  4008 sgd_solver.cpp:106] Iteration 348800, lr = 0.0001
I0519 12:24:50.888103  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4399	3.125	82.3574	0	91.1106	5.98958	89.1439	0	85.2498	0	85.6019	0	78.3442	0	30.387	2.7	
I0519 12:24:50.963841  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:24:50.966266  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:24:50.966318  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:24:50.976403  4008 solver.cpp:260]     Total regularization terms: 0.942691 loss+regular. : 2.21604
I0519 12:26:21.342452  4008 solver.cpp:348] Iteration 349000, Testing net (#0)
I0519 12:27:00.207947  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:27:47.372767  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56664
I0519 12:27:47.373440  4008 solver.cpp:415]     Test net output #1: loss = 1.86055 (* 1 = 1.86055 loss)
I0519 12:27:47.461669  4008 solver.cpp:231] Iteration 349000, loss = 1.17381
I0519 12:27:47.461766  4008 solver.cpp:247]     Train net output #0: loss = 1.17381 (* 1 = 1.17381 loss)
I0519 12:27:47.461791  4008 sgd_solver.cpp:106] Iteration 349000, lr = 0.0001
I0519 12:27:47.629539  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4427	3.125	82.36	0	91.111	5.98958	89.144	0	85.2516	0	85.6019	0	78.3443	0	30.3872	2.7	
I0519 12:27:47.705741  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:27:47.708358  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:27:47.708410  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:27:47.718411  4008 solver.cpp:260]     Total regularization terms: 0.942657 loss+regular. : 2.11646
I0519 12:29:07.356268  4008 solver.cpp:231] Iteration 349200, loss = 1.31879
I0519 12:29:07.356662  4008 solver.cpp:247]     Train net output #0: loss = 1.31879 (* 1 = 1.31879 loss)
I0519 12:29:07.356698  4008 sgd_solver.cpp:106] Iteration 349200, lr = 0.0001
I0519 12:29:07.517647  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4427	3.125	82.3626	0	91.1114	5.98958	89.1442	0	85.2519	0	85.602	0	78.3444	0	30.3873	2.7	
I0519 12:29:07.592835  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:29:07.594774  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:29:07.594832  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:29:07.604799  4008 solver.cpp:260]     Total regularization terms: 0.942622 loss+regular. : 2.26141
I0519 12:30:38.589519  4008 solver.cpp:231] Iteration 349400, loss = 1.02001
I0519 12:30:38.590011  4008 solver.cpp:247]     Train net output #0: loss = 1.02001 (* 1 = 1.02001 loss)
I0519 12:30:38.590037  4008 sgd_solver.cpp:106] Iteration 349400, lr = 0.0001
I0519 12:30:38.749729  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4456	3.125	82.3633	0	91.112	5.98958	89.1449	0	85.2528	0	85.6021	0	78.3444	0	30.3873	2.7	
I0519 12:30:38.825100  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:30:38.827481  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:30:38.827530  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:30:38.837446  4008 solver.cpp:260]     Total regularization terms: 0.942582 loss+regular. : 1.96259
I0519 12:31:06.718523  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:32:03.049075  4008 solver.cpp:231] Iteration 349600, loss = 1.29078
I0519 12:32:03.049451  4008 solver.cpp:247]     Train net output #0: loss = 1.29078 (* 1 = 1.29078 loss)
I0519 12:32:03.049479  4008 sgd_solver.cpp:106] Iteration 349600, lr = 0.0001
I0519 12:32:03.207947  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4456	3.125	82.3649	0	91.1125	5.98958	89.1454	0	85.253	0	85.6022	0	78.3445	0	30.3873	2.7	
I0519 12:32:03.283444  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:32:03.286269  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:32:03.286345  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:32:03.296520  4008 solver.cpp:260]     Total regularization terms: 0.942555 loss+regular. : 2.23334
I0519 12:33:27.881574  4008 solver.cpp:231] Iteration 349800, loss = 1.24492
I0519 12:33:27.881891  4008 solver.cpp:247]     Train net output #0: loss = 1.24492 (* 1 = 1.24492 loss)
I0519 12:33:27.881914  4008 sgd_solver.cpp:106] Iteration 349800, lr = 0.0001
I0519 12:33:28.041318  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4456	3.125	82.3659	0	91.1131	5.98958	89.146	0	85.253	0	85.6023	0	78.3447	0	30.3874	2.7	
I0519 12:33:28.117053  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:33:28.119881  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:33:28.119930  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:33:28.129881  4008 solver.cpp:260]     Total regularization terms: 0.942521 loss+regular. : 2.18744
I0519 12:35:05.831990  4008 solver.cpp:348] Iteration 350000, Testing net (#0)
I0519 12:35:52.035897  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:36:32.192245  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56576
I0519 12:36:32.192584  4008 solver.cpp:415]     Test net output #1: loss = 1.85899 (* 1 = 1.85899 loss)
I0519 12:36:32.285281  4008 solver.cpp:231] Iteration 350000, loss = 1.27754
I0519 12:36:32.285393  4008 solver.cpp:247]     Train net output #0: loss = 1.27754 (* 1 = 1.27754 loss)
I0519 12:36:32.285414  4008 sgd_solver.cpp:106] Iteration 350000, lr = 0.0001
I0519 12:36:32.455631  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4456	3.125	82.3665	0	91.1133	5.98958	89.1469	0	85.2532	0	85.6024	0	78.3447	0	30.3875	2.7	
I0519 12:36:32.545287  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:36:32.551517  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:36:32.551645  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:36:32.575367  4008 solver.cpp:260]     Total regularization terms: 0.942482 loss+regular. : 2.22003
I0519 12:38:01.393035  4008 solver.cpp:231] Iteration 350200, loss = 1.29118
I0519 12:38:01.393421  4008 solver.cpp:247]     Train net output #0: loss = 1.29118 (* 1 = 1.29118 loss)
I0519 12:38:01.393446  4008 sgd_solver.cpp:106] Iteration 350200, lr = 0.0001
I0519 12:38:01.553068  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4485	3.125	82.3682	0	91.1136	5.98958	89.1476	0	85.2532	0	85.6025	0	78.3448	0	30.3876	2.7	
I0519 12:38:01.627779  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:38:01.630153  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:38:01.630195  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:38:01.645303  4008 solver.cpp:260]     Total regularization terms: 0.942446 loss+regular. : 2.23363
I0519 12:39:34.751497  4008 solver.cpp:231] Iteration 350400, loss = 1.2758
I0519 12:39:34.751837  4008 solver.cpp:247]     Train net output #0: loss = 1.2758 (* 1 = 1.2758 loss)
I0519 12:39:34.751870  4008 sgd_solver.cpp:106] Iteration 350400, lr = 0.0001
I0519 12:39:34.911204  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4485	3.125	82.3698	0	91.1143	5.98958	89.1487	0	85.2544	0	85.6026	0	78.3449	0	30.3876	2.7	
I0519 12:39:34.987596  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:39:34.991166  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:39:34.991240  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:39:35.001585  4008 solver.cpp:260]     Total regularization terms: 0.942412 loss+regular. : 2.21821
I0519 12:40:14.707940  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:41:14.071070  4008 solver.cpp:231] Iteration 350600, loss = 1.14982
I0519 12:41:14.071384  4008 solver.cpp:247]     Train net output #0: loss = 1.14982 (* 1 = 1.14982 loss)
I0519 12:41:14.071408  4008 sgd_solver.cpp:106] Iteration 350600, lr = 0.0001
I0519 12:41:14.232641  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4485	3.125	82.3721	0	91.1147	5.98958	89.1495	0	85.2544	0	85.6026	0	78.345	0	30.3877	2.7	
I0519 12:41:14.308347  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:41:14.311676  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:41:14.311727  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:41:14.321782  4008 solver.cpp:260]     Total regularization terms: 0.942379 loss+regular. : 2.0922
I0519 12:42:45.901109  4008 solver.cpp:231] Iteration 350800, loss = 1.34928
I0519 12:42:45.901651  4008 solver.cpp:247]     Train net output #0: loss = 1.34928 (* 1 = 1.34928 loss)
I0519 12:42:45.901695  4008 sgd_solver.cpp:106] Iteration 350800, lr = 0.0001
I0519 12:42:46.063431  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4485	3.125	82.3734	0	91.1151	5.98958	89.1501	0	85.255	0	85.6027	0	78.3451	0	30.3877	2.7	
I0519 12:42:46.139305  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:42:46.143105  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:42:46.143157  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:42:46.155768  4008 solver.cpp:260]     Total regularization terms: 0.942354 loss+regular. : 2.29163
I0519 12:44:08.415700  4008 solver.cpp:348] Iteration 351000, Testing net (#0)
I0519 12:44:48.754137  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:45:30.611264  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56662
I0519 12:45:30.611703  4008 solver.cpp:415]     Test net output #1: loss = 1.86073 (* 1 = 1.86073 loss)
I0519 12:45:30.700451  4008 solver.cpp:231] Iteration 351000, loss = 1.29866
I0519 12:45:30.700594  4008 solver.cpp:247]     Train net output #0: loss = 1.29866 (* 1 = 1.29866 loss)
I0519 12:45:30.700623  4008 sgd_solver.cpp:106] Iteration 351000, lr = 0.0001
I0519 12:45:30.860309  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4485	3.125	82.3744	0	91.1153	5.98958	89.1504	0	85.2564	0	85.6028	0	78.3451	0	30.3878	2.7	
I0519 12:45:30.936995  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:45:30.940770  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:45:30.940831  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:45:30.950918  4008 solver.cpp:260]     Total regularization terms: 0.942316 loss+regular. : 2.24098
I0519 12:46:57.307991  4008 solver.cpp:231] Iteration 351200, loss = 1.14223
I0519 12:46:57.308311  4008 solver.cpp:247]     Train net output #0: loss = 1.14223 (* 1 = 1.14223 loss)
I0519 12:46:57.308336  4008 sgd_solver.cpp:106] Iteration 351200, lr = 0.0001
I0519 12:46:57.468266  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4485	3.125	82.375	0	91.1155	5.98958	89.1505	0	85.2566	0	85.6029	0	78.3452	0	30.3879	2.7	
I0519 12:46:57.543004  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:46:57.545275  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:46:57.545310  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:46:57.554991  4008 solver.cpp:260]     Total regularization terms: 0.942279 loss+regular. : 2.08451
I0519 12:48:28.640631  4008 solver.cpp:231] Iteration 351400, loss = 1.26519
I0519 12:48:28.640923  4008 solver.cpp:247]     Train net output #0: loss = 1.26519 (* 1 = 1.26519 loss)
I0519 12:48:28.640945  4008 sgd_solver.cpp:106] Iteration 351400, lr = 0.0001
I0519 12:48:28.802719  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4485	3.125	82.3763	0	91.1161	5.98958	89.1514	0	85.2573	0	85.603	0	78.3454	0	30.3879	2.7	
I0519 12:48:28.879554  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:48:28.883735  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:48:28.883811  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:48:28.894222  4008 solver.cpp:260]     Total regularization terms: 0.94224 loss+regular. : 2.20743
I0519 12:49:06.976423  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:50:04.276581  4008 solver.cpp:231] Iteration 351600, loss = 1.31371
I0519 12:50:04.277041  4008 solver.cpp:247]     Train net output #0: loss = 1.31371 (* 1 = 1.31371 loss)
I0519 12:50:04.277066  4008 sgd_solver.cpp:106] Iteration 351600, lr = 0.0001
I0519 12:50:04.435909  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4513	3.125	82.3779	0	91.1167	5.98958	89.1519	0	85.2575	0	85.603	0	78.3455	0	30.388	2.7	
I0519 12:50:04.510924  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:50:04.513134  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:50:04.513175  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:50:04.531791  4008 solver.cpp:260]     Total regularization terms: 0.942213 loss+regular. : 2.25592
I0519 12:51:33.435912  4008 solver.cpp:231] Iteration 351800, loss = 1.38918
I0519 12:51:33.436517  4008 solver.cpp:247]     Train net output #0: loss = 1.38918 (* 1 = 1.38918 loss)
I0519 12:51:33.436575  4008 sgd_solver.cpp:106] Iteration 351800, lr = 0.0001
I0519 12:51:33.595495  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4513	3.125	82.3783	0	91.117	5.98958	89.1531	0	85.2578	0	85.6031	0	78.3456	0	30.3881	2.7	
I0519 12:51:33.671953  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:51:33.674207  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:51:33.674314  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:51:33.684355  4008 solver.cpp:260]     Total regularization terms: 0.942174 loss+regular. : 2.33136
I0519 12:53:04.238754  4008 solver.cpp:348] Iteration 352000, Testing net (#0)
I0519 12:53:42.611704  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:54:21.734705  4008 solver.cpp:415]     Test net output #0: accuracy = 0.566999
I0519 12:54:21.735098  4008 solver.cpp:415]     Test net output #1: loss = 1.85857 (* 1 = 1.85857 loss)
I0519 12:54:21.825400  4008 solver.cpp:231] Iteration 352000, loss = 1.27349
I0519 12:54:21.825530  4008 solver.cpp:247]     Train net output #0: loss = 1.27349 (* 1 = 1.27349 loss)
I0519 12:54:21.825565  4008 sgd_solver.cpp:106] Iteration 352000, lr = 0.0001
I0519 12:54:21.988421  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4542	3.125	82.3786	0	91.1173	5.98958	89.1534	0	85.2584	0	85.6032	0	78.3457	0	30.3882	2.7	
I0519 12:54:22.064242  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:54:22.066169  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:54:22.066223  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:54:22.076159  4008 solver.cpp:260]     Total regularization terms: 0.942135 loss+regular. : 2.21563
I0519 12:55:48.473873  4008 solver.cpp:231] Iteration 352200, loss = 1.35769
I0519 12:55:48.474233  4008 solver.cpp:247]     Train net output #0: loss = 1.35769 (* 1 = 1.35769 loss)
I0519 12:55:48.474256  4008 sgd_solver.cpp:106] Iteration 352200, lr = 0.0001
I0519 12:55:48.632971  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4542	3.125	82.3796	0	91.1177	5.98958	89.1535	0	85.2589	0	85.6033	0	78.3457	0	30.3882	2.7	
I0519 12:55:48.708523  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:55:48.711716  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:55:48.711815  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:55:48.722205  4008 solver.cpp:260]     Total regularization terms: 0.942101 loss+regular. : 2.29979
I0519 12:57:12.632302  4008 solver.cpp:231] Iteration 352400, loss = 1.27372
I0519 12:57:12.632644  4008 solver.cpp:247]     Train net output #0: loss = 1.27372 (* 1 = 1.27372 loss)
I0519 12:57:12.632664  4008 sgd_solver.cpp:106] Iteration 352400, lr = 0.0001
I0519 12:57:12.793347  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4542	3.125	82.3818	0	91.118	5.98958	89.1544	0	85.2593	0	85.6034	0	78.3458	0	30.3883	2.7	
I0519 12:57:12.868140  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:57:12.870064  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:57:12.870111  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:57:12.880249  4008 solver.cpp:260]     Total regularization terms: 0.942071 loss+regular. : 2.21579
I0519 12:57:50.595054  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 12:58:41.503609  4008 solver.cpp:231] Iteration 352600, loss = 1.1854
I0519 12:58:41.509862  4008 solver.cpp:247]     Train net output #0: loss = 1.1854 (* 1 = 1.1854 loss)
I0519 12:58:41.509901  4008 sgd_solver.cpp:106] Iteration 352600, lr = 0.0001
I0519 12:58:41.664173  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4542	3.125	82.3835	0	91.1183	5.98958	89.1549	0	85.2598	0	85.6035	0	78.3459	0	30.3883	2.7	
I0519 12:58:41.739055  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 12:58:41.741240  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 12:58:41.741291  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 12:58:41.752972  4008 solver.cpp:260]     Total regularization terms: 0.942031 loss+regular. : 2.12744
I0519 13:00:10.653991  4008 solver.cpp:231] Iteration 352800, loss = 1.33582
I0519 13:00:10.654392  4008 solver.cpp:247]     Train net output #0: loss = 1.33582 (* 1 = 1.33582 loss)
I0519 13:00:10.654413  4008 sgd_solver.cpp:106] Iteration 352800, lr = 0.0001
I0519 13:00:10.813398  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4542	3.125	82.3844	0	91.1186	5.98958	89.1558	0	85.2605	0	85.6035	0	78.346	0	30.3883	2.7	
I0519 13:00:10.888242  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:00:10.890403  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:00:10.890455  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:00:10.900400  4008 solver.cpp:260]     Total regularization terms: 0.942004 loss+regular. : 2.27782
I0519 13:01:45.186643  4008 solver.cpp:348] Iteration 353000, Testing net (#0)
I0519 13:02:27.005893  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:03:08.619405  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567959
I0519 13:03:08.619777  4008 solver.cpp:415]     Test net output #1: loss = 1.85865 (* 1 = 1.85865 loss)
I0519 13:03:08.707818  4008 solver.cpp:231] Iteration 353000, loss = 1.16025
I0519 13:03:08.707912  4008 solver.cpp:247]     Train net output #0: loss = 1.16025 (* 1 = 1.16025 loss)
I0519 13:03:08.707932  4008 sgd_solver.cpp:106] Iteration 353000, lr = 0.0001
I0519 13:03:08.877394  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4571	3.125	82.3857	0	91.1192	5.98958	89.1562	0	85.2609	0	85.6036	0	78.3461	0	30.3884	2.7	
I0519 13:03:08.952733  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:03:08.954563  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:03:08.954615  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:03:08.964710  4008 solver.cpp:260]     Total regularization terms: 0.941968 loss+regular. : 2.10222
I0519 13:04:42.120259  4008 solver.cpp:231] Iteration 353200, loss = 1.25424
I0519 13:04:42.120712  4008 solver.cpp:247]     Train net output #0: loss = 1.25424 (* 1 = 1.25424 loss)
I0519 13:04:42.120746  4008 sgd_solver.cpp:106] Iteration 353200, lr = 0.0001
I0519 13:04:42.279669  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4599	3.125	82.3867	0	91.1194	5.98958	89.1565	0	85.2614	0	85.6037	0	78.3462	0	30.3886	2.7	
I0519 13:04:42.355520  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:04:42.358832  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:04:42.358906  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:04:42.369098  4008 solver.cpp:260]     Total regularization terms: 0.941936 loss+regular. : 2.19617
I0519 13:06:07.016070  4008 solver.cpp:231] Iteration 353400, loss = 1.39101
I0519 13:06:07.017805  4008 solver.cpp:247]     Train net output #0: loss = 1.39101 (* 1 = 1.39101 loss)
I0519 13:06:07.017838  4008 sgd_solver.cpp:106] Iteration 353400, lr = 0.0001
I0519 13:06:07.177351  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4599	3.125	82.388	0	91.1196	5.98958	89.157	0	85.2618	0	85.6038	0	78.3463	0	30.3887	2.7	
I0519 13:06:07.253747  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:06:07.256674  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:06:07.256727  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:06:07.285820  4008 solver.cpp:260]     Total regularization terms: 0.941903 loss+regular. : 2.33291
I0519 13:06:49.821347  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:07:33.583137  4008 solver.cpp:231] Iteration 353600, loss = 1.20141
I0519 13:07:33.584746  4008 solver.cpp:247]     Train net output #0: loss = 1.20141 (* 1 = 1.20141 loss)
I0519 13:07:33.584805  4008 sgd_solver.cpp:106] Iteration 353600, lr = 0.0001
I0519 13:07:33.742398  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4599	3.125	82.3893	0	91.1198	5.98958	89.1577	0	85.2625	0	85.6039	0	78.3464	0	30.3887	2.7	
I0519 13:07:33.817952  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:07:33.820780  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:07:33.820853  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:07:33.830831  4008 solver.cpp:260]     Total regularization terms: 0.941873 loss+regular. : 2.14328
I0519 13:09:03.235777  4008 solver.cpp:231] Iteration 353800, loss = 1.21921
I0519 13:09:03.236151  4008 solver.cpp:247]     Train net output #0: loss = 1.21921 (* 1 = 1.21921 loss)
I0519 13:09:03.236174  4008 sgd_solver.cpp:106] Iteration 353800, lr = 0.0001
I0519 13:09:03.396311  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4599	3.125	82.3906	0	91.1202	5.98958	89.1585	0	85.2634	0	85.6039	0	78.3464	0	30.3887	2.7	
I0519 13:09:03.473145  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:09:03.476241  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:09:03.476286  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:09:03.486444  4008 solver.cpp:260]     Total regularization terms: 0.941841 loss+regular. : 2.16105
I0519 13:10:26.325968  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_354000.caffemodel
I0519 13:11:45.436663  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_354000.solverstate
I0519 13:11:46.237853  4008 solver.cpp:348] Iteration 354000, Testing net (#0)
I0519 13:12:25.114945  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:13:03.931025  4008 solver.cpp:415]     Test net output #0: accuracy = 0.566459
I0519 13:13:03.931295  4008 solver.cpp:415]     Test net output #1: loss = 1.86026 (* 1 = 1.86026 loss)
I0519 13:13:04.018335  4008 solver.cpp:231] Iteration 354000, loss = 1.2667
I0519 13:13:04.018405  4008 solver.cpp:247]     Train net output #0: loss = 1.2667 (* 1 = 1.2667 loss)
I0519 13:13:04.018422  4008 sgd_solver.cpp:106] Iteration 354000, lr = 0.0001
I0519 13:13:04.178611  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4599	3.125	82.3919	0	91.1205	5.98958	89.159	0	85.2634	0	85.604	0	78.3465	0	30.3888	2.7	
I0519 13:13:04.180797  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:13:04.183414  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:13:04.183455  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:13:04.194371  4008 solver.cpp:260]     Total regularization terms: 0.941817 loss+regular. : 2.20852
I0519 13:14:19.056351  4008 solver.cpp:231] Iteration 354200, loss = 1.27398
I0519 13:14:19.056584  4008 solver.cpp:247]     Train net output #0: loss = 1.27398 (* 1 = 1.27398 loss)
I0519 13:14:19.056603  4008 sgd_solver.cpp:106] Iteration 354200, lr = 0.0001
I0519 13:14:19.218726  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4599	3.125	82.3932	0	91.121	5.98958	89.1594	0	85.2639	0	85.6041	0	78.3466	0	30.3888	2.7	
I0519 13:14:19.294598  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:14:19.297091  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:14:19.297121  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:14:19.317883  4008 solver.cpp:260]     Total regularization terms: 0.941776 loss+regular. : 2.21575
I0519 13:15:31.979753  4008 solver.cpp:231] Iteration 354400, loss = 1.19317
I0519 13:15:31.982784  4008 solver.cpp:247]     Train net output #0: loss = 1.19317 (* 1 = 1.19317 loss)
I0519 13:15:31.982813  4008 sgd_solver.cpp:106] Iteration 354400, lr = 0.0001
I0519 13:15:32.142078  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4628	3.125	82.3958	0	91.1213	5.98958	89.16	0	85.2639	0	85.6042	0	78.3467	0	30.3889	2.7	
I0519 13:15:32.217984  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:15:32.220216  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:15:32.220242  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:15:32.240378  4008 solver.cpp:260]     Total regularization terms: 0.941749 loss+regular. : 2.13492
I0519 13:16:11.155411  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:16:46.689409  4008 solver.cpp:231] Iteration 354600, loss = 1.19979
I0519 13:16:46.689851  4008 solver.cpp:247]     Train net output #0: loss = 1.19979 (* 1 = 1.19979 loss)
I0519 13:16:46.689872  4008 sgd_solver.cpp:106] Iteration 354600, lr = 0.0001
I0519 13:16:46.840317  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4657	3.125	82.3978	0	91.1218	5.98958	89.1605	0	85.2641	0	85.6042	0	78.3468	0	30.3889	2.7	
I0519 13:16:46.916169  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:16:46.918531  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:16:46.918561  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:16:46.932076  4008 solver.cpp:260]     Total regularization terms: 0.941722 loss+regular. : 2.14151
I0519 13:18:06.286088  4008 solver.cpp:231] Iteration 354800, loss = 1.12576
I0519 13:18:06.286428  4008 solver.cpp:247]     Train net output #0: loss = 1.12576 (* 1 = 1.12576 loss)
I0519 13:18:06.286456  4008 sgd_solver.cpp:106] Iteration 354800, lr = 0.0001
I0519 13:18:06.446969  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4714	3.125	82.3994	0	91.122	5.98958	89.1611	0	85.2643	0	85.6043	0	78.3468	0	30.389	2.7	
I0519 13:18:06.521865  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:18:06.524329  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:18:06.524363  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:18:06.534322  4008 solver.cpp:260]     Total regularization terms: 0.941684 loss+regular. : 2.06745
I0519 13:19:21.949306  4008 solver.cpp:348] Iteration 355000, Testing net (#0)
I0519 13:20:10.232702  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:20:49.724483  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56664
I0519 13:20:49.725172  4008 solver.cpp:415]     Test net output #1: loss = 1.85791 (* 1 = 1.85791 loss)
I0519 13:20:49.813448  4008 solver.cpp:231] Iteration 355000, loss = 1.20203
I0519 13:20:49.813522  4008 solver.cpp:247]     Train net output #0: loss = 1.20203 (* 1 = 1.20203 loss)
I0519 13:20:49.813542  4008 sgd_solver.cpp:106] Iteration 355000, lr = 0.0001
I0519 13:20:49.978992  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4714	3.125	82.4004	0	91.1221	5.98958	89.1615	0	85.2648	0	85.6044	0	78.347	0	30.389	2.7	
I0519 13:20:50.053977  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:20:50.056371  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:20:50.056406  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:20:50.066175  4008 solver.cpp:260]     Total regularization terms: 0.941647 loss+regular. : 2.14368
I0519 13:22:15.891428  4008 solver.cpp:231] Iteration 355200, loss = 1.38666
I0519 13:22:15.891760  4008 solver.cpp:247]     Train net output #0: loss = 1.38666 (* 1 = 1.38666 loss)
I0519 13:22:15.891780  4008 sgd_solver.cpp:106] Iteration 355200, lr = 0.0001
I0519 13:22:16.052166  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4714	3.125	82.4023	0	91.1226	5.98958	89.1618	0	85.2661	0	85.6045	0	78.347	0	30.3891	2.7	
I0519 13:22:16.129288  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:22:16.131885  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:22:16.131929  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:22:16.147233  4008 solver.cpp:260]     Total regularization terms: 0.941608 loss+regular. : 2.32827
I0519 13:23:39.332262  4008 solver.cpp:231] Iteration 355400, loss = 1.29986
I0519 13:23:39.332634  4008 solver.cpp:247]     Train net output #0: loss = 1.29986 (* 1 = 1.29986 loss)
I0519 13:23:39.332655  4008 sgd_solver.cpp:106] Iteration 355400, lr = 0.0001
I0519 13:23:39.493142  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4714	3.125	82.4036	0	91.123	5.98958	89.1629	0	85.2663	0	85.6046	0	78.3471	0	30.3892	2.7	
I0519 13:23:39.568658  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:23:39.570705  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:23:39.570734  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:23:39.585577  4008 solver.cpp:260]     Total regularization terms: 0.941585 loss+regular. : 2.24145
I0519 13:24:21.679716  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:25:04.550798  4008 solver.cpp:231] Iteration 355600, loss = 1.21996
I0519 13:25:04.551029  4008 solver.cpp:247]     Train net output #0: loss = 1.21996 (* 1 = 1.21996 loss)
I0519 13:25:04.551050  4008 sgd_solver.cpp:106] Iteration 355600, lr = 0.0001
I0519 13:25:04.710119  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4714	3.125	82.4059	0	91.1232	5.98958	89.1632	0	85.2668	0	85.6046	0	78.3472	0	30.3893	2.7	
I0519 13:25:04.785331  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:25:04.787783  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:25:04.787830  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:25:04.797703  4008 solver.cpp:260]     Total regularization terms: 0.941542 loss+regular. : 2.16151
I0519 13:26:50.505342  4008 solver.cpp:231] Iteration 355800, loss = 1.23307
I0519 13:26:50.509703  4008 solver.cpp:247]     Train net output #0: loss = 1.23307 (* 1 = 1.23307 loss)
I0519 13:26:50.509745  4008 sgd_solver.cpp:106] Iteration 355800, lr = 0.0001
I0519 13:26:50.664305  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4714	3.125	82.4079	0	91.1237	5.98958	89.1633	0	85.2672	0	85.6047	0	78.3473	0	30.3894	2.7	
I0519 13:26:50.740727  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:26:50.744606  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:26:50.744669  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:26:50.754876  4008 solver.cpp:260]     Total regularization terms: 0.941517 loss+regular. : 2.17458
I0519 13:28:18.302386  4008 solver.cpp:348] Iteration 356000, Testing net (#0)
I0519 13:29:01.158603  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:29:41.124861  4008 solver.cpp:415]     Test net output #0: accuracy = 0.566839
I0519 13:29:41.125102  4008 solver.cpp:415]     Test net output #1: loss = 1.86049 (* 1 = 1.86049 loss)
I0519 13:29:41.213021  4008 solver.cpp:231] Iteration 356000, loss = 1.32743
I0519 13:29:41.213134  4008 solver.cpp:247]     Train net output #0: loss = 1.32743 (* 1 = 1.32743 loss)
I0519 13:29:41.213155  4008 sgd_solver.cpp:106] Iteration 356000, lr = 0.0001
I0519 13:29:41.380285  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4714	3.125	82.4098	0	91.1241	5.98958	89.1641	0	85.2677	0	85.6048	0	78.3474	0	30.3895	2.7	
I0519 13:29:41.455905  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:29:41.458236  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:29:41.458288  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:29:41.468807  4008 solver.cpp:260]     Total regularization terms: 0.941476 loss+regular. : 2.26891
I0519 13:31:07.226867  4008 solver.cpp:231] Iteration 356200, loss = 1.30843
I0519 13:31:07.227241  4008 solver.cpp:247]     Train net output #0: loss = 1.30843 (* 1 = 1.30843 loss)
I0519 13:31:07.227264  4008 sgd_solver.cpp:106] Iteration 356200, lr = 0.0001
I0519 13:31:07.389081  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4714	3.125	82.4111	0	91.1245	5.98958	89.1644	0	85.2679	0	85.6049	0	78.3475	0	30.3897	2.7	
I0519 13:31:07.464043  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:31:07.466505  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:31:07.466559  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:31:07.476475  4008 solver.cpp:260]     Total regularization terms: 0.941444 loss+regular. : 2.24987
I0519 13:32:31.368842  4008 solver.cpp:231] Iteration 356400, loss = 1.40663
I0519 13:32:31.369110  4008 solver.cpp:247]     Train net output #0: loss = 1.40663 (* 1 = 1.40663 loss)
I0519 13:32:31.369130  4008 sgd_solver.cpp:106] Iteration 356400, lr = 0.0001
I0519 13:32:31.529479  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4714	3.125	82.4124	0	91.125	5.98958	89.1651	0	85.2682	0	85.605	0	78.3476	0	30.3898	2.7	
I0519 13:32:31.604967  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:32:31.607986  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:32:31.608033  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:32:31.617920  4008 solver.cpp:260]     Total regularization terms: 0.941401 loss+regular. : 2.34803
I0519 13:33:20.643210  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:33:56.241410  4008 solver.cpp:231] Iteration 356600, loss = 1.47699
I0519 13:33:56.245674  4008 solver.cpp:247]     Train net output #0: loss = 1.47699 (* 1 = 1.47699 loss)
I0519 13:33:56.245786  4008 sgd_solver.cpp:106] Iteration 356600, lr = 0.0001
I0519 13:33:56.402868  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4714	3.125	82.4144	0	91.1258	5.98958	89.1654	0	85.2684	0	85.6051	0	78.3477	0	30.3898	2.7	
I0519 13:33:56.478262  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:33:56.480989  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:33:56.481034  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:33:56.490945  4008 solver.cpp:260]     Total regularization terms: 0.941367 loss+regular. : 2.41836
I0519 13:35:21.397174  4008 solver.cpp:231] Iteration 356800, loss = 1.30778
I0519 13:35:21.398239  4008 solver.cpp:247]     Train net output #0: loss = 1.30778 (* 1 = 1.30778 loss)
I0519 13:35:21.398267  4008 sgd_solver.cpp:106] Iteration 356800, lr = 0.0001
I0519 13:35:21.558893  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4772	3.125	82.4144	0	91.1264	5.98958	89.1654	0	85.2691	0	85.6052	0	78.3478	0	30.39	2.7	
I0519 13:35:21.634135  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:35:21.637315  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:35:21.637367  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:35:21.657788  4008 solver.cpp:260]     Total regularization terms: 0.941338 loss+regular. : 2.24912
I0519 13:36:55.094348  4008 solver.cpp:348] Iteration 357000, Testing net (#0)
I0519 13:37:36.852641  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:38:17.712327  4008 solver.cpp:415]     Test net output #0: accuracy = 0.566679
I0519 13:38:17.712568  4008 solver.cpp:415]     Test net output #1: loss = 1.85876 (* 1 = 1.85876 loss)
I0519 13:38:17.805965  4008 solver.cpp:231] Iteration 357000, loss = 1.58856
I0519 13:38:17.806043  4008 solver.cpp:247]     Train net output #0: loss = 1.58856 (* 1 = 1.58856 loss)
I0519 13:38:17.806061  4008 sgd_solver.cpp:106] Iteration 357000, lr = 0.0001
I0519 13:38:17.972084  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4772	3.125	82.4163	0	91.1267	5.98958	89.1663	0	85.2695	0	85.6052	0	78.3478	0	30.39	2.7	
I0519 13:38:18.048423  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:38:18.051712  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:38:18.051774  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:38:18.061897  4008 solver.cpp:260]     Total regularization terms: 0.941299 loss+regular. : 2.52986
I0519 13:39:50.476851  4008 solver.cpp:231] Iteration 357200, loss = 1.29686
I0519 13:39:50.477143  4008 solver.cpp:247]     Train net output #0: loss = 1.29686 (* 1 = 1.29686 loss)
I0519 13:39:50.477171  4008 sgd_solver.cpp:106] Iteration 357200, lr = 0.0001
I0519 13:39:50.636857  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4772	3.125	82.4189	0	91.1271	5.98958	89.1666	0	85.2697	0	85.6053	0	78.3479	0	30.3902	2.7	
I0519 13:39:50.712175  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:39:50.714977  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:39:50.715035  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:39:50.730252  4008 solver.cpp:260]     Total regularization terms: 0.941278 loss+regular. : 2.23814
I0519 13:41:14.234824  4008 solver.cpp:231] Iteration 357400, loss = 1.08806
I0519 13:41:14.235188  4008 solver.cpp:247]     Train net output #0: loss = 1.08806 (* 1 = 1.08806 loss)
I0519 13:41:14.235221  4008 sgd_solver.cpp:106] Iteration 357400, lr = 0.0001
I0519 13:41:14.396481  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4772	3.125	82.4209	0	91.1272	5.98958	89.1671	0	85.27	0	85.6054	0	78.348	0	30.3903	2.7	
I0519 13:41:14.473326  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:41:14.476541  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:41:14.476603  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:41:14.492249  4008 solver.cpp:260]     Total regularization terms: 0.941252 loss+regular. : 2.02932
I0519 13:42:09.836225  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:42:40.531913  4008 solver.cpp:231] Iteration 357600, loss = 1.1988
I0519 13:42:40.532321  4008 solver.cpp:247]     Train net output #0: loss = 1.1988 (* 1 = 1.1988 loss)
I0519 13:42:40.532367  4008 sgd_solver.cpp:106] Iteration 357600, lr = 0.0001
I0519 13:42:40.693039  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4772	3.125	82.4222	0	91.1276	5.98958	89.1674	0	85.2706	0	85.6056	0	78.3481	0	30.3903	2.7	
I0519 13:42:40.768679  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:42:40.770813  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:42:40.770869  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:42:40.801031  4008 solver.cpp:260]     Total regularization terms: 0.941209 loss+regular. : 2.14001
I0519 13:44:07.044394  4008 solver.cpp:231] Iteration 357800, loss = 1.31512
I0519 13:44:07.045959  4008 solver.cpp:247]     Train net output #0: loss = 1.31512 (* 1 = 1.31512 loss)
I0519 13:44:07.046000  4008 sgd_solver.cpp:106] Iteration 357800, lr = 0.0001
I0519 13:44:07.205714  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.48	3.125	82.4238	0	91.1283	5.98958	89.168	0	85.2709	0	85.6056	0	78.3482	0	30.3905	2.7	
I0519 13:44:07.281405  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:44:07.284435  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:44:07.284492  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:44:07.294499  4008 solver.cpp:260]     Total regularization terms: 0.941183 loss+regular. : 2.25631
I0519 13:45:35.081235  4008 solver.cpp:348] Iteration 358000, Testing net (#0)
I0519 13:46:16.932490  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:47:01.543390  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56712
I0519 13:47:01.543736  4008 solver.cpp:415]     Test net output #1: loss = 1.85823 (* 1 = 1.85823 loss)
I0519 13:47:01.631623  4008 solver.cpp:231] Iteration 358000, loss = 1.30407
I0519 13:47:01.631749  4008 solver.cpp:247]     Train net output #0: loss = 1.30407 (* 1 = 1.30407 loss)
I0519 13:47:01.631768  4008 sgd_solver.cpp:106] Iteration 358000, lr = 0.0001
I0519 13:47:01.790688  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4829	3.125	82.4255	0	91.1284	5.98958	89.1686	0	85.2715	0	85.6057	0	78.3483	0	30.3905	2.7	
I0519 13:47:01.866041  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:47:01.868315  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:47:01.868366  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:47:01.878316  4008 solver.cpp:260]     Total regularization terms: 0.941148 loss+regular. : 2.24522
I0519 13:48:25.815203  4008 solver.cpp:231] Iteration 358200, loss = 1.31328
I0519 13:48:25.815507  4008 solver.cpp:247]     Train net output #0: loss = 1.31328 (* 1 = 1.31328 loss)
I0519 13:48:25.815529  4008 sgd_solver.cpp:106] Iteration 358200, lr = 0.0001
I0519 13:48:25.975962  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4858	3.125	82.4258	0	91.1291	5.98958	89.1689	0	85.2724	0	85.6058	0	78.3484	0	30.3906	2.7	
I0519 13:48:26.053100  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:48:26.056468  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:48:26.056526  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:48:26.066687  4008 solver.cpp:260]     Total regularization terms: 0.941115 loss+regular. : 2.25439
I0519 13:49:51.858541  4008 solver.cpp:231] Iteration 358400, loss = 1.28293
I0519 13:49:51.858880  4008 solver.cpp:247]     Train net output #0: loss = 1.28293 (* 1 = 1.28293 loss)
I0519 13:49:51.858908  4008 sgd_solver.cpp:106] Iteration 358400, lr = 0.0001
I0519 13:49:52.019227  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4858	3.125	82.4264	0	91.1297	5.98958	89.1696	0	85.2724	0	85.6059	0	78.3485	0	30.3907	2.7	
I0519 13:49:52.095791  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:49:52.103143  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:49:52.103210  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:49:52.115279  4008 solver.cpp:260]     Total regularization terms: 0.941079 loss+regular. : 2.22401
I0519 13:50:50.297423  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:51:21.993080  4008 solver.cpp:231] Iteration 358600, loss = 1.16642
I0519 13:51:21.993446  4008 solver.cpp:247]     Train net output #0: loss = 1.16642 (* 1 = 1.16642 loss)
I0519 13:51:21.993475  4008 sgd_solver.cpp:106] Iteration 358600, lr = 0.0001
I0519 13:51:22.154148  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4858	3.125	82.4277	0	91.1299	5.98958	89.1696	0	85.2731	0	85.606	0	78.3485	0	30.3907	2.7	
I0519 13:51:22.230314  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:51:22.234055  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:51:22.234133  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:51:22.244376  4008 solver.cpp:260]     Total regularization terms: 0.941058 loss+regular. : 2.10748
I0519 13:52:37.015195  4008 solver.cpp:231] Iteration 358800, loss = 1.17536
I0519 13:52:37.015537  4008 solver.cpp:247]     Train net output #0: loss = 1.17536 (* 1 = 1.17536 loss)
I0519 13:52:37.015558  4008 sgd_solver.cpp:106] Iteration 358800, lr = 0.0001
I0519 13:52:37.175303  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4886	3.125	82.4294	0	91.1308	5.98958	89.1696	0	85.2733	0	85.606	0	78.3486	0	30.3908	2.7	
I0519 13:52:37.253168  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:52:37.255311  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:52:37.255352  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:52:37.270217  4008 solver.cpp:260]     Total regularization terms: 0.941016 loss+regular. : 2.11637
I0519 13:53:54.428730  4008 solver.cpp:348] Iteration 359000, Testing net (#0)
I0519 13:54:37.496491  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:55:13.360255  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56612
I0519 13:55:13.361626  4008 solver.cpp:415]     Test net output #1: loss = 1.86049 (* 1 = 1.86049 loss)
I0519 13:55:13.449487  4008 solver.cpp:231] Iteration 359000, loss = 1.10348
I0519 13:55:13.449582  4008 solver.cpp:247]     Train net output #0: loss = 1.10348 (* 1 = 1.10348 loss)
I0519 13:55:13.449604  4008 sgd_solver.cpp:106] Iteration 359000, lr = 0.0001
I0519 13:55:13.617736  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4886	3.125	82.431	0	91.1313	5.98958	89.17	0	85.2738	0	85.6061	0	78.3487	0	30.3909	2.7	
I0519 13:55:13.692697  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:55:13.695288  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:55:13.695338  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:55:13.705456  4008 solver.cpp:260]     Total regularization terms: 0.94099 loss+regular. : 2.04447
I0519 13:56:30.400326  4008 solver.cpp:231] Iteration 359200, loss = 1.39087
I0519 13:56:30.401648  4008 solver.cpp:247]     Train net output #0: loss = 1.39087 (* 1 = 1.39087 loss)
I0519 13:56:30.401677  4008 sgd_solver.cpp:106] Iteration 359200, lr = 0.0001
I0519 13:56:30.560397  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4886	3.125	82.4336	0	91.1315	5.98958	89.1709	0	85.2745	0	85.6062	0	78.3488	0	30.3909	2.7	
I0519 13:56:30.635025  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:56:30.636988  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:56:30.637013  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:56:30.646674  4008 solver.cpp:260]     Total regularization terms: 0.940953 loss+regular. : 2.33182
I0519 13:57:51.956217  4008 solver.cpp:231] Iteration 359400, loss = 1.24122
I0519 13:57:51.957640  4008 solver.cpp:247]     Train net output #0: loss = 1.24122 (* 1 = 1.24122 loss)
I0519 13:57:51.957742  4008 sgd_solver.cpp:106] Iteration 359400, lr = 0.0001
I0519 13:57:52.117102  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4886	3.125	82.4355	0	91.1323	5.98958	89.1713	0	85.2752	0	85.6063	0	78.3489	0	30.3909	2.7	
I0519 13:57:52.193117  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:57:52.195827  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:57:52.195863  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:57:52.205703  4008 solver.cpp:260]     Total regularization terms: 0.940918 loss+regular. : 2.18214
I0519 13:58:46.877113  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 13:59:10.375689  4008 solver.cpp:231] Iteration 359600, loss = 1.23827
I0519 13:59:10.375800  4008 solver.cpp:247]     Train net output #0: loss = 1.23827 (* 1 = 1.23827 loss)
I0519 13:59:10.375820  4008 sgd_solver.cpp:106] Iteration 359600, lr = 0.0001
I0519 13:59:10.537001  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4915	3.125	82.4369	0	91.1327	5.98958	89.1718	0	85.2761	0	85.6064	0	78.349	0	30.3909	2.7	
I0519 13:59:10.612841  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 13:59:10.615216  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 13:59:10.615257  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 13:59:10.630179  4008 solver.cpp:260]     Total regularization terms: 0.940893 loss+regular. : 2.17916
I0519 14:00:31.801625  4008 solver.cpp:231] Iteration 359800, loss = 1.35026
I0519 14:00:31.801903  4008 solver.cpp:247]     Train net output #0: loss = 1.35026 (* 1 = 1.35026 loss)
I0519 14:00:31.801935  4008 sgd_solver.cpp:106] Iteration 359800, lr = 0.0001
I0519 14:00:31.961581  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4915	3.125	82.4381	0	91.1332	5.98958	89.1722	0	85.2763	0	85.6065	0	78.3491	0	30.391	2.7	
I0519 14:00:32.036483  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:00:32.038808  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:00:32.038862  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:00:32.050056  4008 solver.cpp:260]     Total regularization terms: 0.940855 loss+regular. : 2.29112
I0519 14:01:52.076728  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_360000.caffemodel
I0519 14:03:23.552618  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_360000.solverstate
I0519 14:03:24.110569  4008 solver.cpp:348] Iteration 360000, Testing net (#0)
I0519 14:04:09.696180  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:04:45.157325  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56642
I0519 14:04:45.157574  4008 solver.cpp:415]     Test net output #1: loss = 1.85723 (* 1 = 1.85723 loss)
I0519 14:04:45.245296  4008 solver.cpp:231] Iteration 360000, loss = 1.12003
I0519 14:04:45.245368  4008 solver.cpp:247]     Train net output #0: loss = 1.12003 (* 1 = 1.12003 loss)
I0519 14:04:45.245381  4008 sgd_solver.cpp:46] MultiStep Status: Iteration 360000, step = 2
I0519 14:04:45.245388  4008 sgd_solver.cpp:106] Iteration 360000, lr = 1e-05
I0519 14:04:45.410758  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4414	0	91.1333	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3911	2.7	
I0519 14:04:45.413172  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:04:45.416352  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:04:45.416398  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:04:45.426347  4008 solver.cpp:260]     Total regularization terms: 0.94082 loss+regular. : 2.06085
I0519 14:06:04.374194  4008 solver.cpp:231] Iteration 360200, loss = 1.16316
I0519 14:06:04.374663  4008 solver.cpp:247]     Train net output #0: loss = 1.16316 (* 1 = 1.16316 loss)
I0519 14:06:04.374687  4008 sgd_solver.cpp:106] Iteration 360200, lr = 1e-05
I0519 14:06:04.534078  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1333	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3911	2.7	
I0519 14:06:04.610574  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:06:04.613836  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:06:04.614006  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:06:04.629606  4008 solver.cpp:260]     Total regularization terms: 0.940816 loss+regular. : 2.10398
I0519 14:07:19.607650  4008 solver.cpp:231] Iteration 360400, loss = 1.13935
I0519 14:07:19.608012  4008 solver.cpp:247]     Train net output #0: loss = 1.13935 (* 1 = 1.13935 loss)
I0519 14:07:19.608041  4008 sgd_solver.cpp:106] Iteration 360400, lr = 1e-05
I0519 14:07:19.769561  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3911	2.7	
I0519 14:07:19.845587  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:07:19.848064  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:07:19.848109  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:07:19.863476  4008 solver.cpp:260]     Total regularization terms: 0.940814 loss+regular. : 2.08016
I0519 14:08:16.440707  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:08:38.090183  4008 solver.cpp:231] Iteration 360600, loss = 1.1754
I0519 14:08:38.090265  4008 solver.cpp:247]     Train net output #0: loss = 1.1754 (* 1 = 1.1754 loss)
I0519 14:08:38.090282  4008 sgd_solver.cpp:106] Iteration 360600, lr = 1e-05
I0519 14:08:38.250082  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:08:38.324975  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:08:38.327404  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:08:38.327436  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:08:38.337210  4008 solver.cpp:260]     Total regularization terms: 0.940809 loss+regular. : 2.11621
I0519 14:10:02.132408  4008 solver.cpp:231] Iteration 360800, loss = 1.36175
I0519 14:10:02.133143  4008 solver.cpp:247]     Train net output #0: loss = 1.36175 (* 1 = 1.36175 loss)
I0519 14:10:02.133165  4008 sgd_solver.cpp:106] Iteration 360800, lr = 1e-05
I0519 14:10:02.293364  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:10:02.368291  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:10:02.370831  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:10:02.370883  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:10:02.380861  4008 solver.cpp:260]     Total regularization terms: 0.940806 loss+regular. : 2.30256
I0519 14:11:41.836027  4008 solver.cpp:348] Iteration 361000, Testing net (#0)
I0519 14:12:24.845360  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:12:58.804217  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567619
I0519 14:12:58.804546  4008 solver.cpp:415]     Test net output #1: loss = 1.85488 (* 1 = 1.85488 loss)
I0519 14:12:58.896087  4008 solver.cpp:231] Iteration 361000, loss = 1.21217
I0519 14:12:58.896181  4008 solver.cpp:247]     Train net output #0: loss = 1.21217 (* 1 = 1.21217 loss)
I0519 14:12:58.896205  4008 sgd_solver.cpp:106] Iteration 361000, lr = 1e-05
I0519 14:12:59.063256  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:12:59.139250  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:12:59.141265  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:12:59.141310  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:12:59.152582  4008 solver.cpp:260]     Total regularization terms: 0.940802 loss+regular. : 2.15297
I0519 14:14:15.253803  4008 solver.cpp:231] Iteration 361200, loss = 1.25811
I0519 14:14:15.254197  4008 solver.cpp:247]     Train net output #0: loss = 1.25811 (* 1 = 1.25811 loss)
I0519 14:14:15.254215  4008 sgd_solver.cpp:106] Iteration 361200, lr = 1e-05
I0519 14:14:15.416745  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:14:15.491235  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:14:15.492820  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:14:15.492849  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:14:15.502813  4008 solver.cpp:260]     Total regularization terms: 0.940799 loss+regular. : 2.19891
I0519 14:15:35.257633  4008 solver.cpp:231] Iteration 361400, loss = 1.08806
I0519 14:15:35.258435  4008 solver.cpp:247]     Train net output #0: loss = 1.08806 (* 1 = 1.08806 loss)
I0519 14:15:35.258455  4008 sgd_solver.cpp:106] Iteration 361400, lr = 1e-05
I0519 14:15:35.418573  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:15:35.493751  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:15:35.496592  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:15:35.496628  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:15:35.506392  4008 solver.cpp:260]     Total regularization terms: 0.940794 loss+regular. : 2.02885
I0519 14:16:38.016609  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:16:57.432256  4008 solver.cpp:231] Iteration 361600, loss = 1.31028
I0519 14:16:57.432371  4008 solver.cpp:247]     Train net output #0: loss = 1.31028 (* 1 = 1.31028 loss)
I0519 14:16:57.432394  4008 sgd_solver.cpp:106] Iteration 361600, lr = 1e-05
I0519 14:16:57.592627  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:16:57.668884  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:16:57.671752  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:16:57.671797  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:16:57.681931  4008 solver.cpp:260]     Total regularization terms: 0.940791 loss+regular. : 2.25107
I0519 14:18:21.193220  4008 solver.cpp:231] Iteration 361800, loss = 1.25072
I0519 14:18:21.193496  4008 solver.cpp:247]     Train net output #0: loss = 1.25072 (* 1 = 1.25072 loss)
I0519 14:18:21.193517  4008 sgd_solver.cpp:106] Iteration 361800, lr = 1e-05
I0519 14:18:21.352674  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:18:21.428724  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:18:21.431512  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:18:21.431560  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:18:21.446683  4008 solver.cpp:260]     Total regularization terms: 0.940788 loss+regular. : 2.19151
I0519 14:19:39.998332  4008 solver.cpp:348] Iteration 362000, Testing net (#0)
I0519 14:20:27.143540  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:21:00.842357  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567879
I0519 14:21:00.842617  4008 solver.cpp:415]     Test net output #1: loss = 1.85431 (* 1 = 1.85431 loss)
I0519 14:21:00.932937  4008 solver.cpp:231] Iteration 362000, loss = 1.55087
I0519 14:21:00.933053  4008 solver.cpp:247]     Train net output #0: loss = 1.55087 (* 1 = 1.55087 loss)
I0519 14:21:00.933070  4008 sgd_solver.cpp:106] Iteration 362000, lr = 1e-05
I0519 14:21:01.098327  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:21:01.173425  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:21:01.175478  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:21:01.175524  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:21:01.185372  4008 solver.cpp:260]     Total regularization terms: 0.940783 loss+regular. : 2.49166
I0519 14:22:21.970952  4008 solver.cpp:231] Iteration 362200, loss = 1.26819
I0519 14:22:21.971278  4008 solver.cpp:247]     Train net output #0: loss = 1.26819 (* 1 = 1.26819 loss)
I0519 14:22:21.971300  4008 sgd_solver.cpp:106] Iteration 362200, lr = 1e-05
I0519 14:22:22.133131  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:22:22.208309  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:22:22.210863  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:22:22.210911  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:22:22.226176  4008 solver.cpp:260]     Total regularization terms: 0.94078 loss+regular. : 2.20897
I0519 14:23:40.482192  4008 solver.cpp:231] Iteration 362400, loss = 1.1048
I0519 14:23:40.482511  4008 solver.cpp:247]     Train net output #0: loss = 1.1048 (* 1 = 1.1048 loss)
I0519 14:23:40.482528  4008 sgd_solver.cpp:106] Iteration 362400, lr = 1e-05
I0519 14:23:40.643044  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:23:40.717880  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:23:40.719957  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:23:40.720010  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:23:40.734495  4008 solver.cpp:260]     Total regularization terms: 0.940777 loss+regular. : 2.04558
I0519 14:24:51.670675  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:25:08.538244  4008 solver.cpp:231] Iteration 362600, loss = 1.12279
I0519 14:25:08.538405  4008 solver.cpp:247]     Train net output #0: loss = 1.12279 (* 1 = 1.12279 loss)
I0519 14:25:08.538434  4008 sgd_solver.cpp:106] Iteration 362600, lr = 1e-05
I0519 14:25:08.700371  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:25:08.775380  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:25:08.778342  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:25:08.778406  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:25:08.788208  4008 solver.cpp:260]     Total regularization terms: 0.940773 loss+regular. : 2.06356
I0519 14:26:30.714975  4008 solver.cpp:231] Iteration 362800, loss = 1.33328
I0519 14:26:30.715399  4008 solver.cpp:247]     Train net output #0: loss = 1.33328 (* 1 = 1.33328 loss)
I0519 14:26:30.715420  4008 sgd_solver.cpp:106] Iteration 362800, lr = 1e-05
I0519 14:26:30.876152  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:26:30.952571  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:26:30.955950  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:26:30.956019  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:26:30.966126  4008 solver.cpp:260]     Total regularization terms: 0.94077 loss+regular. : 2.27405
I0519 14:28:02.692148  4008 solver.cpp:348] Iteration 363000, Testing net (#0)
I0519 14:28:53.220597  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:29:29.598529  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567799
I0519 14:29:29.599169  4008 solver.cpp:415]     Test net output #1: loss = 1.85377 (* 1 = 1.85377 loss)
I0519 14:29:29.689241  4008 solver.cpp:231] Iteration 363000, loss = 1.2125
I0519 14:29:29.689380  4008 solver.cpp:247]     Train net output #0: loss = 1.2125 (* 1 = 1.2125 loss)
I0519 14:29:29.689406  4008 sgd_solver.cpp:106] Iteration 363000, lr = 1e-05
I0519 14:29:29.848788  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:29:29.925796  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:29:29.928201  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:29:29.928252  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:29:29.938591  4008 solver.cpp:260]     Total regularization terms: 0.940765 loss+regular. : 2.15327
I0519 14:30:58.798804  4008 solver.cpp:231] Iteration 363200, loss = 1.13663
I0519 14:30:58.801656  4008 solver.cpp:247]     Train net output #0: loss = 1.13663 (* 1 = 1.13663 loss)
I0519 14:30:58.801683  4008 sgd_solver.cpp:106] Iteration 363200, lr = 1e-05
I0519 14:30:58.959633  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:30:59.034782  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:30:59.037143  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:30:59.037199  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:30:59.047293  4008 solver.cpp:260]     Total regularization terms: 0.940762 loss+regular. : 2.07739
I0519 14:32:20.948071  4008 solver.cpp:231] Iteration 363400, loss = 1.27688
I0519 14:32:20.948639  4008 solver.cpp:247]     Train net output #0: loss = 1.27688 (* 1 = 1.27688 loss)
I0519 14:32:20.948698  4008 sgd_solver.cpp:106] Iteration 363400, lr = 1e-05
I0519 14:32:21.107808  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:32:21.183686  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:32:21.187356  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:32:21.187449  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:32:21.201835  4008 solver.cpp:260]     Total regularization terms: 0.940758 loss+regular. : 2.21764
I0519 14:33:38.840530  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:33:52.984746  4008 solver.cpp:231] Iteration 363600, loss = 1.09844
I0519 14:33:52.984859  4008 solver.cpp:247]     Train net output #0: loss = 1.09844 (* 1 = 1.09844 loss)
I0519 14:33:52.984879  4008 sgd_solver.cpp:106] Iteration 363600, lr = 1e-05
I0519 14:33:53.144716  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:33:53.220284  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:33:53.222777  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:33:53.222822  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:33:53.232758  4008 solver.cpp:260]     Total regularization terms: 0.940756 loss+regular. : 2.03919
I0519 14:35:19.938544  4008 solver.cpp:231] Iteration 363800, loss = 1.16059
I0519 14:35:19.938881  4008 solver.cpp:247]     Train net output #0: loss = 1.16059 (* 1 = 1.16059 loss)
I0519 14:35:19.938902  4008 sgd_solver.cpp:106] Iteration 363800, lr = 1e-05
I0519 14:35:20.098062  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:35:20.174098  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:35:20.176115  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:35:20.176167  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:35:20.189899  4008 solver.cpp:260]     Total regularization terms: 0.940752 loss+regular. : 2.10134
I0519 14:37:04.001297  4008 solver.cpp:348] Iteration 364000, Testing net (#0)
I0519 14:37:52.132227  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:38:30.215775  4008 solver.cpp:415]     Test net output #0: accuracy = 0.568079
I0519 14:38:30.216125  4008 solver.cpp:415]     Test net output #1: loss = 1.85479 (* 1 = 1.85479 loss)
I0519 14:38:30.310948  4008 solver.cpp:231] Iteration 364000, loss = 1.21083
I0519 14:38:30.311053  4008 solver.cpp:247]     Train net output #0: loss = 1.21083 (* 1 = 1.21083 loss)
I0519 14:38:30.311071  4008 sgd_solver.cpp:106] Iteration 364000, lr = 1e-05
I0519 14:38:30.470661  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:38:30.546224  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:38:30.549175  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:38:30.549244  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:38:30.561921  4008 solver.cpp:260]     Total regularization terms: 0.94075 loss+regular. : 2.15158
I0519 14:39:50.365819  4008 solver.cpp:231] Iteration 364200, loss = 1.26821
I0519 14:39:50.366170  4008 solver.cpp:247]     Train net output #0: loss = 1.26821 (* 1 = 1.26821 loss)
I0519 14:39:50.366189  4008 sgd_solver.cpp:106] Iteration 364200, lr = 1e-05
I0519 14:39:50.528090  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:39:50.603756  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:39:50.606906  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:39:50.606963  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:39:50.621978  4008 solver.cpp:260]     Total regularization terms: 0.940746 loss+regular. : 2.20895
I0519 14:41:17.142699  4008 solver.cpp:231] Iteration 364400, loss = 1.17733
I0519 14:41:17.145728  4008 solver.cpp:247]     Train net output #0: loss = 1.17733 (* 1 = 1.17733 loss)
I0519 14:41:17.145874  4008 sgd_solver.cpp:106] Iteration 364400, lr = 1e-05
I0519 14:41:17.303503  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:41:17.379801  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:41:17.382813  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:41:17.382861  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:41:17.392752  4008 solver.cpp:260]     Total regularization terms: 0.940742 loss+regular. : 2.11807
I0519 14:42:36.029920  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:42:46.766129  4008 solver.cpp:231] Iteration 364600, loss = 1.00588
I0519 14:42:46.766326  4008 solver.cpp:247]     Train net output #0: loss = 1.00588 (* 1 = 1.00588 loss)
I0519 14:42:46.766357  4008 sgd_solver.cpp:106] Iteration 364600, lr = 1e-05
I0519 14:42:46.926291  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:42:47.002048  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:42:47.004801  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:42:47.004868  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:42:47.015108  4008 solver.cpp:260]     Total regularization terms: 0.940739 loss+regular. : 1.94661
I0519 14:44:15.531049  4008 solver.cpp:231] Iteration 364800, loss = 1.23536
I0519 14:44:15.532279  4008 solver.cpp:247]     Train net output #0: loss = 1.23536 (* 1 = 1.23536 loss)
I0519 14:44:15.532316  4008 sgd_solver.cpp:106] Iteration 364800, lr = 1e-05
I0519 14:44:15.691269  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:44:15.767037  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:44:15.769728  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:44:15.769793  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:44:15.779832  4008 solver.cpp:260]     Total regularization terms: 0.940736 loss+regular. : 2.1761
I0519 14:45:44.046010  4008 solver.cpp:348] Iteration 365000, Testing net (#0)
I0519 14:46:42.395735  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:47:19.586782  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56808
I0519 14:47:19.589648  4008 solver.cpp:415]     Test net output #1: loss = 1.85462 (* 1 = 1.85462 loss)
I0519 14:47:19.694108  4008 solver.cpp:231] Iteration 365000, loss = 1.2249
I0519 14:47:19.694202  4008 solver.cpp:247]     Train net output #0: loss = 1.2249 (* 1 = 1.2249 loss)
I0519 14:47:19.694221  4008 sgd_solver.cpp:106] Iteration 365000, lr = 1e-05
I0519 14:47:19.859182  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:47:19.934722  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:47:19.936552  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:47:19.936599  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:47:19.946552  4008 solver.cpp:260]     Total regularization terms: 0.940733 loss+regular. : 2.16563
I0519 14:48:41.467902  4008 solver.cpp:231] Iteration 365200, loss = 1.13238
I0519 14:48:41.473692  4008 solver.cpp:247]     Train net output #0: loss = 1.13238 (* 1 = 1.13238 loss)
I0519 14:48:41.473728  4008 sgd_solver.cpp:106] Iteration 365200, lr = 1e-05
I0519 14:48:41.627892  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:48:41.702792  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:48:41.705029  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:48:41.705078  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:48:41.714962  4008 solver.cpp:260]     Total regularization terms: 0.94073 loss+regular. : 2.07311
I0519 14:50:02.117307  4008 solver.cpp:231] Iteration 365400, loss = 1.32369
I0519 14:50:02.117622  4008 solver.cpp:247]     Train net output #0: loss = 1.32369 (* 1 = 1.32369 loss)
I0519 14:50:02.117645  4008 sgd_solver.cpp:106] Iteration 365400, lr = 1e-05
I0519 14:50:02.277956  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:50:02.353631  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:50:02.355701  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:50:02.355762  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:50:02.369663  4008 solver.cpp:260]     Total regularization terms: 0.940726 loss+regular. : 2.26442
I0519 14:51:23.932088  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:51:30.985427  4008 solver.cpp:231] Iteration 365600, loss = 1.32569
I0519 14:51:30.985529  4008 solver.cpp:247]     Train net output #0: loss = 1.32569 (* 1 = 1.32569 loss)
I0519 14:51:30.985548  4008 sgd_solver.cpp:106] Iteration 365600, lr = 1e-05
I0519 14:51:31.145201  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1334	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:51:31.220158  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:51:31.222287  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:51:31.222349  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:51:31.242645  4008 solver.cpp:260]     Total regularization terms: 0.940722 loss+regular. : 2.26642
I0519 14:52:59.828011  4008 solver.cpp:231] Iteration 365800, loss = 1.27606
I0519 14:52:59.828459  4008 solver.cpp:247]     Train net output #0: loss = 1.27606 (* 1 = 1.27606 loss)
I0519 14:52:59.828480  4008 sgd_solver.cpp:106] Iteration 365800, lr = 1e-05
I0519 14:52:59.988394  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1335	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:53:00.063174  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:53:00.065500  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:53:00.065549  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:53:00.075336  4008 solver.cpp:260]     Total regularization terms: 0.940718 loss+regular. : 2.21678
I0519 14:54:32.958312  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_366000.caffemodel
I0519 14:56:56.788089  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_366000.solverstate
I0519 14:56:57.292999  4008 solver.cpp:348] Iteration 366000, Testing net (#0)
I0519 14:57:48.332324  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 14:58:33.283071  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56808
I0519 14:58:33.283422  4008 solver.cpp:415]     Test net output #1: loss = 1.85443 (* 1 = 1.85443 loss)
I0519 14:58:33.374282  4008 solver.cpp:231] Iteration 366000, loss = 1.48857
I0519 14:58:33.374409  4008 solver.cpp:247]     Train net output #0: loss = 1.48857 (* 1 = 1.48857 loss)
I0519 14:58:33.374459  4008 sgd_solver.cpp:106] Iteration 366000, lr = 1e-05
I0519 14:58:33.540184  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 14:58:33.542076  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 14:58:33.544245  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 14:58:33.544291  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 14:58:33.554173  4008 solver.cpp:260]     Total regularization terms: 0.940714 loss+regular. : 2.42928
I0519 14:59:59.770602  4008 solver.cpp:231] Iteration 366200, loss = 1.16625
I0519 14:59:59.770900  4008 solver.cpp:247]     Train net output #0: loss = 1.16625 (* 1 = 1.16625 loss)
I0519 14:59:59.770925  4008 sgd_solver.cpp:106] Iteration 366200, lr = 1e-05
I0519 14:59:59.931205  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:00:00.007297  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:00:00.010440  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:00:00.010540  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:00:00.025926  4008 solver.cpp:260]     Total regularization terms: 0.940711 loss+regular. : 2.10696
I0519 15:01:27.211287  4008 solver.cpp:231] Iteration 366400, loss = 1.13583
I0519 15:01:27.211686  4008 solver.cpp:247]     Train net output #0: loss = 1.13583 (* 1 = 1.13583 loss)
I0519 15:01:27.211709  4008 sgd_solver.cpp:106] Iteration 366400, lr = 1e-05
I0519 15:01:27.369709  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:01:27.445575  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:01:27.448434  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:01:27.448493  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:01:27.458483  4008 solver.cpp:260]     Total regularization terms: 0.940708 loss+regular. : 2.07653
I0519 15:02:49.275138  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:02:53.285277  4008 solver.cpp:231] Iteration 366600, loss = 1.31415
I0519 15:02:53.285365  4008 solver.cpp:247]     Train net output #0: loss = 1.31415 (* 1 = 1.31415 loss)
I0519 15:02:53.285384  4008 sgd_solver.cpp:106] Iteration 366600, lr = 1e-05
I0519 15:02:53.446447  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:02:53.522346  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:02:53.524910  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:02:53.524960  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:02:53.534859  4008 solver.cpp:260]     Total regularization terms: 0.940704 loss+regular. : 2.25485
I0519 15:04:25.952194  4008 solver.cpp:231] Iteration 366800, loss = 1.32746
I0519 15:04:25.952661  4008 solver.cpp:247]     Train net output #0: loss = 1.32746 (* 1 = 1.32746 loss)
I0519 15:04:25.952703  4008 sgd_solver.cpp:106] Iteration 366800, lr = 1e-05
I0519 15:04:26.111915  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:04:26.188359  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:04:26.192320  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:04:26.192397  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:04:26.202636  4008 solver.cpp:260]     Total regularization terms: 0.940702 loss+regular. : 2.26817
I0519 15:06:00.891983  4008 solver.cpp:348] Iteration 367000, Testing net (#0)
I0519 15:06:53.612133  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:07:26.576032  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567919
I0519 15:07:26.576367  4008 solver.cpp:415]     Test net output #1: loss = 1.85356 (* 1 = 1.85356 loss)
I0519 15:07:26.688886  4008 solver.cpp:231] Iteration 367000, loss = 1.18476
I0519 15:07:26.688984  4008 solver.cpp:247]     Train net output #0: loss = 1.18476 (* 1 = 1.18476 loss)
I0519 15:07:26.689005  4008 sgd_solver.cpp:106] Iteration 367000, lr = 1e-05
I0519 15:07:26.847367  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:07:26.924789  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:07:26.927435  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:07:26.927495  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:07:26.937625  4008 solver.cpp:260]     Total regularization terms: 0.940696 loss+regular. : 2.12546
I0519 15:08:50.213932  4008 solver.cpp:231] Iteration 367200, loss = 1.27862
I0519 15:08:50.214453  4008 solver.cpp:247]     Train net output #0: loss = 1.27862 (* 1 = 1.27862 loss)
I0519 15:08:50.214476  4008 sgd_solver.cpp:106] Iteration 367200, lr = 1e-05
I0519 15:08:50.374411  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:08:50.450091  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:08:50.452322  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:08:50.452373  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:08:50.462532  4008 solver.cpp:260]     Total regularization terms: 0.940692 loss+regular. : 2.21932
I0519 15:10:19.830905  4008 solver.cpp:231] Iteration 367400, loss = 1.24732
I0519 15:10:19.832115  4008 solver.cpp:247]     Train net output #0: loss = 1.24732 (* 1 = 1.24732 loss)
I0519 15:10:19.832144  4008 sgd_solver.cpp:106] Iteration 367400, lr = 1e-05
I0519 15:10:19.991292  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.1728	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:10:20.066361  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:10:20.068477  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:10:20.068528  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:10:20.078372  4008 solver.cpp:260]     Total regularization terms: 0.940689 loss+regular. : 2.18801
I0519 15:11:46.037902  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:11:47.250561  4008 solver.cpp:231] Iteration 367600, loss = 1.27605
I0519 15:11:47.250700  4008 solver.cpp:247]     Train net output #0: loss = 1.27605 (* 1 = 1.27605 loss)
I0519 15:11:47.250740  4008 sgd_solver.cpp:106] Iteration 367600, lr = 1e-05
I0519 15:11:47.410786  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.173	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:11:47.485690  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:11:47.487985  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:11:47.488034  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:11:47.497985  4008 solver.cpp:260]     Total regularization terms: 0.940685 loss+regular. : 2.21673
I0519 15:13:14.089010  4008 solver.cpp:231] Iteration 367800, loss = 1.47052
I0519 15:13:14.089411  4008 solver.cpp:247]     Train net output #0: loss = 1.47052 (* 1 = 1.47052 loss)
I0519 15:13:14.089438  4008 sgd_solver.cpp:106] Iteration 367800, lr = 1e-05
I0519 15:13:14.248498  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.173	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:13:14.325036  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:13:14.328505  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:13:14.328558  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:13:14.338774  4008 solver.cpp:260]     Total regularization terms: 0.940684 loss+regular. : 2.4112
I0519 15:14:59.451777  4008 solver.cpp:348] Iteration 368000, Testing net (#0)
I0519 15:15:47.431176  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:16:20.621384  4008 solver.cpp:415]     Test net output #0: accuracy = 0.568319
I0519 15:16:20.621677  4008 solver.cpp:415]     Test net output #1: loss = 1.85404 (* 1 = 1.85404 loss)
I0519 15:16:20.712334  4008 solver.cpp:231] Iteration 368000, loss = 1.25447
I0519 15:16:20.712417  4008 solver.cpp:247]     Train net output #0: loss = 1.25447 (* 1 = 1.25447 loss)
I0519 15:16:20.712472  4008 sgd_solver.cpp:106] Iteration 368000, lr = 1e-05
I0519 15:16:20.872825  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.173	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:16:20.947965  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:16:20.950152  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:16:20.950188  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:16:20.967536  4008 solver.cpp:260]     Total regularization terms: 0.940678 loss+regular. : 2.19515
I0519 15:17:46.775384  4008 solver.cpp:231] Iteration 368200, loss = 1.26541
I0519 15:17:46.775933  4008 solver.cpp:247]     Train net output #0: loss = 1.26541 (* 1 = 1.26541 loss)
I0519 15:17:46.775974  4008 sgd_solver.cpp:106] Iteration 368200, lr = 1e-05
I0519 15:17:46.939769  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.173	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:17:47.015710  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:17:47.018662  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:17:47.018743  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:17:47.029171  4008 solver.cpp:260]     Total regularization terms: 0.940675 loss+regular. : 2.20609
I0519 15:19:12.961774  4008 solver.cpp:231] Iteration 368400, loss = 1.36656
I0519 15:19:12.964815  4008 solver.cpp:247]     Train net output #0: loss = 1.36656 (* 1 = 1.36656 loss)
I0519 15:19:12.964839  4008 sgd_solver.cpp:106] Iteration 368400, lr = 1e-05
I0519 15:19:13.122124  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.173	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:19:13.196916  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:19:13.198912  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:19:13.198967  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:19:13.208832  4008 solver.cpp:260]     Total regularization terms: 0.940671 loss+regular. : 2.30723
I0519 15:20:41.774744  4008 solver.cpp:231] Iteration 368600, loss = 1.28049
I0519 15:20:41.775045  4008 solver.cpp:247]     Train net output #0: loss = 1.28049 (* 1 = 1.28049 loss)
I0519 15:20:41.775068  4008 sgd_solver.cpp:106] Iteration 368600, lr = 1e-05
I0519 15:20:41.935253  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.173	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:20:42.011031  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:20:42.014224  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:20:42.014276  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:20:42.024207  4008 solver.cpp:260]     Total regularization terms: 0.940669 loss+regular. : 2.22116
I0519 15:20:43.759152  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:22:15.741533  4008 solver.cpp:231] Iteration 368800, loss = 1.1801
I0519 15:22:15.741878  4008 solver.cpp:247]     Train net output #0: loss = 1.1801 (* 1 = 1.1801 loss)
I0519 15:22:15.742058  4008 sgd_solver.cpp:106] Iteration 368800, lr = 1e-05
I0519 15:22:15.900306  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.173	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:22:15.976258  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:22:15.978657  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:22:15.978704  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:22:15.998451  4008 solver.cpp:260]     Total regularization terms: 0.940664 loss+regular. : 2.12077
I0519 15:23:46.225353  4008 solver.cpp:348] Iteration 369000, Testing net (#0)
I0519 15:24:39.932368  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:25:09.798918  4008 solver.cpp:415]     Test net output #0: accuracy = 0.5679
I0519 15:25:09.799054  4008 solver.cpp:415]     Test net output #1: loss = 1.85426 (* 1 = 1.85426 loss)
I0519 15:25:09.927377  4008 solver.cpp:231] Iteration 369000, loss = 1.23029
I0519 15:25:09.927467  4008 solver.cpp:247]     Train net output #0: loss = 1.23029 (* 1 = 1.23029 loss)
I0519 15:25:09.927485  4008 sgd_solver.cpp:106] Iteration 369000, lr = 1e-05
I0519 15:25:10.085330  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.173	0	85.2767	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:25:10.165583  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:25:10.167819  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:25:10.167861  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:25:10.177747  4008 solver.cpp:260]     Total regularization terms: 0.940663 loss+regular. : 2.17095
I0519 15:26:32.597606  4008 solver.cpp:231] Iteration 369200, loss = 1.19982
I0519 15:26:32.598095  4008 solver.cpp:247]     Train net output #0: loss = 1.19982 (* 1 = 1.19982 loss)
I0519 15:26:32.598114  4008 sgd_solver.cpp:106] Iteration 369200, lr = 1e-05
I0519 15:26:32.758251  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4417	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:26:32.834678  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:26:32.836853  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:26:32.836917  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:26:32.858304  4008 solver.cpp:260]     Total regularization terms: 0.94066 loss+regular. : 2.14048
I0519 15:27:59.114199  4008 solver.cpp:231] Iteration 369400, loss = 1.24088
I0519 15:27:59.114524  4008 solver.cpp:247]     Train net output #0: loss = 1.24088 (* 1 = 1.24088 loss)
I0519 15:27:59.114562  4008 sgd_solver.cpp:106] Iteration 369400, lr = 1e-05
I0519 15:27:59.274672  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:27:59.350553  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:27:59.352895  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:27:59.352951  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:27:59.367882  4008 solver.cpp:260]     Total regularization terms: 0.940655 loss+regular. : 2.18153
I0519 15:29:17.305953  4008 solver.cpp:231] Iteration 369600, loss = 1.20095
I0519 15:29:17.306241  4008 solver.cpp:247]     Train net output #0: loss = 1.20095 (* 1 = 1.20095 loss)
I0519 15:29:17.306272  4008 sgd_solver.cpp:106] Iteration 369600, lr = 1e-05
I0519 15:29:17.466279  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:29:17.540972  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:29:17.543154  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:29:17.543200  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:29:17.552999  4008 solver.cpp:260]     Total regularization terms: 0.940652 loss+regular. : 2.14161
I0519 15:29:23.008553  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:30:42.757393  4008 solver.cpp:231] Iteration 369800, loss = 1.24917
I0519 15:30:42.758124  4008 solver.cpp:247]     Train net output #0: loss = 1.24917 (* 1 = 1.24917 loss)
I0519 15:30:42.758191  4008 sgd_solver.cpp:106] Iteration 369800, lr = 1e-05
I0519 15:30:42.917831  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:30:42.992455  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:30:42.994751  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:30:42.994809  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:30:43.007223  4008 solver.cpp:260]     Total regularization terms: 0.940648 loss+regular. : 2.18982
I0519 15:32:15.231407  4008 solver.cpp:348] Iteration 370000, Testing net (#0)
I0519 15:33:06.110039  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:33:38.419176  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56856
I0519 15:33:38.419486  4008 solver.cpp:415]     Test net output #1: loss = 1.85368 (* 1 = 1.85368 loss)
I0519 15:33:38.508461  4008 solver.cpp:231] Iteration 370000, loss = 1.09171
I0519 15:33:38.508584  4008 solver.cpp:247]     Train net output #0: loss = 1.09171 (* 1 = 1.09171 loss)
I0519 15:33:38.508602  4008 sgd_solver.cpp:106] Iteration 370000, lr = 1e-05
I0519 15:33:38.674664  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:33:38.749909  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:33:38.751679  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:33:38.751713  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:33:38.761643  4008 solver.cpp:260]     Total regularization terms: 0.940644 loss+regular. : 2.03236
I0519 15:35:02.431864  4008 solver.cpp:231] Iteration 370200, loss = 1.38394
I0519 15:35:02.432255  4008 solver.cpp:247]     Train net output #0: loss = 1.38394 (* 1 = 1.38394 loss)
I0519 15:35:02.432279  4008 sgd_solver.cpp:106] Iteration 370200, lr = 1e-05
I0519 15:35:02.592033  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:35:02.668382  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:35:02.670522  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:35:02.670572  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:35:02.684881  4008 solver.cpp:260]     Total regularization terms: 0.940641 loss+regular. : 2.32458
I0519 15:36:33.187048  4008 solver.cpp:231] Iteration 370400, loss = 1.27715
I0519 15:36:33.193696  4008 solver.cpp:247]     Train net output #0: loss = 1.27715 (* 1 = 1.27715 loss)
I0519 15:36:33.193843  4008 sgd_solver.cpp:106] Iteration 370400, lr = 1e-05
I0519 15:36:33.346938  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:36:33.421572  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:36:33.423341  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:36:33.423379  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:36:33.433287  4008 solver.cpp:260]     Total regularization terms: 0.940637 loss+regular. : 2.21779
I0519 15:38:05.718871  4008 solver.cpp:231] Iteration 370600, loss = 0.975984
I0519 15:38:05.719192  4008 solver.cpp:247]     Train net output #0: loss = 0.975984 (* 1 = 0.975984 loss)
I0519 15:38:05.719220  4008 sgd_solver.cpp:106] Iteration 370600, lr = 1e-05
I0519 15:38:05.879657  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:38:05.955049  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:38:05.957820  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:38:05.957875  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:38:05.967921  4008 solver.cpp:260]     Total regularization terms: 0.940634 loss+regular. : 1.91662
I0519 15:38:14.024724  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:39:40.270300  4008 solver.cpp:231] Iteration 370800, loss = 1.26507
I0519 15:39:40.270673  4008 solver.cpp:247]     Train net output #0: loss = 1.26507 (* 1 = 1.26507 loss)
I0519 15:39:40.270700  4008 sgd_solver.cpp:106] Iteration 370800, lr = 1e-05
I0519 15:39:40.430863  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:39:40.507006  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:39:40.509543  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:39:40.509609  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:39:40.525346  4008 solver.cpp:260]     Total regularization terms: 0.94063 loss+regular. : 2.2057
I0519 15:41:08.239694  4008 solver.cpp:348] Iteration 371000, Testing net (#0)
I0519 15:41:59.783336  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:42:29.316103  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56792
I0519 15:42:29.316226  4008 solver.cpp:415]     Test net output #1: loss = 1.85481 (* 1 = 1.85481 loss)
I0519 15:42:29.404037  4008 solver.cpp:231] Iteration 371000, loss = 1.09
I0519 15:42:29.404124  4008 solver.cpp:247]     Train net output #0: loss = 1.09 (* 1 = 1.09 loss)
I0519 15:42:29.404141  4008 sgd_solver.cpp:106] Iteration 371000, lr = 1e-05
I0519 15:42:29.566294  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:42:29.641929  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:42:29.644273  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:42:29.644320  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:42:29.654306  4008 solver.cpp:260]     Total regularization terms: 0.940625 loss+regular. : 2.03062
I0519 15:43:57.753219  4008 solver.cpp:231] Iteration 371200, loss = 1.16308
I0519 15:43:57.753495  4008 solver.cpp:247]     Train net output #0: loss = 1.16308 (* 1 = 1.16308 loss)
I0519 15:43:57.753516  4008 sgd_solver.cpp:106] Iteration 371200, lr = 1e-05
I0519 15:43:57.913226  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:43:57.988808  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:43:57.991888  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:43:57.991955  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:43:58.002218  4008 solver.cpp:260]     Total regularization terms: 0.940622 loss+regular. : 2.1037
I0519 15:45:20.697293  4008 solver.cpp:231] Iteration 371400, loss = 1.05457
I0519 15:45:20.697648  4008 solver.cpp:247]     Train net output #0: loss = 1.05457 (* 1 = 1.05457 loss)
I0519 15:45:20.697679  4008 sgd_solver.cpp:106] Iteration 371400, lr = 1e-05
I0519 15:45:20.857970  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:45:20.933650  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:45:20.936179  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:45:20.936228  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:45:20.946332  4008 solver.cpp:260]     Total regularization terms: 0.940617 loss+regular. : 1.99519
I0519 15:46:44.623689  4008 solver.cpp:231] Iteration 371600, loss = 1.1522
I0519 15:46:44.624189  4008 solver.cpp:247]     Train net output #0: loss = 1.1522 (* 1 = 1.1522 loss)
I0519 15:46:44.624220  4008 sgd_solver.cpp:106] Iteration 371600, lr = 1e-05
I0519 15:46:44.785075  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:46:44.863679  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:46:44.865851  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:46:44.865902  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:46:44.880931  4008 solver.cpp:260]     Total regularization terms: 0.940613 loss+regular. : 2.09282
I0519 15:46:55.052355  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:48:12.028272  4008 solver.cpp:231] Iteration 371800, loss = 1.31458
I0519 15:48:12.028861  4008 solver.cpp:247]     Train net output #0: loss = 1.31458 (* 1 = 1.31458 loss)
I0519 15:48:12.028892  4008 sgd_solver.cpp:106] Iteration 371800, lr = 1e-05
I0519 15:48:12.187777  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:48:12.263427  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:48:12.265995  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:48:12.266062  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:48:12.276113  4008 solver.cpp:260]     Total regularization terms: 0.94061 loss+regular. : 2.25519
I0519 15:49:46.782183  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_372000.caffemodel
I0519 15:53:01.723759  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_372000.solverstate
I0519 15:53:02.324086  4008 solver.cpp:348] Iteration 372000, Testing net (#0)
I0519 15:53:55.055296  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 15:54:31.663017  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56786
I0519 15:54:31.663311  4008 solver.cpp:415]     Test net output #1: loss = 1.85365 (* 1 = 1.85365 loss)
I0519 15:54:31.752058  4008 solver.cpp:231] Iteration 372000, loss = 1.25829
I0519 15:54:31.752190  4008 solver.cpp:247]     Train net output #0: loss = 1.25829 (* 1 = 1.25829 loss)
I0519 15:54:31.752215  4008 sgd_solver.cpp:106] Iteration 372000, lr = 1e-05
I0519 15:54:31.918978  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:54:31.920824  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:54:31.923087  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:54:31.923135  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:54:31.933084  4008 solver.cpp:260]     Total regularization terms: 0.940604 loss+regular. : 2.1989
I0519 15:55:53.505604  4008 solver.cpp:231] Iteration 372200, loss = 1.30196
I0519 15:55:53.506007  4008 solver.cpp:247]     Train net output #0: loss = 1.30196 (* 1 = 1.30196 loss)
I0519 15:55:53.506043  4008 sgd_solver.cpp:106] Iteration 372200, lr = 1e-05
I0519 15:55:53.663763  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:55:53.738883  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:55:53.741312  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:55:53.741360  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:55:53.751310  4008 solver.cpp:260]     Total regularization terms: 0.940601 loss+regular. : 2.24256
I0519 15:57:31.821741  4008 solver.cpp:231] Iteration 372400, loss = 1.16353
I0519 15:57:31.822257  4008 solver.cpp:247]     Train net output #0: loss = 1.16353 (* 1 = 1.16353 loss)
I0519 15:57:31.822283  4008 sgd_solver.cpp:106] Iteration 372400, lr = 1e-05
I0519 15:57:31.981776  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:57:32.056807  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:57:32.059224  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:57:32.059279  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:57:32.069145  4008 solver.cpp:260]     Total regularization terms: 0.940598 loss+regular. : 2.10413
I0519 15:58:58.505671  4008 solver.cpp:231] Iteration 372600, loss = 1.20117
I0519 15:58:58.508647  4008 solver.cpp:247]     Train net output #0: loss = 1.20117 (* 1 = 1.20117 loss)
I0519 15:58:58.508678  4008 sgd_solver.cpp:106] Iteration 372600, lr = 1e-05
I0519 15:58:58.666162  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 15:58:58.741339  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 15:58:58.743751  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 15:58:58.743811  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 15:58:58.758832  4008 solver.cpp:260]     Total regularization terms: 0.940595 loss+regular. : 2.14177
I0519 15:59:12.776702  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:00:26.263429  4008 solver.cpp:231] Iteration 372800, loss = 1.19989
I0519 16:00:26.263943  4008 solver.cpp:247]     Train net output #0: loss = 1.19989 (* 1 = 1.19989 loss)
I0519 16:00:26.263965  4008 sgd_solver.cpp:106] Iteration 372800, lr = 1e-05
I0519 16:00:26.422283  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3492	0	30.3912	2.7	
I0519 16:00:26.497514  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:00:26.499913  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:00:26.499965  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:00:26.512949  4008 solver.cpp:260]     Total regularization terms: 0.940592 loss+regular. : 2.14048
I0519 16:02:01.171648  4008 solver.cpp:348] Iteration 373000, Testing net (#0)
I0519 16:02:53.951102  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:03:29.764473  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56804
I0519 16:03:29.764860  4008 solver.cpp:415]     Test net output #1: loss = 1.85394 (* 1 = 1.85394 loss)
I0519 16:03:29.857184  4008 solver.cpp:231] Iteration 373000, loss = 1.41637
I0519 16:03:29.857280  4008 solver.cpp:247]     Train net output #0: loss = 1.41637 (* 1 = 1.41637 loss)
I0519 16:03:29.857302  4008 sgd_solver.cpp:106] Iteration 373000, lr = 1e-05
I0519 16:03:30.025446  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3493	0	30.3912	2.7	
I0519 16:03:30.101021  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:03:30.104014  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:03:30.104060  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:03:30.113920  4008 solver.cpp:260]     Total regularization terms: 0.940586 loss+regular. : 2.35696
I0519 16:04:59.134953  4008 solver.cpp:231] Iteration 373200, loss = 1.14552
I0519 16:04:59.135334  4008 solver.cpp:247]     Train net output #0: loss = 1.14552 (* 1 = 1.14552 loss)
I0519 16:04:59.135360  4008 sgd_solver.cpp:106] Iteration 373200, lr = 1e-05
I0519 16:04:59.292744  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3493	0	30.3912	2.7	
I0519 16:04:59.368326  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:04:59.371407  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:04:59.371459  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:04:59.381415  4008 solver.cpp:260]     Total regularization terms: 0.940583 loss+regular. : 2.08611
I0519 16:06:37.617578  4008 solver.cpp:231] Iteration 373400, loss = 1.28623
I0519 16:06:37.618121  4008 solver.cpp:247]     Train net output #0: loss = 1.28623 (* 1 = 1.28623 loss)
I0519 16:06:37.618142  4008 sgd_solver.cpp:106] Iteration 373400, lr = 1e-05
I0519 16:06:37.777806  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.277	0	85.6066	0	78.3493	0	30.3912	2.7	
I0519 16:06:37.853066  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:06:37.855767  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:06:37.855818  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:06:37.865908  4008 solver.cpp:260]     Total regularization terms: 0.940579 loss+regular. : 2.2268
I0519 16:08:00.170508  4008 solver.cpp:231] Iteration 373600, loss = 1.336
I0519 16:08:00.171346  4008 solver.cpp:247]     Train net output #0: loss = 1.336 (* 1 = 1.336 loss)
I0519 16:08:00.171375  4008 sgd_solver.cpp:106] Iteration 373600, lr = 1e-05
I0519 16:08:00.331153  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.2772	0	85.6066	0	78.3493	0	30.3912	2.7	
I0519 16:08:00.406522  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:08:00.408936  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:08:00.408982  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:08:00.418954  4008 solver.cpp:260]     Total regularization terms: 0.940577 loss+regular. : 2.27658
I0519 16:08:16.039940  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:09:23.907145  4008 solver.cpp:231] Iteration 373800, loss = 1.21815
I0519 16:09:23.908771  4008 solver.cpp:247]     Train net output #0: loss = 1.21815 (* 1 = 1.21815 loss)
I0519 16:09:23.908800  4008 sgd_solver.cpp:106] Iteration 373800, lr = 1e-05
I0519 16:09:24.068483  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.2772	0	85.6066	0	78.3493	0	30.3912	2.7	
I0519 16:09:24.143846  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:09:24.146782  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:09:24.146838  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:09:24.157006  4008 solver.cpp:260]     Total regularization terms: 0.940574 loss+regular. : 2.15872
I0519 16:10:42.686419  4008 solver.cpp:348] Iteration 374000, Testing net (#0)
I0519 16:11:41.147405  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:12:13.368268  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56822
I0519 16:12:13.368643  4008 solver.cpp:415]     Test net output #1: loss = 1.85448 (* 1 = 1.85448 loss)
I0519 16:12:13.459656  4008 solver.cpp:231] Iteration 374000, loss = 1.08373
I0519 16:12:13.459796  4008 solver.cpp:247]     Train net output #0: loss = 1.08373 (* 1 = 1.08373 loss)
I0519 16:12:13.459854  4008 sgd_solver.cpp:106] Iteration 374000, lr = 1e-05
I0519 16:12:13.620450  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.2772	0	85.6066	0	78.3493	0	30.3912	2.7	
I0519 16:12:13.698657  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:12:13.700811  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:12:13.700855  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:12:13.710871  4008 solver.cpp:260]     Total regularization terms: 0.94057 loss+regular. : 2.0243
I0519 16:13:42.667654  4008 solver.cpp:231] Iteration 374200, loss = 1.20248
I0519 16:13:42.668149  4008 solver.cpp:247]     Train net output #0: loss = 1.20248 (* 1 = 1.20248 loss)
I0519 16:13:42.668192  4008 sgd_solver.cpp:106] Iteration 374200, lr = 1e-05
I0519 16:13:42.828198  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.2772	0	85.6066	0	78.3493	0	30.3912	2.7	
I0519 16:13:42.904203  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:13:42.907893  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:13:42.907964  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:13:42.918474  4008 solver.cpp:260]     Total regularization terms: 0.940567 loss+regular. : 2.14304
I0519 16:15:07.871115  4008 solver.cpp:231] Iteration 374400, loss = 1.28026
I0519 16:15:07.871459  4008 solver.cpp:247]     Train net output #0: loss = 1.28026 (* 1 = 1.28026 loss)
I0519 16:15:07.871490  4008 sgd_solver.cpp:106] Iteration 374400, lr = 1e-05
I0519 16:15:08.031441  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.2772	0	85.6066	0	78.3493	0	30.3912	2.7	
I0519 16:15:08.107236  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:15:08.110291  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:15:08.110332  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:15:08.121665  4008 solver.cpp:260]     Total regularization terms: 0.940563 loss+regular. : 2.22082
I0519 16:16:37.062400  4008 solver.cpp:231] Iteration 374600, loss = 1.20709
I0519 16:16:37.062743  4008 solver.cpp:247]     Train net output #0: loss = 1.20709 (* 1 = 1.20709 loss)
I0519 16:16:37.062764  4008 sgd_solver.cpp:106] Iteration 374600, lr = 1e-05
I0519 16:16:37.222213  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.2772	0	85.6066	0	78.3493	0	30.3913	2.7	
I0519 16:16:37.297070  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:16:37.298943  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:16:37.298990  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:16:37.308859  4008 solver.cpp:260]     Total regularization terms: 0.94056 loss+regular. : 2.14765
I0519 16:16:57.686153  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:18:05.046710  4008 solver.cpp:231] Iteration 374800, loss = 1.27891
I0519 16:18:05.047121  4008 solver.cpp:247]     Train net output #0: loss = 1.27891 (* 1 = 1.27891 loss)
I0519 16:18:05.047147  4008 sgd_solver.cpp:106] Iteration 374800, lr = 1e-05
I0519 16:18:05.207835  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1336	5.98958	89.173	0	85.2772	0	85.6066	0	78.3493	0	30.3913	2.7	
I0519 16:18:05.283529  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:18:05.285285  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:18:05.285325  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:18:05.301985  4008 solver.cpp:260]     Total regularization terms: 0.940558 loss+regular. : 2.21947
I0519 16:19:25.662236  4008 solver.cpp:348] Iteration 375000, Testing net (#0)
I0519 16:20:17.255379  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:20:46.046428  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56812
I0519 16:20:46.046591  4008 solver.cpp:415]     Test net output #1: loss = 1.85455 (* 1 = 1.85455 loss)
I0519 16:20:46.134348  4008 solver.cpp:231] Iteration 375000, loss = 1.09135
I0519 16:20:46.134431  4008 solver.cpp:247]     Train net output #0: loss = 1.09135 (* 1 = 1.09135 loss)
I0519 16:20:46.134450  4008 sgd_solver.cpp:106] Iteration 375000, lr = 1e-05
I0519 16:20:46.303150  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.173	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:20:46.383332  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:20:46.386482  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:20:46.386533  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:20:46.396659  4008 solver.cpp:260]     Total regularization terms: 0.940554 loss+regular. : 2.03191
I0519 16:22:11.389039  4008 solver.cpp:231] Iteration 375200, loss = 1.47728
I0519 16:22:11.390348  4008 solver.cpp:247]     Train net output #0: loss = 1.47728 (* 1 = 1.47728 loss)
I0519 16:22:11.390380  4008 sgd_solver.cpp:106] Iteration 375200, lr = 1e-05
I0519 16:22:11.549612  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.173	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:22:11.626267  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:22:11.629745  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:22:11.629814  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:22:11.640031  4008 solver.cpp:260]     Total regularization terms: 0.94055 loss+regular. : 2.41783
I0519 16:23:39.352000  4008 solver.cpp:231] Iteration 375400, loss = 1.25854
I0519 16:23:39.353646  4008 solver.cpp:247]     Train net output #0: loss = 1.25854 (* 1 = 1.25854 loss)
I0519 16:23:39.353674  4008 sgd_solver.cpp:106] Iteration 375400, lr = 1e-05
I0519 16:23:39.513226  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.173	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:23:39.593715  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:23:39.596181  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:23:39.596240  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:23:39.606297  4008 solver.cpp:260]     Total regularization terms: 0.940546 loss+regular. : 2.19908
I0519 16:25:05.736680  4008 solver.cpp:231] Iteration 375600, loss = 1.44185
I0519 16:25:05.737004  4008 solver.cpp:247]     Train net output #0: loss = 1.44185 (* 1 = 1.44185 loss)
I0519 16:25:05.737027  4008 sgd_solver.cpp:106] Iteration 375600, lr = 1e-05
I0519 16:25:05.898077  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.173	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:25:05.973492  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:25:05.976742  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:25:05.976797  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:25:05.986757  4008 solver.cpp:260]     Total regularization terms: 0.940542 loss+regular. : 2.38239
I0519 16:25:31.223881  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:26:32.680733  4008 solver.cpp:231] Iteration 375800, loss = 1.31317
I0519 16:26:32.681824  4008 solver.cpp:247]     Train net output #0: loss = 1.31317 (* 1 = 1.31317 loss)
I0519 16:26:32.681854  4008 sgd_solver.cpp:106] Iteration 375800, lr = 1e-05
I0519 16:26:32.841043  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1731	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:26:32.916235  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:26:32.919185  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:26:32.919236  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:26:32.929105  4008 solver.cpp:260]     Total regularization terms: 0.940539 loss+regular. : 2.25371
I0519 16:28:03.263159  4008 solver.cpp:348] Iteration 376000, Testing net (#0)
I0519 16:29:03.953970  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:29:33.855747  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56784
I0519 16:29:33.855840  4008 solver.cpp:415]     Test net output #1: loss = 1.85437 (* 1 = 1.85437 loss)
I0519 16:29:33.944145  4008 solver.cpp:231] Iteration 376000, loss = 1.36265
I0519 16:29:33.944264  4008 solver.cpp:247]     Train net output #0: loss = 1.36265 (* 1 = 1.36265 loss)
I0519 16:29:33.944285  4008 sgd_solver.cpp:106] Iteration 376000, lr = 1e-05
I0519 16:29:34.109058  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1731	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:29:34.184942  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:29:34.187841  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:29:34.187912  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:29:34.197978  4008 solver.cpp:260]     Total regularization terms: 0.940534 loss+regular. : 2.30318
I0519 16:31:03.747550  4008 solver.cpp:231] Iteration 376200, loss = 1.15204
I0519 16:31:03.747972  4008 solver.cpp:247]     Train net output #0: loss = 1.15204 (* 1 = 1.15204 loss)
I0519 16:31:03.748003  4008 sgd_solver.cpp:106] Iteration 376200, lr = 1e-05
I0519 16:31:03.909216  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1731	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:31:03.985672  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:31:03.989315  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:31:03.989368  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:31:03.999406  4008 solver.cpp:260]     Total regularization terms: 0.94053 loss+regular. : 2.09257
I0519 16:32:28.619251  4008 solver.cpp:231] Iteration 376400, loss = 1.23179
I0519 16:32:28.619616  4008 solver.cpp:247]     Train net output #0: loss = 1.23179 (* 1 = 1.23179 loss)
I0519 16:32:28.619639  4008 sgd_solver.cpp:106] Iteration 376400, lr = 1e-05
I0519 16:32:28.779849  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1731	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:32:28.855478  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:32:28.858289  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:32:28.858336  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:32:28.879357  4008 solver.cpp:260]     Total regularization terms: 0.940526 loss+regular. : 2.17231
I0519 16:33:50.411278  4008 solver.cpp:231] Iteration 376600, loss = 1.01833
I0519 16:33:50.411612  4008 solver.cpp:247]     Train net output #0: loss = 1.01833 (* 1 = 1.01833 loss)
I0519 16:33:50.411633  4008 sgd_solver.cpp:106] Iteration 376600, lr = 1e-05
I0519 16:33:50.572746  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1731	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:33:50.648113  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:33:50.651092  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:33:50.651146  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:33:50.666440  4008 solver.cpp:260]     Total regularization terms: 0.940522 loss+regular. : 1.95885
I0519 16:34:14.910516  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:35:18.752228  4008 solver.cpp:231] Iteration 376800, loss = 1.04099
I0519 16:35:18.752737  4008 solver.cpp:247]     Train net output #0: loss = 1.04099 (* 1 = 1.04099 loss)
I0519 16:35:18.752769  4008 sgd_solver.cpp:106] Iteration 376800, lr = 1e-05
I0519 16:35:18.911803  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1731	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:35:18.987131  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:35:18.989979  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:35:18.990025  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:35:18.999830  4008 solver.cpp:260]     Total regularization terms: 0.940519 loss+regular. : 1.98151
I0519 16:36:48.156594  4008 solver.cpp:348] Iteration 377000, Testing net (#0)
I0519 16:37:37.803253  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:38:05.480331  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56806
I0519 16:38:05.480428  4008 solver.cpp:415]     Test net output #1: loss = 1.85392 (* 1 = 1.85392 loss)
I0519 16:38:05.569520  4008 solver.cpp:231] Iteration 377000, loss = 1.19007
I0519 16:38:05.569656  4008 solver.cpp:247]     Train net output #0: loss = 1.19007 (* 1 = 1.19007 loss)
I0519 16:38:05.569674  4008 sgd_solver.cpp:106] Iteration 377000, lr = 1e-05
I0519 16:38:05.739050  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1733	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:38:05.814786  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:38:05.816970  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:38:05.817018  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:38:05.832286  4008 solver.cpp:260]     Total regularization terms: 0.940515 loss+regular. : 2.13059
I0519 16:39:33.624948  4008 solver.cpp:231] Iteration 377200, loss = 1.45753
I0519 16:39:33.625653  4008 solver.cpp:247]     Train net output #0: loss = 1.45753 (* 1 = 1.45753 loss)
I0519 16:39:33.625682  4008 sgd_solver.cpp:106] Iteration 377200, lr = 1e-05
I0519 16:39:33.785392  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1733	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:39:33.860494  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:39:33.862666  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:39:33.862711  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:39:33.872588  4008 solver.cpp:260]     Total regularization terms: 0.940511 loss+regular. : 2.39805
I0519 16:41:03.627629  4008 solver.cpp:231] Iteration 377400, loss = 1.11813
I0519 16:41:03.628963  4008 solver.cpp:247]     Train net output #0: loss = 1.11813 (* 1 = 1.11813 loss)
I0519 16:41:03.628998  4008 sgd_solver.cpp:106] Iteration 377400, lr = 1e-05
I0519 16:41:03.787896  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1733	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:41:03.862804  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:41:03.865078  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:41:03.865152  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:41:03.875192  4008 solver.cpp:260]     Total regularization terms: 0.940508 loss+regular. : 2.05863
I0519 16:42:31.655979  4008 solver.cpp:231] Iteration 377600, loss = 1.35928
I0519 16:42:31.656478  4008 solver.cpp:247]     Train net output #0: loss = 1.35928 (* 1 = 1.35928 loss)
I0519 16:42:31.656509  4008 sgd_solver.cpp:106] Iteration 377600, lr = 1e-05
I0519 16:42:31.820338  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1733	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:42:31.895217  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:42:31.897176  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:42:31.897215  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:42:31.906875  4008 solver.cpp:260]     Total regularization terms: 0.940504 loss+regular. : 2.29979
I0519 16:42:58.030526  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:43:53.434370  4008 solver.cpp:231] Iteration 377800, loss = 1.22143
I0519 16:43:53.434691  4008 solver.cpp:247]     Train net output #0: loss = 1.22143 (* 1 = 1.22143 loss)
I0519 16:43:53.434721  4008 sgd_solver.cpp:106] Iteration 377800, lr = 1e-05
I0519 16:43:53.594501  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1733	0	85.2772	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:43:53.671636  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:43:53.676223  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:43:53.676306  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:43:53.687368  4008 solver.cpp:260]     Total regularization terms: 0.940501 loss+regular. : 2.16193
I0519 16:45:24.386199  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_378000.caffemodel
I0519 16:47:11.522416  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_378000.solverstate
I0519 16:47:12.200136  4008 solver.cpp:348] Iteration 378000, Testing net (#0)
I0519 16:48:05.171532  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:48:28.928469  4008 solver.cpp:415]     Test net output #0: accuracy = 0.568359
I0519 16:48:28.928594  4008 solver.cpp:415]     Test net output #1: loss = 1.85333 (* 1 = 1.85333 loss)
I0519 16:48:29.016784  4008 solver.cpp:231] Iteration 378000, loss = 1.29328
I0519 16:48:29.016875  4008 solver.cpp:247]     Train net output #0: loss = 1.29328 (* 1 = 1.29328 loss)
I0519 16:48:29.016914  4008 sgd_solver.cpp:106] Iteration 378000, lr = 1e-05
I0519 16:48:29.176857  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:48:29.179119  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:48:29.181794  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:48:29.181849  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:48:29.195703  4008 solver.cpp:260]     Total regularization terms: 0.940496 loss+regular. : 2.23377
I0519 16:49:58.325721  4008 solver.cpp:231] Iteration 378200, loss = 1.4514
I0519 16:49:58.326562  4008 solver.cpp:247]     Train net output #0: loss = 1.4514 (* 1 = 1.4514 loss)
I0519 16:49:58.326588  4008 sgd_solver.cpp:106] Iteration 378200, lr = 1e-05
I0519 16:49:58.486110  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:49:58.561568  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:49:58.564000  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:49:58.564050  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:49:58.575714  4008 solver.cpp:260]     Total regularization terms: 0.940493 loss+regular. : 2.3919
I0519 16:51:29.252977  4008 solver.cpp:231] Iteration 378400, loss = 1.2257
I0519 16:51:29.253408  4008 solver.cpp:247]     Train net output #0: loss = 1.2257 (* 1 = 1.2257 loss)
I0519 16:51:29.253430  4008 sgd_solver.cpp:106] Iteration 378400, lr = 1e-05
I0519 16:51:29.417493  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:51:29.493515  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:51:29.495926  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:51:29.495972  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:51:29.506116  4008 solver.cpp:260]     Total regularization terms: 0.94049 loss+regular. : 2.16619
I0519 16:52:51.547384  4008 solver.cpp:231] Iteration 378600, loss = 1.16351
I0519 16:52:51.547727  4008 solver.cpp:247]     Train net output #0: loss = 1.16351 (* 1 = 1.16351 loss)
I0519 16:52:51.547750  4008 sgd_solver.cpp:106] Iteration 378600, lr = 1e-05
I0519 16:52:51.707721  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:52:51.783149  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:52:51.784754  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:52:51.784772  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:52:51.799885  4008 solver.cpp:260]     Total regularization terms: 0.940487 loss+regular. : 2.104
I0519 16:53:20.094070  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:54:13.452982  4008 solver.cpp:231] Iteration 378800, loss = 1.33636
I0519 16:54:13.453308  4008 solver.cpp:247]     Train net output #0: loss = 1.33636 (* 1 = 1.33636 loss)
I0519 16:54:13.453336  4008 sgd_solver.cpp:106] Iteration 378800, lr = 1e-05
I0519 16:54:13.617460  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:54:13.692471  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:54:13.695215  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:54:13.695287  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:54:13.705425  4008 solver.cpp:260]     Total regularization terms: 0.940483 loss+regular. : 2.27684
I0519 16:55:37.948400  4008 solver.cpp:348] Iteration 379000, Testing net (#0)
I0519 16:56:43.180390  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 16:57:12.143646  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567819
I0519 16:57:12.143759  4008 solver.cpp:415]     Test net output #1: loss = 1.85432 (* 1 = 1.85432 loss)
I0519 16:57:12.233096  4008 solver.cpp:231] Iteration 379000, loss = 1.37106
I0519 16:57:12.233180  4008 solver.cpp:247]     Train net output #0: loss = 1.37106 (* 1 = 1.37106 loss)
I0519 16:57:12.233196  4008 sgd_solver.cpp:106] Iteration 379000, lr = 1e-05
I0519 16:57:12.399427  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4421	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:57:12.474422  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:57:12.476533  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:57:12.476606  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:57:12.486490  4008 solver.cpp:260]     Total regularization terms: 0.94048 loss+regular. : 2.31154
I0519 16:58:38.139330  4008 solver.cpp:231] Iteration 379200, loss = 1.13088
I0519 16:58:38.139701  4008 solver.cpp:247]     Train net output #0: loss = 1.13088 (* 1 = 1.13088 loss)
I0519 16:58:38.139721  4008 sgd_solver.cpp:106] Iteration 379200, lr = 1e-05
I0519 16:58:38.300178  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4424	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 16:58:38.374961  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 16:58:38.377331  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 16:58:38.377393  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 16:58:38.394423  4008 solver.cpp:260]     Total regularization terms: 0.940477 loss+regular. : 2.07136
I0519 17:00:01.619125  4008 solver.cpp:231] Iteration 379400, loss = 1.37625
I0519 17:00:01.622108  4008 solver.cpp:247]     Train net output #0: loss = 1.37625 (* 1 = 1.37625 loss)
I0519 17:00:01.622158  4008 sgd_solver.cpp:106] Iteration 379400, lr = 1e-05
I0519 17:00:01.779783  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4424	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:00:01.855206  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:00:01.857522  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:00:01.857589  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:00:01.867504  4008 solver.cpp:260]     Total regularization terms: 0.940474 loss+regular. : 2.31672
I0519 17:01:34.014283  4008 solver.cpp:231] Iteration 379600, loss = 1.15873
I0519 17:01:34.014787  4008 solver.cpp:247]     Train net output #0: loss = 1.15873 (* 1 = 1.15873 loss)
I0519 17:01:34.014806  4008 sgd_solver.cpp:106] Iteration 379600, lr = 1e-05
I0519 17:01:34.175946  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4424	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:01:34.255409  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:01:34.258566  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:01:34.258616  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:01:34.270023  4008 solver.cpp:260]     Total regularization terms: 0.940471 loss+regular. : 2.0992
I0519 17:02:11.818600  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:03:11.244653  4008 solver.cpp:231] Iteration 379800, loss = 1.25636
I0519 17:03:11.247253  4008 solver.cpp:247]     Train net output #0: loss = 1.25636 (* 1 = 1.25636 loss)
I0519 17:03:11.247292  4008 sgd_solver.cpp:106] Iteration 379800, lr = 1e-05
I0519 17:03:11.405864  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4424	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:03:11.481678  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:03:11.484726  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:03:11.484767  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:03:11.494741  4008 solver.cpp:260]     Total regularization terms: 0.940468 loss+regular. : 2.19683
I0519 17:04:34.428773  4008 solver.cpp:348] Iteration 380000, Testing net (#0)
I0519 17:05:33.453322  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:06:02.756208  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56856
I0519 17:06:02.756299  4008 solver.cpp:415]     Test net output #1: loss = 1.85371 (* 1 = 1.85371 loss)
I0519 17:06:02.846860  4008 solver.cpp:231] Iteration 380000, loss = 1.11743
I0519 17:06:02.846940  4008 solver.cpp:247]     Train net output #0: loss = 1.11743 (* 1 = 1.11743 loss)
I0519 17:06:02.846959  4008 sgd_solver.cpp:106] Iteration 380000, lr = 1e-05
I0519 17:06:03.006863  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4424	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:06:03.082774  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:06:03.086251  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:06:03.086308  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:06:03.100159  4008 solver.cpp:260]     Total regularization terms: 0.940463 loss+regular. : 2.05789
I0519 17:07:36.080021  4008 solver.cpp:231] Iteration 380200, loss = 1.28887
I0519 17:07:36.080662  4008 solver.cpp:247]     Train net output #0: loss = 1.28887 (* 1 = 1.28887 loss)
I0519 17:07:36.080689  4008 sgd_solver.cpp:106] Iteration 380200, lr = 1e-05
I0519 17:07:36.242187  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:07:36.318758  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:07:36.321085  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:07:36.321136  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:07:36.330955  4008 solver.cpp:260]     Total regularization terms: 0.940459 loss+regular. : 2.22933
I0519 17:09:12.498906  4008 solver.cpp:231] Iteration 380400, loss = 1.22189
I0519 17:09:12.499342  4008 solver.cpp:247]     Train net output #0: loss = 1.22189 (* 1 = 1.22189 loss)
I0519 17:09:12.499368  4008 sgd_solver.cpp:106] Iteration 380400, lr = 1e-05
I0519 17:09:12.659226  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1337	5.98958	89.1733	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:09:12.734650  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:09:12.736759  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:09:12.736807  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:09:12.746924  4008 solver.cpp:260]     Total regularization terms: 0.940455 loss+regular. : 2.16235
I0519 17:10:43.770220  4008 solver.cpp:231] Iteration 380600, loss = 1.30001
I0519 17:10:43.770519  4008 solver.cpp:247]     Train net output #0: loss = 1.30001 (* 1 = 1.30001 loss)
I0519 17:10:43.770541  4008 sgd_solver.cpp:106] Iteration 380600, lr = 1e-05
I0519 17:10:43.930869  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1337	5.98958	89.1734	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:10:44.006702  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:10:44.009897  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:10:44.009953  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:10:44.019996  4008 solver.cpp:260]     Total regularization terms: 0.940452 loss+regular. : 2.24046
I0519 17:11:27.830962  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:12:19.792047  4008 solver.cpp:231] Iteration 380800, loss = 1.1299
I0519 17:12:19.792991  4008 solver.cpp:247]     Train net output #0: loss = 1.1299 (* 1 = 1.1299 loss)
I0519 17:12:19.793015  4008 sgd_solver.cpp:106] Iteration 380800, lr = 1e-05
I0519 17:12:19.954911  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1337	5.98958	89.1734	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:12:20.030263  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:12:20.032352  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:12:20.032430  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:12:20.042464  4008 solver.cpp:260]     Total regularization terms: 0.940447 loss+regular. : 2.07035
I0519 17:13:46.373160  4008 solver.cpp:348] Iteration 381000, Testing net (#0)
I0519 17:14:47.416863  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:15:13.812105  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56786
I0519 17:15:13.812204  4008 solver.cpp:415]     Test net output #1: loss = 1.85416 (* 1 = 1.85416 loss)
I0519 17:15:13.899955  4008 solver.cpp:231] Iteration 381000, loss = 1.38237
I0519 17:15:13.900045  4008 solver.cpp:247]     Train net output #0: loss = 1.38237 (* 1 = 1.38237 loss)
I0519 17:15:13.900063  4008 sgd_solver.cpp:106] Iteration 381000, lr = 1e-05
I0519 17:15:14.065229  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1337	5.98958	89.1734	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:15:14.140285  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:15:14.142591  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:15:14.142642  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:15:14.152480  4008 solver.cpp:260]     Total regularization terms: 0.940443 loss+regular. : 2.32281
I0519 17:16:39.905882  4008 solver.cpp:231] Iteration 381200, loss = 1.3862
I0519 17:16:39.906702  4008 solver.cpp:247]     Train net output #0: loss = 1.3862 (* 1 = 1.3862 loss)
I0519 17:16:39.906728  4008 sgd_solver.cpp:106] Iteration 381200, lr = 1e-05
I0519 17:16:40.066083  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1337	5.98958	89.1736	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:16:40.140982  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:16:40.143270  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:16:40.143323  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:16:40.157655  4008 solver.cpp:260]     Total regularization terms: 0.94044 loss+regular. : 2.32664
I0519 17:18:07.501072  4008 solver.cpp:231] Iteration 381400, loss = 1.34251
I0519 17:18:07.501529  4008 solver.cpp:247]     Train net output #0: loss = 1.34251 (* 1 = 1.34251 loss)
I0519 17:18:07.501549  4008 sgd_solver.cpp:106] Iteration 381400, lr = 1e-05
I0519 17:18:07.662935  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1337	5.98958	89.1736	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:18:07.737906  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:18:07.739934  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:18:07.739984  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:18:07.749899  4008 solver.cpp:260]     Total regularization terms: 0.940436 loss+regular. : 2.28294
I0519 17:19:30.572361  4008 solver.cpp:231] Iteration 381600, loss = 1.2517
I0519 17:19:30.572752  4008 solver.cpp:247]     Train net output #0: loss = 1.2517 (* 1 = 1.2517 loss)
I0519 17:19:30.572774  4008 sgd_solver.cpp:106] Iteration 381600, lr = 1e-05
I0519 17:19:30.732161  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1337	5.98958	89.1736	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:19:30.807009  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:19:30.809238  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:19:30.809283  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:19:30.824399  4008 solver.cpp:260]     Total regularization terms: 0.940432 loss+regular. : 2.19213
I0519 17:20:08.653764  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:20:52.195818  4008 solver.cpp:231] Iteration 381800, loss = 1.22095
I0519 17:20:52.196190  4008 solver.cpp:247]     Train net output #0: loss = 1.22095 (* 1 = 1.22095 loss)
I0519 17:20:52.196220  4008 sgd_solver.cpp:106] Iteration 381800, lr = 1e-05
I0519 17:20:52.355056  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.1736	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:20:52.430336  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:20:52.432521  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:20:52.432567  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:20:52.444331  4008 solver.cpp:260]     Total regularization terms: 0.940431 loss+regular. : 2.16138
I0519 17:22:14.544474  4008 solver.cpp:348] Iteration 382000, Testing net (#0)
I0519 17:23:07.456507  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:23:32.148082  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56836
I0519 17:23:32.148178  4008 solver.cpp:415]     Test net output #1: loss = 1.85315 (* 1 = 1.85315 loss)
I0519 17:23:32.238270  4008 solver.cpp:231] Iteration 382000, loss = 1.15631
I0519 17:23:32.238380  4008 solver.cpp:247]     Train net output #0: loss = 1.15631 (* 1 = 1.15631 loss)
I0519 17:23:32.238400  4008 sgd_solver.cpp:106] Iteration 382000, lr = 1e-05
I0519 17:23:32.405724  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.1737	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:23:32.480451  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:23:32.482244  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:23:32.482293  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:23:32.492179  4008 solver.cpp:260]     Total regularization terms: 0.940425 loss+regular. : 2.09673
I0519 17:24:59.354440  4008 solver.cpp:231] Iteration 382200, loss = 1.33952
I0519 17:24:59.354817  4008 solver.cpp:247]     Train net output #0: loss = 1.33952 (* 1 = 1.33952 loss)
I0519 17:24:59.354842  4008 sgd_solver.cpp:106] Iteration 382200, lr = 1e-05
I0519 17:24:59.514899  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.1737	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:24:59.589160  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:24:59.590818  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:24:59.590862  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:24:59.600790  4008 solver.cpp:260]     Total regularization terms: 0.940422 loss+regular. : 2.27994
I0519 17:26:27.180649  4008 solver.cpp:231] Iteration 382400, loss = 1.25584
I0519 17:26:27.180990  4008 solver.cpp:247]     Train net output #0: loss = 1.25584 (* 1 = 1.25584 loss)
I0519 17:26:27.181020  4008 sgd_solver.cpp:106] Iteration 382400, lr = 1e-05
I0519 17:26:27.339270  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.1737	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:26:27.414572  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:26:27.417398  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:26:27.417448  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:26:27.427410  4008 solver.cpp:260]     Total regularization terms: 0.94042 loss+regular. : 2.19626
I0519 17:27:56.978595  4008 solver.cpp:231] Iteration 382600, loss = 1.22375
I0519 17:27:56.978863  4008 solver.cpp:247]     Train net output #0: loss = 1.22375 (* 1 = 1.22375 loss)
I0519 17:27:56.978893  4008 sgd_solver.cpp:106] Iteration 382600, lr = 1e-05
I0519 17:27:57.138504  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.1737	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:27:57.213543  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:27:57.215263  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:27:57.215314  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:27:57.225195  4008 solver.cpp:260]     Total regularization terms: 0.940416 loss+regular. : 2.16417
I0519 17:28:44.532953  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:29:36.695407  4008 solver.cpp:231] Iteration 382800, loss = 1.32101
I0519 17:29:36.695626  4008 solver.cpp:247]     Train net output #0: loss = 1.32101 (* 1 = 1.32101 loss)
I0519 17:29:36.695642  4008 sgd_solver.cpp:106] Iteration 382800, lr = 1e-05
I0519 17:29:36.854888  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.1737	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:29:36.929211  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:29:36.930932  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:29:36.930956  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:29:36.940593  4008 solver.cpp:260]     Total regularization terms: 0.940413 loss+regular. : 2.26142
I0519 17:30:53.297130  4008 solver.cpp:348] Iteration 383000, Testing net (#0)
I0519 17:31:48.780119  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:32:16.549373  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56788
I0519 17:32:16.549461  4008 solver.cpp:415]     Test net output #1: loss = 1.85298 (* 1 = 1.85298 loss)
I0519 17:32:16.635951  4008 solver.cpp:231] Iteration 383000, loss = 1.23381
I0519 17:32:16.636041  4008 solver.cpp:247]     Train net output #0: loss = 1.23381 (* 1 = 1.23381 loss)
I0519 17:32:16.636059  4008 sgd_solver.cpp:106] Iteration 383000, lr = 1e-05
I0519 17:32:16.802649  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.1737	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:32:16.877167  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:32:16.878911  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:32:16.878948  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:32:16.893749  4008 solver.cpp:260]     Total regularization terms: 0.940407 loss+regular. : 2.17422
I0519 17:33:42.008501  4008 solver.cpp:231] Iteration 383200, loss = 1.35348
I0519 17:33:42.008829  4008 solver.cpp:247]     Train net output #0: loss = 1.35348 (* 1 = 1.35348 loss)
I0519 17:33:42.008858  4008 sgd_solver.cpp:106] Iteration 383200, lr = 1e-05
I0519 17:33:42.169117  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.1739	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:33:42.244918  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:33:42.247035  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:33:42.247056  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:33:42.262089  4008 solver.cpp:260]     Total regularization terms: 0.940404 loss+regular. : 2.29389
I0519 17:35:02.011837  4008 solver.cpp:231] Iteration 383400, loss = 1.19339
I0519 17:35:02.012122  4008 solver.cpp:247]     Train net output #0: loss = 1.19339 (* 1 = 1.19339 loss)
I0519 17:35:02.012141  4008 sgd_solver.cpp:106] Iteration 383400, lr = 1e-05
I0519 17:35:02.171937  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.1739	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:35:02.246626  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:35:02.248628  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:35:02.248661  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:35:02.258411  4008 solver.cpp:260]     Total regularization terms: 0.9404 loss+regular. : 2.13379
I0519 17:36:36.474131  4008 solver.cpp:231] Iteration 383600, loss = 1.18441
I0519 17:36:36.474496  4008 solver.cpp:247]     Train net output #0: loss = 1.18441 (* 1 = 1.18441 loss)
I0519 17:36:36.474515  4008 sgd_solver.cpp:106] Iteration 383600, lr = 1e-05
I0519 17:36:36.634693  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.174	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:36:36.709202  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:36:36.711118  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:36:36.711153  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:36:36.720957  4008 solver.cpp:260]     Total regularization terms: 0.940397 loss+regular. : 2.12481
I0519 17:37:19.150645  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:37:55.712499  4008 solver.cpp:231] Iteration 383800, loss = 1.26202
I0519 17:37:55.712832  4008 solver.cpp:247]     Train net output #0: loss = 1.26202 (* 1 = 1.26202 loss)
I0519 17:37:55.712857  4008 sgd_solver.cpp:106] Iteration 383800, lr = 1e-05
I0519 17:37:55.873374  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.174	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:37:55.947803  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:37:55.949895  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:37:55.949920  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:37:55.959511  4008 solver.cpp:260]     Total regularization terms: 0.940393 loss+regular. : 2.20241
I0519 17:39:26.741338  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_384000.caffemodel
I0519 17:40:44.119393  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_384000.solverstate
I0519 17:40:44.746755  4008 solver.cpp:348] Iteration 384000, Testing net (#0)
I0519 17:41:37.906474  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:42:02.503208  4008 solver.cpp:415]     Test net output #0: accuracy = 0.568159
I0519 17:42:02.503300  4008 solver.cpp:415]     Test net output #1: loss = 1.85373 (* 1 = 1.85373 loss)
I0519 17:42:02.591696  4008 solver.cpp:231] Iteration 384000, loss = 1.26791
I0519 17:42:02.591783  4008 solver.cpp:247]     Train net output #0: loss = 1.26791 (* 1 = 1.26791 loss)
I0519 17:42:02.591802  4008 sgd_solver.cpp:106] Iteration 384000, lr = 1e-05
I0519 17:42:02.756167  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.174	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:42:02.757879  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:42:02.759873  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:42:02.759908  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:42:02.769747  4008 solver.cpp:260]     Total regularization terms: 0.94039 loss+regular. : 2.2083
I0519 17:43:24.161314  4008 solver.cpp:231] Iteration 384200, loss = 1.34178
I0519 17:43:24.161666  4008 solver.cpp:247]     Train net output #0: loss = 1.34178 (* 1 = 1.34178 loss)
I0519 17:43:24.161686  4008 sgd_solver.cpp:106] Iteration 384200, lr = 1e-05
I0519 17:43:24.324348  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4427	0	91.1339	5.98958	89.174	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:43:24.398999  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:43:24.400859  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:43:24.400887  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:43:24.410981  4008 solver.cpp:260]     Total regularization terms: 0.940388 loss+regular. : 2.28217
I0519 17:44:49.523403  4008 solver.cpp:231] Iteration 384400, loss = 1.30755
I0519 17:44:49.523893  4008 solver.cpp:247]     Train net output #0: loss = 1.30755 (* 1 = 1.30755 loss)
I0519 17:44:49.523913  4008 sgd_solver.cpp:106] Iteration 384400, lr = 1e-05
I0519 17:44:49.686321  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.443	0	91.1339	5.98958	89.1742	0	85.2774	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:44:49.761556  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:44:49.763762  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:44:49.763799  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:44:49.773519  4008 solver.cpp:260]     Total regularization terms: 0.940383 loss+regular. : 2.24793
I0519 17:46:18.423562  4008 solver.cpp:231] Iteration 384600, loss = 1.28324
I0519 17:46:18.423889  4008 solver.cpp:247]     Train net output #0: loss = 1.28324 (* 1 = 1.28324 loss)
I0519 17:46:18.423909  4008 sgd_solver.cpp:106] Iteration 384600, lr = 1e-05
I0519 17:46:18.582541  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.443	0	91.1339	5.98958	89.1742	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:46:18.657541  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:46:18.660132  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:46:18.660173  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:46:18.670178  4008 solver.cpp:260]     Total regularization terms: 0.940381 loss+regular. : 2.22362
I0519 17:47:10.428726  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:47:42.651767  4008 solver.cpp:231] Iteration 384800, loss = 1.17456
I0519 17:47:42.652024  4008 solver.cpp:247]     Train net output #0: loss = 1.17456 (* 1 = 1.17456 loss)
I0519 17:47:42.652040  4008 sgd_solver.cpp:106] Iteration 384800, lr = 1e-05
I0519 17:47:42.812351  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.443	0	91.1339	5.98958	89.1742	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:47:42.886523  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:47:42.888257  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:47:42.888295  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:47:42.898005  4008 solver.cpp:260]     Total regularization terms: 0.940378 loss+regular. : 2.11494
I0519 17:49:08.879467  4008 solver.cpp:348] Iteration 385000, Testing net (#0)
I0519 17:50:05.025269  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:50:25.427976  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56842
I0519 17:50:25.428056  4008 solver.cpp:415]     Test net output #1: loss = 1.85398 (* 1 = 1.85398 loss)
I0519 17:50:25.514962  4008 solver.cpp:231] Iteration 385000, loss = 1.06422
I0519 17:50:25.515043  4008 solver.cpp:247]     Train net output #0: loss = 1.06422 (* 1 = 1.06422 loss)
I0519 17:50:25.515060  4008 sgd_solver.cpp:106] Iteration 385000, lr = 1e-05
I0519 17:50:25.682909  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.443	0	91.1339	5.98958	89.1742	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:50:25.757504  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:50:25.759249  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:50:25.759277  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:50:25.768995  4008 solver.cpp:260]     Total regularization terms: 0.940374 loss+regular. : 2.00459
I0519 17:51:41.492818  4008 solver.cpp:231] Iteration 385200, loss = 1.28547
I0519 17:51:41.493124  4008 solver.cpp:247]     Train net output #0: loss = 1.28547 (* 1 = 1.28547 loss)
I0519 17:51:41.493144  4008 sgd_solver.cpp:106] Iteration 385200, lr = 1e-05
I0519 17:51:41.653302  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.443	0	91.1339	5.98958	89.1742	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:51:41.728586  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:51:41.730617  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:51:41.730662  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:51:41.745898  4008 solver.cpp:260]     Total regularization terms: 0.94037 loss+regular. : 2.22584
I0519 17:53:02.493043  4008 solver.cpp:231] Iteration 385400, loss = 1.23033
I0519 17:53:02.493258  4008 solver.cpp:247]     Train net output #0: loss = 1.23033 (* 1 = 1.23033 loss)
I0519 17:53:02.493290  4008 sgd_solver.cpp:106] Iteration 385400, lr = 1e-05
I0519 17:53:02.651965  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.443	0	91.1339	5.98958	89.1742	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:53:02.727597  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:53:02.729621  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:53:02.729660  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:53:02.759575  4008 solver.cpp:260]     Total regularization terms: 0.940366 loss+regular. : 2.1707
I0519 17:54:19.888355  4008 solver.cpp:231] Iteration 385600, loss = 1.22177
I0519 17:54:19.888643  4008 solver.cpp:247]     Train net output #0: loss = 1.22177 (* 1 = 1.22177 loss)
I0519 17:54:19.888667  4008 sgd_solver.cpp:106] Iteration 385600, lr = 1e-05
I0519 17:54:20.061285  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.443	0	91.1339	5.98958	89.1742	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:54:20.136759  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:54:20.138442  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:54:20.138471  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:54:20.152292  4008 solver.cpp:260]     Total regularization terms: 0.940362 loss+regular. : 2.16213
I0519 17:55:10.572808  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:55:41.933951  4008 solver.cpp:231] Iteration 385800, loss = 1.29568
I0519 17:55:41.934252  4008 solver.cpp:247]     Train net output #0: loss = 1.29568 (* 1 = 1.29568 loss)
I0519 17:55:41.934272  4008 sgd_solver.cpp:106] Iteration 385800, lr = 1e-05
I0519 17:55:42.094183  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.443	0	91.1339	5.98958	89.1743	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:55:42.168861  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:55:42.170812  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:55:42.170845  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:55:42.180532  4008 solver.cpp:260]     Total regularization terms: 0.940356 loss+regular. : 2.23603
I0519 17:57:10.109480  4008 solver.cpp:348] Iteration 386000, Testing net (#0)
I0519 17:58:06.660001  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 17:58:26.814868  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56746
I0519 17:58:26.814997  4008 solver.cpp:415]     Test net output #1: loss = 1.8547 (* 1 = 1.8547 loss)
I0519 17:58:26.902707  4008 solver.cpp:231] Iteration 386000, loss = 1.21684
I0519 17:58:26.902794  4008 solver.cpp:247]     Train net output #0: loss = 1.21684 (* 1 = 1.21684 loss)
I0519 17:58:26.902812  4008 sgd_solver.cpp:106] Iteration 386000, lr = 1e-05
I0519 17:58:27.063838  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.443	0	91.1339	5.98958	89.1743	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:58:27.139907  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:58:27.141960  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:58:27.141996  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:58:27.152707  4008 solver.cpp:260]     Total regularization terms: 0.940353 loss+regular. : 2.15719
I0519 17:59:46.503243  4008 solver.cpp:231] Iteration 386200, loss = 1.24212
I0519 17:59:46.503618  4008 solver.cpp:247]     Train net output #0: loss = 1.24212 (* 1 = 1.24212 loss)
I0519 17:59:46.503654  4008 sgd_solver.cpp:106] Iteration 386200, lr = 1e-05
I0519 17:59:46.664137  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1339	5.98958	89.1743	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 17:59:46.742749  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 17:59:46.744274  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 17:59:46.744314  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 17:59:46.757745  4008 solver.cpp:260]     Total regularization terms: 0.940351 loss+regular. : 2.18247
I0519 18:01:06.134665  4008 solver.cpp:231] Iteration 386400, loss = 1.33707
I0519 18:01:06.135004  4008 solver.cpp:247]     Train net output #0: loss = 1.33707 (* 1 = 1.33707 loss)
I0519 18:01:06.135025  4008 sgd_solver.cpp:106] Iteration 386400, lr = 1e-05
I0519 18:01:06.296120  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1339	5.98958	89.1743	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 18:01:06.372107  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:01:06.373713  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:01:06.373742  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:01:06.388643  4008 solver.cpp:260]     Total regularization terms: 0.940347 loss+regular. : 2.27742
I0519 18:02:23.455091  4008 solver.cpp:231] Iteration 386600, loss = 1.10264
I0519 18:02:23.455432  4008 solver.cpp:247]     Train net output #0: loss = 1.10264 (* 1 = 1.10264 loss)
I0519 18:02:23.455451  4008 sgd_solver.cpp:106] Iteration 386600, lr = 1e-05
I0519 18:02:23.614806  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1339	5.98958	89.1743	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 18:02:23.690872  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:02:23.692524  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:02:23.692554  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:02:23.707371  4008 solver.cpp:260]     Total regularization terms: 0.940343 loss+regular. : 2.04298
I0519 18:03:16.063032  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:03:42.243468  4008 solver.cpp:231] Iteration 386800, loss = 1.27186
I0519 18:03:42.243579  4008 solver.cpp:247]     Train net output #0: loss = 1.27186 (* 1 = 1.27186 loss)
I0519 18:03:42.243599  4008 sgd_solver.cpp:106] Iteration 386800, lr = 1e-05
I0519 18:03:42.402407  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1339	5.98958	89.1743	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 18:03:42.478267  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:03:42.480808  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:03:42.480839  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:03:42.496011  4008 solver.cpp:260]     Total regularization terms: 0.94034 loss+regular. : 2.2122
I0519 18:05:02.703979  4008 solver.cpp:348] Iteration 387000, Testing net (#0)
I0519 18:06:00.257511  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:06:22.252885  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56808
I0519 18:06:22.252998  4008 solver.cpp:415]     Test net output #1: loss = 1.85429 (* 1 = 1.85429 loss)
I0519 18:06:22.365517  4008 solver.cpp:231] Iteration 387000, loss = 1.28699
I0519 18:06:22.365612  4008 solver.cpp:247]     Train net output #0: loss = 1.28699 (* 1 = 1.28699 loss)
I0519 18:06:22.365629  4008 sgd_solver.cpp:106] Iteration 387000, lr = 1e-05
I0519 18:06:22.537154  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1339	5.98958	89.1743	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 18:06:22.628598  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:06:22.630677  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:06:22.630704  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:06:22.653611  4008 solver.cpp:260]     Total regularization terms: 0.940335 loss+regular. : 2.22733
I0519 18:07:53.267204  4008 solver.cpp:231] Iteration 387200, loss = 1.28635
I0519 18:07:53.267452  4008 solver.cpp:247]     Train net output #0: loss = 1.28635 (* 1 = 1.28635 loss)
I0519 18:07:53.267529  4008 sgd_solver.cpp:106] Iteration 387200, lr = 1e-05
I0519 18:07:53.427175  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1339	5.98958	89.1743	0	85.2776	0	85.6067	0	78.3493	0	30.3913	2.7	
I0519 18:07:53.502416  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:07:53.505023  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:07:53.505055  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:07:53.514803  4008 solver.cpp:260]     Total regularization terms: 0.940333 loss+regular. : 2.22668
I0519 18:09:18.937886  4008 solver.cpp:231] Iteration 387400, loss = 1.12823
I0519 18:09:18.942813  4008 solver.cpp:247]     Train net output #0: loss = 1.12823 (* 1 = 1.12823 loss)
I0519 18:09:18.942842  4008 sgd_solver.cpp:106] Iteration 387400, lr = 1e-05
I0519 18:09:19.097955  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1339	5.98958	89.1745	0	85.2776	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:09:19.173394  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:09:19.175663  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:09:19.175704  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:09:19.185904  4008 solver.cpp:260]     Total regularization terms: 0.940329 loss+regular. : 2.06856
I0519 18:10:36.057799  4008 solver.cpp:231] Iteration 387600, loss = 1.28239
I0519 18:10:36.058087  4008 solver.cpp:247]     Train net output #0: loss = 1.28239 (* 1 = 1.28239 loss)
I0519 18:10:36.058109  4008 sgd_solver.cpp:106] Iteration 387600, lr = 1e-05
I0519 18:10:36.218418  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1339	5.98958	89.1745	0	85.2779	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:10:36.294457  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:10:36.297080  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:10:36.297116  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:10:36.317147  4008 solver.cpp:260]     Total regularization terms: 0.940325 loss+regular. : 2.22272
I0519 18:11:30.923434  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:11:53.891926  4008 solver.cpp:231] Iteration 387800, loss = 1.31656
I0519 18:11:53.891994  4008 solver.cpp:247]     Train net output #0: loss = 1.31656 (* 1 = 1.31656 loss)
I0519 18:11:53.892014  4008 sgd_solver.cpp:106] Iteration 387800, lr = 1e-05
I0519 18:11:54.051617  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1339	5.98958	89.1745	0	85.2779	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:11:54.126662  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:11:54.129272  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:11:54.129312  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:11:54.139152  4008 solver.cpp:260]     Total regularization terms: 0.940321 loss+regular. : 2.25688
I0519 18:13:08.751505  4008 solver.cpp:348] Iteration 388000, Testing net (#0)
I0519 18:14:07.236098  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:14:26.504281  4008 solver.cpp:415]     Test net output #0: accuracy = 0.568479
I0519 18:14:26.504371  4008 solver.cpp:415]     Test net output #1: loss = 1.85324 (* 1 = 1.85324 loss)
I0519 18:14:26.591393  4008 solver.cpp:231] Iteration 388000, loss = 1.12759
I0519 18:14:26.591509  4008 solver.cpp:247]     Train net output #0: loss = 1.12759 (* 1 = 1.12759 loss)
I0519 18:14:26.591529  4008 sgd_solver.cpp:106] Iteration 388000, lr = 1e-05
I0519 18:14:26.758944  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1339	5.98958	89.1745	0	85.2779	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:14:26.833540  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:14:26.835502  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:14:26.835542  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:14:26.845307  4008 solver.cpp:260]     Total regularization terms: 0.940316 loss+regular. : 2.0679
I0519 18:15:43.192293  4008 solver.cpp:231] Iteration 388200, loss = 1.36248
I0519 18:15:43.192714  4008 solver.cpp:247]     Train net output #0: loss = 1.36248 (* 1 = 1.36248 loss)
I0519 18:15:43.192745  4008 sgd_solver.cpp:106] Iteration 388200, lr = 1e-05
I0519 18:15:43.351119  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1745	0	85.2781	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:15:43.426316  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:15:43.428375  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:15:43.428411  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:15:43.443476  4008 solver.cpp:260]     Total regularization terms: 0.940314 loss+regular. : 2.3028
I0519 18:16:59.134572  4008 solver.cpp:231] Iteration 388400, loss = 1.24153
I0519 18:16:59.134949  4008 solver.cpp:247]     Train net output #0: loss = 1.24153 (* 1 = 1.24153 loss)
I0519 18:16:59.134970  4008 sgd_solver.cpp:106] Iteration 388400, lr = 1e-05
I0519 18:16:59.295392  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1746	0	85.2781	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:16:59.370770  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:16:59.373522  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:16:59.373574  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:16:59.383285  4008 solver.cpp:260]     Total regularization terms: 0.94031 loss+regular. : 2.18184
I0519 18:18:17.036579  4008 solver.cpp:231] Iteration 388600, loss = 1.21962
I0519 18:18:17.037071  4008 solver.cpp:247]     Train net output #0: loss = 1.21962 (* 1 = 1.21962 loss)
I0519 18:18:17.037101  4008 sgd_solver.cpp:106] Iteration 388600, lr = 1e-05
I0519 18:18:17.197337  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1746	0	85.2781	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:18:17.274195  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:18:17.276130  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:18:17.276152  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:18:17.285730  4008 solver.cpp:260]     Total regularization terms: 0.940307 loss+regular. : 2.15993
I0519 18:19:14.917119  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:19:39.738934  4008 solver.cpp:231] Iteration 388800, loss = 1.24547
I0519 18:19:39.739042  4008 solver.cpp:247]     Train net output #0: loss = 1.24547 (* 1 = 1.24547 loss)
I0519 18:19:39.739063  4008 sgd_solver.cpp:106] Iteration 388800, lr = 1e-05
I0519 18:19:39.898988  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1746	0	85.2781	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:19:39.974686  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:19:39.976418  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:19:39.976457  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:19:39.991380  4008 solver.cpp:260]     Total regularization terms: 0.940304 loss+regular. : 2.18577
I0519 18:21:02.581316  4008 solver.cpp:348] Iteration 389000, Testing net (#0)
I0519 18:22:05.481525  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:22:28.946879  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56796
I0519 18:22:28.946971  4008 solver.cpp:415]     Test net output #1: loss = 1.85395 (* 1 = 1.85395 loss)
I0519 18:22:29.037664  4008 solver.cpp:231] Iteration 389000, loss = 1.3159
I0519 18:22:29.037747  4008 solver.cpp:247]     Train net output #0: loss = 1.3159 (* 1 = 1.3159 loss)
I0519 18:22:29.037766  4008 sgd_solver.cpp:106] Iteration 389000, lr = 1e-05
I0519 18:22:29.202155  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1746	0	85.2781	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:22:29.277333  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:22:29.279376  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:22:29.279415  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:22:29.289165  4008 solver.cpp:260]     Total regularization terms: 0.9403 loss+regular. : 2.2562
I0519 18:23:48.883931  4008 solver.cpp:231] Iteration 389200, loss = 1.22983
I0519 18:23:48.884239  4008 solver.cpp:247]     Train net output #0: loss = 1.22983 (* 1 = 1.22983 loss)
I0519 18:23:48.884259  4008 sgd_solver.cpp:106] Iteration 389200, lr = 1e-05
I0519 18:23:49.043676  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:23:49.118279  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:23:49.120380  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:23:49.120409  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:23:49.130197  4008 solver.cpp:260]     Total regularization terms: 0.940298 loss+regular. : 2.17013
I0519 18:25:11.883993  4008 solver.cpp:231] Iteration 389400, loss = 1.01147
I0519 18:25:11.884258  4008 solver.cpp:247]     Train net output #0: loss = 1.01147 (* 1 = 1.01147 loss)
I0519 18:25:11.884276  4008 sgd_solver.cpp:106] Iteration 389400, lr = 1e-05
I0519 18:25:12.044695  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:25:12.120427  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:25:12.122599  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:25:12.122642  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:25:12.137698  4008 solver.cpp:260]     Total regularization terms: 0.940293 loss+regular. : 1.95177
I0519 18:26:34.053014  4008 solver.cpp:231] Iteration 389600, loss = 1.07337
I0519 18:26:34.053427  4008 solver.cpp:247]     Train net output #0: loss = 1.07337 (* 1 = 1.07337 loss)
I0519 18:26:34.053459  4008 sgd_solver.cpp:106] Iteration 389600, lr = 1e-05
I0519 18:26:34.213696  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:26:34.289206  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:26:34.291399  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:26:34.291431  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:26:34.306371  4008 solver.cpp:260]     Total regularization terms: 0.94029 loss+regular. : 2.01366
I0519 18:27:33.263491  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:27:53.229291  4008 solver.cpp:231] Iteration 389800, loss = 1.15249
I0519 18:27:53.229383  4008 solver.cpp:247]     Train net output #0: loss = 1.15249 (* 1 = 1.15249 loss)
I0519 18:27:53.229401  4008 sgd_solver.cpp:106] Iteration 389800, lr = 1e-05
I0519 18:27:53.389797  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:27:53.467555  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:27:53.469275  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:27:53.469300  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:27:53.484647  4008 solver.cpp:260]     Total regularization terms: 0.940288 loss+regular. : 2.09278
I0519 18:29:15.510360  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_390000.caffemodel
I0519 18:30:29.269529  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_390000.solverstate
I0519 18:30:30.077750  4008 solver.cpp:348] Iteration 390000, Testing net (#0)
I0519 18:31:34.139642  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:31:54.876088  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56846
I0519 18:31:54.876191  4008 solver.cpp:415]     Test net output #1: loss = 1.85409 (* 1 = 1.85409 loss)
I0519 18:31:54.963721  4008 solver.cpp:231] Iteration 390000, loss = 1.31857
I0519 18:31:54.963814  4008 solver.cpp:247]     Train net output #0: loss = 1.31857 (* 1 = 1.31857 loss)
I0519 18:31:54.963845  4008 sgd_solver.cpp:106] Iteration 390000, lr = 1e-05
I0519 18:31:55.134999  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:31:55.136699  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:31:55.138667  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:31:55.138697  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:31:55.148532  4008 solver.cpp:260]     Total regularization terms: 0.940284 loss+regular. : 2.25885
I0519 18:33:15.279309  4008 solver.cpp:231] Iteration 390200, loss = 1.09963
I0519 18:33:15.279708  4008 solver.cpp:247]     Train net output #0: loss = 1.09963 (* 1 = 1.09963 loss)
I0519 18:33:15.279742  4008 sgd_solver.cpp:106] Iteration 390200, lr = 1e-05
I0519 18:33:15.439983  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:33:15.514055  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:33:15.515605  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:33:15.515627  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:33:15.525239  4008 solver.cpp:260]     Total regularization terms: 0.940279 loss+regular. : 2.03991
I0519 18:34:31.826617  4008 solver.cpp:231] Iteration 390400, loss = 1.38091
I0519 18:34:31.826997  4008 solver.cpp:247]     Train net output #0: loss = 1.38091 (* 1 = 1.38091 loss)
I0519 18:34:31.827016  4008 sgd_solver.cpp:106] Iteration 390400, lr = 1e-05
I0519 18:34:31.989233  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:34:32.065246  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:34:32.068119  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:34:32.068161  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:34:32.088778  4008 solver.cpp:260]     Total regularization terms: 0.940275 loss+regular. : 2.32118
I0519 18:35:50.196228  4008 solver.cpp:231] Iteration 390600, loss = 1.37807
I0519 18:35:50.196540  4008 solver.cpp:247]     Train net output #0: loss = 1.37807 (* 1 = 1.37807 loss)
I0519 18:35:50.196562  4008 sgd_solver.cpp:106] Iteration 390600, lr = 1e-05
I0519 18:35:50.356379  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:35:50.432695  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:35:50.435040  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:35:50.435080  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:35:50.464594  4008 solver.cpp:260]     Total regularization terms: 0.940272 loss+regular. : 2.31834
I0519 18:36:49.282027  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:37:04.435494  4008 solver.cpp:231] Iteration 390800, loss = 1.55608
I0519 18:37:04.435585  4008 solver.cpp:247]     Train net output #0: loss = 1.55608 (* 1 = 1.55608 loss)
I0519 18:37:04.435602  4008 sgd_solver.cpp:106] Iteration 390800, lr = 1e-05
I0519 18:37:04.597223  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:37:04.673913  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:37:04.676591  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:37:04.676630  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:37:04.697726  4008 solver.cpp:260]     Total regularization terms: 0.940267 loss+regular. : 2.49635
I0519 18:38:21.635242  4008 solver.cpp:348] Iteration 391000, Testing net (#0)
I0519 18:39:22.508059  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:39:40.872215  4008 solver.cpp:415]     Test net output #0: accuracy = 0.568119
I0519 18:39:40.872295  4008 solver.cpp:415]     Test net output #1: loss = 1.85363 (* 1 = 1.85363 loss)
I0519 18:39:40.959877  4008 solver.cpp:231] Iteration 391000, loss = 1.06423
I0519 18:39:40.959945  4008 solver.cpp:247]     Train net output #0: loss = 1.06423 (* 1 = 1.06423 loss)
I0519 18:39:40.959964  4008 sgd_solver.cpp:106] Iteration 391000, lr = 1e-05
I0519 18:39:41.125218  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:39:41.200868  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:39:41.203450  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:39:41.203490  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:39:41.213346  4008 solver.cpp:260]     Total regularization terms: 0.940262 loss+regular. : 2.00449
I0519 18:41:02.817023  4008 solver.cpp:231] Iteration 391200, loss = 1.14346
I0519 18:41:02.817515  4008 solver.cpp:247]     Train net output #0: loss = 1.14346 (* 1 = 1.14346 loss)
I0519 18:41:02.817534  4008 sgd_solver.cpp:106] Iteration 391200, lr = 1e-05
I0519 18:41:02.978255  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:41:03.052809  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:41:03.054852  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:41:03.054890  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:41:03.064977  4008 solver.cpp:260]     Total regularization terms: 0.94026 loss+regular. : 2.08372
I0519 18:42:25.547348  4008 solver.cpp:231] Iteration 391400, loss = 1.34075
I0519 18:42:25.549204  4008 solver.cpp:247]     Train net output #0: loss = 1.34075 (* 1 = 1.34075 loss)
I0519 18:42:25.549231  4008 sgd_solver.cpp:106] Iteration 391400, lr = 1e-05
I0519 18:42:25.708149  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2783	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:42:25.783252  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:42:25.785245  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:42:25.785274  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:42:25.799562  4008 solver.cpp:260]     Total regularization terms: 0.940256 loss+regular. : 2.28101
I0519 18:43:43.874588  4008 solver.cpp:231] Iteration 391600, loss = 1.19839
I0519 18:43:43.875890  4008 solver.cpp:247]     Train net output #0: loss = 1.19839 (* 1 = 1.19839 loss)
I0519 18:43:43.875922  4008 sgd_solver.cpp:106] Iteration 391600, lr = 1e-05
I0519 18:43:44.040588  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.134	5.98958	89.1748	0	85.2785	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:43:44.115686  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:43:44.117950  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:43:44.117990  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:43:44.128387  4008 solver.cpp:260]     Total regularization terms: 0.940253 loss+regular. : 2.13865
I0519 18:44:51.425058  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:45:07.330463  4008 solver.cpp:231] Iteration 391800, loss = 1.4776
I0519 18:45:07.330550  4008 solver.cpp:247]     Train net output #0: loss = 1.4776 (* 1 = 1.4776 loss)
I0519 18:45:07.330569  4008 sgd_solver.cpp:106] Iteration 391800, lr = 1e-05
I0519 18:45:07.488767  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1341	5.98958	89.1748	0	85.2785	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:45:07.564626  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:45:07.567317  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:45:07.567359  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:45:07.577144  4008 solver.cpp:260]     Total regularization terms: 0.94025 loss+regular. : 2.41784
I0519 18:46:31.645423  4008 solver.cpp:348] Iteration 392000, Testing net (#0)
I0519 18:47:34.236577  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:47:53.716060  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56814
I0519 18:47:53.716147  4008 solver.cpp:415]     Test net output #1: loss = 1.85375 (* 1 = 1.85375 loss)
I0519 18:47:53.804623  4008 solver.cpp:231] Iteration 392000, loss = 1.11149
I0519 18:47:53.804709  4008 solver.cpp:247]     Train net output #0: loss = 1.11149 (* 1 = 1.11149 loss)
I0519 18:47:53.804726  4008 sgd_solver.cpp:106] Iteration 392000, lr = 1e-05
I0519 18:47:53.965014  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1341	5.98958	89.1748	0	85.2785	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:47:54.039717  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:47:54.041760  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:47:54.041795  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:47:54.058763  4008 solver.cpp:260]     Total regularization terms: 0.940245 loss+regular. : 2.05174
I0519 18:49:10.827775  4008 solver.cpp:231] Iteration 392200, loss = 1.01644
I0519 18:49:10.828068  4008 solver.cpp:247]     Train net output #0: loss = 1.01644 (* 1 = 1.01644 loss)
I0519 18:49:10.828085  4008 sgd_solver.cpp:106] Iteration 392200, lr = 1e-05
I0519 18:49:10.988221  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1341	5.98958	89.1748	0	85.2788	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:49:11.063132  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:49:11.065055  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:49:11.065089  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:49:11.076407  4008 solver.cpp:260]     Total regularization terms: 0.940241 loss+regular. : 1.95668
I0519 18:50:28.637151  4008 solver.cpp:231] Iteration 392400, loss = 1.41337
I0519 18:50:28.637418  4008 solver.cpp:247]     Train net output #0: loss = 1.41337 (* 1 = 1.41337 loss)
I0519 18:50:28.637439  4008 sgd_solver.cpp:106] Iteration 392400, lr = 1e-05
I0519 18:50:28.796947  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1341	5.98958	89.1748	0	85.2788	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:50:28.872871  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:50:28.875381  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:50:28.875425  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:50:28.890713  4008 solver.cpp:260]     Total regularization terms: 0.940238 loss+regular. : 2.35361
I0519 18:51:54.933698  4008 solver.cpp:231] Iteration 392600, loss = 1.14763
I0519 18:51:54.935899  4008 solver.cpp:247]     Train net output #0: loss = 1.14763 (* 1 = 1.14763 loss)
I0519 18:51:54.935926  4008 sgd_solver.cpp:106] Iteration 392600, lr = 1e-05
I0519 18:51:55.093055  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4434	0	91.1341	5.98958	89.1748	0	85.2788	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:51:55.168725  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:51:55.170742  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:51:55.170776  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:51:55.185914  4008 solver.cpp:260]     Total regularization terms: 0.940234 loss+regular. : 2.08787
I0519 18:53:07.643236  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:53:19.318788  4008 solver.cpp:231] Iteration 392800, loss = 1.23241
I0519 18:53:19.318882  4008 solver.cpp:247]     Train net output #0: loss = 1.23241 (* 1 = 1.23241 loss)
I0519 18:53:19.318922  4008 sgd_solver.cpp:106] Iteration 392800, lr = 1e-05
I0519 18:53:19.478642  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1342	5.98958	89.1748	0	85.2788	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:53:19.553323  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:53:19.555335  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:53:19.555372  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:53:19.575453  4008 solver.cpp:260]     Total regularization terms: 0.940232 loss+regular. : 2.17264
I0519 18:54:41.119012  4008 solver.cpp:348] Iteration 393000, Testing net (#0)
I0519 18:55:48.308087  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 18:56:05.252041  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56812
I0519 18:56:05.252130  4008 solver.cpp:415]     Test net output #1: loss = 1.85379 (* 1 = 1.85379 loss)
I0519 18:56:05.339537  4008 solver.cpp:231] Iteration 393000, loss = 1.21214
I0519 18:56:05.339620  4008 solver.cpp:247]     Train net output #0: loss = 1.21214 (* 1 = 1.21214 loss)
I0519 18:56:05.339638  4008 sgd_solver.cpp:106] Iteration 393000, lr = 1e-05
I0519 18:56:05.507858  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1342	5.98958	89.1748	0	85.2788	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:56:05.582556  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:56:05.584650  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:56:05.584681  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:56:05.594470  4008 solver.cpp:260]     Total regularization terms: 0.940228 loss+regular. : 2.15237
I0519 18:57:19.183866  4008 solver.cpp:231] Iteration 393200, loss = 1.2708
I0519 18:57:19.184149  4008 solver.cpp:247]     Train net output #0: loss = 1.2708 (* 1 = 1.2708 loss)
I0519 18:57:19.184168  4008 sgd_solver.cpp:106] Iteration 393200, lr = 1e-05
I0519 18:57:19.343155  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1342	5.98958	89.1749	0	85.2788	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:57:19.417860  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:57:19.419627  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:57:19.419662  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:57:19.429499  4008 solver.cpp:260]     Total regularization terms: 0.940225 loss+regular. : 2.21102
I0519 18:58:35.856326  4008 solver.cpp:231] Iteration 393400, loss = 1.19699
I0519 18:58:35.856621  4008 solver.cpp:247]     Train net output #0: loss = 1.19699 (* 1 = 1.19699 loss)
I0519 18:58:35.856642  4008 sgd_solver.cpp:106] Iteration 393400, lr = 1e-05
I0519 18:58:36.016954  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1342	5.98958	89.1749	0	85.2788	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:58:36.092108  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:58:36.094724  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:58:36.094756  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:58:36.109905  4008 solver.cpp:260]     Total regularization terms: 0.94022 loss+regular. : 2.13721
I0519 18:59:50.345109  4008 solver.cpp:231] Iteration 393600, loss = 1.26245
I0519 18:59:50.345376  4008 solver.cpp:247]     Train net output #0: loss = 1.26245 (* 1 = 1.26245 loss)
I0519 18:59:50.345396  4008 sgd_solver.cpp:106] Iteration 393600, lr = 1e-05
I0519 18:59:50.505496  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1343	5.98958	89.1751	0	85.2788	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 18:59:50.580687  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 18:59:50.583010  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 18:59:50.583047  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 18:59:50.592798  4008 solver.cpp:260]     Total regularization terms: 0.940218 loss+regular. : 2.20267
I0519 19:01:01.922798  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:01:09.351990  4008 solver.cpp:231] Iteration 393800, loss = 1.34167
I0519 19:01:09.352066  4008 solver.cpp:247]     Train net output #0: loss = 1.34167 (* 1 = 1.34167 loss)
I0519 19:01:09.352085  4008 sgd_solver.cpp:106] Iteration 393800, lr = 1e-05
I0519 19:01:09.512374  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1343	5.98958	89.1751	0	85.2788	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 19:01:09.588032  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:01:09.590399  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:01:09.590426  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:01:09.605398  4008 solver.cpp:260]     Total regularization terms: 0.940214 loss+regular. : 2.28188
I0519 19:02:32.031280  4008 solver.cpp:348] Iteration 394000, Testing net (#0)
I0519 19:03:31.383107  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:03:47.926844  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56808
I0519 19:03:47.926939  4008 solver.cpp:415]     Test net output #1: loss = 1.85385 (* 1 = 1.85385 loss)
I0519 19:03:48.013949  4008 solver.cpp:231] Iteration 394000, loss = 1.14923
I0519 19:03:48.014040  4008 solver.cpp:247]     Train net output #0: loss = 1.14923 (* 1 = 1.14923 loss)
I0519 19:03:48.014055  4008 sgd_solver.cpp:106] Iteration 394000, lr = 1e-05
I0519 19:03:48.178833  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1344	5.98958	89.1751	0	85.2788	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 19:03:48.253643  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:03:48.255496  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:03:48.255527  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:03:48.265328  4008 solver.cpp:260]     Total regularization terms: 0.940212 loss+regular. : 2.08944
I0519 19:05:02.532217  4008 solver.cpp:231] Iteration 394200, loss = 1.27461
I0519 19:05:02.532526  4008 solver.cpp:247]     Train net output #0: loss = 1.27461 (* 1 = 1.27461 loss)
I0519 19:05:02.532546  4008 sgd_solver.cpp:106] Iteration 394200, lr = 1e-05
I0519 19:05:02.692152  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1344	5.98958	89.1751	0	85.2788	0	85.6067	0	78.3494	0	30.3914	2.7	
I0519 19:05:02.767334  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.12674	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:05:02.769532  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:05:02.769588  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:05:02.779585  4008 solver.cpp:260]     Total regularization terms: 0.940209 loss+regular. : 2.21482
I0519 19:06:27.029438  4008 solver.cpp:231] Iteration 394400, loss = 1.08608
I0519 19:06:27.029779  4008 solver.cpp:247]     Train net output #0: loss = 1.08608 (* 1 = 1.08608 loss)
I0519 19:06:27.029803  4008 sgd_solver.cpp:106] Iteration 394400, lr = 1e-05
I0519 19:06:27.191222  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1345	5.98958	89.1751	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:06:27.266752  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:06:27.268796  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:06:27.268821  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:06:27.282312  4008 solver.cpp:260]     Total regularization terms: 0.940204 loss+regular. : 2.02629
I0519 19:07:51.661576  4008 solver.cpp:231] Iteration 394600, loss = 1.13005
I0519 19:07:51.663852  4008 solver.cpp:247]     Train net output #0: loss = 1.13005 (* 1 = 1.13005 loss)
I0519 19:07:51.663875  4008 sgd_solver.cpp:106] Iteration 394600, lr = 1e-05
I0519 19:07:51.822985  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1346	5.98958	89.1751	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:07:51.898844  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:07:51.901007  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:07:51.901046  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:07:51.916136  4008 solver.cpp:260]     Total regularization terms: 0.940201 loss+regular. : 2.07025
I0519 19:09:15.195073  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:09:21.461565  4008 solver.cpp:231] Iteration 394800, loss = 1.23022
I0519 19:09:21.461642  4008 solver.cpp:247]     Train net output #0: loss = 1.23022 (* 1 = 1.23022 loss)
I0519 19:09:21.461661  4008 sgd_solver.cpp:106] Iteration 394800, lr = 1e-05
I0519 19:09:21.621479  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1346	5.98958	89.1751	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:09:21.696748  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:09:21.699216  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:09:21.699259  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:09:21.709017  4008 solver.cpp:260]     Total regularization terms: 0.940198 loss+regular. : 2.17042
I0519 19:10:40.756575  4008 solver.cpp:348] Iteration 395000, Testing net (#0)
I0519 19:11:41.002326  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:11:57.630812  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56852
I0519 19:11:57.630902  4008 solver.cpp:415]     Test net output #1: loss = 1.85333 (* 1 = 1.85333 loss)
I0519 19:11:57.718183  4008 solver.cpp:231] Iteration 395000, loss = 1.24257
I0519 19:11:57.718302  4008 solver.cpp:247]     Train net output #0: loss = 1.24257 (* 1 = 1.24257 loss)
I0519 19:11:57.718320  4008 sgd_solver.cpp:106] Iteration 395000, lr = 1e-05
I0519 19:11:57.882740  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1346	5.98958	89.1751	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:11:57.957562  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:11:57.959563  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:11:57.959597  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:11:57.969404  4008 solver.cpp:260]     Total regularization terms: 0.940194 loss+regular. : 2.18276
I0519 19:13:14.263274  4008 solver.cpp:231] Iteration 395200, loss = 1.19592
I0519 19:13:14.263586  4008 solver.cpp:247]     Train net output #0: loss = 1.19592 (* 1 = 1.19592 loss)
I0519 19:13:14.263613  4008 sgd_solver.cpp:106] Iteration 395200, lr = 1e-05
I0519 19:13:14.423039  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1346	5.98958	89.1752	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:13:14.497948  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:13:14.500109  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:13:14.500146  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:13:14.510138  4008 solver.cpp:260]     Total regularization terms: 0.94019 loss+regular. : 2.13611
I0519 19:14:35.613667  4008 solver.cpp:231] Iteration 395400, loss = 1.14873
I0519 19:14:35.613924  4008 solver.cpp:247]     Train net output #0: loss = 1.14873 (* 1 = 1.14873 loss)
I0519 19:14:35.613946  4008 sgd_solver.cpp:106] Iteration 395400, lr = 1e-05
I0519 19:14:35.774704  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1346	5.98958	89.1752	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:14:35.850201  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:14:35.852082  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:14:35.852116  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:14:35.867158  4008 solver.cpp:260]     Total regularization terms: 0.940187 loss+regular. : 2.08891
I0519 19:16:04.009937  4008 solver.cpp:231] Iteration 395600, loss = 1.23555
I0519 19:16:04.010289  4008 solver.cpp:247]     Train net output #0: loss = 1.23555 (* 1 = 1.23555 loss)
I0519 19:16:04.010316  4008 sgd_solver.cpp:106] Iteration 395600, lr = 1e-05
I0519 19:16:04.169512  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1346	5.98958	89.1752	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:16:04.245404  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:16:04.248390  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:16:04.248431  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:16:04.258224  4008 solver.cpp:260]     Total regularization terms: 0.940184 loss+regular. : 2.17573
I0519 19:17:26.713277  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:17:28.998172  4008 solver.cpp:231] Iteration 395800, loss = 1.24143
I0519 19:17:28.998246  4008 solver.cpp:247]     Train net output #0: loss = 1.24143 (* 1 = 1.24143 loss)
I0519 19:17:28.998261  4008 sgd_solver.cpp:106] Iteration 395800, lr = 1e-05
I0519 19:17:29.157166  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1346	5.98958	89.1752	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:17:29.232903  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:17:29.234956  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:17:29.234989  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:17:29.255553  4008 solver.cpp:260]     Total regularization terms: 0.940178 loss+regular. : 2.1816
I0519 19:18:59.037822  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_396000.caffemodel
I0519 19:19:39.546640  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_396000.solverstate
I0519 19:19:40.117038  4008 solver.cpp:348] Iteration 396000, Testing net (#0)
I0519 19:20:36.947263  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:20:51.628185  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56752
I0519 19:20:51.628312  4008 solver.cpp:415]     Test net output #1: loss = 1.85406 (* 1 = 1.85406 loss)
I0519 19:20:51.716483  4008 solver.cpp:231] Iteration 396000, loss = 1.41573
I0519 19:20:51.716583  4008 solver.cpp:247]     Train net output #0: loss = 1.41573 (* 1 = 1.41573 loss)
I0519 19:20:51.716616  4008 sgd_solver.cpp:106] Iteration 396000, lr = 1e-05
I0519 19:20:51.875937  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1346	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:20:51.877713  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:20:51.879647  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:20:51.879678  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:20:51.895428  4008 solver.cpp:260]     Total regularization terms: 0.940174 loss+regular. : 2.35591
I0519 19:22:12.688558  4008 solver.cpp:231] Iteration 396200, loss = 1.16551
I0519 19:22:12.689009  4008 solver.cpp:247]     Train net output #0: loss = 1.16551 (* 1 = 1.16551 loss)
I0519 19:22:12.689030  4008 sgd_solver.cpp:106] Iteration 396200, lr = 1e-05
I0519 19:22:12.849382  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1346	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:22:12.924142  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:22:12.925750  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:22:12.925786  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:22:12.935484  4008 solver.cpp:260]     Total regularization terms: 0.940172 loss+regular. : 2.10568
I0519 19:23:39.185075  4008 solver.cpp:231] Iteration 396400, loss = 1.41361
I0519 19:23:39.185426  4008 solver.cpp:247]     Train net output #0: loss = 1.41361 (* 1 = 1.41361 loss)
I0519 19:23:39.185451  4008 sgd_solver.cpp:106] Iteration 396400, lr = 1e-05
I0519 19:23:39.346554  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4437	0	91.1346	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:23:39.421375  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:23:39.423496  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:23:39.423524  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:23:39.437129  4008 solver.cpp:260]     Total regularization terms: 0.940168 loss+regular. : 2.35378
I0519 19:24:58.122874  4008 solver.cpp:231] Iteration 396600, loss = 1.14491
I0519 19:24:58.123142  4008 solver.cpp:247]     Train net output #0: loss = 1.14491 (* 1 = 1.14491 loss)
I0519 19:24:58.123162  4008 sgd_solver.cpp:106] Iteration 396600, lr = 1e-05
I0519 19:24:58.285209  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.444	0	91.1346	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:24:58.361753  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:24:58.364569  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:24:58.364608  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:24:58.379534  4008 solver.cpp:260]     Total regularization terms: 0.940164 loss+regular. : 2.08507
I0519 19:26:20.986232  4008 solver.cpp:231] Iteration 396800, loss = 1.35197
I0519 19:26:20.986552  4008 solver.cpp:247]     Train net output #0: loss = 1.35197 (* 1 = 1.35197 loss)
I0519 19:26:20.986577  4008 sgd_solver.cpp:106] Iteration 396800, lr = 1e-05
I0519 19:26:21.147161  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.444	0	91.1346	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:26:21.222306  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:26:21.224814  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:26:21.224848  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:26:21.234704  4008 solver.cpp:260]     Total regularization terms: 0.940161 loss+regular. : 2.29213
I0519 19:26:21.658536  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:27:51.563740  4008 solver.cpp:348] Iteration 397000, Testing net (#0)
I0519 19:29:04.498810  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:29:19.084498  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56784
I0519 19:29:19.084584  4008 solver.cpp:415]     Test net output #1: loss = 1.85365 (* 1 = 1.85365 loss)
I0519 19:29:19.172103  4008 solver.cpp:231] Iteration 397000, loss = 1.5696
I0519 19:29:19.172175  4008 solver.cpp:247]     Train net output #0: loss = 1.5696 (* 1 = 1.5696 loss)
I0519 19:29:19.172193  4008 sgd_solver.cpp:106] Iteration 397000, lr = 1e-05
I0519 19:29:19.334188  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1346	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:29:19.410167  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:29:19.412286  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:29:19.412317  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:29:19.422077  4008 solver.cpp:260]     Total regularization terms: 0.940157 loss+regular. : 2.50976
I0519 19:30:44.169371  4008 solver.cpp:231] Iteration 397200, loss = 1.2275
I0519 19:30:44.172332  4008 solver.cpp:247]     Train net output #0: loss = 1.2275 (* 1 = 1.2275 loss)
I0519 19:30:44.172358  4008 sgd_solver.cpp:106] Iteration 397200, lr = 1e-05
I0519 19:30:44.329653  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1346	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3494	0	30.3914	2.7	
I0519 19:30:44.404141  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:30:44.405891  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:30:44.405920  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:30:44.415536  4008 solver.cpp:260]     Total regularization terms: 0.940154 loss+regular. : 2.16766
I0519 19:32:03.881227  4008 solver.cpp:231] Iteration 397400, loss = 1.24841
I0519 19:32:03.881476  4008 solver.cpp:247]     Train net output #0: loss = 1.24841 (* 1 = 1.24841 loss)
I0519 19:32:03.881495  4008 sgd_solver.cpp:106] Iteration 397400, lr = 1e-05
I0519 19:32:04.041749  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1348	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3494	0	30.3915	2.7	
I0519 19:32:04.116726  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:32:04.119251  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:32:04.119392  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:32:04.129410  4008 solver.cpp:260]     Total regularization terms: 0.94015 loss+regular. : 2.18856
I0519 19:33:25.239009  4008 solver.cpp:231] Iteration 397600, loss = 1.1613
I0519 19:33:25.239173  4008 solver.cpp:247]     Train net output #0: loss = 1.1613 (* 1 = 1.1613 loss)
I0519 19:33:25.239194  4008 sgd_solver.cpp:106] Iteration 397600, lr = 1e-05
I0519 19:33:25.402040  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1348	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3494	0	30.3915	2.7	
I0519 19:33:25.478546  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:33:25.481215  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:33:25.481261  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:33:25.494802  4008 solver.cpp:260]     Total regularization terms: 0.940147 loss+regular. : 2.10144
I0519 19:34:49.039537  4008 solver.cpp:231] Iteration 397800, loss = 1.12652
I0519 19:34:49.039868  4008 solver.cpp:247]     Train net output #0: loss = 1.12652 (* 1 = 1.12652 loss)
I0519 19:34:49.039901  4008 sgd_solver.cpp:106] Iteration 397800, lr = 1e-05
I0519 19:34:49.200192  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1348	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:34:49.275913  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:34:49.277640  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:34:49.277662  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:34:49.300161  4008 solver.cpp:260]     Total regularization terms: 0.940143 loss+regular. : 2.06666
I0519 19:34:52.562484  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:36:14.886006  4008 solver.cpp:348] Iteration 398000, Testing net (#0)
I0519 19:37:12.787078  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:37:27.578820  4008 solver.cpp:415]     Test net output #0: accuracy = 0.568019
I0519 19:37:27.578909  4008 solver.cpp:415]     Test net output #1: loss = 1.85287 (* 1 = 1.85287 loss)
I0519 19:37:27.666331  4008 solver.cpp:231] Iteration 398000, loss = 1.20037
I0519 19:37:27.666404  4008 solver.cpp:247]     Train net output #0: loss = 1.20037 (* 1 = 1.20037 loss)
I0519 19:37:27.666424  4008 sgd_solver.cpp:106] Iteration 398000, lr = 1e-05
I0519 19:37:27.834265  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:37:27.909301  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:37:27.912111  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:37:27.912153  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:37:27.927075  4008 solver.cpp:260]     Total regularization terms: 0.940138 loss+regular. : 2.14051
I0519 19:38:47.415051  4008 solver.cpp:231] Iteration 398200, loss = 1.29344
I0519 19:38:47.415359  4008 solver.cpp:247]     Train net output #0: loss = 1.29344 (* 1 = 1.29344 loss)
I0519 19:38:47.415381  4008 sgd_solver.cpp:106] Iteration 398200, lr = 1e-05
I0519 19:38:47.575397  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:38:47.650738  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:38:47.652506  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:38:47.652530  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:38:47.666734  4008 solver.cpp:260]     Total regularization terms: 0.940135 loss+regular. : 2.23358
I0519 19:40:02.286882  4008 solver.cpp:231] Iteration 398400, loss = 1.21128
I0519 19:40:02.288794  4008 solver.cpp:247]     Train net output #0: loss = 1.21128 (* 1 = 1.21128 loss)
I0519 19:40:02.288816  4008 sgd_solver.cpp:106] Iteration 398400, lr = 1e-05
I0519 19:40:02.447654  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:40:02.522917  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:40:02.524370  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:40:02.524386  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:40:02.545469  4008 solver.cpp:260]     Total regularization terms: 0.940131 loss+regular. : 2.15142
I0519 19:41:16.739286  4008 solver.cpp:231] Iteration 398600, loss = 1.26831
I0519 19:41:16.739528  4008 solver.cpp:247]     Train net output #0: loss = 1.26831 (* 1 = 1.26831 loss)
I0519 19:41:16.739548  4008 sgd_solver.cpp:106] Iteration 398600, lr = 1e-05
I0519 19:41:16.900089  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:41:16.974705  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:41:16.976704  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:41:16.976737  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:41:16.986569  4008 solver.cpp:260]     Total regularization terms: 0.940129 loss+regular. : 2.20844
I0519 19:42:32.359792  4008 solver.cpp:231] Iteration 398800, loss = 1.28768
I0519 19:42:32.360136  4008 solver.cpp:247]     Train net output #0: loss = 1.28768 (* 1 = 1.28768 loss)
I0519 19:42:32.360157  4008 sgd_solver.cpp:106] Iteration 398800, lr = 1e-05
I0519 19:42:32.521337  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:42:32.595950  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:42:32.597916  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:42:32.597945  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:42:32.607628  4008 solver.cpp:260]     Total regularization terms: 0.940125 loss+regular. : 2.22781
I0519 19:42:39.231245  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:43:46.484002  4008 solver.cpp:348] Iteration 399000, Testing net (#0)
I0519 19:45:07.344300  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:45:22.831037  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56854
I0519 19:45:22.831127  4008 solver.cpp:415]     Test net output #1: loss = 1.8532 (* 1 = 1.8532 loss)
I0519 19:45:22.919863  4008 solver.cpp:231] Iteration 399000, loss = 1.2862
I0519 19:45:22.919952  4008 solver.cpp:247]     Train net output #0: loss = 1.2862 (* 1 = 1.2862 loss)
I0519 19:45:22.919970  4008 sgd_solver.cpp:106] Iteration 399000, lr = 1e-05
I0519 19:45:23.087306  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.2788	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:45:23.161967  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:45:23.164036  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:45:23.164067  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:45:23.173822  4008 solver.cpp:260]     Total regularization terms: 0.940122 loss+regular. : 2.22632
I0519 19:46:39.165712  4008 solver.cpp:231] Iteration 399200, loss = 1.10521
I0519 19:46:39.165976  4008 solver.cpp:247]     Train net output #0: loss = 1.10521 (* 1 = 1.10521 loss)
I0519 19:46:39.165995  4008 sgd_solver.cpp:106] Iteration 399200, lr = 1e-05
I0519 19:46:39.326416  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:46:39.401964  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:46:39.403975  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:46:39.404016  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:46:39.427281  4008 solver.cpp:260]     Total regularization terms: 0.940118 loss+regular. : 2.04533
I0519 19:47:57.857694  4008 solver.cpp:231] Iteration 399400, loss = 1.28508
I0519 19:47:57.858006  4008 solver.cpp:247]     Train net output #0: loss = 1.28508 (* 1 = 1.28508 loss)
I0519 19:47:57.858026  4008 sgd_solver.cpp:106] Iteration 399400, lr = 1e-05
I0519 19:47:58.018685  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:47:58.094349  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:47:58.097071  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:47:58.097110  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:47:58.106943  4008 solver.cpp:260]     Total regularization terms: 0.940114 loss+regular. : 2.2252
I0519 19:49:15.706466  4008 solver.cpp:231] Iteration 399600, loss = 1.12922
I0519 19:49:15.706778  4008 solver.cpp:247]     Train net output #0: loss = 1.12922 (* 1 = 1.12922 loss)
I0519 19:49:15.706797  4008 sgd_solver.cpp:106] Iteration 399600, lr = 1e-05
I0519 19:49:15.866711  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:49:15.941496  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:49:15.943532  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:49:15.943590  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:49:15.957643  4008 solver.cpp:260]     Total regularization terms: 0.940111 loss+regular. : 2.06933
I0519 19:50:29.847167  4008 solver.cpp:231] Iteration 399800, loss = 1.35847
I0519 19:50:29.847556  4008 solver.cpp:247]     Train net output #0: loss = 1.35847 (* 1 = 1.35847 loss)
I0519 19:50:29.847574  4008 sgd_solver.cpp:106] Iteration 399800, lr = 1e-05
I0519 19:50:30.007905  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:50:30.083565  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:50:30.085567  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:50:30.085595  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:50:30.100641  4008 solver.cpp:260]     Total regularization terms: 0.940108 loss+regular. : 2.29858
I0519 19:50:39.091464  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:51:46.301506  4008 solver.cpp:348] Iteration 400000, Testing net (#0)
I0519 19:52:45.659417  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:52:59.029036  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56812
I0519 19:52:59.029129  4008 solver.cpp:415]     Test net output #1: loss = 1.85381 (* 1 = 1.85381 loss)
I0519 19:52:59.118417  4008 solver.cpp:231] Iteration 400000, loss = 1.15585
I0519 19:52:59.118494  4008 solver.cpp:247]     Train net output #0: loss = 1.15585 (* 1 = 1.15585 loss)
I0519 19:52:59.118510  4008 sgd_solver.cpp:106] Iteration 400000, lr = 1e-05
I0519 19:52:59.283964  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:52:59.358618  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:52:59.360232  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:52:59.360255  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:52:59.370020  4008 solver.cpp:260]     Total regularization terms: 0.940104 loss+regular. : 2.09596
I0519 19:54:19.973000  4008 solver.cpp:231] Iteration 400200, loss = 1.21241
I0519 19:54:19.973309  4008 solver.cpp:247]     Train net output #0: loss = 1.21241 (* 1 = 1.21241 loss)
I0519 19:54:19.973330  4008 sgd_solver.cpp:106] Iteration 400200, lr = 1e-05
I0519 19:54:20.133047  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:54:20.208134  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:54:20.210909  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:54:20.210947  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:54:20.220669  4008 solver.cpp:260]     Total regularization terms: 0.940101 loss+regular. : 2.15251
I0519 19:55:48.440382  4008 solver.cpp:231] Iteration 400400, loss = 1.26217
I0519 19:55:48.440626  4008 solver.cpp:247]     Train net output #0: loss = 1.26217 (* 1 = 1.26217 loss)
I0519 19:55:48.440793  4008 sgd_solver.cpp:106] Iteration 400400, lr = 1e-05
I0519 19:55:48.599509  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:55:48.674800  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:55:48.676223  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:55:48.676239  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:55:48.690986  4008 solver.cpp:260]     Total regularization terms: 0.940097 loss+regular. : 2.20227
I0519 19:57:05.244721  4008 solver.cpp:231] Iteration 400600, loss = 1.29646
I0519 19:57:05.245084  4008 solver.cpp:247]     Train net output #0: loss = 1.29646 (* 1 = 1.29646 loss)
I0519 19:57:05.245117  4008 sgd_solver.cpp:106] Iteration 400600, lr = 1e-05
I0519 19:57:05.404454  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:57:05.483149  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:57:05.485268  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:57:05.485298  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:57:05.499466  4008 solver.cpp:260]     Total regularization terms: 0.940093 loss+regular. : 2.23655
I0519 19:58:34.694387  4008 solver.cpp:231] Iteration 400800, loss = 1.15761
I0519 19:58:34.694850  4008 solver.cpp:247]     Train net output #0: loss = 1.15761 (* 1 = 1.15761 loss)
I0519 19:58:34.694871  4008 sgd_solver.cpp:106] Iteration 400800, lr = 1e-05
I0519 19:58:34.854667  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4443	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 19:58:34.929183  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 19:58:34.930780  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 19:58:34.930809  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 19:58:34.940599  4008 solver.cpp:260]     Total regularization terms: 0.940088 loss+regular. : 2.0977
I0519 19:58:48.730190  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 19:59:54.946502  4008 solver.cpp:348] Iteration 401000, Testing net (#0)
I0519 20:00:58.175263  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:01:09.817414  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56792
I0519 20:01:09.817514  4008 solver.cpp:415]     Test net output #1: loss = 1.85422 (* 1 = 1.85422 loss)
I0519 20:01:09.905427  4008 solver.cpp:231] Iteration 401000, loss = 1.22407
I0519 20:01:09.905506  4008 solver.cpp:247]     Train net output #0: loss = 1.22407 (* 1 = 1.22407 loss)
I0519 20:01:09.905527  4008 sgd_solver.cpp:106] Iteration 401000, lr = 1e-05
I0519 20:01:10.063863  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4447	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:01:10.140722  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:01:10.142770  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:01:10.142802  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:01:10.152623  4008 solver.cpp:260]     Total regularization terms: 0.940084 loss+regular. : 2.16415
I0519 20:02:32.527622  4008 solver.cpp:231] Iteration 401200, loss = 1.37765
I0519 20:02:32.528604  4008 solver.cpp:247]     Train net output #0: loss = 1.37765 (* 1 = 1.37765 loss)
I0519 20:02:32.528623  4008 sgd_solver.cpp:106] Iteration 401200, lr = 1e-05
I0519 20:02:32.687260  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:02:32.762780  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:02:32.764721  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:02:32.764749  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:02:32.785079  4008 solver.cpp:260]     Total regularization terms: 0.940082 loss+regular. : 2.31773
I0519 20:03:56.511442  4008 solver.cpp:231] Iteration 401400, loss = 1.25775
I0519 20:03:56.511771  4008 solver.cpp:247]     Train net output #0: loss = 1.25775 (* 1 = 1.25775 loss)
I0519 20:03:56.511800  4008 sgd_solver.cpp:106] Iteration 401400, lr = 1e-05
I0519 20:03:56.672111  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.1349	5.98958	89.1754	0	85.279	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:03:56.746835  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:03:56.748589  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:03:56.748615  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:03:56.758440  4008 solver.cpp:260]     Total regularization terms: 0.940078 loss+regular. : 2.19783
I0519 20:05:13.089717  4008 solver.cpp:231] Iteration 401600, loss = 1.3772
I0519 20:05:13.090131  4008 solver.cpp:247]     Train net output #0: loss = 1.3772 (* 1 = 1.3772 loss)
I0519 20:05:13.090162  4008 sgd_solver.cpp:106] Iteration 401600, lr = 1e-05
I0519 20:05:13.249742  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.1349	5.98958	89.1754	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:05:13.325736  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:05:13.327899  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:05:13.327944  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:05:13.357154  4008 solver.cpp:260]     Total regularization terms: 0.940073 loss+regular. : 2.31727
I0519 20:06:32.770120  4008 solver.cpp:231] Iteration 401800, loss = 1.14524
I0519 20:06:32.770587  4008 solver.cpp:247]     Train net output #0: loss = 1.14524 (* 1 = 1.14524 loss)
I0519 20:06:32.770700  4008 sgd_solver.cpp:106] Iteration 401800, lr = 1e-05
I0519 20:06:32.930994  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.1349	5.98958	89.1755	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:06:33.007558  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:06:33.010278  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:06:33.010319  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:06:33.025321  4008 solver.cpp:260]     Total regularization terms: 0.94007 loss+regular. : 2.08531
I0519 20:06:48.660269  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:07:52.172823  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_402000.caffemodel
I0519 20:08:16.112471  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_402000.solverstate
I0519 20:08:16.607839  4008 solver.cpp:348] Iteration 402000, Testing net (#0)
I0519 20:09:16.803464  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:09:28.786967  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567479
I0519 20:09:28.787061  4008 solver.cpp:415]     Test net output #1: loss = 1.85366 (* 1 = 1.85366 loss)
I0519 20:09:28.877107  4008 solver.cpp:231] Iteration 402000, loss = 1.2471
I0519 20:09:28.877187  4008 solver.cpp:247]     Train net output #0: loss = 1.2471 (* 1 = 1.2471 loss)
I0519 20:09:28.877204  4008 sgd_solver.cpp:106] Iteration 402000, lr = 1e-05
I0519 20:09:29.053508  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.1349	5.98958	89.1755	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:09:29.055692  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:09:29.071496  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:09:29.071557  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:09:29.081444  4008 solver.cpp:260]     Total regularization terms: 0.940066 loss+regular. : 2.18717
I0519 20:10:49.870055  4008 solver.cpp:231] Iteration 402200, loss = 1.10059
I0519 20:10:49.870443  4008 solver.cpp:247]     Train net output #0: loss = 1.10059 (* 1 = 1.10059 loss)
I0519 20:10:49.870463  4008 sgd_solver.cpp:106] Iteration 402200, lr = 1e-05
I0519 20:10:50.031004  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.1755	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:10:50.106076  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:10:50.108763  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:10:50.108810  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:10:50.118554  4008 solver.cpp:260]     Total regularization terms: 0.940063 loss+regular. : 2.04066
I0519 20:12:19.718652  4008 solver.cpp:231] Iteration 402400, loss = 1.22032
I0519 20:12:19.721312  4008 solver.cpp:247]     Train net output #0: loss = 1.22032 (* 1 = 1.22032 loss)
I0519 20:12:19.721349  4008 sgd_solver.cpp:106] Iteration 402400, lr = 1e-05
I0519 20:12:19.880579  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.1757	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:12:19.956145  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:12:19.958432  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:12:19.958479  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:12:19.972144  4008 solver.cpp:260]     Total regularization terms: 0.94006 loss+regular. : 2.16038
I0519 20:13:52.232466  4008 solver.cpp:231] Iteration 402600, loss = 1.30694
I0519 20:13:52.232689  4008 solver.cpp:247]     Train net output #0: loss = 1.30694 (* 1 = 1.30694 loss)
I0519 20:13:52.232705  4008 sgd_solver.cpp:106] Iteration 402600, lr = 1e-05
I0519 20:13:52.394151  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.1757	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:13:52.469324  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:13:52.471793  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:13:52.471828  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:13:52.486866  4008 solver.cpp:260]     Total regularization terms: 0.940055 loss+regular. : 2.247
I0519 20:15:22.432615  4008 solver.cpp:231] Iteration 402800, loss = 1.1467
I0519 20:15:22.432983  4008 solver.cpp:247]     Train net output #0: loss = 1.1467 (* 1 = 1.1467 loss)
I0519 20:15:22.433010  4008 sgd_solver.cpp:106] Iteration 402800, lr = 1e-05
I0519 20:15:22.593204  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.1757	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:15:22.668381  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:15:22.670992  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:15:22.671049  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:15:22.681005  4008 solver.cpp:260]     Total regularization terms: 0.940051 loss+regular. : 2.08675
I0519 20:15:41.454273  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:16:51.453835  4008 solver.cpp:348] Iteration 403000, Testing net (#0)
I0519 20:17:59.923583  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:18:11.816256  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56764
I0519 20:18:11.816359  4008 solver.cpp:415]     Test net output #1: loss = 1.85354 (* 1 = 1.85354 loss)
I0519 20:18:11.907614  4008 solver.cpp:231] Iteration 403000, loss = 1.35219
I0519 20:18:11.907697  4008 solver.cpp:247]     Train net output #0: loss = 1.35219 (* 1 = 1.35219 loss)
I0519 20:18:11.907718  4008 sgd_solver.cpp:106] Iteration 403000, lr = 1e-05
I0519 20:18:12.073685  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.1757	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:18:12.149345  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:18:12.152693  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:18:12.152745  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:18:12.162672  4008 solver.cpp:260]     Total regularization terms: 0.940047 loss+regular. : 2.29223
I0519 20:19:46.225886  4008 solver.cpp:231] Iteration 403200, loss = 1.24903
I0519 20:19:46.226575  4008 solver.cpp:247]     Train net output #0: loss = 1.24903 (* 1 = 1.24903 loss)
I0519 20:19:46.226619  4008 sgd_solver.cpp:106] Iteration 403200, lr = 1e-05
I0519 20:19:46.385969  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.1757	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:19:46.462370  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:19:46.466236  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:19:46.466303  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:19:46.476590  4008 solver.cpp:260]     Total regularization terms: 0.940044 loss+regular. : 2.18907
I0519 20:21:16.376051  4008 solver.cpp:231] Iteration 403400, loss = 1.28242
I0519 20:21:16.376330  4008 solver.cpp:247]     Train net output #0: loss = 1.28242 (* 1 = 1.28242 loss)
I0519 20:21:16.376350  4008 sgd_solver.cpp:106] Iteration 403400, lr = 1e-05
I0519 20:21:16.538321  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.1757	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:21:16.614398  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:21:16.617051  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:21:16.617091  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:21:16.632196  4008 solver.cpp:260]     Total regularization terms: 0.940039 loss+regular. : 2.22246
I0519 20:22:33.020696  4008 solver.cpp:231] Iteration 403600, loss = 1.1146
I0519 20:22:33.020994  4008 solver.cpp:247]     Train net output #0: loss = 1.1146 (* 1 = 1.1146 loss)
I0519 20:22:33.021013  4008 sgd_solver.cpp:106] Iteration 403600, lr = 1e-05
I0519 20:22:33.180416  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.1757	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:22:33.255237  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:22:33.257390  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:22:33.257419  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:22:33.272311  4008 solver.cpp:260]     Total regularization terms: 0.940037 loss+regular. : 2.05463
I0519 20:23:50.943974  4008 solver.cpp:231] Iteration 403800, loss = 1.15953
I0519 20:23:50.944322  4008 solver.cpp:247]     Train net output #0: loss = 1.15953 (* 1 = 1.15953 loss)
I0519 20:23:50.944342  4008 sgd_solver.cpp:106] Iteration 403800, lr = 1e-05
I0519 20:23:51.104032  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.1758	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:23:51.178957  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:23:51.180851  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:23:51.180883  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:23:51.190780  4008 solver.cpp:260]     Total regularization terms: 0.940035 loss+regular. : 2.09956
I0519 20:24:11.756872  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:25:11.414724  4008 solver.cpp:348] Iteration 404000, Testing net (#0)
I0519 20:26:19.774782  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:26:30.380698  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567999
I0519 20:26:30.380785  4008 solver.cpp:415]     Test net output #1: loss = 1.85381 (* 1 = 1.85381 loss)
I0519 20:26:30.467645  4008 solver.cpp:231] Iteration 404000, loss = 1.11969
I0519 20:26:30.467721  4008 solver.cpp:247]     Train net output #0: loss = 1.11969 (* 1 = 1.11969 loss)
I0519 20:26:30.467736  4008 sgd_solver.cpp:106] Iteration 404000, lr = 1e-05
I0519 20:26:30.630229  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:26:30.705864  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:26:30.707937  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:26:30.707969  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:26:30.717732  4008 solver.cpp:260]     Total regularization terms: 0.940031 loss+regular. : 2.05972
I0519 20:27:53.575242  4008 solver.cpp:231] Iteration 404200, loss = 1.11573
I0519 20:27:53.575556  4008 solver.cpp:247]     Train net output #0: loss = 1.11573 (* 1 = 1.11573 loss)
I0519 20:27:53.575574  4008 sgd_solver.cpp:106] Iteration 404200, lr = 1e-05
I0519 20:27:53.735203  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:27:53.809835  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:27:53.811869  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:27:53.811895  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:27:53.821627  4008 solver.cpp:260]     Total regularization terms: 0.940027 loss+regular. : 2.05576
I0519 20:29:18.488445  4008 solver.cpp:231] Iteration 404400, loss = 1.29684
I0519 20:29:18.488661  4008 solver.cpp:247]     Train net output #0: loss = 1.29684 (* 1 = 1.29684 loss)
I0519 20:29:18.488678  4008 sgd_solver.cpp:106] Iteration 404400, lr = 1e-05
I0519 20:29:18.648763  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:29:18.727388  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:29:18.729748  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:29:18.729794  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:29:18.744947  4008 solver.cpp:260]     Total regularization terms: 0.940022 loss+regular. : 2.23686
I0519 20:30:40.746562  4008 solver.cpp:231] Iteration 404600, loss = 1.31884
I0519 20:30:40.746837  4008 solver.cpp:247]     Train net output #0: loss = 1.31884 (* 1 = 1.31884 loss)
I0519 20:30:40.746860  4008 sgd_solver.cpp:106] Iteration 404600, lr = 1e-05
I0519 20:30:40.907749  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:30:40.982348  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:30:40.984076  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:30:40.984105  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:30:40.993805  4008 solver.cpp:260]     Total regularization terms: 0.94002 loss+regular. : 2.25886
I0519 20:32:01.256570  4008 solver.cpp:231] Iteration 404800, loss = 1.40747
I0519 20:32:01.259181  4008 solver.cpp:247]     Train net output #0: loss = 1.40747 (* 1 = 1.40747 loss)
I0519 20:32:01.259205  4008 sgd_solver.cpp:106] Iteration 404800, lr = 1e-05
I0519 20:32:01.417865  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.445	0	91.135	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:32:01.493696  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:32:01.495679  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:32:01.495702  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:32:01.509366  4008 solver.cpp:260]     Total regularization terms: 0.940016 loss+regular. : 2.34749
I0519 20:32:22.347066  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:33:22.166090  4008 solver.cpp:348] Iteration 405000, Testing net (#0)
I0519 20:34:27.690867  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:34:39.018857  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56818
I0519 20:34:39.018942  4008 solver.cpp:415]     Test net output #1: loss = 1.85363 (* 1 = 1.85363 loss)
I0519 20:34:39.106714  4008 solver.cpp:231] Iteration 405000, loss = 1.08896
I0519 20:34:39.106796  4008 solver.cpp:247]     Train net output #0: loss = 1.08896 (* 1 = 1.08896 loss)
I0519 20:34:39.106817  4008 sgd_solver.cpp:106] Iteration 405000, lr = 1e-05
I0519 20:34:39.278861  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.135	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:34:39.354367  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:34:39.356326  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:34:39.356365  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:34:39.367218  4008 solver.cpp:260]     Total regularization terms: 0.940014 loss+regular. : 2.02897
I0519 20:36:07.693035  4008 solver.cpp:231] Iteration 405200, loss = 1.4887
I0519 20:36:07.693416  4008 solver.cpp:247]     Train net output #0: loss = 1.4887 (* 1 = 1.4887 loss)
I0519 20:36:07.693449  4008 sgd_solver.cpp:106] Iteration 405200, lr = 1e-05
I0519 20:36:07.853237  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1351	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:36:07.927883  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:36:07.929867  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:36:07.929898  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:36:07.939628  4008 solver.cpp:260]     Total regularization terms: 0.940012 loss+regular. : 2.42871
I0519 20:37:26.856516  4008 solver.cpp:231] Iteration 405400, loss = 1.23322
I0519 20:37:26.856840  4008 solver.cpp:247]     Train net output #0: loss = 1.23322 (* 1 = 1.23322 loss)
I0519 20:37:26.856859  4008 sgd_solver.cpp:106] Iteration 405400, lr = 1e-05
I0519 20:37:27.017493  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1351	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:37:27.098605  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:37:27.100066  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:37:27.100086  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:37:27.114920  4008 solver.cpp:260]     Total regularization terms: 0.940006 loss+regular. : 2.17322
I0519 20:38:48.463615  4008 solver.cpp:231] Iteration 405600, loss = 1.34624
I0519 20:38:48.463876  4008 solver.cpp:247]     Train net output #0: loss = 1.34624 (* 1 = 1.34624 loss)
I0519 20:38:48.463906  4008 sgd_solver.cpp:106] Iteration 405600, lr = 1e-05
I0519 20:38:48.623219  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1351	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:38:48.698377  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:38:48.700412  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:38:48.700446  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:38:48.710108  4008 solver.cpp:260]     Total regularization terms: 0.940003 loss+regular. : 2.28624
I0519 20:40:19.275331  4008 solver.cpp:231] Iteration 405800, loss = 1.17457
I0519 20:40:19.275710  4008 solver.cpp:247]     Train net output #0: loss = 1.17457 (* 1 = 1.17457 loss)
I0519 20:40:19.275756  4008 sgd_solver.cpp:106] Iteration 405800, lr = 1e-05
I0519 20:40:19.435583  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1352	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:40:19.511994  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:40:19.514837  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:40:19.514890  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:40:19.535480  4008 solver.cpp:260]     Total regularization terms: 0.939998 loss+regular. : 2.11456
I0519 20:40:44.880375  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:41:44.181337  4008 solver.cpp:348] Iteration 406000, Testing net (#0)
I0519 20:43:00.680080  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:43:12.038832  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56744
I0519 20:43:12.038959  4008 solver.cpp:415]     Test net output #1: loss = 1.85422 (* 1 = 1.85422 loss)
I0519 20:43:12.127653  4008 solver.cpp:231] Iteration 406000, loss = 1.29195
I0519 20:43:12.127768  4008 solver.cpp:247]     Train net output #0: loss = 1.29195 (* 1 = 1.29195 loss)
I0519 20:43:12.127794  4008 sgd_solver.cpp:106] Iteration 406000, lr = 1e-05
I0519 20:43:12.298956  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1352	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:43:12.374771  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:43:12.376759  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:43:12.376811  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:43:12.386894  4008 solver.cpp:260]     Total regularization terms: 0.939994 loss+regular. : 2.23195
I0519 20:44:50.809303  4008 solver.cpp:231] Iteration 406200, loss = 1.36484
I0519 20:44:50.809805  4008 solver.cpp:247]     Train net output #0: loss = 1.36484 (* 1 = 1.36484 loss)
I0519 20:44:50.809829  4008 sgd_solver.cpp:106] Iteration 406200, lr = 1e-05
I0519 20:44:50.967582  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1352	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:44:51.050165  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:44:51.052292  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:44:51.052327  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:44:51.067512  4008 solver.cpp:260]     Total regularization terms: 0.939991 loss+regular. : 2.30483
I0519 20:46:07.864478  4008 solver.cpp:231] Iteration 406400, loss = 1.19116
I0519 20:46:07.864753  4008 solver.cpp:247]     Train net output #0: loss = 1.19116 (* 1 = 1.19116 loss)
I0519 20:46:07.864770  4008 sgd_solver.cpp:106] Iteration 406400, lr = 1e-05
I0519 20:46:08.024592  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1352	5.98958	89.176	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:46:08.099835  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:46:08.101582  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:46:08.101601  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:46:08.116607  4008 solver.cpp:260]     Total regularization terms: 0.939987 loss+regular. : 2.13114
I0519 20:47:27.526804  4008 solver.cpp:231] Iteration 406600, loss = 1.29007
I0519 20:47:27.527161  4008 solver.cpp:247]     Train net output #0: loss = 1.29007 (* 1 = 1.29007 loss)
I0519 20:47:27.527181  4008 sgd_solver.cpp:106] Iteration 406600, lr = 1e-05
I0519 20:47:27.689271  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1352	5.98958	89.1761	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:47:27.768178  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:47:27.770064  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:47:27.770093  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:47:27.783695  4008 solver.cpp:260]     Total regularization terms: 0.939983 loss+regular. : 2.23005
I0519 20:48:55.494721  4008 solver.cpp:231] Iteration 406800, loss = 1.25927
I0519 20:48:55.497644  4008 solver.cpp:247]     Train net output #0: loss = 1.25927 (* 1 = 1.25927 loss)
I0519 20:48:55.497670  4008 sgd_solver.cpp:106] Iteration 406800, lr = 1e-05
I0519 20:48:55.657395  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1352	5.98958	89.1761	0	85.2792	0	85.6068	0	78.3495	0	30.3915	2.7	
I0519 20:48:55.733124  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:48:55.735229  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:48:55.735265  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:48:55.755312  4008 solver.cpp:260]     Total regularization terms: 0.93998 loss+regular. : 2.19925
I0519 20:49:23.403525  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:50:17.106796  4008 solver.cpp:348] Iteration 407000, Testing net (#0)
I0519 20:51:30.069051  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:51:39.617601  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56804
I0519 20:51:39.617689  4008 solver.cpp:415]     Test net output #1: loss = 1.85401 (* 1 = 1.85401 loss)
I0519 20:51:39.710132  4008 solver.cpp:231] Iteration 407000, loss = 1.00464
I0519 20:51:39.710211  4008 solver.cpp:247]     Train net output #0: loss = 1.00464 (* 1 = 1.00464 loss)
I0519 20:51:39.710230  4008 sgd_solver.cpp:106] Iteration 407000, lr = 1e-05
I0519 20:51:39.877714  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1352	5.98958	89.1761	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 20:51:39.953214  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:51:39.955569  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:51:39.955616  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:51:39.965545  4008 solver.cpp:260]     Total regularization terms: 0.939977 loss+regular. : 1.94462
I0519 20:53:07.094815  4008 solver.cpp:231] Iteration 407200, loss = 1.15023
I0519 20:53:07.095311  4008 solver.cpp:247]     Train net output #0: loss = 1.15023 (* 1 = 1.15023 loss)
I0519 20:53:07.095332  4008 sgd_solver.cpp:106] Iteration 407200, lr = 1e-05
I0519 20:53:07.254482  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1353	5.98958	89.1761	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 20:53:07.329452  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:53:07.331570  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:53:07.331617  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:53:07.341469  4008 solver.cpp:260]     Total regularization terms: 0.939973 loss+regular. : 2.0902
I0519 20:54:32.299664  4008 solver.cpp:231] Iteration 407400, loss = 1.06462
I0519 20:54:32.300196  4008 solver.cpp:247]     Train net output #0: loss = 1.06462 (* 1 = 1.06462 loss)
I0519 20:54:32.300256  4008 sgd_solver.cpp:106] Iteration 407400, lr = 1e-05
I0519 20:54:32.459873  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1353	5.98958	89.1763	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 20:54:32.536149  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:54:32.539849  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:54:32.539918  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:54:32.550247  4008 solver.cpp:260]     Total regularization terms: 0.93997 loss+regular. : 2.00459
I0519 20:56:05.284994  4008 solver.cpp:231] Iteration 407600, loss = 1.26884
I0519 20:56:05.285248  4008 solver.cpp:247]     Train net output #0: loss = 1.26884 (* 1 = 1.26884 loss)
I0519 20:56:05.285267  4008 sgd_solver.cpp:106] Iteration 407600, lr = 1e-05
I0519 20:56:05.443778  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1353	5.98958	89.1763	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 20:56:05.518682  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:56:05.520184  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:56:05.520201  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:56:05.534896  4008 solver.cpp:260]     Total regularization terms: 0.939966 loss+regular. : 2.20881
I0519 20:57:25.678503  4008 solver.cpp:231] Iteration 407800, loss = 1.19738
I0519 20:57:25.678694  4008 solver.cpp:247]     Train net output #0: loss = 1.19738 (* 1 = 1.19738 loss)
I0519 20:57:25.678714  4008 sgd_solver.cpp:106] Iteration 407800, lr = 1e-05
I0519 20:57:25.838161  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1763	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 20:57:25.913923  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 20:57:25.917006  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 20:57:25.917047  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 20:57:25.926826  4008 solver.cpp:260]     Total regularization terms: 0.939963 loss+regular. : 2.13735
I0519 20:57:54.728878  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 20:58:47.273620  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_408000.caffemodel
I0519 20:59:50.827210  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_408000.solverstate
I0519 20:59:51.390424  4008 solver.cpp:348] Iteration 408000, Testing net (#0)
I0519 21:01:01.211192  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:01:10.019103  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567939
I0519 21:01:10.019219  4008 solver.cpp:415]     Test net output #1: loss = 1.8528 (* 1 = 1.8528 loss)
I0519 21:01:10.107620  4008 solver.cpp:231] Iteration 408000, loss = 1.13361
I0519 21:01:10.107703  4008 solver.cpp:247]     Train net output #0: loss = 1.13361 (* 1 = 1.13361 loss)
I0519 21:01:10.107720  4008 sgd_solver.cpp:106] Iteration 408000, lr = 1e-05
I0519 21:01:10.274716  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1763	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:01:10.276265  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:01:10.278131  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:01:10.278159  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:01:10.287874  4008 solver.cpp:260]     Total regularization terms: 0.939958 loss+regular. : 2.07357
I0519 21:02:32.874989  4008 solver.cpp:231] Iteration 408200, loss = 1.39623
I0519 21:02:32.875458  4008 solver.cpp:247]     Train net output #0: loss = 1.39623 (* 1 = 1.39623 loss)
I0519 21:02:32.875480  4008 sgd_solver.cpp:106] Iteration 408200, lr = 1e-05
I0519 21:02:33.035202  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1763	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:02:33.109787  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:02:33.111431  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:02:33.111455  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:02:33.121165  4008 solver.cpp:260]     Total regularization terms: 0.939954 loss+regular. : 2.33619
I0519 21:03:57.093092  4008 solver.cpp:231] Iteration 408400, loss = 1.1255
I0519 21:03:57.093471  4008 solver.cpp:247]     Train net output #0: loss = 1.1255 (* 1 = 1.1255 loss)
I0519 21:03:57.093488  4008 sgd_solver.cpp:106] Iteration 408400, lr = 1e-05
I0519 21:03:57.254843  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1763	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:03:57.329767  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:03:57.331811  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:03:57.331851  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:03:57.341579  4008 solver.cpp:260]     Total regularization terms: 0.93995 loss+regular. : 2.06545
I0519 21:05:15.526590  4008 solver.cpp:231] Iteration 408600, loss = 1.10237
I0519 21:05:15.526918  4008 solver.cpp:247]     Train net output #0: loss = 1.10237 (* 1 = 1.10237 loss)
I0519 21:05:15.526937  4008 sgd_solver.cpp:106] Iteration 408600, lr = 1e-05
I0519 21:05:15.685742  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1763	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:05:15.760361  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:05:15.764184  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:05:15.764240  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:05:15.774024  4008 solver.cpp:260]     Total regularization terms: 0.939948 loss+regular. : 2.04232
I0519 21:06:40.098862  4008 solver.cpp:231] Iteration 408800, loss = 1.13405
I0519 21:06:40.099205  4008 solver.cpp:247]     Train net output #0: loss = 1.13405 (* 1 = 1.13405 loss)
I0519 21:06:40.099227  4008 sgd_solver.cpp:106] Iteration 408800, lr = 1e-05
I0519 21:06:40.259979  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1763	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:06:40.335258  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:06:40.337635  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:06:40.337684  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:06:40.347623  4008 solver.cpp:260]     Total regularization terms: 0.939945 loss+regular. : 2.074
I0519 21:07:23.183331  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:08:09.924031  4008 solver.cpp:348] Iteration 409000, Testing net (#0)
I0519 21:09:23.304561  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:09:31.661772  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56834
I0519 21:09:31.661890  4008 solver.cpp:415]     Test net output #1: loss = 1.8537 (* 1 = 1.8537 loss)
I0519 21:09:31.755954  4008 solver.cpp:231] Iteration 409000, loss = 1.22523
I0519 21:09:31.756031  4008 solver.cpp:247]     Train net output #0: loss = 1.22523 (* 1 = 1.22523 loss)
I0519 21:09:31.756072  4008 sgd_solver.cpp:106] Iteration 409000, lr = 1e-05
I0519 21:09:31.914783  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1763	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:09:31.990670  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:09:31.993749  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:09:31.993801  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:09:32.003590  4008 solver.cpp:260]     Total regularization terms: 0.939942 loss+regular. : 2.16517
I0519 21:11:01.049213  4008 solver.cpp:231] Iteration 409200, loss = 1.22952
I0519 21:11:01.049566  4008 solver.cpp:247]     Train net output #0: loss = 1.22952 (* 1 = 1.22952 loss)
I0519 21:11:01.049587  4008 sgd_solver.cpp:106] Iteration 409200, lr = 1e-05
I0519 21:11:01.212744  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1764	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:11:01.287502  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:11:01.289515  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:11:01.289547  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:11:01.299253  4008 solver.cpp:260]     Total regularization terms: 0.939939 loss+regular. : 2.16946
I0519 21:12:18.719455  4008 solver.cpp:231] Iteration 409400, loss = 1.26147
I0519 21:12:18.719759  4008 solver.cpp:247]     Train net output #0: loss = 1.26147 (* 1 = 1.26147 loss)
I0519 21:12:18.719777  4008 sgd_solver.cpp:106] Iteration 409400, lr = 1e-05
I0519 21:12:18.880000  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1764	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:12:18.955976  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:12:18.957725  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:12:18.957754  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:12:18.971391  4008 solver.cpp:260]     Total regularization terms: 0.939933 loss+regular. : 2.2014
I0519 21:13:39.613517  4008 solver.cpp:231] Iteration 409600, loss = 1.24645
I0519 21:13:39.613876  4008 solver.cpp:247]     Train net output #0: loss = 1.24645 (* 1 = 1.24645 loss)
I0519 21:13:39.613895  4008 sgd_solver.cpp:106] Iteration 409600, lr = 1e-05
I0519 21:13:39.774480  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1766	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:13:39.850179  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:13:39.852360  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:13:39.852397  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:13:39.865967  4008 solver.cpp:260]     Total regularization terms: 0.939931 loss+regular. : 2.18639
I0519 21:14:59.467932  4008 solver.cpp:231] Iteration 409800, loss = 1.12652
I0519 21:14:59.468679  4008 solver.cpp:247]     Train net output #0: loss = 1.12652 (* 1 = 1.12652 loss)
I0519 21:14:59.468700  4008 sgd_solver.cpp:106] Iteration 409800, lr = 1e-05
I0519 21:14:59.629034  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1766	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:14:59.703811  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:14:59.705951  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:14:59.705988  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:14:59.720909  4008 solver.cpp:260]     Total regularization terms: 0.939928 loss+regular. : 2.06645
I0519 21:15:37.697717  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:16:20.345732  4008 solver.cpp:348] Iteration 410000, Testing net (#0)
I0519 21:17:28.580684  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:17:36.580811  4008 solver.cpp:415]     Test net output #0: accuracy = 0.568119
I0519 21:17:36.580909  4008 solver.cpp:415]     Test net output #1: loss = 1.8542 (* 1 = 1.8542 loss)
I0519 21:17:36.669749  4008 solver.cpp:231] Iteration 410000, loss = 1.46096
I0519 21:17:36.669821  4008 solver.cpp:247]     Train net output #0: loss = 1.46096 (* 1 = 1.46096 loss)
I0519 21:17:36.669838  4008 sgd_solver.cpp:106] Iteration 410000, lr = 1e-05
I0519 21:17:36.836230  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1354	5.98958	89.1766	0	85.2792	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:17:36.911458  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:17:36.913699  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:17:36.913739  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:17:36.923593  4008 solver.cpp:260]     Total regularization terms: 0.939925 loss+regular. : 2.40089
I0519 21:19:03.133121  4008 solver.cpp:231] Iteration 410200, loss = 1.27975
I0519 21:19:03.133936  4008 solver.cpp:247]     Train net output #0: loss = 1.27975 (* 1 = 1.27975 loss)
I0519 21:19:03.133958  4008 sgd_solver.cpp:106] Iteration 410200, lr = 1e-05
I0519 21:19:03.294201  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1355	5.98958	89.1766	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:19:03.370314  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:19:03.372520  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:19:03.372553  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:19:03.393285  4008 solver.cpp:260]     Total regularization terms: 0.939922 loss+regular. : 2.21967
I0519 21:20:21.213960  4008 solver.cpp:231] Iteration 410400, loss = 1.24367
I0519 21:20:21.215060  4008 solver.cpp:247]     Train net output #0: loss = 1.24367 (* 1 = 1.24367 loss)
I0519 21:20:21.215081  4008 sgd_solver.cpp:106] Iteration 410400, lr = 1e-05
I0519 21:20:21.374415  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1355	5.98958	89.1766	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:20:21.450265  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:20:21.452216  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:20:21.452249  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:20:21.472576  4008 solver.cpp:260]     Total regularization terms: 0.939919 loss+regular. : 2.18359
I0519 21:21:48.148370  4008 solver.cpp:231] Iteration 410600, loss = 1.16722
I0519 21:21:48.148663  4008 solver.cpp:247]     Train net output #0: loss = 1.16722 (* 1 = 1.16722 loss)
I0519 21:21:48.148684  4008 sgd_solver.cpp:106] Iteration 410600, lr = 1e-05
I0519 21:21:48.308985  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1355	5.98958	89.1766	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:21:48.385123  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:21:48.387173  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:21:48.387202  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:21:48.417079  4008 solver.cpp:260]     Total regularization terms: 0.939914 loss+regular. : 2.10713
I0519 21:23:04.848289  4008 solver.cpp:231] Iteration 410800, loss = 1.41032
I0519 21:23:04.848698  4008 solver.cpp:247]     Train net output #0: loss = 1.41032 (* 1 = 1.41032 loss)
I0519 21:23:04.848726  4008 sgd_solver.cpp:106] Iteration 410800, lr = 1e-05
I0519 21:23:05.007287  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1357	5.98958	89.1766	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:23:05.083606  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:23:05.085376  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:23:05.085399  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:23:05.099012  4008 solver.cpp:260]     Total regularization terms: 0.93991 loss+regular. : 2.35023
I0519 21:23:42.271440  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:24:20.157913  4008 solver.cpp:348] Iteration 411000, Testing net (#0)
I0519 21:25:33.454907  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:25:40.845517  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56768
I0519 21:25:40.845623  4008 solver.cpp:415]     Test net output #1: loss = 1.85435 (* 1 = 1.85435 loss)
I0519 21:25:40.939411  4008 solver.cpp:231] Iteration 411000, loss = 1.32346
I0519 21:25:40.939486  4008 solver.cpp:247]     Train net output #0: loss = 1.32346 (* 1 = 1.32346 loss)
I0519 21:25:40.939505  4008 sgd_solver.cpp:106] Iteration 411000, lr = 1e-05
I0519 21:25:41.093391  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1358	5.98958	89.1766	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:25:41.168790  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:25:41.170889  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:25:41.170929  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:25:41.180693  4008 solver.cpp:260]     Total regularization terms: 0.939906 loss+regular. : 2.26336
I0519 21:27:06.855721  4008 solver.cpp:231] Iteration 411200, loss = 1.18815
I0519 21:27:06.856835  4008 solver.cpp:247]     Train net output #0: loss = 1.18815 (* 1 = 1.18815 loss)
I0519 21:27:06.856859  4008 sgd_solver.cpp:106] Iteration 411200, lr = 1e-05
I0519 21:27:07.016372  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1358	5.98958	89.1766	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:27:07.091816  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:27:07.094414  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:27:07.094451  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:27:07.104202  4008 solver.cpp:260]     Total regularization terms: 0.939902 loss+regular. : 2.12806
I0519 21:28:24.554697  4008 solver.cpp:231] Iteration 411400, loss = 1.16769
I0519 21:28:24.555021  4008 solver.cpp:247]     Train net output #0: loss = 1.16769 (* 1 = 1.16769 loss)
I0519 21:28:24.555040  4008 sgd_solver.cpp:106] Iteration 411400, lr = 1e-05
I0519 21:28:24.717592  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4453	0	91.1358	5.98958	89.1766	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:28:24.793202  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:28:24.795265  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:28:24.795300  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:28:24.810160  4008 solver.cpp:260]     Total regularization terms: 0.939899 loss+regular. : 2.10759
I0519 21:29:40.555454  4008 solver.cpp:231] Iteration 411600, loss = 1.35245
I0519 21:29:40.557648  4008 solver.cpp:247]     Train net output #0: loss = 1.35245 (* 1 = 1.35245 loss)
I0519 21:29:40.557677  4008 sgd_solver.cpp:106] Iteration 411600, lr = 1e-05
I0519 21:29:40.716028  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4456	0	91.1358	5.98958	89.1767	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:29:40.791043  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:29:40.793086  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:29:40.793118  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:29:40.802840  4008 solver.cpp:260]     Total regularization terms: 0.939896 loss+regular. : 2.29235
I0519 21:30:58.782989  4008 solver.cpp:231] Iteration 411800, loss = 1.28284
I0519 21:30:58.784467  4008 solver.cpp:247]     Train net output #0: loss = 1.28284 (* 1 = 1.28284 loss)
I0519 21:30:58.784487  4008 sgd_solver.cpp:106] Iteration 411800, lr = 1e-05
I0519 21:30:58.942970  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.446	0	91.1358	5.98958	89.1767	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:30:59.018414  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:30:59.019948  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:30:59.019973  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:30:59.035038  4008 solver.cpp:260]     Total regularization terms: 0.939893 loss+regular. : 2.22273
I0519 21:31:44.925623  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:32:19.551947  4008 solver.cpp:348] Iteration 412000, Testing net (#0)
I0519 21:33:24.160163  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:33:31.242779  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56758
I0519 21:33:31.242866  4008 solver.cpp:415]     Test net output #1: loss = 1.8539 (* 1 = 1.8539 loss)
I0519 21:33:31.332295  4008 solver.cpp:231] Iteration 412000, loss = 1.44228
I0519 21:33:31.332393  4008 solver.cpp:247]     Train net output #0: loss = 1.44228 (* 1 = 1.44228 loss)
I0519 21:33:31.332429  4008 sgd_solver.cpp:106] Iteration 412000, lr = 1e-05
I0519 21:33:31.491340  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.446	0	91.1358	5.98958	89.1767	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:33:31.566007  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:33:31.568225  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:33:31.568284  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:33:31.578222  4008 solver.cpp:260]     Total regularization terms: 0.939888 loss+regular. : 2.38217
I0519 21:34:53.886567  4008 solver.cpp:231] Iteration 412200, loss = 1.4897
I0519 21:34:53.886921  4008 solver.cpp:247]     Train net output #0: loss = 1.4897 (* 1 = 1.4897 loss)
I0519 21:34:53.886940  4008 sgd_solver.cpp:106] Iteration 412200, lr = 1e-05
I0519 21:34:54.046799  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.446	0	91.1358	5.98958	89.1767	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:34:54.122478  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:34:54.124480  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:34:54.124511  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:34:54.138105  4008 solver.cpp:260]     Total regularization terms: 0.939884 loss+regular. : 2.42958
I0519 21:36:12.432932  4008 solver.cpp:231] Iteration 412400, loss = 1.19682
I0519 21:36:12.433188  4008 solver.cpp:247]     Train net output #0: loss = 1.19682 (* 1 = 1.19682 loss)
I0519 21:36:12.433208  4008 sgd_solver.cpp:106] Iteration 412400, lr = 1e-05
I0519 21:36:12.593428  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.446	0	91.1358	5.98958	89.1767	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:36:12.668629  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:36:12.671335  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:36:12.671393  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:36:12.681201  4008 solver.cpp:260]     Total regularization terms: 0.939881 loss+regular. : 2.1367
I0519 21:37:37.835887  4008 solver.cpp:231] Iteration 412600, loss = 1.29562
I0519 21:37:37.836948  4008 solver.cpp:247]     Train net output #0: loss = 1.29562 (* 1 = 1.29562 loss)
I0519 21:37:37.836968  4008 sgd_solver.cpp:106] Iteration 412600, lr = 1e-05
I0519 21:37:37.996805  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4463	0	91.1358	5.98958	89.1767	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:37:38.071557  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:37:38.073606  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:37:38.073639  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:37:38.083379  4008 solver.cpp:260]     Total regularization terms: 0.939877 loss+regular. : 2.2355
I0519 21:38:55.242703  4008 solver.cpp:231] Iteration 412800, loss = 1.09584
I0519 21:38:55.243017  4008 solver.cpp:247]     Train net output #0: loss = 1.09584 (* 1 = 1.09584 loss)
I0519 21:38:55.243041  4008 sgd_solver.cpp:106] Iteration 412800, lr = 1e-05
I0519 21:38:55.404778  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4463	0	91.1358	5.98958	89.1767	0	85.2794	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:38:55.478925  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:38:55.480386  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:38:55.480404  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:38:55.502890  4008 solver.cpp:260]     Total regularization terms: 0.939873 loss+regular. : 2.03572
I0519 21:39:40.601213  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:40:12.165519  4008 solver.cpp:348] Iteration 413000, Testing net (#0)
I0519 21:41:16.635880  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:41:22.683528  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56818
I0519 21:41:22.683660  4008 solver.cpp:415]     Test net output #1: loss = 1.85298 (* 1 = 1.85298 loss)
I0519 21:41:22.772080  4008 solver.cpp:231] Iteration 413000, loss = 1.12242
I0519 21:41:22.772153  4008 solver.cpp:247]     Train net output #0: loss = 1.12242 (* 1 = 1.12242 loss)
I0519 21:41:22.772171  4008 sgd_solver.cpp:106] Iteration 413000, lr = 1e-05
I0519 21:41:22.937026  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4469	0	91.1358	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:41:23.012187  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:41:23.014168  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:41:23.014199  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:41:23.024050  4008 solver.cpp:260]     Total regularization terms: 0.939869 loss+regular. : 2.06229
I0519 21:42:46.699591  4008 solver.cpp:231] Iteration 413200, loss = 1.36652
I0519 21:42:46.701620  4008 solver.cpp:247]     Train net output #0: loss = 1.36652 (* 1 = 1.36652 loss)
I0519 21:42:46.701642  4008 sgd_solver.cpp:106] Iteration 413200, lr = 1e-05
I0519 21:42:46.861183  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4469	0	91.1358	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:42:46.936491  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:42:46.938380  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:42:46.938408  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:42:46.953184  4008 solver.cpp:260]     Total regularization terms: 0.939865 loss+regular. : 2.30639
I0519 21:44:08.254612  4008 solver.cpp:231] Iteration 413400, loss = 1.0181
I0519 21:44:08.255023  4008 solver.cpp:247]     Train net output #0: loss = 1.0181 (* 1 = 1.0181 loss)
I0519 21:44:08.255038  4008 sgd_solver.cpp:106] Iteration 413400, lr = 1e-05
I0519 21:44:08.413410  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4473	0	91.1358	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:44:08.488461  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:44:08.489975  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:44:08.489995  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:44:08.505043  4008 solver.cpp:260]     Total regularization terms: 0.939861 loss+regular. : 1.95797
I0519 21:45:42.219282  4008 solver.cpp:231] Iteration 413600, loss = 1.13754
I0519 21:45:42.219579  4008 solver.cpp:247]     Train net output #0: loss = 1.13754 (* 1 = 1.13754 loss)
I0519 21:45:42.219599  4008 sgd_solver.cpp:106] Iteration 413600, lr = 1e-05
I0519 21:45:42.378437  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4473	0	91.1358	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:45:42.453081  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:45:42.455152  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:45:42.455188  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:45:42.464941  4008 solver.cpp:260]     Total regularization terms: 0.939859 loss+regular. : 2.0774
I0519 21:47:04.967751  4008 solver.cpp:231] Iteration 413800, loss = 1.23566
I0519 21:47:04.968065  4008 solver.cpp:247]     Train net output #0: loss = 1.23566 (* 1 = 1.23566 loss)
I0519 21:47:04.968085  4008 sgd_solver.cpp:106] Iteration 413800, lr = 1e-05
I0519 21:47:05.127187  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4473	0	91.1358	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:47:05.201483  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:47:05.202996  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:47:05.203019  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:47:05.215131  4008 solver.cpp:260]     Total regularization terms: 0.939854 loss+regular. : 2.17551
I0519 21:47:51.301867  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:48:20.599159  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_414000.caffemodel
I0519 21:49:06.680809  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_414000.solverstate
I0519 21:49:07.385996  4008 solver.cpp:348] Iteration 414000, Testing net (#0)
I0519 21:50:11.058820  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:50:16.218868  4008 solver.cpp:415]     Test net output #0: accuracy = 0.568019
I0519 21:50:16.218998  4008 solver.cpp:415]     Test net output #1: loss = 1.85349 (* 1 = 1.85349 loss)
I0519 21:50:16.305822  4008 solver.cpp:231] Iteration 414000, loss = 1.36625
I0519 21:50:16.305894  4008 solver.cpp:247]     Train net output #0: loss = 1.36625 (* 1 = 1.36625 loss)
I0519 21:50:16.305912  4008 sgd_solver.cpp:106] Iteration 414000, lr = 1e-05
I0519 21:50:16.474557  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4473	0	91.1358	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:50:16.476565  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:50:16.478909  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:50:16.478958  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:50:16.488685  4008 solver.cpp:260]     Total regularization terms: 0.939851 loss+regular. : 2.3061
I0519 21:51:42.421437  4008 solver.cpp:231] Iteration 414200, loss = 1.1402
I0519 21:51:42.421793  4008 solver.cpp:247]     Train net output #0: loss = 1.1402 (* 1 = 1.1402 loss)
I0519 21:51:42.421815  4008 sgd_solver.cpp:106] Iteration 414200, lr = 1e-05
I0519 21:51:42.581082  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4476	0	91.1358	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:51:42.657019  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:51:42.659554  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:51:42.659590  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:51:42.674705  4008 solver.cpp:260]     Total regularization terms: 0.939848 loss+regular. : 2.08004
I0519 21:53:06.149801  4008 solver.cpp:231] Iteration 414400, loss = 1.18958
I0519 21:53:06.150079  4008 solver.cpp:247]     Train net output #0: loss = 1.18958 (* 1 = 1.18958 loss)
I0519 21:53:06.150099  4008 sgd_solver.cpp:106] Iteration 414400, lr = 1e-05
I0519 21:53:06.309424  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4476	0	91.1358	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:53:06.384744  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:53:06.387411  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:53:06.387444  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:53:06.397253  4008 solver.cpp:260]     Total regularization terms: 0.939843 loss+regular. : 2.12942
I0519 21:54:30.485065  4008 solver.cpp:231] Iteration 414600, loss = 1.27403
I0519 21:54:30.485409  4008 solver.cpp:247]     Train net output #0: loss = 1.27403 (* 1 = 1.27403 loss)
I0519 21:54:30.485440  4008 sgd_solver.cpp:106] Iteration 414600, lr = 1e-05
I0519 21:54:30.646898  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4476	0	91.1358	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:54:30.722755  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:54:30.724933  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:54:30.724956  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:54:30.745693  4008 solver.cpp:260]     Total regularization terms: 0.93984 loss+regular. : 2.21387
I0519 21:55:42.411690  4008 solver.cpp:231] Iteration 414800, loss = 1.23775
I0519 21:55:42.411906  4008 solver.cpp:247]     Train net output #0: loss = 1.23775 (* 1 = 1.23775 loss)
I0519 21:55:42.411921  4008 sgd_solver.cpp:106] Iteration 414800, lr = 1e-05
I0519 21:55:42.573122  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4476	0	91.1358	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:55:42.648521  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:55:42.650693  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:55:42.650719  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:55:42.665417  4008 solver.cpp:260]     Total regularization terms: 0.939836 loss+regular. : 2.17759
I0519 21:56:28.589546  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:56:54.003314  4008 solver.cpp:348] Iteration 415000, Testing net (#0)
I0519 21:57:58.777995  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 21:58:03.467057  4008 solver.cpp:415]     Test net output #0: accuracy = 0.56804
I0519 21:58:03.467133  4008 solver.cpp:415]     Test net output #1: loss = 1.85323 (* 1 = 1.85323 loss)
I0519 21:58:03.555634  4008 solver.cpp:231] Iteration 415000, loss = 1.28868
I0519 21:58:03.555721  4008 solver.cpp:247]     Train net output #0: loss = 1.28868 (* 1 = 1.28868 loss)
I0519 21:58:03.555735  4008 sgd_solver.cpp:106] Iteration 415000, lr = 1e-05
I0519 21:58:03.723882  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4476	0	91.1359	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:58:03.798359  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:58:03.800242  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:58:03.800262  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:58:03.812549  4008 solver.cpp:260]     Total regularization terms: 0.939833 loss+regular. : 2.22851
I0519 21:59:20.475215  4008 solver.cpp:231] Iteration 415200, loss = 1.37475
I0519 21:59:20.475577  4008 solver.cpp:247]     Train net output #0: loss = 1.37475 (* 1 = 1.37475 loss)
I0519 21:59:20.475597  4008 sgd_solver.cpp:106] Iteration 415200, lr = 1e-05
I0519 21:59:20.635864  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4476	0	91.1359	5.98958	89.1767	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 21:59:20.711629  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 21:59:20.713855  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 21:59:20.713882  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 21:59:20.728642  4008 solver.cpp:260]     Total regularization terms: 0.93983 loss+regular. : 2.31458
I0519 22:00:38.383514  4008 solver.cpp:231] Iteration 415400, loss = 1.25464
I0519 22:00:38.383641  4008 solver.cpp:247]     Train net output #0: loss = 1.25464 (* 1 = 1.25464 loss)
I0519 22:00:38.383659  4008 sgd_solver.cpp:106] Iteration 415400, lr = 1e-05
I0519 22:00:38.544666  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4476	0	91.1359	5.98958	89.1769	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 22:00:38.621328  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:00:38.624011  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:00:38.624068  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:00:38.638010  4008 solver.cpp:260]     Total regularization terms: 0.939825 loss+regular. : 2.19447
I0519 22:01:59.440896  4008 solver.cpp:231] Iteration 415600, loss = 1.37603
I0519 22:01:59.441180  4008 solver.cpp:247]     Train net output #0: loss = 1.37603 (* 1 = 1.37603 loss)
I0519 22:01:59.441203  4008 sgd_solver.cpp:106] Iteration 415600, lr = 1e-05
I0519 22:01:59.600864  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4479	0	91.1359	5.98958	89.1769	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 22:01:59.680265  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:01:59.682767  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:01:59.682806  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:01:59.698029  4008 solver.cpp:260]     Total regularization terms: 0.939821 loss+regular. : 2.31585
I0519 22:03:24.279345  4008 solver.cpp:231] Iteration 415800, loss = 1.13018
I0519 22:03:24.279695  4008 solver.cpp:247]     Train net output #0: loss = 1.13018 (* 1 = 1.13018 loss)
I0519 22:03:24.279714  4008 sgd_solver.cpp:106] Iteration 415800, lr = 1e-05
I0519 22:03:24.438895  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4479	0	91.1359	5.98958	89.1769	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 22:03:24.513777  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:03:24.515969  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:03:24.516007  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:03:24.525851  4008 solver.cpp:260]     Total regularization terms: 0.939816 loss+regular. : 2.06999
I0519 22:04:17.457702  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 22:04:43.226480  4008 solver.cpp:348] Iteration 416000, Testing net (#0)
I0519 22:05:54.534020  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 22:05:58.978863  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567919
I0519 22:05:58.978945  4008 solver.cpp:415]     Test net output #1: loss = 1.85377 (* 1 = 1.85377 loss)
I0519 22:05:59.066068  4008 solver.cpp:231] Iteration 416000, loss = 1.19315
I0519 22:05:59.066180  4008 solver.cpp:247]     Train net output #0: loss = 1.19315 (* 1 = 1.19315 loss)
I0519 22:05:59.066198  4008 sgd_solver.cpp:106] Iteration 416000, lr = 1e-05
I0519 22:05:59.232862  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4479	0	91.1359	5.98958	89.1769	0	85.2797	0	85.6069	0	78.3495	0	30.3915	2.7	
I0519 22:05:59.307426  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:05:59.309320  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:05:59.309345  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:05:59.319118  4008 solver.cpp:260]     Total regularization terms: 0.939812 loss+regular. : 2.13296
I0519 22:07:15.089428  4008 solver.cpp:231] Iteration 416200, loss = 1.41012
I0519 22:07:15.089792  4008 solver.cpp:247]     Train net output #0: loss = 1.41012 (* 1 = 1.41012 loss)
I0519 22:07:15.089823  4008 sgd_solver.cpp:106] Iteration 416200, lr = 1e-05
I0519 22:07:15.250247  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4479	0	91.1359	5.98958	89.177	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:07:15.326108  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:07:15.328011  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:07:15.328038  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:07:15.343040  4008 solver.cpp:260]     Total regularization terms: 0.939809 loss+regular. : 2.34992
I0519 22:08:27.093211  4008 solver.cpp:231] Iteration 416400, loss = 1.3688
I0519 22:08:27.093462  4008 solver.cpp:247]     Train net output #0: loss = 1.3688 (* 1 = 1.3688 loss)
I0519 22:08:27.093601  4008 sgd_solver.cpp:106] Iteration 416400, lr = 1e-05
I0519 22:08:27.256156  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4479	0	91.1359	5.98958	89.177	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:08:27.332278  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:08:27.334465  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:08:27.334498  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:08:27.355574  4008 solver.cpp:260]     Total regularization terms: 0.939806 loss+regular. : 2.30861
I0519 22:09:48.207340  4008 solver.cpp:231] Iteration 416600, loss = 1.24535
I0519 22:09:48.209625  4008 solver.cpp:247]     Train net output #0: loss = 1.24535 (* 1 = 1.24535 loss)
I0519 22:09:48.209650  4008 sgd_solver.cpp:106] Iteration 416600, lr = 1e-05
I0519 22:09:48.368228  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4479	0	91.1359	5.98958	89.177	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:09:48.444051  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:09:48.446523  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:09:48.446562  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:09:48.461922  4008 solver.cpp:260]     Total regularization terms: 0.939801 loss+regular. : 2.18516
I0519 22:11:08.393256  4008 solver.cpp:231] Iteration 416800, loss = 1.25508
I0519 22:11:08.393596  4008 solver.cpp:247]     Train net output #0: loss = 1.25508 (* 1 = 1.25508 loss)
I0519 22:11:08.393616  4008 sgd_solver.cpp:106] Iteration 416800, lr = 1e-05
I0519 22:11:08.553903  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4479	0	91.1359	5.98958	89.1772	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:11:08.628821  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:11:08.631247  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:11:08.631305  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:11:08.641309  4008 solver.cpp:260]     Total regularization terms: 0.939798 loss+regular. : 2.19488
I0519 22:12:04.752009  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 22:12:27.492460  4008 solver.cpp:348] Iteration 417000, Testing net (#0)
I0519 22:13:41.860033  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 22:13:45.548593  4008 solver.cpp:415]     Test net output #0: accuracy = 0.567299
I0519 22:13:45.548740  4008 solver.cpp:415]     Test net output #1: loss = 1.85384 (* 1 = 1.85384 loss)
I0519 22:13:45.636112  4008 solver.cpp:231] Iteration 417000, loss = 1.17656
I0519 22:13:45.636188  4008 solver.cpp:247]     Train net output #0: loss = 1.17656 (* 1 = 1.17656 loss)
I0519 22:13:45.636204  4008 sgd_solver.cpp:106] Iteration 417000, lr = 1e-05
I0519 22:13:45.796252  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4479	0	91.1359	5.98958	89.1772	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:13:45.871539  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:13:45.873978  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:13:45.874022  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:13:45.887442  4008 solver.cpp:260]     Total regularization terms: 0.939794 loss+regular. : 2.11635
I0519 22:14:59.782704  4008 solver.cpp:231] Iteration 417200, loss = 1.4124
I0519 22:14:59.782912  4008 solver.cpp:247]     Train net output #0: loss = 1.4124 (* 1 = 1.4124 loss)
I0519 22:14:59.782933  4008 sgd_solver.cpp:106] Iteration 417200, lr = 1e-05
I0519 22:14:59.944041  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4479	0	91.1359	5.98958	89.1772	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:15:00.019891  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:15:00.022011  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:15:00.022048  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:15:00.036977  4008 solver.cpp:260]     Total regularization terms: 0.93979 loss+regular. : 2.35219
I0519 22:16:18.460749  4008 solver.cpp:231] Iteration 417400, loss = 1.25792
I0519 22:16:18.461000  4008 solver.cpp:247]     Train net output #0: loss = 1.25792 (* 1 = 1.25792 loss)
I0519 22:16:18.461020  4008 sgd_solver.cpp:106] Iteration 417400, lr = 1e-05
I0519 22:16:18.621062  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4479	0	91.1359	5.98958	89.1772	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:16:18.695652  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:16:18.697412  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:16:18.697445  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:16:18.707244  4008 solver.cpp:260]     Total regularization terms: 0.939787 loss+regular. : 2.19771
I0519 22:17:34.395864  4008 solver.cpp:231] Iteration 417600, loss = 1.34156
I0519 22:17:34.397624  4008 solver.cpp:247]     Train net output #0: loss = 1.34156 (* 1 = 1.34156 loss)
I0519 22:17:34.397646  4008 sgd_solver.cpp:106] Iteration 417600, lr = 1e-05
I0519 22:17:34.557196  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4486	0	91.1359	5.98958	89.1772	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:17:34.636541  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:17:34.638422  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:17:34.638447  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:17:34.653508  4008 solver.cpp:260]     Total regularization terms: 0.939784 loss+regular. : 2.28134
I0519 22:18:50.523023  4008 solver.cpp:231] Iteration 417800, loss = 1.29202
I0519 22:18:50.523473  4008 solver.cpp:247]     Train net output #0: loss = 1.29202 (* 1 = 1.29202 loss)
I0519 22:18:50.523500  4008 sgd_solver.cpp:106] Iteration 417800, lr = 1e-05
I0519 22:18:50.683771  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4489	0	91.1359	5.98958	89.1772	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:18:50.758985  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:18:50.761582  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:18:50.761620  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:18:50.771385  4008 solver.cpp:260]     Total regularization terms: 0.93978 loss+regular. : 2.2318
I0519 22:19:46.037209  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 22:20:06.093045  4008 solver.cpp:348] Iteration 418000, Testing net (#0)
I0519 22:21:17.204769  4008 blocking_queue.cpp:50] Data layer prefetch queue empty
I0519 22:21:20.662847  4008 solver.cpp:415]     Test net output #0: accuracy = 0.568
I0519 22:21:20.662925  4008 solver.cpp:415]     Test net output #1: loss = 1.85268 (* 1 = 1.85268 loss)
I0519 22:21:20.750229  4008 solver.cpp:231] Iteration 418000, loss = 1.00168
I0519 22:21:20.750305  4008 solver.cpp:247]     Train net output #0: loss = 1.00168 (* 1 = 1.00168 loss)
I0519 22:21:20.750321  4008 sgd_solver.cpp:106] Iteration 418000, lr = 1e-05
I0519 22:21:20.918480  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4492	0	91.1359	5.98958	89.1773	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:21:20.993201  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:21:20.995234  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:21:20.995270  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:21:21.005142  4008 solver.cpp:260]     Total regularization terms: 0.939776 loss+regular. : 1.94146
I0519 22:22:50.351095  4008 solver.cpp:231] Iteration 418200, loss = 1.0836
I0519 22:22:50.355147  4008 solver.cpp:247]     Train net output #0: loss = 1.0836 (* 1 = 1.0836 loss)
I0519 22:22:50.355175  4008 sgd_solver.cpp:106] Iteration 418200, lr = 1e-05
I0519 22:22:50.511557  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4492	0	91.1359	5.98958	89.1773	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:22:50.587036  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:22:50.589207  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:22:50.589228  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:22:50.604106  4008 solver.cpp:260]     Total regularization terms: 0.939772 loss+regular. : 2.02338
I0519 22:24:15.330400  4008 solver.cpp:231] Iteration 418400, loss = 1.16506
I0519 22:24:15.330786  4008 solver.cpp:247]     Train net output #0: loss = 1.16506 (* 1 = 1.16506 loss)
I0519 22:24:15.330808  4008 sgd_solver.cpp:106] Iteration 418400, lr = 1e-05
I0519 22:24:15.490892  4008 sgd_solver.cpp:120]     Element Sparsity %: 
14.4944	3.125	82.4492	0	91.1359	5.98958	89.1775	0	85.2797	0	85.6069	0	78.3496	0	30.3915	2.7	
I0519 22:24:15.566586  4008 sgd_solver.cpp:130]      Column Sparsity %: 
0	0	0	0	2.17014	0	0	0	0	0	0	0	0	0	0	0	
I0519 22:24:15.569715  4008 sgd_solver.cpp:139]         Row Sparsity %: 
0	3.125	1.5625	0	0	5.98958	0	0	0	0	0	0	0	0	0	2.7	
I0519 22:24:15.569749  4008 sgd_solver.cpp:153]       Block Sparsity %: 
																
I0519 22:24:15.579663  4008 solver.cpp:260]     Total regularization terms: 0.939768 loss+regular. : 2.10483
I0519 22:24:22.097239  4008 solver.cpp:465] Snapshotting to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_418417.caffemodel
I0519 22:24:55.270890  4008 sgd_solver.cpp:657] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet/0.001_0.00005_0.0_0.0_0.0_Tue_May_17_08-20-09_PDT_2016/caffenet_train_iter_418417.solverstate
I0519 22:24:55.993000  4008 solver.cpp:312] Optimization stopped early.
I0519 22:24:55.993075  4008 caffe.cpp:223] Optimization Done.
